{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8153205,"sourceType":"datasetVersion","datasetId":4822379},{"sourceId":8175461,"sourceType":"datasetVersion","datasetId":4839281},{"sourceId":8175464,"sourceType":"datasetVersion","datasetId":4839283},{"sourceId":8194523,"sourceType":"datasetVersion","datasetId":4853536}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### UTILITIES\nfrom keras.datasets import cifar10\nfrom keras.utils import to_categorical\nimport pickle\nimport sys\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nimport numpy as np\n\ndef load_dataset(batch_size, num_classes, epochs):\n    (x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n\n    # Select a random subset of 4500 images for training\n    random_indices = np.random.choice(len(x_train_full), size=50000, replace=False)\n    x_train = x_train_full[random_indices]\n    y_train = y_train_full[random_indices]\n\n    # Normalize and one-hot encode the labels\n    x_train = x_train.astype('float32') / 255\n    x_test = x_test.astype('float32') / 255\n    y_train = to_categorical(y_train, num_classes)\n    y_test = to_categorical(y_test, num_classes)\n\n    # Randomly select 500 images for validation\n    random_indices = np.random.choice(len(x_test), size=10000, replace=False)\n    x_val = x_test[random_indices]\n    y_val = y_test[random_indices]\n\n    dataset = {\n        'batch_size': batch_size,\n        'num_classes': num_classes,\n        'epochs': epochs,\n        'x_train': x_train,\n        'y_train': y_train,\n        'x_val': x_val,\n        'y_val': y_val,\n        'x_test': x_test,  \n        'y_test': y_test\n    }\n\n    return dataset\n\n\ndef save_network(network):\n    #object_file = open(network.name + '.obj', 'wb')\n    #pickle.dump(network, object_file)\n    #tf.keras.models.save_model(network, network.name)\n\n    model_path = network.name + '_model.h5'\n    tf.keras.models.save_model(network.model, model_path)\n\n    # Save the rest of the network information\n    network_info = {\n        'name': network.name,\n        'block_list': network.block_list,\n        'fitness': network.fitness\n    }\n    network_info_path = network.name + '_info.pkl'\n    with open(network_info_path, 'wb') as info_file:\n        pickle.dump(network_info, info_file)\n\n\ndef load_network(name):\n    model_path = name + '_model.h5'\n    loaded_model = tf.keras.models.load_model(model_path)\n\n    # Load the network information\n    info_path = name + '_info.pkl'\n    with open(info_path, 'rb') as info_file:\n        network_info = pickle.load(info_file)\n\n    # Create a new Network instance\n    loaded_network = Network(0)  # Update with appropriate 'it' value\n\n    # Set the attributes of the loaded network\n    loaded_network.name = network_info['name']\n    loaded_network.block_list = network_info['block_list']\n    loaded_network.fitness = network_info['fitness']\n    loaded_network.model = loaded_model\n\n    return loaded_network\n\n\n\ndef order_indexes(self):\n    i = 0\n    for block in self.block_list:\n        block.index = i\n        i += 1\n\n\ndef plot_training(history):                                           # plot diagnostic learning curves\n    plt.figure(figsize=[8, 6])  # accuracy curves\n    plt.plot(history.history['accuracy'], 'r', linewidth=3.0)\n    plt.plot(history.history['val_accuracy'], 'b', linewidth=3.0)  # <-- Change 'val_acc' to 'val_accuracy'\n    plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n    plt.xlabel('Epochs ', fontsize=16)\n    plt.ylabel('Accuracy', fontsize=16)\n    plt.title('Accuracy Curves', fontsize=16)\n\n    filename = sys.argv[0].split('/')[-1]\n    plt.savefig(filename + '_acc_plot.png')\n    plt.close()\n\n\n\ndef plot_statistics(stats):\n    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# fitness curves\n    plt.plot([s[0] for s in stats], 'r', linewidth=3.0)\n    plt.plot([stats[0][0]] * len(stats), 'b', linewidth=3.0)\n    plt.legend(['BestFitness', 'InitialFitness'], fontsize=18)\n    plt.xlabel('Generations', fontsize=16)\n    plt.ylabel('FitnessValue', fontsize=16)\n    plt.title('Fitness Curve', fontsize=16)\n    filename = sys.argv[0].split('/')[-1]\n    plt.savefig(filename + '_fitness_plot.png')\n\n    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# parameters curves\n    plt.plot([s[1] for s in stats], 'r', linewidth=3.0)\n    plt.plot([stats[0][1]] * len(stats), 'b', linewidth=3.0)\n    plt.legend(['BestParamsNum', 'InitialParamsNum'], fontsize=18)\n    plt.xlabel('Generations', fontsize=16)\n    plt.ylabel('ParamsNum', fontsize=16)\n    plt.title('Parameters Curve', fontsize=16)\n    filename = sys.argv[0].split('/')[-1]\n    plt.savefig(filename + '_params_plot.png')\n    plt.close()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:08.865544Z","iopub.execute_input":"2024-03-21T14:35:08.866376Z","iopub.status.idle":"2024-03-21T14:35:21.633023Z","shell.execute_reply.started":"2024-03-21T14:35:08.866339Z","shell.execute_reply":"2024-03-21T14:35:21.631981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INOUT\nimport os\ndef compute_parent(dataset):\n    if os.path.isfile('parent_0.h5'):\n        daddy = load_network('parent_0')\n        model = tf.keras.models.load_model('parent_0.h5')\n        print(\"Loading parent_0\")\n        print(\"SUMMARY OF\", daddy.name)\n        print(model.summary())\n        print(\"FITNESS:\", daddy.fitness)\n        return daddy\n\n    daddy = Network(0)\n    \n    \n    #INI BLOCK\n    layerList1 = [\n        Convolutional(filters=32, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(0, 0, layerList1, layerList2))\n    \n    #MIDDLE BLOCK 1\n    layerList1 = [\n        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 1, layerList1, layerList2))\n\n     #MIDDLE BLOCK 2\n    layerList1 = [\n        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 2, layerList1, layerList2))\n\n    \n    #MIDDLE BLOCK 3\n    layerList1 = [\n        Convolutional(filters=256, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=256, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 3, layerList1, layerList2))\n    \n    \n    \n    #MIDDLE BLOCK 4\n    layerList1 = [\n        Convolutional(filters=512, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=512, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 4, layerList1, layerList2))\n    \n    \n    \n    #FULLY CONNECTED LAYER\n    layerList1 = [\n        FlattenLayer(),\n        FullyConnected(units=128, num_classes=dataset['num_classes'])\n    ]\n    layerList2 = []\n    daddy.block_list.append(Block(2, 5, layerList1, layerList2))\n    \n    \n\n    model = daddy.build_model()\n    print(\"Type of model_final:\", type(model))\n    daddy.train_and_evaluate(model, dataset)\n    return daddy","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:25.599146Z","iopub.execute_input":"2024-03-21T14:35:25.599778Z","iopub.status.idle":"2024-03-21T14:35:25.621856Z","shell.execute_reply.started":"2024-03-21T14:35:25.599747Z","shell.execute_reply":"2024-03-21T14:35:25.620860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NETWORK\nimport tensorflow as tf\nimport os\nimport pickle\nfrom keras.callbacks import Callback\nfrom keras.models import Sequential\nfrom random import randint, choice\nfrom copy import deepcopy\n\n\nclass Network:\n    __slots__ = ('name', 'block_list', 'fitness', 'model')\n\n    def __init__(self, it):\n        self.name = 'parent_' + str(it) if it == 0 else 'net_' + str(it)\n        self.block_list = []\n        self.fitness = None\n        self.model = None\n\n    \"\"\"def build_model(self):\n        model = Sequential()                                # create model\n        for block in self.block_list:\n            for layer in block.get_layers():                # build model\n                try:\n                    layer.build_layer(model)\n                except:\n                    print(\"\\nINDIVIDUAL ABORTED, CREATING A NEW ONE\\n\")\n                    return -1\n        return model\"\"\"\n    def build_model(self):\n        model = Sequential()              \n        print(\"The block is:\")\n        print(self.block_list)                 # create model\n        for block in self.block_list:\n            #print(\"Building block type:\", block.type)\n            #print(\"TOTAL :::\")\n            #print(block.get_layer_name())\n            for layer in block.get_layers():                # build model\n                #print(\"Adding layer:\", layer.name)\n                try:\n                    layer.build_layer(model)\n                    print(\"Layer added successfully.\")\n                except Exception as e:\n                    print(\"Error occurred while adding layer:\", e)\n                    print(\"Returning None.\")\n                    return -1\n        print(\"Model successfully built.\")\n        return model\n\n    def train_and_evaluate(self, model, dataset):\n        print(\"Training\", self.name)\n        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n        try:\n            history = model.fit(dataset['x_train'],\n                                dataset['y_train'],\n                                batch_size=dataset['batch_size'],\n                                epochs=dataset['epochs'],\n                                validation_data=(dataset['x_val'], dataset['y_val']),\n                                shuffle=True)\n        except Exception as e:\n            print(\"An error occurred during model training:\", e)\n            return -1\n            # You can choose to handle the error in a specific way here, like logging it or taking corrective actions.\n\n\n        # Extract metrics from the training history\n        training_loss = history.history['loss'][-1]\n        training_accuracy = history.history['accuracy'][-1]\n        validation_loss = history.history['val_loss'][-1]\n        validation_accuracy = history.history['val_accuracy'][-1]\n\n        # Additional metrics (you can customize this based on your needs)\n        classification_error_rate = 1.0 - validation_accuracy\n\n        self.model = model  # Save the model\n        self.fitness = validation_loss  # Use validation loss as fitness\n\n        # Print metrics\n        print(\"SUMMARY OF\", self.name)\n        print(\"Training Loss:\", training_loss)\n        print(\"Training Accuracy:\", training_accuracy)\n        print(\"Validation Loss:\", validation_loss)\n        print(\"Validation Accuracy:\", validation_accuracy)\n        print(\"Classification Error Rate:\", classification_error_rate)\n\n        tf.keras.models.save_model(model, self.name + '.h5')         # save model\n        #model.save(self.name + '.h5')                       # save model\n        save_network(self)                                  # save topology, model and fitness\n\n    def asexual_reproduction(self, it, dataset):\n\n        # if the individual already exists, just load it\n        if os.path.isfile('net_' + str(it) + '.h5'):\n            print(\"\\n-------------------------------------\")\n            print(\"Loading individual net_\" + str(it))\n            print(\"--------------------------------------\\n\")\n            individual = load_network('net_' + str(it))\n            model = tf.keras.models.load_model(individual.name + '.h5')\n            print(\"SUMMARY OF\", individual.name)\n            print(model.summary())\n            print(\"FITNESS: \", individual.fitness)\n            return individual\n\n        # otherwise, create the individual by mutating the parent\n        individual = Network(it)\n\n        print(\"\\n-------------------------------------\")\n        print(\"\\nCreating individual\", individual.name)\n        print(\"--------------------------------------\\n\")\n\n        individual.block_list = deepcopy(self.block_list)           # copy the layer list from parent\n\n        print(\"----->Strong Mutation\")\n        individual.block_mutation(dataset)                          # mutate a block\n        individual.layer_mutation(dataset)                          # mutate a layer\n        individual.parameters_mutation()                            # mutate some parameters\n\n        model = individual.build_model()\n        \n        if model == -1:\n            return self.asexual_reproduction(it, dataset)\n        \n        if(individual.train_and_evaluate(model, dataset)==-1):\n            return self.asexual_reproduction(it, dataset)\n        else:\n            return individual\n            \n\n    def block_mutation(self, dataset):\n        try:\n            print(\"Block Mutation\")\n\n            print([(block.index, block.type) for block in self.block_list])\n\n            # block list containing all the blocks with type = 1\n            bl = [block.index for block in self.block_list if block.type == 1]\n\n            if len(bl) == 0:\n                print(\"Creating a new block with two Convolutional layers and a Pooling layer\")\n                self.block_list[1].index = 2\n                layerList1 = [\n                    Convolutional(filters=pow(2, randint(5, 8)),\n                                  filter_size=(3, 3),\n                                  stride_size=(1, 1),\n                                  padding='same',\n                                  input_shape=dataset['x_train'].shape[1:]),\n                    Convolutional(filters=pow(2, randint(5, 8)),\n                                  filter_size=(3, 3),\n                                  stride_size=(1, 1),\n                                  padding='same',\n                                  input_shape=dataset['x_train'].shape[1:])\n                ]\n                layerList2 = [\n                    Pooling(pool_size=(2, 2),\n                            stride_size=(2, 2),\n                            padding='same')\n                ]\n                b = Block(1, 1, layerList1, layerList2)\n                self.block_list.insert(1, b)\n                return\n\n            block_idx = randint(1, max(bl))         # pick a random block among all the blocks with type = 1\n            block_type_idx = randint(0, 1)          # 1 -> Conv2D; 0 -> Pooling or Dropout\n            mutation_type = randint(0, 1)           # 1 -> remove; 0 -> add\n\n            # list of layers of the selected block\n            layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n            length = len(layerList)\n\n            if mutation_type:                                       # remove\n                if length == 1:\n                    del self.block_list[block_idx]\n                elif block_type_idx:\n                    pos = randint(0, length - 1)\n                    print(\"Removing a Conv2D layer at\", pos)\n                    del layerList[pos]\n                else:\n                    pos = randint(0, length - 1)\n                    print(\"Removing a Pooling/Dropout layer at\", pos)\n                    del layerList[pos]\n            else:                                                   # add\n                if block_type_idx:\n                    print(\"Inserting a Convolutional layer\")\n                    layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                          filter_size=(3, 3),\n                                          stride_size=(1, 1),\n                                          padding='same',\n                                          input_shape=dataset['x_train'].shape[1:])\n                    layerList.insert(randint(0, length - 1), layer)\n                else:\n                    if randint(0, 1):                               # 1 -> Pooling; 0 -> Dropout\n                        print(\"Inserting a Pooling layer\")\n                        layer = Pooling(pool_size=(2, 2),\n                                        stride_size=(2, 2),\n                                        padding='same')\n                        layerList.insert(randint(0, length - 1), layer)\n                    else:\n                        print(\"Inserting a Dropout layer\")\n                        rate = choice([0.15, 0.25, 0.35, 0.50])\n                        layer = Dropout(rate=rate)\n                        layerList.insert(randint(0, length - 1), layer)\n        except Exception as e:\n            print(f\"An error occurred during block mutation: {e}\")\n            return None\n\n                    \n                    \n                    \n                    \n                    \n\n    \"\"\"def layer_mutation(self, dataset):\n        print(\"Layer Mutation\")\n\n        # pick a random block among all the blocks with type = 1\n        bl = [block.index for block in self.block_list if block.type == 1]\n\n        if len(bl) == 0:\n            return\n\n        block_idx = randint(1, max(bl))\n        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n\n        # list of layers of the selected block\n        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n\n        if len(layerList) == 0:\n            if block_type_idx:\n                layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                      filter_size=(3, 3),\n                                      stride_size=(1, 1),\n                                      padding='same',\n                                      input_shape=dataset['x_train'].shape[1:])\n                self.block_list[block_idx].layerList1.append(layer)\n                return\n            else:\n                layer = Pooling(pool_size=(2, 2),\n                                stride_size=(2, 2),\n                                padding='same')\n                self.block_list[block_idx].layerList2.append(layer)\n\n        idx = randint(0, len(layerList) - 1)\n        layer = layerList[idx]\n\n        if layer.name == 'Conv2D':\n            print(\"Splitting Conv2D layer at index\", idx)\n            layer.filters = int(layer.filters * 0.5)\n            layerList.insert(idx, deepcopy(layer))\n        elif layer.name == 'MaxPooling2D' or layer.name == 'AveragePooling2D':\n            print(\"Changing Pooling layer at index\", idx, \"with Conv2D layer\")\n            del layerList[idx]\n            conv_layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                       filter_size=(3, 3),\n                                       stride_size=(2, 2),\n                                       padding=layer.padding,\n                                       input_shape=dataset['x_train'].shape[1:])\n            layerList.insert(idx, conv_layer)\"\"\"\n    \n    def layer_mutation(self, dataset):\n        print(\"Layer Mutation\")\n\n        # Determine the maximum number of layers that can be added or removed\n        max_layers_to_add = 16 - sum(len(block.layerList1) + len(block.layerList2) for block in self.block_list)\n        max_layers_to_remove = sum(len(block.layerList1) + len(block.layerList2) - 1 for block in self.block_list)\n\n        if max_layers_to_add == 0 and max_layers_to_remove == 0:\n            return\n\n        # Pick a random block among all the blocks with type = 1\n        bl = [block.index for block in self.block_list if block.type == 1]\n\n        if len(bl) == 0:\n            return\n\n        block_idx = randint(1, max(bl))\n        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n\n        # List of layers of the selected block\n        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n\n        if len(layerList) == 0:\n            if block_type_idx:\n                layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                      filter_size=(3, 3),\n                                      stride_size=(1, 1),\n                                      padding='same',\n                                      input_shape=dataset['x_train'].shape[1:])\n                self.block_list[block_idx].layerList1.append(layer)\n            else:\n                layer = Pooling(pool_size=(2, 2),\n                                stride_size=(2, 2),\n                                padding='same')\n                self.block_list[block_idx].layerList2.append(layer)\n        else:\n            # Randomly choose whether to add or remove a layer\n            add_layer = bool(randint(0, 1))\n\n            if add_layer and max_layers_to_add > 0:\n                # Add a layer\n                layer = self.create_random_layer(dataset)\n                layerList.insert(randint(0, len(layerList)), layer)\n            elif not add_layer and max_layers_to_remove > 0:\n                # Remove a layer\n                idx = randint(0, len(layerList) - 1)\n                del layerList[idx]\n\n        # Ensure the total number of layers in the block doesn't exceed 16\n        if len(self.block_list[block_idx].layerList1) + len(self.block_list[block_idx].layerList2) > 16:\n            # Remove a random layer to maintain the total count of 16 layers\n            block_layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n            del block_layerList[randint(0, len(block_layerList) - 1)]\n\n    def create_random_layer(self, dataset):\n        # Create a random layer (Conv2D or Pooling)\n        if randint(0, 1):\n            # Conv2D layer\n            return Convolutional(filters=pow(2, randint(5, 8)),\n                                 filter_size=(3, 3),\n                                 stride_size=(1, 1),\n                                 padding='same',\n                                 input_shape=dataset['x_train'].shape[1:])\n        else:\n            # Pooling layer\n            return Pooling(pool_size=(2, 2),\n                           stride_size=(2, 2),\n                           padding='same')\n\n            \n            \n            \n            \n            \n            \n            \n            \n\n    def parameters_mutation(self):\n        print(\"Parameters Mutation\")\n        for block in self.block_list:\n            for layer in block.get_layers():\n                if randint(0, 1):\n                    layer.mutate_parameters()\n\n    def save_network_info(self, info_filename):\n        network_info = {\n            'name': self.name,\n            'block_list': self.block_list,\n            'fitness': self.fitness\n        }\n\n        with open(info_filename, 'wb') as info_file:\n            pickle.dump(network_info, info_file)\n\n    def load_network_info(self, info_filename):\n        with open(info_filename, 'rb') as info_file:\n            network_info = pickle.load(info_file)\n\n        self.name = network_info['name']\n        self.block_list = network_info['block_list']\n        self.fitness = network_info['fitness']\n\n    def save_model(self, model_filename):\n        self.model.save(model_filename)\n\n    def load_model(self, model_filename):\n        self.model = tf.keras.models.load_model(model_filename)\n\n    def save_network(self, network_info_filename, model_filename):\n        # Save non-model attributes\n        self.save_network_info(network_info_filename)\n\n        # Save the model separately\n        self.save_model(model_filename)\n\n    def load_network(self, network_info_filename, model_filename):\n        # Load non-model attributes\n        self.load_network_info(network_info_filename)\n\n        # Load the model separately\n        self.load_model(model_filename)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:27.022012Z","iopub.execute_input":"2024-03-21T14:35:27.022374Z","iopub.status.idle":"2024-03-21T14:35:27.078711Z","shell.execute_reply.started":"2024-03-21T14:35:27.022345Z","shell.execute_reply":"2024-03-21T14:35:27.077468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TOPOLOGY\n\nimport keras.layers\nfrom random import randint\n\n\nclass Block:\n\t__slots__ = ('type', 'index', 'layerList1', 'layerList2')\n\n\tdef __init__(self, type, index, layerList1, layerList2):\n\t\tself.type = type\t\t\t\t\t\t\t\t\t\t# 0 -> initial layer; 1 -> mid layers; 2 -> final layer\n\t\tself.index = index\t\t\t\t\t\t\t\t\t\t# block index among all the blocks\n\t\tself.layerList1 = layerList1\t\t\t\t\t\t\t# Convolutional layers\n\t\tself.layerList2 = layerList2\t\t\t\t\t\t\t# Pooling and Dropout layers\n\n\tdef get_layers(self):\n\t\treturn self.layerList1 + self.layerList2\n\n\tdef get_size(self):\n\t\treturn len(self.get_layers())\n\n\nclass Convolutional:\n\t# __slots__ = ('name', 'filters', 'padding', 'filter_size', 'stride_size', 'input_shape')\n\n\tdef __init__(self, filters, padding, filter_size, stride_size, input_shape):\n\t\tself.name = 'Conv2D'\n\t\tself.filters = filters\n\t\tself.padding = padding\n\t\tself.filter_size = filter_size\n\t\tself.stride_size = stride_size\n\t\tself.input_shape = input_shape\n\n\tdef build_layer(self, model):\n\t\ttry:\n\t\t\tmodel.add(keras.layers.Conv2D(filters=self.filters,\n\t\t\t\t\t\t\t\t\t\t\tkernel_size=self.filter_size,\n\t\t\t\t\t\t\t\t\t\t\tstrides=self.stride_size,\n\t\t\t\t\t\t\t\t\t\t\tpadding=self.padding,\n\t\t\t\t\t\t\t\t\t\t\tactivation='relu',\n\t\t\t\t\t\t\t\t\t\t\tkernel_initializer='he_uniform',\n\t\t\t\t\t\t\t\t\t\t\tinput_shape=self.input_shape))\n\t\texcept ValueError as e:\n\t\t\tprint(\"Error occurred while adding layer:\", e)\n\t\t\tprint(\"Skipping current architecture.\")\n\t\t\treturn  # Skip adding this layer\n\tdef mutate_parameters(self):\n\t\tmutation = randint(0, 2)  # Adjusted the number of mutations\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tif mutation == 0 and self.filters >= 64:  # Adjusted the filter reduction threshold\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters = int(self.filters / 2)\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 1 and self.filters <= 256:  # Adjusted the filter increase threshold\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters *= 2\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 2:\n\t\t\tif self.padding == 'valid':\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'same'\n\t\t\t\tprint(\"to \", self.padding)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'valid'\n\t\t\t\tprint(\"to \", self.padding)\n\n        \n\n        \n\n\n\t\"\"\"def mutate_parameters(self):\n\t\tmutation = randint(0, 4)\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tif mutation == 0 and self.filters >= 32:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters = int(self.filters / 2)\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 1 and self.filters >= 32:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters = int(self.filters / 2)\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 2 and self.filters <= 512:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters *= 2\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 3 and self.filters <= 512:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters *= 2\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 4:\n\t\t\tif self.padding == 'valid':\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'same'\n\t\t\t\tprint(\"to \", self.padding)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'valid'\n\t\t\t\tprint(\"to \", self.padding)\n\"\"\"\n    \n\n'''\nelif mutation is 4:\n\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n\tprint(\"to \", self.stride_size, \" and \", end=\"\")\n\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n\tprint(\"to \", self.stride_size)\n'''\n\n\nclass Pooling:\n\t__slots__ = ('name', 'pool_size', 'stride_size', 'padding')\n\n\tdef __init__(self, pool_size, stride_size, padding):\n\t\tself.name = 'MaxPooling2D'\n\t\tself.pool_size = pool_size\n\t\tself.stride_size = stride_size\n\t\tself.padding = padding\n\n\tdef build_layer(self, model):\n\t\tif self.name == 'MaxPooling2D':\n\t\t\tmodel.add(keras.layers.MaxPooling2D(self.pool_size, self.stride_size, self.padding))\n\t\telif self.name == 'AveragePooling2D':\n\t\t\tmodel.add(keras.layers.AveragePooling2D(self.pool_size, self.stride_size, self.padding))\n\n\tdef mutate_parameters(self):\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tmutation = randint(0, 1)\n\t\tif mutation == 0:\n\t\t\tif self.padding == 'valid':\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'same'\n\t\t\t\tprint(\"to \", self.padding)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'valid'\n\t\t\t\tprint(\"to \", self.padding)\n\t\telif mutation == 1:\n\t\t\tif self.name == 'MaxPooling2D':\n\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n\t\t\t\tself.name = 'AveragePooling2D'\n\t\t\t\tprint(\"to \", self.name)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n\t\t\t\tself.name = 'MaxPooling2D'\n\t\t\t\tprint(\"to \", self.name)\n\n\n'''\nif mutation is 0:\n\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n\tprint(\"to \", self.stride_size)\n'''\n\n\nclass FullyConnected:\n\t__slots__ = ('name', 'units', 'num_classes')\n\n\tdef __init__(self, units, num_classes):\n\t\tself.name = \"FullyConnected\"\n\t\tself.units = units\n\t\tself.num_classes = num_classes\n\n\tdef build_layer(self, model):\n\t\tmodel.add(keras.layers.Flatten())\n\t\tmodel.add(keras.layers.Dense(self.units, activation='relu', kernel_initializer='he_uniform'))\n\t\tmodel.add(keras.layers.Dense(self.num_classes, activation='softmax'))\n\n\tdef mutate_parameters(self):\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tmutation = randint(0, 2)\n\t\tif mutation == 0:\n\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n\t\t\tself.units *= 2\n\t\t\tprint(\"to \", self.units)\n\t\telif mutation == 1:\n\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n\t\t\tself.units *= 2\n\t\t\tprint(\"to \", self.units)\n\t\telif mutation == 2:\n\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n\t\t\tself.units /= 2\n\t\t\tprint(\"to \", self.units)\n\n\n'''\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(self.num_classes, activation='softmax'))\n'''\n\n\nclass Dropout:\n\t__slots__ = ('name', 'rate')\n\n\tdef __init__(self, rate):\n\t\tself.name = \"Dropout\"\n\t\tself.rate = rate\n\n\tdef build_layer(self, model):\n\t\tmodel.add(keras.layers.Dropout(self.rate))\n\n\tdef mutate_parameters(self):\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tmutation = randint(0, 3)\n\t\tif mutation == 0 and self.rate <= 0.85:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate + 0.10\n\t\t\tprint(\"to \", self.rate)\n\t\telif mutation == 1 and self.rate <= 0.90:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate + 0.05\n\t\t\tprint(\"to \", self.rate)\n\t\telif mutation == 2 and self.rate >= 0.15:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate - 0.10\n\t\t\tprint(\"to \", self.rate)\n\t\telif mutation == 3 and self.rate >= 0.10:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate - 0.05\n\t\t\tprint(\"to \", self.rate)\n\nclass FlattenLayer:\n    def __init__(self):\n        self.name = 'Flatten'\n\n    def build_layer(self, model):\n        model.add(keras.layers.Flatten())\n\n    def mutate_parameters(self):\n        # The Flatten layer does not have any parameters to mutate\n        pass\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:28.087245Z","iopub.execute_input":"2024-03-21T14:35:28.087711Z","iopub.status.idle":"2024-03-21T14:35:28.125784Z","shell.execute_reply.started":"2024-03-21T14:35:28.087683Z","shell.execute_reply":"2024-03-21T14:35:28.124727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"# MAIN\n\nimport tensorflow as tf\ntf.compat.v1.enable_eager_execution()\nimport os\nfrom copy import deepcopy\nfrom random import sample\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)      # suppress messages from Tensorflow\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\n\ndef initialize_population(population_size, dataset):\n    print(\"----->Initializing Population\")\n    daddy = compute_parent(dataset)                                 # load parent from input\n    population = [daddy]\n    for it in range(1, population_size):\n        population.append(daddy.asexual_reproduction(it, dataset))\n\n    # sort population on ascending order based on fitness\n    return sorted(population, key=lambda cnn: cnn.fitness)\n\n\ndef selection(k, population, num_population):\n    if k == 0:                                              # elitism selection\n        print(\"----->Elitism selection\")\n        return population[0], population[1]\n    elif k == 1:                                            # tournament selection\n        print(\"----->Tournament selection\")\n        i = randint(0, num_population - 1)\n        j = i\n        while j < num_population - 1:\n            j += 1\n            if randint(1, 100) <= 50:\n                return population[i], population[j]\n        return population[i], population[0]\n    else:                                                   # proportionate selection\n        print(\"----->Proportionate selection\")\n        cum_sum = 0\n        for i in range(num_population):\n            cum_sum += population[i].fitness\n        perc_range = []\n        for i in range(num_population):\n            count = 100 - int(100 * population[i].fitness / cum_sum)\n            for j in range(count):\n                perc_range.append(i)\n        i, j = sample(range(1, len(perc_range)), 2)\n        while i == j:\n            i, j = sample(range(1, len(perc_range)), 2)\n        return population[perc_range[i]], population[perc_range[j]]\n\n\ndef crossover(parent1, parent2, it):\n    print(\"----->Crossover\")\n    child = Network(it)\n\n    first, second = None, None\n    if randint(0, 1):\n        first = parent1\n        second = parent2\n    else:\n        first = parent2\n        second = parent1\n\n    child.block_list = deepcopy(first.block_list[:randint(1, len(first.block_list) - 1)]) \\\n                       + deepcopy(second.block_list[randint(1, len(second.block_list) - 1):])\n\n    order_indexes(child)                            # order the indexes of the blocks\n\n    return child\n\n\ndef genetic_algorithm(num_population, num_generation, num_offspring, dataset, early_stopping_generations=3):\n    print(\"Genetic Algorithm\")\n\n    population = initialize_population(num_population, dataset)\n\n    print(\"\\n-------------------------------------\")\n    print(\"Initial Population:\")\n    for cnn in population:\n        print(cnn.name, ': ', cnn.fitness)\n    print(\"--------------------------------------\\n\")\n\n    # for printing statistics about fitness and the number of parameters of the best individual\n    stats = [(population[0].fitness, population[0].model.count_params())]\n\n    # Initialize a variable to keep track of consecutive generations with the same best fitness\n    consecutive_same_fitness = 0\n\n    for gen in range(1, num_generation + 1):\n        '''\n            k is the selection parameter:\n                k = 0 -> elitism selection\n                k = 1 -> tournament selection\n                k = 2 -> proportionate selection\n        '''\n        k = randint(0, 2)\n\n        print(\"\\n------------------------------------\")\n        print(\"Generation -----------------------------------------------------------------------------------\", gen)\n        print(\"-------------------------------------\")\n\n        for c in range(num_offspring):\n\n            print(\"\\nCreating Child\", c)\n\n            parent1, parent2 = selection(k, population, num_population)                 # selection\n            print(\"Selected\", parent1.name, \"and\", parent2.name, \"for reproduction\")\n\n            child = crossover(parent1, parent2, c + num_population)                     # crossover\n            print(\"Child has been created\")\n\n            print(\"----->Soft Mutation\")\n            child.layer_mutation(dataset)                                               # mutation\n            child.parameters_mutation()\n            print(\"Child has been mutated\")\n            model = child.build_model()  \n            # evaluation\n            if model==-1:\n                pass\n            else:\n                if(child.train_and_evaluate(model,dataset)==-1):\n                    model=-1  \n            #if(child.train_and_evaluate(model,dataset)==-1):\n                    #model=-1  # evaluation\n\n            while model == -1:\n                child = crossover(parent1, parent2, c + num_population)\n                child.block_mutation(dataset)\n                child.layer_mutation(dataset)\n                child.parameters_mutation()\n                model = child.build_model()\n                if(model==-1):\n                    pass\n                else:\n                    if(child.train_and_evaluate(model,dataset)==-1):\n                        model=-1\n\n            #child.train_and_evaluate(model, dataset)\n\n            if child.fitness < population[-1].fitness:                                  # evolve population\n                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"replaces parent \", end=\"\")\n                print(population[-1].name, \"with fitness\", population[-1].fitness)\n                name = population[-1].name\n\n                child.save_network(\"child_model_info.pkl\", \"child_model.h5\")\n                population[-1].load_network(\"child_model_info.pkl\", \"child_model.h5\")\n\n                population[-1].name = name\n                population = sorted(population, key=lambda net: net.fitness)\n            else:\n                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"is discarded\")\n        \n        if gen >= 3 and all(population[i].fitness == population[i + 1].fitness for i in range(-3, -1)):\n            consecutive_same_fitness += 1\n            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n        if consecutive_same_fitness >= 3:\n            print(\"Stopping the algorithm as the best fitness has remained the same for the last 3 generations.\")\n            break\n    else:\n        consecutive_same_fitness = 0\n        \n       #Check if the best fitness has remained the same for the last early_stopping_generations generations\n        if all(population[i].fitness == population[i + 1].fitness for i in range(-early_stopping_generations, -1)):\n            consecutive_same_fitness += 1\n            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n            if consecutive_same_fitness == early_stopping_generations:\n                print(f\"Stopping the algorithm as the best fitness has remained the same for {early_stopping_generations} generations.\")\n        else:\n            consecutive_same_fitness = 0\n        stats.append((population[0].fitness, population[0].model.count_params()))\n\n    print(\"\\n\\n-------------------------------------\")\n    print(\"Final Population\")\n    print(\"-------------------------------------\\n\")\n    for cnn in population:\n        print(cnn.name, ': ', cnn.fitness)\n\n    print(\"\\n-------------------------------------\")\n    print(\"Stats\")\n    for i in range(len(stats)):\n        print(\"Best individual at generation\", i + 1, \"has fitness\", stats[i][0], \"and parameters\", stats[i][1])\n    print(\"-------------------------------------\\n\")\n\n    # plot the fitness and the number of parameters of the best individual at each iteration\n    plot_statistics(stats)\n\n    return population[0]\n\n\n\ndef main():    \n        #with strategy.scope():\n        #from tensorflow.python.client import device_lib\n        #print(device_lib.list_local_devices())\n        #batch_size = 8\n        #batch_size = batch_size * strategy.num_replicas_in_sync\n        batch_size = 32                       # the number of training examples in one forward/backward pass\n        num_classes = 10                        # number of cifar-10 dataset classes\n        epochs =20              # number of forward and backward passes of all the training examples\n\n        '''\n            dataset contains the hyper parameters for loading data and the dataset:\n                dataset = {\n                    'batch_size': batch_size,\n                    'num_classes': num_classes,\n                    'epochs': epochs,\n                    'x_train': x_train,\n                    'x_test': x_test,\n                    'y_train': y_train,\n                    'y_test': y_test\n                }\n        '''\n        dataset = load_dataset(batch_size, num_classes, epochs)\n\n        num_population = 10\n        num_generation = 20\n        num_offspring = 4\n\n        # plot the best model obtained\n        optCNN = genetic_algorithm(num_population, num_generation, num_offspring, dataset)\n\n        # plot the training and validation loss and accuracy\n        num_epoch = 20\n        model = optCNN.build_model()\n        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n        history = model.fit(dataset['x_train'],\n                            dataset['y_train'],\n                            batch_size=dataset['batch_size'],\n                            epochs=num_epoch,\n                            validation_data=(dataset['x_test'], dataset['y_test']),\n                            shuffle=True)\n        optCNN.model = model                                        # model\n        optCNN.fitness = history.history['val_loss'][-1]            # fitness\n\n        print(\"\\n\\n-------------------------------------\")\n        print(\"The Final CNN has been evolved successfully in the individual\", optCNN.name)\n        print(\"-------------------------------------\\n\")\n        daddy = load_network('parent_0')\n        model = tf.keras.models.load_model('parent_0.h5')\n        print(\"\\n\\n-------------------------------------\")\n        print(\"Summary of initial CNN\")\n        print(model.summary())\n        print(\"Fitness of initial CNN:\", daddy.fitness)\n\n        print(\"\\n\\n-------------------------------------\")\n        print(\"Summary of evolved individual\")\n        print(optCNN.model.summary())\n        print(\"Fitness of the evolved individual:\", optCNN.fitness)\n        print(\"-------------------------------------\\n\")\n\n        plot_training(history)\n\n\nif __name__ == '__main__':\n    main()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:34:10.099189Z","iopub.execute_input":"2024-03-19T09:34:10.099594Z","iopub.status.idle":"2024-03-19T09:34:10.118001Z","shell.execute_reply.started":"2024-03-19T09:34:10.099563Z","shell.execute_reply":"2024-03-19T09:34:10.116664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"## To remove a folder\n# Clear output folder\nimport os\n\ndef remove_folder_contents(folder):\n    for the_file in os.listdir(folder):\n        file_path = os.path.join(folder, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                remove_folder_contents(file_path)\n                os.rmdir(file_path)\n        except Exception as e:\n            print(e)\n\nfolder_path = '/kaggle/working'\nremove_folder_contents(folder_path)\nos.rmdir(folder_path)\"\"\"\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:34:11.054431Z","iopub.execute_input":"2024-03-19T09:34:11.054798Z","iopub.status.idle":"2024-03-19T09:34:11.061017Z","shell.execute_reply.started":"2024-03-19T09:34:11.054771Z","shell.execute_reply":"2024-03-19T09:34:11.059840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport tensorflow as tf\nimport numpy as np\n\n# Set the paths to the datasets\nimage_dir = '/kaggle/input/fashion-mnist-images-new'\ncsv_file = '/kaggle/input/fashion-mnist-captions-new/Fashion_mnist_captions_new.csv'","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:12:34.714708Z","iopub.execute_input":"2024-04-22T13:12:34.715573Z","iopub.status.idle":"2024-04-22T13:12:34.720058Z","shell.execute_reply.started":"2024-04-22T13:12:34.715542Z","shell.execute_reply":"2024-04-22T13:12:34.719183Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Load the image and text data\nimage_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\ndata = pd.read_csv(csv_file)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:12:36.135418Z","iopub.execute_input":"2024-04-22T13:12:36.135765Z","iopub.status.idle":"2024-04-22T13:12:36.161484Z","shell.execute_reply.started":"2024-04-22T13:12:36.135735Z","shell.execute_reply":"2024-04-22T13:12:36.160685Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:12:37.994464Z","iopub.execute_input":"2024-04-22T13:12:37.994845Z","iopub.status.idle":"2024-04-22T13:12:38.006340Z","shell.execute_reply.started":"2024-04-22T13:12:37.994793Z","shell.execute_reply":"2024-04-22T13:12:38.005294Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"                                                caption  class  \\\n0          A plain white T-shirt with a round neckline.      0   \n1            A graphic-print T-shirt in shades of blue.      0   \n2           A striped T-shirt featuring vibrant colors.      0   \n3            A fitted black T-shirt with short sleeves.      0   \n4              A casual gray T-shirt with a V-neckline.      0   \n...                                                 ...    ...   \n4993  Ankle boot featuring a sleek and streamlined s...      9   \n4994  Ankle boot crafted with attention to detail an...      9   \n4995           Ankle boot designed for all-day comfort.      9   \n4996      Ankle boot with a sleek and modern aesthetic.      9   \n4997  Ankle boot featuring a minimalist yet stylish ...      9   \n\n               filename  \n0       class_0_image_0  \n1       class_0_image_1  \n2       class_0_image_2  \n3       class_0_image_3  \n4       class_0_image_4  \n...                 ...  \n4993  class_9_image_495  \n4994  class_9_image_496  \n4995  class_9_image_497  \n4996  class_9_image_498  \n4997  class_9_image_499  \n\n[4998 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>class</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A plain white T-shirt with a round neckline.</td>\n      <td>0</td>\n      <td>class_0_image_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A graphic-print T-shirt in shades of blue.</td>\n      <td>0</td>\n      <td>class_0_image_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A striped T-shirt featuring vibrant colors.</td>\n      <td>0</td>\n      <td>class_0_image_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A fitted black T-shirt with short sleeves.</td>\n      <td>0</td>\n      <td>class_0_image_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A casual gray T-shirt with a V-neckline.</td>\n      <td>0</td>\n      <td>class_0_image_4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4993</th>\n      <td>Ankle boot featuring a sleek and streamlined s...</td>\n      <td>9</td>\n      <td>class_9_image_495</td>\n    </tr>\n    <tr>\n      <th>4994</th>\n      <td>Ankle boot crafted with attention to detail an...</td>\n      <td>9</td>\n      <td>class_9_image_496</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>Ankle boot designed for all-day comfort.</td>\n      <td>9</td>\n      <td>class_9_image_497</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>Ankle boot with a sleek and modern aesthetic.</td>\n      <td>9</td>\n      <td>class_9_image_498</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>Ankle boot featuring a minimalist yet stylish ...</td>\n      <td>9</td>\n      <td>class_9_image_499</td>\n    </tr>\n  </tbody>\n</table>\n<p>4998 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the LSTM and CNN models\nlstm_model = tf.keras.models.load_model('/kaggle/input/fashion-mnist-lstm-model/fashion_mnist_lstm.h5')\ncnn_model = tf.keras.models.load_model('/kaggle/input/fashion-mnist-cnn-model/fashion_mnist_cnn.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:12:40.179193Z","iopub.execute_input":"2024-04-22T13:12:40.179920Z","iopub.status.idle":"2024-04-22T13:12:40.749028Z","shell.execute_reply.started":"2024-04-22T13:12:40.179890Z","shell.execute_reply":"2024-04-22T13:12:40.748168Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom keras.utils import to_categorical\nfrom PIL import Image\n\ndef load_image(image_path, image_shape):\n    image = Image.open(image_path)\n    image = image.resize((image_shape[1], image_shape[0]))  # Resize to match the required shape\n    image = np.array(image) / 255.0  # Normalize pixel values to [0, 1]\n    return image","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:12:45.654643Z","iopub.execute_input":"2024-04-22T13:12:45.655556Z","iopub.status.idle":"2024-04-22T13:12:45.661523Z","shell.execute_reply.started":"2024-04-22T13:12:45.655522Z","shell.execute_reply":"2024-04-22T13:12:45.660212Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Usage:\nimage_folder = '/kaggle/input/fashion-mnist-images-new'\ncaptions_df = pd.read_csv('/kaggle/input/fashion-mnist-captions-new/Fashion_mnist_captions_new.csv')  # Assuming captions are stored in a CSV file\nnum_classes = 10  # Number of classes/categories\nimage_shape = (28,28,1)  # Define the shape of the images","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:12:46.824507Z","iopub.execute_input":"2024-04-22T13:12:46.824890Z","iopub.status.idle":"2024-04-22T13:12:46.839117Z","shell.execute_reply.started":"2024-04-22T13:12:46.824862Z","shell.execute_reply":"2024-04-22T13:12:46.838311Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"# Step 1: Load image data from the folder\nimages = []\nimage_filenames = []\nfor filename in os.listdir(image_folder):\n    if filename.endswith(\".png\"):  # Assuming images are in png format\n            image_path = os.path.join(image_folder, filename)\n            image = load_image(image_path, image_shape)\n            images.append(image)\n            image_filenames.append(os.path.splitext(filename)[0])  # Remove file extension\n\n\nimages = []\nimage_filenames = []\n\n# Iterate through each class folder\nfor class_folder in range(10):  # Assuming class folders are named class_0 to class_9\n    class_folder_path = os.path.join(image_folder, f\"class_{class_folder}\")\n\n    # Iterate through each image file in the class folder\n    for filename in os.listdir(class_folder_path):\n        if filename.endswith(\".png\"):  # Assuming images are in png format\n            image_path = os.path.join(class_folder_path, filename)\n            image = load_image(image_path, image_shape)  # Assuming load_image function is defined elsewhere\n            images.append(image)\n            image_filenames.append(os.path.splitext(filename)[0])\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:12:48.134452Z","iopub.execute_input":"2024-04-22T13:12:48.135086Z","iopub.status.idle":"2024-04-22T13:12:48.142390Z","shell.execute_reply.started":"2024-04-22T13:12:48.135053Z","shell.execute_reply":"2024-04-22T13:12:48.141361Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'# Step 1: Load image data from the folder\\nimages = []\\nimage_filenames = []\\nfor filename in os.listdir(image_folder):\\n    if filename.endswith(\".png\"):  # Assuming images are in png format\\n            image_path = os.path.join(image_folder, filename)\\n            image = load_image(image_path, image_shape)\\n            images.append(image)\\n            image_filenames.append(os.path.splitext(filename)[0])  # Remove file extension\\n\\n\\nimages = []\\nimage_filenames = []\\n\\n# Iterate through each class folder\\nfor class_folder in range(10):  # Assuming class folders are named class_0 to class_9\\n    class_folder_path = os.path.join(image_folder, f\"class_{class_folder}\")\\n\\n    # Iterate through each image file in the class folder\\n    for filename in os.listdir(class_folder_path):\\n        if filename.endswith(\".png\"):  # Assuming images are in png format\\n            image_path = os.path.join(class_folder_path, filename)\\n            image = load_image(image_path, image_shape)  # Assuming load_image function is defined elsewhere\\n            images.append(image)\\n            image_filenames.append(os.path.splitext(filename)[0])'"},"metadata":{}}]},{"cell_type":"code","source":"import os\nfrom multiprocessing import Pool\nfrom functools import partial\n\ndef load_image_from_folder(class_folder_path, image_shape):\n    images = []\n    image_filenames = []\n\n    for filename in os.listdir(class_folder_path):\n        if filename.endswith(\".jpg\"):  \n            image_path = os.path.join(class_folder_path, filename)\n            image = load_image(image_path, image_shape)  \n            images.append(image)\n            image_filenames.append(os.path.splitext(filename)[0])\n\n    return images, image_filenames\n\n# Assuming the load_image function is defined elsewhere\ndef load_image(image_path, image_shape):\n    image = Image.open(image_path)\n    image = image.resize((image_shape[1], image_shape[0]))  # Resize to match the required shape\n    image = np.array(image) / 255.0  # Normalize pixel values to [0, 1]\n    return image\n\nimage_folder = image_dir\nimage_shape = image_shape  # Define your image shape\n\nnum_classes = 10  # Assuming there are 10 classes\npool = Pool()  # Create a multiprocessing Pool\n\n# Use partial to pass fixed arguments to the load_image_from_folder function\nload_partial = partial(load_image_from_folder, image_shape=image_shape)\n\n# Map the function to process each class folder in parallel\nresults = pool.map(load_partial, [os.path.join(image_folder, f\"class_{i}\") for i in range(num_classes)])\n\n# Combine the results\nimages = []\nimage_filenames = []\nfor class_images, class_filenames in results:\n    images.extend(class_images)\n    image_filenames.extend(class_filenames)\n\npool.close()\npool.join()\n\n# Now you have all images and their filenames loaded efficiently\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:14:14.464962Z","iopub.execute_input":"2024-04-22T13:14:14.465649Z","iopub.status.idle":"2024-04-22T13:14:18.460875Z","shell.execute_reply.started":"2024-04-22T13:14:14.465616Z","shell.execute_reply":"2024-04-22T13:14:18.459567Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"image_filenames[0:20]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:14:24.069516Z","iopub.execute_input":"2024-04-22T13:14:24.070226Z","iopub.status.idle":"2024-04-22T13:14:24.077256Z","shell.execute_reply.started":"2024-04-22T13:14:24.070186Z","shell.execute_reply":"2024-04-22T13:14:24.076317Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"['class_0_image_65',\n 'class_0_image_460',\n 'class_0_image_417',\n 'class_0_image_238',\n 'class_0_image_283',\n 'class_0_image_372',\n 'class_0_image_219',\n 'class_0_image_98',\n 'class_0_image_281',\n 'class_0_image_413',\n 'class_0_image_351',\n 'class_0_image_74',\n 'class_0_image_432',\n 'class_0_image_101',\n 'class_0_image_379',\n 'class_0_image_138',\n 'class_0_image_310',\n 'class_0_image_352',\n 'class_0_image_369',\n 'class_0_image_188']"},"metadata":{}}]},{"cell_type":"code","source":"image_filenames[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:14:26.154174Z","iopub.execute_input":"2024-04-22T13:14:26.154540Z","iopub.status.idle":"2024-04-22T13:14:26.160262Z","shell.execute_reply.started":"2024-04-22T13:14:26.154512Z","shell.execute_reply":"2024-04-22T13:14:26.159366Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"'class_0_image_65'"},"metadata":{}}]},{"cell_type":"code","source":"captions_df['caption']","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:14:27.304139Z","iopub.execute_input":"2024-04-22T13:14:27.305041Z","iopub.status.idle":"2024-04-22T13:14:27.313575Z","shell.execute_reply.started":"2024-04-22T13:14:27.305009Z","shell.execute_reply":"2024-04-22T13:14:27.312694Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"0            A plain white T-shirt with a round neckline.\n1              A graphic-print T-shirt in shades of blue.\n2             A striped T-shirt featuring vibrant colors.\n3              A fitted black T-shirt with short sleeves.\n4                A casual gray T-shirt with a V-neckline.\n                              ...                        \n4993    Ankle boot featuring a sleek and streamlined s...\n4994    Ankle boot crafted with attention to detail an...\n4995             Ankle boot designed for all-day comfort.\n4996        Ankle boot with a sleek and modern aesthetic.\n4997    Ankle boot featuring a minimalist yet stylish ...\nName: caption, Length: 4998, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"filename","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:14:28.324567Z","iopub.execute_input":"2024-04-22T13:14:28.325428Z","iopub.status.idle":"2024-04-22T13:14:28.330917Z","shell.execute_reply.started":"2024-04-22T13:14:28.325395Z","shell.execute_reply":"2024-04-22T13:14:28.329961Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"'class_0_image_4200'"},"metadata":{}}]},{"cell_type":"code","source":"\nclass_index = int(filename.split('_')[1])\nclass_index","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:14:29.374064Z","iopub.execute_input":"2024-04-22T13:14:29.374414Z","iopub.status.idle":"2024-04-22T13:14:29.380511Z","shell.execute_reply.started":"2024-04-22T13:14:29.374386Z","shell.execute_reply":"2024-04-22T13:14:29.379398Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"image_index = int(filename.split('_')[3].split('.')[0])\nimage_index","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:14:30.324786Z","iopub.execute_input":"2024-04-22T13:14:30.325162Z","iopub.status.idle":"2024-04-22T13:14:30.331344Z","shell.execute_reply.started":"2024-04-22T13:14:30.325134Z","shell.execute_reply":"2024-04-22T13:14:30.330434Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"4200"},"metadata":{}}]},{"cell_type":"code","source":"image_filenames[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:14:31.184282Z","iopub.execute_input":"2024-04-22T13:14:31.184640Z","iopub.status.idle":"2024-04-22T13:14:31.190738Z","shell.execute_reply.started":"2024-04-22T13:14:31.184611Z","shell.execute_reply":"2024-04-22T13:14:31.189679Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"'class_0_image_65'"},"metadata":{}}]},{"cell_type":"code","source":"len(image_filenames)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:14:31.914376Z","iopub.execute_input":"2024-04-22T13:14:31.915077Z","iopub.status.idle":"2024-04-22T13:14:31.921013Z","shell.execute_reply.started":"2024-04-22T13:14:31.915044Z","shell.execute_reply":"2024-04-22T13:14:31.920027Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"4998"},"metadata":{}}]},{"cell_type":"code","source":"image_captions = []\nimage_classes = []\nfor filename in image_filenames:\n    #print(filename)\n    class_index = int(filename.split('_')[1])\n    #print(class_index)\n    image_index = int(filename.split('_')[3].split('.')[0])\n    #print(image_index)\n    row = captions_df[captions_df['filename'] == filename]\n    #print(row)\n    try:\n        caption = row['caption'].values[0]\n    except:\n        print(filename)\n    \n    image_captions.append(caption)\n    image_classes.append(class_index)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:14:35.874327Z","iopub.execute_input":"2024-04-22T13:14:35.874686Z","iopub.status.idle":"2024-04-22T13:14:42.193319Z","shell.execute_reply.started":"2024-04-22T13:14:35.874657Z","shell.execute_reply":"2024-04-22T13:14:42.192282Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"captions_df['filename'][600:650]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:14:44.604328Z","iopub.execute_input":"2024-04-22T13:14:44.605024Z","iopub.status.idle":"2024-04-22T13:14:44.614743Z","shell.execute_reply.started":"2024-04-22T13:14:44.604993Z","shell.execute_reply":"2024-04-22T13:14:44.613793Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"600    class_1_image_101\n601    class_1_image_102\n602    class_1_image_103\n603    class_1_image_104\n604    class_1_image_105\n605    class_1_image_106\n606    class_1_image_107\n607    class_1_image_108\n608    class_1_image_109\n609    class_1_image_110\n610    class_1_image_111\n611    class_1_image_112\n612    class_1_image_113\n613    class_1_image_114\n614    class_1_image_115\n615    class_1_image_116\n616    class_1_image_117\n617    class_1_image_118\n618    class_1_image_119\n619    class_1_image_120\n620    class_1_image_121\n621    class_1_image_122\n622    class_1_image_123\n623    class_1_image_124\n624    class_1_image_125\n625    class_1_image_126\n626    class_1_image_127\n627    class_1_image_128\n628    class_1_image_129\n629    class_1_image_130\n630    class_1_image_131\n631    class_1_image_132\n632    class_1_image_133\n633    class_1_image_134\n634    class_1_image_135\n635    class_1_image_136\n636    class_1_image_137\n637    class_1_image_138\n638    class_1_image_139\n639    class_1_image_140\n640    class_1_image_141\n641    class_1_image_142\n642    class_1_image_143\n643    class_1_image_144\n644    class_1_image_145\n645    class_1_image_146\n646    class_1_image_147\n647    class_1_image_148\n648    class_1_image_149\n649    class_1_image_150\nName: filename, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"len(image_captions)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:14:55.094329Z","iopub.execute_input":"2024-04-22T13:14:55.094951Z","iopub.status.idle":"2024-04-22T13:14:55.100564Z","shell.execute_reply.started":"2024-04-22T13:14:55.094921Z","shell.execute_reply":"2024-04-22T13:14:55.099667Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"4998"},"metadata":{}}]},{"cell_type":"code","source":"image_filenames[34]\n#image_captions[34]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:15:00.753978Z","iopub.execute_input":"2024-04-22T13:15:00.754321Z","iopub.status.idle":"2024-04-22T13:15:00.760321Z","shell.execute_reply.started":"2024-04-22T13:15:00.754290Z","shell.execute_reply":"2024-04-22T13:15:00.759484Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"'class_0_image_274'"},"metadata":{}}]},{"cell_type":"code","source":"images[0].size","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:19:30.219295Z","iopub.execute_input":"2024-04-22T13:19:30.219655Z","iopub.status.idle":"2024-04-22T13:19:30.225659Z","shell.execute_reply.started":"2024-04-22T13:19:30.219625Z","shell.execute_reply":"2024-04-22T13:19:30.224696Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"784"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\n\n# Display the image\nplt.imshow(images[2])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:15:03.354064Z","iopub.execute_input":"2024-04-22T13:15:03.354667Z","iopub.status.idle":"2024-04-22T13:15:03.568875Z","shell.execute_reply.started":"2024-04-22T13:15:03.354637Z","shell.execute_reply":"2024-04-22T13:15:03.567989Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7816c1a83b80>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"image_captions[2]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:15:06.914188Z","iopub.execute_input":"2024-04-22T13:15:06.914547Z","iopub.status.idle":"2024-04-22T13:15:06.920701Z","shell.execute_reply.started":"2024-04-22T13:15:06.914517Z","shell.execute_reply":"2024-04-22T13:15:06.919636Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"'A T-shirt with a minimalist design.'"},"metadata":{}}]},{"cell_type":"code","source":"image_classes[2]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:15:08.234546Z","iopub.execute_input":"2024-04-22T13:15:08.234935Z","iopub.status.idle":"2024-04-22T13:15:08.240898Z","shell.execute_reply.started":"2024-04-22T13:15:08.234906Z","shell.execute_reply":"2024-04-22T13:15:08.239987Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Assuming you have lists images, image_captions, and image_classes containing your data\n\n# Create an array of indices from 0 to the length of your data\nindices = np.arange(len(images))\n\n# Randomly select 20,000 indices for testing without replacement\ntesting_indices = np.random.choice(indices, size=2000, replace=False)\n\n# Use the remaining indices for training\ntraining_indices = np.setdiff1d(indices, testing_indices)\n\n# Use the selected indices to create the testing and training datasets\ntesting_cnn_data_selected = [images[i] for i in testing_indices]\ntraining_cnn_data_selected = [images[i] for i in training_indices]\n\ntesting_lstm_data_selected = [image_captions[i] for i in testing_indices]\ntraining_lstm_data_selected = [image_captions[i] for i in training_indices]\n\n# Create labels (y) for testing and training datasets\ntesting_labels = [image_classes[i] for i in testing_indices]\ntraining_labels = [image_classes[i] for i in training_indices]\n\n# Now testing_data_selected contains 20,000 randomly selected items for testing\n# and training_data_selected contains the remaining items for training\n# testing_labels and training_labels contain corresponding labels for testing and training datasets\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:15:09.574472Z","iopub.execute_input":"2024-04-22T13:15:09.575027Z","iopub.status.idle":"2024-04-22T13:15:09.586877Z","shell.execute_reply.started":"2024-04-22T13:15:09.574996Z","shell.execute_reply":"2024-04-22T13:15:09.586045Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\n\n# Display the image\nplt.imshow(training_cnn_data_selected[1])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:15:20.384543Z","iopub.execute_input":"2024-04-22T13:15:20.384927Z","iopub.status.idle":"2024-04-22T13:15:20.568996Z","shell.execute_reply.started":"2024-04-22T13:15:20.384898Z","shell.execute_reply":"2024-04-22T13:15:20.568109Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7816742d4e50>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Sample testing_labels array\ntraining_labels = np.array(training_labels)\n\n# Define a mapping dictionary to map original labels to new labels (0 to 20)\nlabel_mapping = {}\nnew_label = 0\nfor label in sorted(np.unique(training_labels)):\n    label_mapping[label] = new_label\n    new_label += 1\n\n# Convert the testing_labels array using the mapping dictionary\nconverted_labels_training = np.array([label_mapping[label] for label in training_labels])\n\n# Print the converted labels\nprint(converted_labels_training)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:15:21.474177Z","iopub.execute_input":"2024-04-22T13:15:21.474503Z","iopub.status.idle":"2024-04-22T13:15:21.483076Z","shell.execute_reply.started":"2024-04-22T13:15:21.474480Z","shell.execute_reply":"2024-04-22T13:15:21.481994Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"[0 0 0 ... 9 9 9]\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Sample testing_labels array\ntesting_labels = np.array(testing_labels)\n\n# Define a mapping dictionary to map original labels to new labels (0 to 20)\nlabel_mapping = {}\nnew_label = 0\nfor label in sorted(np.unique(testing_labels)):\n    label_mapping[label] = new_label\n    new_label += 1\n\n# Convert the testing_labels array using the mapping dictionary\nconverted_labels_testing = np.array([label_mapping[label] for label in testing_labels])\n\n# Print the converted labels\nprint(converted_labels_testing)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:15:23.644307Z","iopub.execute_input":"2024-04-22T13:15:23.644666Z","iopub.status.idle":"2024-04-22T13:15:23.653271Z","shell.execute_reply.started":"2024-04-22T13:15:23.644636Z","shell.execute_reply":"2024-04-22T13:15:23.652189Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"[7 0 2 ... 6 6 5]\n","output_type":"stream"}]},{"cell_type":"code","source":"testing_labels[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:15:24.894470Z","iopub.execute_input":"2024-04-22T13:15:24.895109Z","iopub.status.idle":"2024-04-22T13:15:24.901067Z","shell.execute_reply.started":"2024-04-22T13:15:24.895078Z","shell.execute_reply":"2024-04-22T13:15:24.900200Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"array([7, 0, 2, 3, 8, 4, 3, 8, 8, 4])"},"metadata":{}}]},{"cell_type":"code","source":"converted_labels_testing[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:15:25.743974Z","iopub.execute_input":"2024-04-22T13:15:25.744290Z","iopub.status.idle":"2024-04-22T13:15:25.750414Z","shell.execute_reply.started":"2024-04-22T13:15:25.744266Z","shell.execute_reply":"2024-04-22T13:15:25.749481Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"array([7, 0, 2, 3, 8, 4, 3, 8, 8, 4])"},"metadata":{}}]},{"cell_type":"code","source":"testing_labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:15:26.814282Z","iopub.execute_input":"2024-04-22T13:15:26.814635Z","iopub.status.idle":"2024-04-22T13:15:26.820603Z","shell.execute_reply.started":"2024-04-22T13:15:26.814607Z","shell.execute_reply":"2024-04-22T13:15:26.819553Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"(2000,)"},"metadata":{}}]},{"cell_type":"code","source":"converted_labels_training[450:460]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:16:14.004381Z","iopub.execute_input":"2024-04-22T13:16:14.004747Z","iopub.status.idle":"2024-04-22T13:16:14.011093Z","shell.execute_reply.started":"2024-04-22T13:16:14.004716Z","shell.execute_reply":"2024-04-22T13:16:14.010214Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"},"metadata":{}}]},{"cell_type":"code","source":"training_lstm_data_selected[1]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:16:17.344353Z","iopub.execute_input":"2024-04-22T13:16:17.344971Z","iopub.status.idle":"2024-04-22T13:16:17.350490Z","shell.execute_reply.started":"2024-04-22T13:16:17.344942Z","shell.execute_reply":"2024-04-22T13:16:17.349636Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"'A T-shirt with a cropped hem.'"},"metadata":{}}]},{"cell_type":"markdown","source":"## CNN ","metadata":{}},{"cell_type":"code","source":"# Convert labels to one-hot encoding\ntraining_labels=np.array(training_labels)\ntesting_labels=np.array(testing_labels)\ntraining_labels = tf.keras.utils.to_categorical(converted_labels_training, 10)\ntesting_labels = tf.keras.utils.to_categorical(converted_labels_testing, 10)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:16:25.354181Z","iopub.execute_input":"2024-04-22T13:16:25.354533Z","iopub.status.idle":"2024-04-22T13:16:25.360210Z","shell.execute_reply.started":"2024-04-22T13:16:25.354506Z","shell.execute_reply":"2024-04-22T13:16:25.359361Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_cnn_data_selected=np.array(training_cnn_data_selected)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:16:28.104029Z","iopub.execute_input":"2024-04-22T13:16:28.104392Z","iopub.status.idle":"2024-04-22T13:16:28.118119Z","shell.execute_reply.started":"2024-04-22T13:16:28.104363Z","shell.execute_reply":"2024-04-22T13:16:28.117333Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"testing_cnn_data_selected=np.array(testing_cnn_data_selected)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:16:35.324407Z","iopub.execute_input":"2024-04-22T13:16:35.324738Z","iopub.status.idle":"2024-04-22T13:16:35.337391Z","shell.execute_reply.started":"2024-04-22T13:16:35.324714Z","shell.execute_reply":"2024-04-22T13:16:35.336579Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"training_cnn_data_selected.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:16:36.245830Z","iopub.execute_input":"2024-04-22T13:16:36.246614Z","iopub.status.idle":"2024-04-22T13:16:36.252956Z","shell.execute_reply.started":"2024-04-22T13:16:36.246574Z","shell.execute_reply":"2024-04-22T13:16:36.252045Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"(2998, 28, 28)"},"metadata":{}}]},{"cell_type":"code","source":"training_cnn_data_selected.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:16:37.474045Z","iopub.execute_input":"2024-04-22T13:16:37.474393Z","iopub.status.idle":"2024-04-22T13:16:37.480144Z","shell.execute_reply.started":"2024-04-22T13:16:37.474368Z","shell.execute_reply":"2024-04-22T13:16:37.479249Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"(2998, 28, 28)"},"metadata":{}}]},{"cell_type":"code","source":"tf.config.experimental_run_functions_eagerly(False)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:16:38.854076Z","iopub.execute_input":"2024-04-22T13:16:38.854948Z","iopub.status.idle":"2024-04-22T13:16:38.858984Z","shell.execute_reply.started":"2024-04-22T13:16:38.854915Z","shell.execute_reply":"2024-04-22T13:16:38.857984Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"training_labels","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:20:09.674401Z","iopub.execute_input":"2024-04-22T13:20:09.674764Z","iopub.status.idle":"2024-04-22T13:20:09.682027Z","shell.execute_reply.started":"2024-04-22T13:20:09.674735Z","shell.execute_reply":"2024-04-22T13:20:09.681017Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"array([[1., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 1.],\n       [0., 0., 0., ..., 0., 0., 1.],\n       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"cnn_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = cnn_model.fit(training_cnn_data_selected,\n                            training_labels,\n                            batch_size=32,\n                            epochs=30,\n                            validation_data=(testing_cnn_data_selected,testing_labels),\n                            shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:21:54.594053Z","iopub.execute_input":"2024-04-22T13:21:54.594659Z","iopub.status.idle":"2024-04-22T13:21:54.737366Z","shell.execute_reply.started":"2024-04-22T13:21:54.594630Z","shell.execute_reply":"2024-04-22T13:21:54.736110Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[69], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cnn_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_cnn_data_selected\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtraining_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtesting_cnn_data_selected\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtesting_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/tmp/__autograph_generated_filesapmvtcr.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_7\" is incompatible with the layer: expected shape=(None, 32, 32, 3), found shape=(None, 28, 28)\n"],"ename":"ValueError","evalue":"in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_7\" is incompatible with the layer: expected shape=(None, 32, 32, 3), found shape=(None, 28, 28)\n","output_type":"error"}]},{"cell_type":"code","source":"testing_labels = np.argmax(testing_labels, axis=1)\ntraining_labels = np.argmax(training_labels, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:32.801616Z","iopub.execute_input":"2024-04-17T10:47:32.802031Z","iopub.status.idle":"2024-04-17T10:47:32.808629Z","shell.execute_reply.started":"2024-04-17T10:47:32.801995Z","shell.execute_reply":"2024-04-17T10:47:32.807503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_predictions = cnn_model.predict(testing_cnn_data_selected)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:20:36.044720Z","iopub.execute_input":"2024-04-22T13:20:36.045626Z","iopub.status.idle":"2024-04-22T13:20:36.209280Z","shell.execute_reply.started":"2024-04-22T13:20:36.045592Z","shell.execute_reply":"2024-04-22T13:20:36.208007Z"},"trusted":true},"execution_count":67,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cnn_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtesting_cnn_data_selected\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/tmp/__autograph_generated_file2738bfzo.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_7\" is incompatible with the layer: expected shape=(None, 32, 32, 3), found shape=(None, 28, 28)\n"],"ename":"ValueError","evalue":"in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_7\" is incompatible with the layer: expected shape=(None, 32, 32, 3), found shape=(None, 28, 28)\n","output_type":"error"}]},{"cell_type":"code","source":"predicted_labels = np.argmax(cnn_predictions, axis=1)\n\n# Calculate accuracy\ncnn_accuracy = np.mean(predicted_labels == testing_labels)\nprint(\"CNN Model Accuracy:\", cnn_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:34.317616Z","iopub.execute_input":"2024-04-17T10:47:34.318023Z","iopub.status.idle":"2024-04-17T10:47:34.324332Z","shell.execute_reply.started":"2024-04-17T10:47:34.317993Z","shell.execute_reply":"2024-04-17T10:47:34.323252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({'caption': training_lstm_data_selected, 'class': training_labels})","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:35.131911Z","iopub.execute_input":"2024-04-17T10:47:35.132665Z","iopub.status.idle":"2024-04-17T10:47:35.138696Z","shell.execute_reply.started":"2024-04-17T10:47:35.132634Z","shell.execute_reply":"2024-04-17T10:47:35.137608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[20:30]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:36.167688Z","iopub.execute_input":"2024-04-17T10:47:36.168129Z","iopub.status.idle":"2024-04-17T10:47:36.178639Z","shell.execute_reply.started":"2024-04-17T10:47:36.168098Z","shell.execute_reply":"2024-04-17T10:47:36.177510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nfrom gensim.models import Word2Vec\n\ndef tokenize_text(text_data):\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(text_data)\n    return tokenizer\n\ndef train_word2vec(text_data, embedding_dim):\n    tokenized_text = [text.split() for text in text_data]\n    model = Word2Vec(sentences=tokenized_text, vector_size=embedding_dim, window=5, min_count=1, workers=4)\n    return model\n\ndef convert_text_to_vectors(text_data, word2vec_model, max_length):\n    vectors = []\n    for text in text_data:\n        words = text.split()\n        vec = []\n        for word in words:\n            if word in word2vec_model.wv:\n                vec.append(word2vec_model.wv[word])\n            else:\n                vec.append(np.zeros(word2vec_model.vector_size))  # Zero vector for out-of-vocabulary words\n        vectors.append(vec)\n    padded_vectors = pad_sequences(vectors, maxlen=max_length, padding='post')\n    return padded_vectors","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:36.578297Z","iopub.execute_input":"2024-04-17T10:47:36.578997Z","iopub.status.idle":"2024-04-17T10:47:36.588730Z","shell.execute_reply.started":"2024-04-17T10:47:36.578963Z","shell.execute_reply":"2024-04-17T10:47:36.587640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['caption'][147]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:37.364818Z","iopub.execute_input":"2024-04-17T10:47:37.365621Z","iopub.status.idle":"2024-04-17T10:47:37.371886Z","shell.execute_reply.started":"2024-04-17T10:47:37.365587Z","shell.execute_reply":"2024-04-17T10:47:37.370824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_words=10000\nembedding_dim=10\n\ntokenizer = tokenize_text(df['caption'].values)\nword2vec_model = train_word2vec(df['caption'].values, embedding_dim)\n\nmax_length = max(len(text.split()) for text in df['caption'].values)\n\n#x_vec = convert_text_to_vectors(df['caption'].values, word2vec_model, max_length)\n#class_mapping = {f'class_{i}': i for i in range(num_classes)}\n#df['class'] = df['class']\n\n#y = df['class'].values","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:38.186287Z","iopub.execute_input":"2024-04-17T10:47:38.186663Z","iopub.status.idle":"2024-04-17T10:47:39.028150Z","shell.execute_reply.started":"2024-04-17T10:47:38.186633Z","shell.execute_reply":"2024-04-17T10:47:39.027299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_train = convert_text_to_vectors(training_lstm_data_selected, word2vec_model, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:39.153041Z","iopub.execute_input":"2024-04-17T10:47:39.153461Z","iopub.status.idle":"2024-04-17T10:47:39.588377Z","shell.execute_reply.started":"2024-04-17T10:47:39.153417Z","shell.execute_reply":"2024-04-17T10:47:39.587480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_test = convert_text_to_vectors(testing_lstm_data_selected, word2vec_model, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:40.211020Z","iopub.execute_input":"2024-04-17T10:47:40.211381Z","iopub.status.idle":"2024-04-17T10:47:40.303184Z","shell.execute_reply.started":"2024-04-17T10:47:40.211352Z","shell.execute_reply":"2024-04-17T10:47:40.302097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_lstm_data_selected[2]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:40.443958Z","iopub.execute_input":"2024-04-17T10:47:40.444877Z","iopub.status.idle":"2024-04-17T10:47:40.450671Z","shell.execute_reply.started":"2024-04-17T10:47:40.444840Z","shell.execute_reply":"2024-04-17T10:47:40.449677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_lstm_data_selected[0:2]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:40.897809Z","iopub.execute_input":"2024-04-17T10:47:40.898920Z","iopub.status.idle":"2024-04-17T10:47:40.905499Z","shell.execute_reply.started":"2024-04-17T10:47:40.898878Z","shell.execute_reply":"2024-04-17T10:47:40.904523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_train=np.array(x_vec_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:41.001907Z","iopub.execute_input":"2024-04-17T10:47:41.002480Z","iopub.status.idle":"2024-04-17T10:47:41.010440Z","shell.execute_reply.started":"2024-04-17T10:47:41.002450Z","shell.execute_reply":"2024-04-17T10:47:41.009580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_test=np.array(x_vec_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:41.304150Z","iopub.execute_input":"2024-04-17T10:47:41.304536Z","iopub.status.idle":"2024-04-17T10:47:41.309510Z","shell.execute_reply.started":"2024-04-17T10:47:41.304506Z","shell.execute_reply":"2024-04-17T10:47:41.308466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_labels=np.array(training_labels)\ntesting_labels=np.array(testing_labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:41.585070Z","iopub.execute_input":"2024-04-17T10:47:41.585723Z","iopub.status.idle":"2024-04-17T10:47:41.590723Z","shell.execute_reply.started":"2024-04-17T10:47:41.585674Z","shell.execute_reply":"2024-04-17T10:47:41.589678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:42.451818Z","iopub.execute_input":"2024-04-17T10:47:42.452606Z","iopub.status.idle":"2024-04-17T10:47:42.465354Z","shell.execute_reply.started":"2024-04-17T10:47:42.452574Z","shell.execute_reply":"2024-04-17T10:47:42.464472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:43.083655Z","iopub.execute_input":"2024-04-17T10:47:43.084520Z","iopub.status.idle":"2024-04-17T10:47:43.091381Z","shell.execute_reply.started":"2024-04-17T10:47:43.084489Z","shell.execute_reply":"2024-04-17T10:47:43.089521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:44.129848Z","iopub.execute_input":"2024-04-17T10:47:44.130225Z","iopub.status.idle":"2024-04-17T10:47:44.136605Z","shell.execute_reply.started":"2024-04-17T10:47:44.130194Z","shell.execute_reply":"2024-04-17T10:47:44.135531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:45.329067Z","iopub.execute_input":"2024-04-17T10:47:45.330092Z","iopub.status.idle":"2024-04-17T10:47:45.337098Z","shell.execute_reply.started":"2024-04-17T10:47:45.330056Z","shell.execute_reply":"2024-04-17T10:47:45.336240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_labels = tf.keras.utils.to_categorical(converted_labels_training, 20)\ntesting_labels = tf.keras.utils.to_categorical(converted_labels_testing, 20)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:46.597567Z","iopub.execute_input":"2024-04-17T10:47:46.598509Z","iopub.status.idle":"2024-04-17T10:47:46.603655Z","shell.execute_reply.started":"2024-04-17T10:47:46.598472Z","shell.execute_reply":"2024-04-17T10:47:46.602738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"tf.config.experimental_run_functions_eagerly(True)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:42:13.306635Z","iopub.execute_input":"2024-04-17T10:42:13.307041Z","iopub.status.idle":"2024-04-17T10:42:13.312125Z","shell.execute_reply.started":"2024-04-17T10:42:13.307008Z","shell.execute_reply":"2024-04-17T10:42:13.311037Z"}}},{"cell_type":"code","source":"history = lstm_model.fit(x_vec_train,\n                                training_labels,\n                                batch_size=32,\n                                epochs=30,\n                                validation_data=(x_vec_test,testing_labels),\n                                shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:47.778261Z","iopub.execute_input":"2024-04-17T10:47:47.778908Z","iopub.status.idle":"2024-04-17T10:49:11.204677Z","shell.execute_reply.started":"2024-04-17T10:47:47.778873Z","shell.execute_reply":"2024-04-17T10:49:11.203660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:18.625338Z","iopub.execute_input":"2024-04-17T10:49:18.625933Z","iopub.status.idle":"2024-04-17T10:49:18.632128Z","shell.execute_reply.started":"2024-04-17T10:49:18.625900Z","shell.execute_reply":"2024-04-17T10:49:18.631213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_predictions = lstm_model.predict(x_vec_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:19.598520Z","iopub.execute_input":"2024-04-17T10:49:19.598925Z","iopub.status.idle":"2024-04-17T10:49:20.134549Z","shell.execute_reply.started":"2024-04-17T10:49:19.598895Z","shell.execute_reply":"2024-04-17T10:49:20.133524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_labels = np.argmax(lstm_predictions, axis=1)\n\n# Calculate accuracy\nlstm_accuracy = np.mean(predicted_labels == testing_labels)\nprint(\"LSTM Model Accuracy:\", lstm_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:51:04.191705Z","iopub.execute_input":"2024-04-17T10:51:04.192444Z","iopub.status.idle":"2024-04-17T10:51:04.198848Z","shell.execute_reply.started":"2024-04-17T10:51:04.192410Z","shell.execute_reply":"2024-04-17T10:51:04.197631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_labels","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:32.851581Z","iopub.execute_input":"2024-04-17T10:49:32.852498Z","iopub.status.idle":"2024-04-17T10:49:32.859151Z","shell.execute_reply.started":"2024-04-17T10:49:32.852460Z","shell.execute_reply":"2024-04-17T10:49:32.858068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_labels","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:37.168435Z","iopub.execute_input":"2024-04-17T10:49:37.169150Z","iopub.status.idle":"2024-04-17T10:49:37.176328Z","shell.execute_reply.started":"2024-04-17T10:49:37.169115Z","shell.execute_reply":"2024-04-17T10:49:37.175289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(cnn_predictions)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:41.558654Z","iopub.execute_input":"2024-04-17T10:49:41.559057Z","iopub.status.idle":"2024-04-17T10:49:41.565249Z","shell.execute_reply.started":"2024-04-17T10:49:41.559026Z","shell.execute_reply":"2024-04-17T10:49:41.564317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(lstm_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:42.194281Z","iopub.execute_input":"2024-04-17T10:49:42.194685Z","iopub.status.idle":"2024-04-17T10:49:42.201481Z","shell.execute_reply.started":"2024-04-17T10:49:42.194652Z","shell.execute_reply":"2024-04-17T10:49:42.200290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_predictions[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:43.885474Z","iopub.execute_input":"2024-04-17T10:49:43.886373Z","iopub.status.idle":"2024-04-17T10:49:43.893437Z","shell.execute_reply.started":"2024-04-17T10:49:43.886338Z","shell.execute_reply":"2024-04-17T10:49:43.892313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LSTM is working and acc is 86.6% (Cifar 10) - VitGpt2 model\n## LSTM is working and acc is 93.6% (Cifar 100 - 20 random classes) - Manually generated captions","metadata":{}},{"cell_type":"code","source":"cnn_predictions[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:48.061817Z","iopub.execute_input":"2024-04-17T10:49:48.062424Z","iopub.status.idle":"2024-04-17T10:49:48.069345Z","shell.execute_reply.started":"2024-04-17T10:49:48.062392Z","shell.execute_reply":"2024-04-17T10:49:48.068428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_predictions.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:49.295504Z","iopub.execute_input":"2024-04-17T10:49:49.296383Z","iopub.status.idle":"2024-04-17T10:49:49.302289Z","shell.execute_reply.started":"2024-04-17T10:49:49.296345Z","shell.execute_reply":"2024-04-17T10:49:49.301253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_predictions.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:50.802356Z","iopub.execute_input":"2024-04-17T10:49:50.803069Z","iopub.status.idle":"2024-04-17T10:49:50.809496Z","shell.execute_reply.started":"2024-04-17T10:49:50.803033Z","shell.execute_reply":"2024-04-17T10:49:50.808565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_labels","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:50:08.441341Z","iopub.execute_input":"2024-04-17T10:50:08.441770Z","iopub.status.idle":"2024-04-17T10:50:08.449613Z","shell.execute_reply.started":"2024-04-17T10:50:08.441739Z","shell.execute_reply":"2024-04-17T10:50:08.448495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 5: Late Fusion Ensemble\ntesting_labels = np.argmax(testing_labels, axis=1)\n\nensemble_predictions = np.argmax(np.sum([cnn_predictions, lstm_predictions], axis=0), axis=1)\n\n# Step 6: Compare Predictions with Original Classes\naccuracy = np.mean(ensemble_predictions == testing_labels)\nprint(\"Ensemble Model Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:50:44.454947Z","iopub.execute_input":"2024-04-17T10:50:44.455382Z","iopub.status.idle":"2024-04-17T10:50:44.463474Z","shell.execute_reply.started":"2024-04-17T10:50:44.455353Z","shell.execute_reply":"2024-04-17T10:50:44.462349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AUTOMATE ENSEMBLE","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow as tf\n\n# Define the folder path\nfolder_path = '/kaggle/input/cnn-models/cnn'\n\n# Get a list of all files in the folder\nfile_list = os.listdir(folder_path)\n\n# Filter out only the .h5 files\nmodel_files = [file for file in file_list if file.endswith('.h5')]\n\n# Load each model\ncnn_models = []\nfor model_file in model_files[0:4]:\n    model_path = os.path.join(folder_path, model_file)\n    cnn_model = tf.keras.models.load_model(model_path)\n    cnn_models.append(cnn_model)\n\n# Now cnn_models list contains all the loaded CNN models\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:50.075341Z","iopub.execute_input":"2024-03-21T14:46:50.075701Z","iopub.status.idle":"2024-03-21T14:46:52.857385Z","shell.execute_reply.started":"2024-03-21T14:46:50.075672Z","shell.execute_reply":"2024-03-21T14:46:52.856344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train each model and track validation accuracy\nvalidation_accuracies = []\nfor lstm_model in top_lstm_models:\n    history = lstm_model.fit(x_vec_train,\n                             training_labels,\n                             batch_size=32,\n                             epochs=1,\n                             validation_data=(x_vec_test, testing_labels),\n                             shuffle=True)\n    \n    # Get the validation accuracy from the history\n    validation_accuracy = history.history['val_accuracy'][-1]\n    validation_accuracies.append(validation_accuracy)\n\n# Sort the models based on validation accuracy\nsorted_indices = sorted(range(len(validation_accuracies)), key=lambda i: validation_accuracies[i], reverse=True)\ntop_lstm_models = [lstm_models[i] for i in sorted_indices[:4]]  # Select the top 4 models\n\n# Train the top 4 LSTM models\nhistories = []\nfor lstm_model in top_lstm_models:\n    lstm_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    history = lstm_model.fit(x_vec_train,\n                             training_labels,\n                             batch_size=32,\n                             epochs=1,\n                             validation_data=(x_vec_test, testing_labels),\n                             shuffle=True)\n    histories.append(history)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:47:18.511846Z","iopub.execute_input":"2024-03-21T14:47:18.512756Z","iopub.status.idle":"2024-03-21T14:47:18.560206Z","shell.execute_reply.started":"2024-03-21T14:47:18.512723Z","shell.execute_reply":"2024-03-21T14:47:18.559035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the LSTM and CNN models\nlstm_model = tf.keras.models.load_model('/kaggle/input/lstm-parent-model-final/parent_0_model (1).h5')\ncnn_model = tf.keras.models.load_model('/kaggle/input/cnn-model-16layers/cnn_model_.h5')","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n# Assuming you have lists of predictions from the top LSTM and CNN models\ncnn_predictions = [model.predict(testing_cnn_data_selected) for model in cnn_models]\nlstm_predictions = [model.predict(x_vec_test) for model in top_lstm_models]\n\n# Combine predictions using majority voting\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:53:03.403505Z","iopub.execute_input":"2024-03-19T10:53:03.403861Z","iopub.status.idle":"2024-03-19T10:53:22.292528Z","shell.execute_reply.started":"2024-03-19T10:53:03.403834Z","shell.execute_reply":"2024-03-19T10:53:22.291675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Combine predictions using majority voting\ndef majority_voting(predictions):\n    combined_predictions = []\n    for sample_predictions in zip(*predictions):\n        sample_predictions_list = [tuple(prediction) for prediction in sample_predictions]\n        votes = Counter(sample_predictions_list)\n        majority_vote = votes.most_common(1)[0][0]\n        combined_predictions.append(majority_vote)\n    return combined_predictions\n\n\n\n\n# Combine LSTM and CNN predictions using majority voting\nensemble_predictions = majority_voting(lstm_predictions + cnn_predictions)\nensemble_classes = [prediction.index(max(prediction)) for prediction in ensemble_predictions]\n\n\npredicted_labels = np.argmax(lstm_predictions, axis=1)\n\n# Calculate accuracy\n#lstm_accuracy = np.mean(ensemble_predictions == testing_labels)\n#print(\"Ensemble Accuracy:\", lstm_accuracy)\n\n\n# Evaluate ensemble performance\nensemble_accuracy = accuracy_score(testing_labels, ensemble_classes)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:44:35.398346Z","iopub.execute_input":"2024-03-19T10:44:35.398744Z","iopub.status.idle":"2024-03-19T10:44:36.075712Z","shell.execute_reply.started":"2024-03-19T10:44:35.398715Z","shell.execute_reply":"2024-03-19T10:44:36.074856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.shape(lstm_predictions)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:55:15.363127Z","iopub.execute_input":"2024-03-19T10:55:15.363509Z","iopub.status.idle":"2024-03-19T10:55:15.370482Z","shell.execute_reply.started":"2024-03-19T10:55:15.363479Z","shell.execute_reply":"2024-03-19T10:55:15.369543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.shape(cnn_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:55:16.122988Z","iopub.execute_input":"2024-03-19T10:55:16.123352Z","iopub.status.idle":"2024-03-19T10:55:16.130424Z","shell.execute_reply.started":"2024-03-19T10:55:16.123323Z","shell.execute_reply":"2024-03-19T10:55:16.129477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_predictions","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:52:10.078728Z","iopub.execute_input":"2024-03-19T10:52:10.079125Z","iopub.status.idle":"2024-03-19T10:52:10.090250Z","shell.execute_reply.started":"2024-03-19T10:52:10.079096Z","shell.execute_reply":"2024-03-19T10:52:10.089236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Convert lists to NumPy arrays\nlstm_predictions_array = np.array(lstm_predictions)\ncnn_predictions_array = np.array(cnn_predictions)\n\n# Reshape LSTM and CNN predictions to (num_samples, sequence_length * num_classes)\nlstm_predictions_reshaped = lstm_predictions_array.reshape(lstm_predictions_array.shape[0], -1)\ncnn_predictions_reshaped = cnn_predictions_array.reshape(cnn_predictions_array.shape[0], -1)\n\n# Concatenate reshaped predictions\nx_train = np.concatenate((lstm_predictions_reshaped, cnn_predictions_reshaped), axis=1)\n\n# Assuming y_train contains ground truth labels with shape (num_samples,)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:59:20.963469Z","iopub.execute_input":"2024-03-19T10:59:20.964317Z","iopub.status.idle":"2024-03-19T10:59:20.972996Z","shell.execute_reply.started":"2024-03-19T10:59:20.964275Z","shell.execute_reply":"2024-03-19T10:59:20.972063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_predictions[0][0]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:24:14.712708Z","iopub.execute_input":"2024-03-19T11:24:14.713061Z","iopub.status.idle":"2024-03-19T11:24:14.720141Z","shell.execute_reply.started":"2024-03-19T11:24:14.713036Z","shell.execute_reply":"2024-03-19T11:24:14.718906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_pred = ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\n# Prepare Data\n# Assuming lstm_predictions, cnn_predictions, and correct_outputs contain the predictions and correct outputs\n# Concatenate LSTM and CNN predictions\nx_train = np.concatenate((lstm_predictions[0], cnn_predictions[0]), axis=1)\n\n# Calculate Weightage Distribution\n# For example, calculate the weightage based on accuracy\nlstm_accuracy = accuracy_score(lstm_predictions[0], testing_labels)\ncnn_accuracy = accuracy_score(cnn_predictions[0], testing_labels)\ntotal_accuracy = lstm_accuracy + cnn_accuracy\nlstm_weight = lstm_accuracy / total_accuracy\ncnn_weight = cnn_accuracy / total_accuracy\n\n# Prepare Target Weightage Distribution\ntarget_weightage = np.concatenate((lstm_weight, cnn_weight), axis=1)\n\n# Define Fusion Network Architecture\nfusion_network = tf.keras.Sequential([\n    tf.keras.layers.Dense(64, activation='relu', input_shape=(num_features,)),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(num_modalities, activation='softmax')  # Output layer for weightage distribution\n])\n\n# Compile Fusion Network\nfusion_network.compile(optimizer='adam', loss='categorical_crossentropy')\n\n# Train Fusion Network\nfusion_network.fit(x_train, target_weightage, epochs=10, batch_size=32, validation_split=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:23:48.952093Z","iopub.execute_input":"2024-03-19T11:23:48.952500Z","iopub.status.idle":"2024-03-19T11:23:49.046462Z","shell.execute_reply.started":"2024-03-19T11:23:48.952470Z","shell.execute_reply":"2024-03-19T11:23:49.045125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_classes = [prediction.index(max(prediction)) for prediction in ensemble_predictions]\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:35:02.178910Z","iopub.execute_input":"2024-03-19T10:35:02.179276Z","iopub.status.idle":"2024-03-19T10:35:02.204524Z","shell.execute_reply.started":"2024-03-19T10:35:02.179247Z","shell.execute_reply":"2024-03-19T10:35:02.203587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_classes[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:35:08.323066Z","iopub.execute_input":"2024-03-19T10:35:08.323779Z","iopub.status.idle":"2024-03-19T10:35:08.329716Z","shell.execute_reply.started":"2024-03-19T10:35:08.323742Z","shell.execute_reply":"2024-03-19T10:35:08.328534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CIFAR-10 class names\ncifar_10_classes = {\n    0: 'airplane',\n    1: 'automobile',\n    2: 'bird',\n    3: 'cat',\n    4: 'deer',\n    5: 'dog',\n    6: 'frog',\n    7: 'horse',\n    8: 'ship',\n    9: 'truck'\n}\n\n# Printing class names for the first 10 elements in image_classes\nprint(\"Class Names:\")\nfor class_index in image_classes[:10]:\n    print(cifar_10_classes[class_index])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T06:28:50.471687Z","iopub.execute_input":"2024-03-08T06:28:50.472061Z","iopub.status.idle":"2024-03-08T06:28:50.478728Z","shell.execute_reply.started":"2024-03-08T06:28:50.472033Z","shell.execute_reply":"2024-03-08T06:28:50.477485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_captions[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-03-08T06:25:59.692904Z","iopub.execute_input":"2024-03-08T06:25:59.693621Z","iopub.status.idle":"2024-03-08T06:25:59.700244Z","shell.execute_reply.started":"2024-03-08T06:25:59.693588Z","shell.execute_reply":"2024-03-08T06:25:59.699205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_classes[0:10]\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T06:26:19.538109Z","iopub.execute_input":"2024-03-08T06:26:19.538621Z","iopub.status.idle":"2024-03-08T06:26:19.546439Z","shell.execute_reply.started":"2024-03-08T06:26:19.538580Z","shell.execute_reply":"2024-03-08T06:26:19.545271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define the ensemble function\ndef ensemble(lstm_outputs, cnn_outputs):\n    # Add your ensemble code here\n    return lstm_outputs, cnn_outputs\n\n# Make predictions on the image and text data\nlstm_predictions = []\ncnn_predictions = []\nfor image_batch, text_batch in zip(image_generator, text_generator):\n    lstm_outputs = lstm_model.predict(text_batch)\n    cnn_outputs = cnn_model.predict(image_batch)\n    lstm_predictions.append(lstm_outputs)\n    cnn_predictions.append(cnn_outputs)\nlstm_predictions = np.vstack(lstm_predictions)\ncnn_predictions = np.vstack(cnn_predictions)\n\n# Ensemble the predictions using voting strategy\nensemble_predictions = ensemble(lstm_predictions, cnn_predictions)\n\n# Take the average of the probabilities from both models for each class\nensemble_predictions = (ensemble_predictions[0] + ensemble_predictions[1]) / 2\n\n# Select the class with the highest average probability as the final prediction\nfinal_predictions = np.argmax(ensemble_predictions, axis=1)","metadata":{},"execution_count":null,"outputs":[]}]}