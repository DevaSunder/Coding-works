{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7764647,"sourceType":"datasetVersion","datasetId":4541506},{"sourceId":7764682,"sourceType":"datasetVersion","datasetId":4541533},{"sourceId":7782124,"sourceType":"datasetVersion","datasetId":4554156},{"sourceId":7786353,"sourceType":"datasetVersion","datasetId":4557329},{"sourceId":7790157,"sourceType":"datasetVersion","datasetId":4559830},{"sourceId":7821267,"sourceType":"datasetVersion","datasetId":4582498},{"sourceId":7822287,"sourceType":"datasetVersion","datasetId":4583259},{"sourceId":7822850,"sourceType":"datasetVersion","datasetId":4583639},{"sourceId":8122636,"sourceType":"datasetVersion","datasetId":4799764},{"sourceId":8122723,"sourceType":"datasetVersion","datasetId":4799820},{"sourceId":8123082,"sourceType":"datasetVersion","datasetId":4800104},{"sourceId":8123791,"sourceType":"datasetVersion","datasetId":4800633}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### UTILITIES\nfrom keras.datasets import cifar10\nfrom keras.utils import to_categorical\nimport pickle\nimport sys\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nimport numpy as np\n\ndef load_dataset(batch_size, num_classes, epochs):\n    (x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n\n    # Select a random subset of 4500 images for training\n    random_indices = np.random.choice(len(x_train_full), size=50000, replace=False)\n    x_train = x_train_full[random_indices]\n    y_train = y_train_full[random_indices]\n\n    # Normalize and one-hot encode the labels\n    x_train = x_train.astype('float32') / 255\n    x_test = x_test.astype('float32') / 255\n    y_train = to_categorical(y_train, num_classes)\n    y_test = to_categorical(y_test, num_classes)\n\n    # Randomly select 500 images for validation\n    random_indices = np.random.choice(len(x_test), size=10000, replace=False)\n    x_val = x_test[random_indices]\n    y_val = y_test[random_indices]\n\n    dataset = {\n        'batch_size': batch_size,\n        'num_classes': num_classes,\n        'epochs': epochs,\n        'x_train': x_train,\n        'y_train': y_train,\n        'x_val': x_val,\n        'y_val': y_val,\n        'x_test': x_test,  \n        'y_test': y_test\n    }\n\n    return dataset\n\n\ndef save_network(network):\n    #object_file = open(network.name + '.obj', 'wb')\n    #pickle.dump(network, object_file)\n    #tf.keras.models.save_model(network, network.name)\n\n    model_path = network.name + '_model.h5'\n    tf.keras.models.save_model(network.model, model_path)\n\n    # Save the rest of the network information\n    network_info = {\n        'name': network.name,\n        'block_list': network.block_list,\n        'fitness': network.fitness\n    }\n    network_info_path = network.name + '_info.pkl'\n    with open(network_info_path, 'wb') as info_file:\n        pickle.dump(network_info, info_file)\n\n\ndef load_network(name):\n    model_path = name + '_model.h5'\n    loaded_model = tf.keras.models.load_model(model_path)\n\n    # Load the network information\n    info_path = name + '_info.pkl'\n    with open(info_path, 'rb') as info_file:\n        network_info = pickle.load(info_file)\n\n    # Create a new Network instance\n    loaded_network = Network(0)  # Update with appropriate 'it' value\n\n    # Set the attributes of the loaded network\n    loaded_network.name = network_info['name']\n    loaded_network.block_list = network_info['block_list']\n    loaded_network.fitness = network_info['fitness']\n    loaded_network.model = loaded_model\n\n    return loaded_network\n\n\n\ndef order_indexes(self):\n    i = 0\n    for block in self.block_list:\n        block.index = i\n        i += 1\n\n\ndef plot_training(history):                                           # plot diagnostic learning curves\n    plt.figure(figsize=[8, 6])  # accuracy curves\n    plt.plot(history.history['accuracy'], 'r', linewidth=3.0)\n    plt.plot(history.history['val_accuracy'], 'b', linewidth=3.0)  # <-- Change 'val_acc' to 'val_accuracy'\n    plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n    plt.xlabel('Epochs ', fontsize=16)\n    plt.ylabel('Accuracy', fontsize=16)\n    plt.title('Accuracy Curves', fontsize=16)\n\n    filename = sys.argv[0].split('/')[-1]\n    plt.savefig(filename + '_acc_plot.png')\n    plt.close()\n\n\n\ndef plot_statistics(stats):\n    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# fitness curves\n    plt.plot([s[0] for s in stats], 'r', linewidth=3.0)\n    plt.plot([stats[0][0]] * len(stats), 'b', linewidth=3.0)\n    plt.legend(['BestFitness', 'InitialFitness'], fontsize=18)\n    plt.xlabel('Generations', fontsize=16)\n    plt.ylabel('FitnessValue', fontsize=16)\n    plt.title('Fitness Curve', fontsize=16)\n    filename = sys.argv[0].split('/')[-1]\n    plt.savefig(filename + '_fitness_plot.png')\n\n    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# parameters curves\n    plt.plot([s[1] for s in stats], 'r', linewidth=3.0)\n    plt.plot([stats[0][1]] * len(stats), 'b', linewidth=3.0)\n    plt.legend(['BestParamsNum', 'InitialParamsNum'], fontsize=18)\n    plt.xlabel('Generations', fontsize=16)\n    plt.ylabel('ParamsNum', fontsize=16)\n    plt.title('Parameters Curve', fontsize=16)\n    filename = sys.argv[0].split('/')[-1]\n    plt.savefig(filename + '_params_plot.png')\n    plt.close()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:08.865544Z","iopub.execute_input":"2024-03-21T14:35:08.866376Z","iopub.status.idle":"2024-03-21T14:35:21.633023Z","shell.execute_reply.started":"2024-03-21T14:35:08.866339Z","shell.execute_reply":"2024-03-21T14:35:21.631981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INOUT\nimport os\ndef compute_parent(dataset):\n    if os.path.isfile('parent_0.h5'):\n        daddy = load_network('parent_0')\n        model = tf.keras.models.load_model('parent_0.h5')\n        print(\"Loading parent_0\")\n        print(\"SUMMARY OF\", daddy.name)\n        print(model.summary())\n        print(\"FITNESS:\", daddy.fitness)\n        return daddy\n\n    daddy = Network(0)\n    \n    \n    #INI BLOCK\n    layerList1 = [\n        Convolutional(filters=32, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(0, 0, layerList1, layerList2))\n    \n    #MIDDLE BLOCK 1\n    layerList1 = [\n        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 1, layerList1, layerList2))\n\n     #MIDDLE BLOCK 2\n    layerList1 = [\n        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 2, layerList1, layerList2))\n\n    \n    #MIDDLE BLOCK 3\n    layerList1 = [\n        Convolutional(filters=256, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=256, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 3, layerList1, layerList2))\n    \n    \n    \n    #MIDDLE BLOCK 4\n    layerList1 = [\n        Convolutional(filters=512, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=512, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 4, layerList1, layerList2))\n    \n    \n    \n    #FULLY CONNECTED LAYER\n    layerList1 = [\n        FlattenLayer(),\n        FullyConnected(units=128, num_classes=dataset['num_classes'])\n    ]\n    layerList2 = []\n    daddy.block_list.append(Block(2, 5, layerList1, layerList2))\n    \n    \n\n    model = daddy.build_model()\n    print(\"Type of model_final:\", type(model))\n    daddy.train_and_evaluate(model, dataset)\n    return daddy","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:25.599146Z","iopub.execute_input":"2024-03-21T14:35:25.599778Z","iopub.status.idle":"2024-03-21T14:35:25.621856Z","shell.execute_reply.started":"2024-03-21T14:35:25.599747Z","shell.execute_reply":"2024-03-21T14:35:25.620860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NETWORK\nimport tensorflow as tf\nimport os\nimport pickle\nfrom keras.callbacks import Callback\nfrom keras.models import Sequential\nfrom random import randint, choice\nfrom copy import deepcopy\n\n\nclass Network:\n    __slots__ = ('name', 'block_list', 'fitness', 'model')\n\n    def __init__(self, it):\n        self.name = 'parent_' + str(it) if it == 0 else 'net_' + str(it)\n        self.block_list = []\n        self.fitness = None\n        self.model = None\n\n    \"\"\"def build_model(self):\n        model = Sequential()                                # create model\n        for block in self.block_list:\n            for layer in block.get_layers():                # build model\n                try:\n                    layer.build_layer(model)\n                except:\n                    print(\"\\nINDIVIDUAL ABORTED, CREATING A NEW ONE\\n\")\n                    return -1\n        return model\"\"\"\n    def build_model(self):\n        model = Sequential()              \n        print(\"The block is:\")\n        print(self.block_list)                 # create model\n        for block in self.block_list:\n            #print(\"Building block type:\", block.type)\n            #print(\"TOTAL :::\")\n            #print(block.get_layer_name())\n            for layer in block.get_layers():                # build model\n                #print(\"Adding layer:\", layer.name)\n                try:\n                    layer.build_layer(model)\n                    print(\"Layer added successfully.\")\n                except Exception as e:\n                    print(\"Error occurred while adding layer:\", e)\n                    print(\"Returning None.\")\n                    return -1\n        print(\"Model successfully built.\")\n        return model\n\n    def train_and_evaluate(self, model, dataset):\n        print(\"Training\", self.name)\n        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n        try:\n            history = model.fit(dataset['x_train'],\n                                dataset['y_train'],\n                                batch_size=dataset['batch_size'],\n                                epochs=dataset['epochs'],\n                                validation_data=(dataset['x_val'], dataset['y_val']),\n                                shuffle=True)\n        except Exception as e:\n            print(\"An error occurred during model training:\", e)\n            return -1\n            # You can choose to handle the error in a specific way here, like logging it or taking corrective actions.\n\n\n        # Extract metrics from the training history\n        training_loss = history.history['loss'][-1]\n        training_accuracy = history.history['accuracy'][-1]\n        validation_loss = history.history['val_loss'][-1]\n        validation_accuracy = history.history['val_accuracy'][-1]\n\n        # Additional metrics (you can customize this based on your needs)\n        classification_error_rate = 1.0 - validation_accuracy\n\n        self.model = model  # Save the model\n        self.fitness = validation_loss  # Use validation loss as fitness\n\n        # Print metrics\n        print(\"SUMMARY OF\", self.name)\n        print(\"Training Loss:\", training_loss)\n        print(\"Training Accuracy:\", training_accuracy)\n        print(\"Validation Loss:\", validation_loss)\n        print(\"Validation Accuracy:\", validation_accuracy)\n        print(\"Classification Error Rate:\", classification_error_rate)\n\n        tf.keras.models.save_model(model, self.name + '.h5')         # save model\n        #model.save(self.name + '.h5')                       # save model\n        save_network(self)                                  # save topology, model and fitness\n\n    def asexual_reproduction(self, it, dataset):\n\n        # if the individual already exists, just load it\n        if os.path.isfile('net_' + str(it) + '.h5'):\n            print(\"\\n-------------------------------------\")\n            print(\"Loading individual net_\" + str(it))\n            print(\"--------------------------------------\\n\")\n            individual = load_network('net_' + str(it))\n            model = tf.keras.models.load_model(individual.name + '.h5')\n            print(\"SUMMARY OF\", individual.name)\n            print(model.summary())\n            print(\"FITNESS: \", individual.fitness)\n            return individual\n\n        # otherwise, create the individual by mutating the parent\n        individual = Network(it)\n\n        print(\"\\n-------------------------------------\")\n        print(\"\\nCreating individual\", individual.name)\n        print(\"--------------------------------------\\n\")\n\n        individual.block_list = deepcopy(self.block_list)           # copy the layer list from parent\n\n        print(\"----->Strong Mutation\")\n        individual.block_mutation(dataset)                          # mutate a block\n        individual.layer_mutation(dataset)                          # mutate a layer\n        individual.parameters_mutation()                            # mutate some parameters\n\n        model = individual.build_model()\n        \n        if model == -1:\n            return self.asexual_reproduction(it, dataset)\n        \n        if(individual.train_and_evaluate(model, dataset)==-1):\n            return self.asexual_reproduction(it, dataset)\n        else:\n            return individual\n            \n\n    def block_mutation(self, dataset):\n        try:\n            print(\"Block Mutation\")\n\n            print([(block.index, block.type) for block in self.block_list])\n\n            # block list containing all the blocks with type = 1\n            bl = [block.index for block in self.block_list if block.type == 1]\n\n            if len(bl) == 0:\n                print(\"Creating a new block with two Convolutional layers and a Pooling layer\")\n                self.block_list[1].index = 2\n                layerList1 = [\n                    Convolutional(filters=pow(2, randint(5, 8)),\n                                  filter_size=(3, 3),\n                                  stride_size=(1, 1),\n                                  padding='same',\n                                  input_shape=dataset['x_train'].shape[1:]),\n                    Convolutional(filters=pow(2, randint(5, 8)),\n                                  filter_size=(3, 3),\n                                  stride_size=(1, 1),\n                                  padding='same',\n                                  input_shape=dataset['x_train'].shape[1:])\n                ]\n                layerList2 = [\n                    Pooling(pool_size=(2, 2),\n                            stride_size=(2, 2),\n                            padding='same')\n                ]\n                b = Block(1, 1, layerList1, layerList2)\n                self.block_list.insert(1, b)\n                return\n\n            block_idx = randint(1, max(bl))         # pick a random block among all the blocks with type = 1\n            block_type_idx = randint(0, 1)          # 1 -> Conv2D; 0 -> Pooling or Dropout\n            mutation_type = randint(0, 1)           # 1 -> remove; 0 -> add\n\n            # list of layers of the selected block\n            layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n            length = len(layerList)\n\n            if mutation_type:                                       # remove\n                if length == 1:\n                    del self.block_list[block_idx]\n                elif block_type_idx:\n                    pos = randint(0, length - 1)\n                    print(\"Removing a Conv2D layer at\", pos)\n                    del layerList[pos]\n                else:\n                    pos = randint(0, length - 1)\n                    print(\"Removing a Pooling/Dropout layer at\", pos)\n                    del layerList[pos]\n            else:                                                   # add\n                if block_type_idx:\n                    print(\"Inserting a Convolutional layer\")\n                    layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                          filter_size=(3, 3),\n                                          stride_size=(1, 1),\n                                          padding='same',\n                                          input_shape=dataset['x_train'].shape[1:])\n                    layerList.insert(randint(0, length - 1), layer)\n                else:\n                    if randint(0, 1):                               # 1 -> Pooling; 0 -> Dropout\n                        print(\"Inserting a Pooling layer\")\n                        layer = Pooling(pool_size=(2, 2),\n                                        stride_size=(2, 2),\n                                        padding='same')\n                        layerList.insert(randint(0, length - 1), layer)\n                    else:\n                        print(\"Inserting a Dropout layer\")\n                        rate = choice([0.15, 0.25, 0.35, 0.50])\n                        layer = Dropout(rate=rate)\n                        layerList.insert(randint(0, length - 1), layer)\n        except Exception as e:\n            print(f\"An error occurred during block mutation: {e}\")\n            return None\n\n                    \n                    \n                    \n                    \n                    \n\n    \"\"\"def layer_mutation(self, dataset):\n        print(\"Layer Mutation\")\n\n        # pick a random block among all the blocks with type = 1\n        bl = [block.index for block in self.block_list if block.type == 1]\n\n        if len(bl) == 0:\n            return\n\n        block_idx = randint(1, max(bl))\n        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n\n        # list of layers of the selected block\n        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n\n        if len(layerList) == 0:\n            if block_type_idx:\n                layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                      filter_size=(3, 3),\n                                      stride_size=(1, 1),\n                                      padding='same',\n                                      input_shape=dataset['x_train'].shape[1:])\n                self.block_list[block_idx].layerList1.append(layer)\n                return\n            else:\n                layer = Pooling(pool_size=(2, 2),\n                                stride_size=(2, 2),\n                                padding='same')\n                self.block_list[block_idx].layerList2.append(layer)\n\n        idx = randint(0, len(layerList) - 1)\n        layer = layerList[idx]\n\n        if layer.name == 'Conv2D':\n            print(\"Splitting Conv2D layer at index\", idx)\n            layer.filters = int(layer.filters * 0.5)\n            layerList.insert(idx, deepcopy(layer))\n        elif layer.name == 'MaxPooling2D' or layer.name == 'AveragePooling2D':\n            print(\"Changing Pooling layer at index\", idx, \"with Conv2D layer\")\n            del layerList[idx]\n            conv_layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                       filter_size=(3, 3),\n                                       stride_size=(2, 2),\n                                       padding=layer.padding,\n                                       input_shape=dataset['x_train'].shape[1:])\n            layerList.insert(idx, conv_layer)\"\"\"\n    \n    def layer_mutation(self, dataset):\n        print(\"Layer Mutation\")\n\n        # Determine the maximum number of layers that can be added or removed\n        max_layers_to_add = 16 - sum(len(block.layerList1) + len(block.layerList2) for block in self.block_list)\n        max_layers_to_remove = sum(len(block.layerList1) + len(block.layerList2) - 1 for block in self.block_list)\n\n        if max_layers_to_add == 0 and max_layers_to_remove == 0:\n            return\n\n        # Pick a random block among all the blocks with type = 1\n        bl = [block.index for block in self.block_list if block.type == 1]\n\n        if len(bl) == 0:\n            return\n\n        block_idx = randint(1, max(bl))\n        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n\n        # List of layers of the selected block\n        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n\n        if len(layerList) == 0:\n            if block_type_idx:\n                layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                      filter_size=(3, 3),\n                                      stride_size=(1, 1),\n                                      padding='same',\n                                      input_shape=dataset['x_train'].shape[1:])\n                self.block_list[block_idx].layerList1.append(layer)\n            else:\n                layer = Pooling(pool_size=(2, 2),\n                                stride_size=(2, 2),\n                                padding='same')\n                self.block_list[block_idx].layerList2.append(layer)\n        else:\n            # Randomly choose whether to add or remove a layer\n            add_layer = bool(randint(0, 1))\n\n            if add_layer and max_layers_to_add > 0:\n                # Add a layer\n                layer = self.create_random_layer(dataset)\n                layerList.insert(randint(0, len(layerList)), layer)\n            elif not add_layer and max_layers_to_remove > 0:\n                # Remove a layer\n                idx = randint(0, len(layerList) - 1)\n                del layerList[idx]\n\n        # Ensure the total number of layers in the block doesn't exceed 16\n        if len(self.block_list[block_idx].layerList1) + len(self.block_list[block_idx].layerList2) > 16:\n            # Remove a random layer to maintain the total count of 16 layers\n            block_layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n            del block_layerList[randint(0, len(block_layerList) - 1)]\n\n    def create_random_layer(self, dataset):\n        # Create a random layer (Conv2D or Pooling)\n        if randint(0, 1):\n            # Conv2D layer\n            return Convolutional(filters=pow(2, randint(5, 8)),\n                                 filter_size=(3, 3),\n                                 stride_size=(1, 1),\n                                 padding='same',\n                                 input_shape=dataset['x_train'].shape[1:])\n        else:\n            # Pooling layer\n            return Pooling(pool_size=(2, 2),\n                           stride_size=(2, 2),\n                           padding='same')\n\n            \n            \n            \n            \n            \n            \n            \n            \n\n    def parameters_mutation(self):\n        print(\"Parameters Mutation\")\n        for block in self.block_list:\n            for layer in block.get_layers():\n                if randint(0, 1):\n                    layer.mutate_parameters()\n\n    def save_network_info(self, info_filename):\n        network_info = {\n            'name': self.name,\n            'block_list': self.block_list,\n            'fitness': self.fitness\n        }\n\n        with open(info_filename, 'wb') as info_file:\n            pickle.dump(network_info, info_file)\n\n    def load_network_info(self, info_filename):\n        with open(info_filename, 'rb') as info_file:\n            network_info = pickle.load(info_file)\n\n        self.name = network_info['name']\n        self.block_list = network_info['block_list']\n        self.fitness = network_info['fitness']\n\n    def save_model(self, model_filename):\n        self.model.save(model_filename)\n\n    def load_model(self, model_filename):\n        self.model = tf.keras.models.load_model(model_filename)\n\n    def save_network(self, network_info_filename, model_filename):\n        # Save non-model attributes\n        self.save_network_info(network_info_filename)\n\n        # Save the model separately\n        self.save_model(model_filename)\n\n    def load_network(self, network_info_filename, model_filename):\n        # Load non-model attributes\n        self.load_network_info(network_info_filename)\n\n        # Load the model separately\n        self.load_model(model_filename)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:27.022012Z","iopub.execute_input":"2024-03-21T14:35:27.022374Z","iopub.status.idle":"2024-03-21T14:35:27.078711Z","shell.execute_reply.started":"2024-03-21T14:35:27.022345Z","shell.execute_reply":"2024-03-21T14:35:27.077468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TOPOLOGY\n\nimport keras.layers\nfrom random import randint\n\n\nclass Block:\n\t__slots__ = ('type', 'index', 'layerList1', 'layerList2')\n\n\tdef __init__(self, type, index, layerList1, layerList2):\n\t\tself.type = type\t\t\t\t\t\t\t\t\t\t# 0 -> initial layer; 1 -> mid layers; 2 -> final layer\n\t\tself.index = index\t\t\t\t\t\t\t\t\t\t# block index among all the blocks\n\t\tself.layerList1 = layerList1\t\t\t\t\t\t\t# Convolutional layers\n\t\tself.layerList2 = layerList2\t\t\t\t\t\t\t# Pooling and Dropout layers\n\n\tdef get_layers(self):\n\t\treturn self.layerList1 + self.layerList2\n\n\tdef get_size(self):\n\t\treturn len(self.get_layers())\n\n\nclass Convolutional:\n\t# __slots__ = ('name', 'filters', 'padding', 'filter_size', 'stride_size', 'input_shape')\n\n\tdef __init__(self, filters, padding, filter_size, stride_size, input_shape):\n\t\tself.name = 'Conv2D'\n\t\tself.filters = filters\n\t\tself.padding = padding\n\t\tself.filter_size = filter_size\n\t\tself.stride_size = stride_size\n\t\tself.input_shape = input_shape\n\n\tdef build_layer(self, model):\n\t\ttry:\n\t\t\tmodel.add(keras.layers.Conv2D(filters=self.filters,\n\t\t\t\t\t\t\t\t\t\t\tkernel_size=self.filter_size,\n\t\t\t\t\t\t\t\t\t\t\tstrides=self.stride_size,\n\t\t\t\t\t\t\t\t\t\t\tpadding=self.padding,\n\t\t\t\t\t\t\t\t\t\t\tactivation='relu',\n\t\t\t\t\t\t\t\t\t\t\tkernel_initializer='he_uniform',\n\t\t\t\t\t\t\t\t\t\t\tinput_shape=self.input_shape))\n\t\texcept ValueError as e:\n\t\t\tprint(\"Error occurred while adding layer:\", e)\n\t\t\tprint(\"Skipping current architecture.\")\n\t\t\treturn  # Skip adding this layer\n\tdef mutate_parameters(self):\n\t\tmutation = randint(0, 2)  # Adjusted the number of mutations\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tif mutation == 0 and self.filters >= 64:  # Adjusted the filter reduction threshold\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters = int(self.filters / 2)\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 1 and self.filters <= 256:  # Adjusted the filter increase threshold\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters *= 2\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 2:\n\t\t\tif self.padding == 'valid':\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'same'\n\t\t\t\tprint(\"to \", self.padding)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'valid'\n\t\t\t\tprint(\"to \", self.padding)\n\n        \n\n        \n\n\n\t\"\"\"def mutate_parameters(self):\n\t\tmutation = randint(0, 4)\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tif mutation == 0 and self.filters >= 32:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters = int(self.filters / 2)\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 1 and self.filters >= 32:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters = int(self.filters / 2)\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 2 and self.filters <= 512:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters *= 2\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 3 and self.filters <= 512:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters *= 2\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 4:\n\t\t\tif self.padding == 'valid':\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'same'\n\t\t\t\tprint(\"to \", self.padding)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'valid'\n\t\t\t\tprint(\"to \", self.padding)\n\"\"\"\n    \n\n'''\nelif mutation is 4:\n\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n\tprint(\"to \", self.stride_size, \" and \", end=\"\")\n\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n\tprint(\"to \", self.stride_size)\n'''\n\n\nclass Pooling:\n\t__slots__ = ('name', 'pool_size', 'stride_size', 'padding')\n\n\tdef __init__(self, pool_size, stride_size, padding):\n\t\tself.name = 'MaxPooling2D'\n\t\tself.pool_size = pool_size\n\t\tself.stride_size = stride_size\n\t\tself.padding = padding\n\n\tdef build_layer(self, model):\n\t\tif self.name == 'MaxPooling2D':\n\t\t\tmodel.add(keras.layers.MaxPooling2D(self.pool_size, self.stride_size, self.padding))\n\t\telif self.name == 'AveragePooling2D':\n\t\t\tmodel.add(keras.layers.AveragePooling2D(self.pool_size, self.stride_size, self.padding))\n\n\tdef mutate_parameters(self):\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tmutation = randint(0, 1)\n\t\tif mutation == 0:\n\t\t\tif self.padding == 'valid':\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'same'\n\t\t\t\tprint(\"to \", self.padding)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'valid'\n\t\t\t\tprint(\"to \", self.padding)\n\t\telif mutation == 1:\n\t\t\tif self.name == 'MaxPooling2D':\n\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n\t\t\t\tself.name = 'AveragePooling2D'\n\t\t\t\tprint(\"to \", self.name)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n\t\t\t\tself.name = 'MaxPooling2D'\n\t\t\t\tprint(\"to \", self.name)\n\n\n'''\nif mutation is 0:\n\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n\tprint(\"to \", self.stride_size)\n'''\n\n\nclass FullyConnected:\n\t__slots__ = ('name', 'units', 'num_classes')\n\n\tdef __init__(self, units, num_classes):\n\t\tself.name = \"FullyConnected\"\n\t\tself.units = units\n\t\tself.num_classes = num_classes\n\n\tdef build_layer(self, model):\n\t\tmodel.add(keras.layers.Flatten())\n\t\tmodel.add(keras.layers.Dense(self.units, activation='relu', kernel_initializer='he_uniform'))\n\t\tmodel.add(keras.layers.Dense(self.num_classes, activation='softmax'))\n\n\tdef mutate_parameters(self):\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tmutation = randint(0, 2)\n\t\tif mutation == 0:\n\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n\t\t\tself.units *= 2\n\t\t\tprint(\"to \", self.units)\n\t\telif mutation == 1:\n\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n\t\t\tself.units *= 2\n\t\t\tprint(\"to \", self.units)\n\t\telif mutation == 2:\n\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n\t\t\tself.units /= 2\n\t\t\tprint(\"to \", self.units)\n\n\n'''\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(self.num_classes, activation='softmax'))\n'''\n\n\nclass Dropout:\n\t__slots__ = ('name', 'rate')\n\n\tdef __init__(self, rate):\n\t\tself.name = \"Dropout\"\n\t\tself.rate = rate\n\n\tdef build_layer(self, model):\n\t\tmodel.add(keras.layers.Dropout(self.rate))\n\n\tdef mutate_parameters(self):\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tmutation = randint(0, 3)\n\t\tif mutation == 0 and self.rate <= 0.85:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate + 0.10\n\t\t\tprint(\"to \", self.rate)\n\t\telif mutation == 1 and self.rate <= 0.90:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate + 0.05\n\t\t\tprint(\"to \", self.rate)\n\t\telif mutation == 2 and self.rate >= 0.15:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate - 0.10\n\t\t\tprint(\"to \", self.rate)\n\t\telif mutation == 3 and self.rate >= 0.10:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate - 0.05\n\t\t\tprint(\"to \", self.rate)\n\nclass FlattenLayer:\n    def __init__(self):\n        self.name = 'Flatten'\n\n    def build_layer(self, model):\n        model.add(keras.layers.Flatten())\n\n    def mutate_parameters(self):\n        # The Flatten layer does not have any parameters to mutate\n        pass\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:28.087245Z","iopub.execute_input":"2024-03-21T14:35:28.087711Z","iopub.status.idle":"2024-03-21T14:35:28.125784Z","shell.execute_reply.started":"2024-03-21T14:35:28.087683Z","shell.execute_reply":"2024-03-21T14:35:28.124727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"# MAIN\n\nimport tensorflow as tf\ntf.compat.v1.enable_eager_execution()\nimport os\nfrom copy import deepcopy\nfrom random import sample\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)      # suppress messages from Tensorflow\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\n\ndef initialize_population(population_size, dataset):\n    print(\"----->Initializing Population\")\n    daddy = compute_parent(dataset)                                 # load parent from input\n    population = [daddy]\n    for it in range(1, population_size):\n        population.append(daddy.asexual_reproduction(it, dataset))\n\n    # sort population on ascending order based on fitness\n    return sorted(population, key=lambda cnn: cnn.fitness)\n\n\ndef selection(k, population, num_population):\n    if k == 0:                                              # elitism selection\n        print(\"----->Elitism selection\")\n        return population[0], population[1]\n    elif k == 1:                                            # tournament selection\n        print(\"----->Tournament selection\")\n        i = randint(0, num_population - 1)\n        j = i\n        while j < num_population - 1:\n            j += 1\n            if randint(1, 100) <= 50:\n                return population[i], population[j]\n        return population[i], population[0]\n    else:                                                   # proportionate selection\n        print(\"----->Proportionate selection\")\n        cum_sum = 0\n        for i in range(num_population):\n            cum_sum += population[i].fitness\n        perc_range = []\n        for i in range(num_population):\n            count = 100 - int(100 * population[i].fitness / cum_sum)\n            for j in range(count):\n                perc_range.append(i)\n        i, j = sample(range(1, len(perc_range)), 2)\n        while i == j:\n            i, j = sample(range(1, len(perc_range)), 2)\n        return population[perc_range[i]], population[perc_range[j]]\n\n\ndef crossover(parent1, parent2, it):\n    print(\"----->Crossover\")\n    child = Network(it)\n\n    first, second = None, None\n    if randint(0, 1):\n        first = parent1\n        second = parent2\n    else:\n        first = parent2\n        second = parent1\n\n    child.block_list = deepcopy(first.block_list[:randint(1, len(first.block_list) - 1)]) \\\n                       + deepcopy(second.block_list[randint(1, len(second.block_list) - 1):])\n\n    order_indexes(child)                            # order the indexes of the blocks\n\n    return child\n\n\ndef genetic_algorithm(num_population, num_generation, num_offspring, dataset, early_stopping_generations=3):\n    print(\"Genetic Algorithm\")\n\n    population = initialize_population(num_population, dataset)\n\n    print(\"\\n-------------------------------------\")\n    print(\"Initial Population:\")\n    for cnn in population:\n        print(cnn.name, ': ', cnn.fitness)\n    print(\"--------------------------------------\\n\")\n\n    # for printing statistics about fitness and the number of parameters of the best individual\n    stats = [(population[0].fitness, population[0].model.count_params())]\n\n    # Initialize a variable to keep track of consecutive generations with the same best fitness\n    consecutive_same_fitness = 0\n\n    for gen in range(1, num_generation + 1):\n        '''\n            k is the selection parameter:\n                k = 0 -> elitism selection\n                k = 1 -> tournament selection\n                k = 2 -> proportionate selection\n        '''\n        k = randint(0, 2)\n\n        print(\"\\n------------------------------------\")\n        print(\"Generation -----------------------------------------------------------------------------------\", gen)\n        print(\"-------------------------------------\")\n\n        for c in range(num_offspring):\n\n            print(\"\\nCreating Child\", c)\n\n            parent1, parent2 = selection(k, population, num_population)                 # selection\n            print(\"Selected\", parent1.name, \"and\", parent2.name, \"for reproduction\")\n\n            child = crossover(parent1, parent2, c + num_population)                     # crossover\n            print(\"Child has been created\")\n\n            print(\"----->Soft Mutation\")\n            child.layer_mutation(dataset)                                               # mutation\n            child.parameters_mutation()\n            print(\"Child has been mutated\")\n            model = child.build_model()  \n            # evaluation\n            if model==-1:\n                pass\n            else:\n                if(child.train_and_evaluate(model,dataset)==-1):\n                    model=-1  \n            #if(child.train_and_evaluate(model,dataset)==-1):\n                    #model=-1  # evaluation\n\n            while model == -1:\n                child = crossover(parent1, parent2, c + num_population)\n                child.block_mutation(dataset)\n                child.layer_mutation(dataset)\n                child.parameters_mutation()\n                model = child.build_model()\n                if(model==-1):\n                    pass\n                else:\n                    if(child.train_and_evaluate(model,dataset)==-1):\n                        model=-1\n\n            #child.train_and_evaluate(model, dataset)\n\n            if child.fitness < population[-1].fitness:                                  # evolve population\n                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"replaces parent \", end=\"\")\n                print(population[-1].name, \"with fitness\", population[-1].fitness)\n                name = population[-1].name\n\n                child.save_network(\"child_model_info.pkl\", \"child_model.h5\")\n                population[-1].load_network(\"child_model_info.pkl\", \"child_model.h5\")\n\n                population[-1].name = name\n                population = sorted(population, key=lambda net: net.fitness)\n            else:\n                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"is discarded\")\n        \n        if gen >= 3 and all(population[i].fitness == population[i + 1].fitness for i in range(-3, -1)):\n            consecutive_same_fitness += 1\n            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n        if consecutive_same_fitness >= 3:\n            print(\"Stopping the algorithm as the best fitness has remained the same for the last 3 generations.\")\n            break\n    else:\n        consecutive_same_fitness = 0\n        \n       #Check if the best fitness has remained the same for the last early_stopping_generations generations\n        if all(population[i].fitness == population[i + 1].fitness for i in range(-early_stopping_generations, -1)):\n            consecutive_same_fitness += 1\n            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n            if consecutive_same_fitness == early_stopping_generations:\n                print(f\"Stopping the algorithm as the best fitness has remained the same for {early_stopping_generations} generations.\")\n        else:\n            consecutive_same_fitness = 0\n        stats.append((population[0].fitness, population[0].model.count_params()))\n\n    print(\"\\n\\n-------------------------------------\")\n    print(\"Final Population\")\n    print(\"-------------------------------------\\n\")\n    for cnn in population:\n        print(cnn.name, ': ', cnn.fitness)\n\n    print(\"\\n-------------------------------------\")\n    print(\"Stats\")\n    for i in range(len(stats)):\n        print(\"Best individual at generation\", i + 1, \"has fitness\", stats[i][0], \"and parameters\", stats[i][1])\n    print(\"-------------------------------------\\n\")\n\n    # plot the fitness and the number of parameters of the best individual at each iteration\n    plot_statistics(stats)\n\n    return population[0]\n\n\n\ndef main():    \n        #with strategy.scope():\n        #from tensorflow.python.client import device_lib\n        #print(device_lib.list_local_devices())\n        #batch_size = 8\n        #batch_size = batch_size * strategy.num_replicas_in_sync\n        batch_size = 32                       # the number of training examples in one forward/backward pass\n        num_classes = 10                        # number of cifar-10 dataset classes\n        epochs =20              # number of forward and backward passes of all the training examples\n\n        '''\n            dataset contains the hyper parameters for loading data and the dataset:\n                dataset = {\n                    'batch_size': batch_size,\n                    'num_classes': num_classes,\n                    'epochs': epochs,\n                    'x_train': x_train,\n                    'x_test': x_test,\n                    'y_train': y_train,\n                    'y_test': y_test\n                }\n        '''\n        dataset = load_dataset(batch_size, num_classes, epochs)\n\n        num_population = 10\n        num_generation = 20\n        num_offspring = 4\n\n        # plot the best model obtained\n        optCNN = genetic_algorithm(num_population, num_generation, num_offspring, dataset)\n\n        # plot the training and validation loss and accuracy\n        num_epoch = 20\n        model = optCNN.build_model()\n        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n        history = model.fit(dataset['x_train'],\n                            dataset['y_train'],\n                            batch_size=dataset['batch_size'],\n                            epochs=num_epoch,\n                            validation_data=(dataset['x_test'], dataset['y_test']),\n                            shuffle=True)\n        optCNN.model = model                                        # model\n        optCNN.fitness = history.history['val_loss'][-1]            # fitness\n\n        print(\"\\n\\n-------------------------------------\")\n        print(\"The Final CNN has been evolved successfully in the individual\", optCNN.name)\n        print(\"-------------------------------------\\n\")\n        daddy = load_network('parent_0')\n        model = tf.keras.models.load_model('parent_0.h5')\n        print(\"\\n\\n-------------------------------------\")\n        print(\"Summary of initial CNN\")\n        print(model.summary())\n        print(\"Fitness of initial CNN:\", daddy.fitness)\n\n        print(\"\\n\\n-------------------------------------\")\n        print(\"Summary of evolved individual\")\n        print(optCNN.model.summary())\n        print(\"Fitness of the evolved individual:\", optCNN.fitness)\n        print(\"-------------------------------------\\n\")\n\n        plot_training(history)\n\n\nif __name__ == '__main__':\n    main()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:34:10.099189Z","iopub.execute_input":"2024-03-19T09:34:10.099594Z","iopub.status.idle":"2024-03-19T09:34:10.118001Z","shell.execute_reply.started":"2024-03-19T09:34:10.099563Z","shell.execute_reply":"2024-03-19T09:34:10.116664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"## To remove a folder\n# Clear output folder\nimport os\n\ndef remove_folder_contents(folder):\n    for the_file in os.listdir(folder):\n        file_path = os.path.join(folder, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                remove_folder_contents(file_path)\n                os.rmdir(file_path)\n        except Exception as e:\n            print(e)\n\nfolder_path = '/kaggle/working'\nremove_folder_contents(folder_path)\nos.rmdir(folder_path)\"\"\"\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:34:11.054431Z","iopub.execute_input":"2024-03-19T09:34:11.054798Z","iopub.status.idle":"2024-03-19T09:34:11.061017Z","shell.execute_reply.started":"2024-03-19T09:34:11.054771Z","shell.execute_reply":"2024-03-19T09:34:11.059840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport tensorflow as tf\nimport numpy as np\n\n# Set the paths to the datasets\nimage_dir = '/kaggle/input/cifar100-20-classes-images/final'\ncsv_file = '/kaggle/input/cifar100captions-new/cifar100_20classes_mixing_new.csv'","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:15:47.789335Z","iopub.execute_input":"2024-04-15T16:15:47.790201Z","iopub.status.idle":"2024-04-15T16:15:47.794723Z","shell.execute_reply.started":"2024-04-15T16:15:47.790163Z","shell.execute_reply":"2024-04-15T16:15:47.793771Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"# Load the image and text data\nimage_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\ndata = pd.read_csv(csv_file)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:15:48.660768Z","iopub.execute_input":"2024-04-15T16:15:48.661113Z","iopub.status.idle":"2024-04-15T16:15:48.702111Z","shell.execute_reply.started":"2024-04-15T16:15:48.661085Z","shell.execute_reply":"2024-04-15T16:15:48.701182Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:15:49.489206Z","iopub.execute_input":"2024-04-15T16:15:49.489558Z","iopub.status.idle":"2024-04-15T16:15:49.500826Z","shell.execute_reply.started":"2024-04-15T16:15:49.489531Z","shell.execute_reply":"2024-04-15T16:15:49.499942Z"},"trusted":true},"execution_count":134,"outputs":[{"execution_count":134,"output_type":"execute_result","data":{"text/plain":"                                                 caption  class  \\\n0                            An apple on a wooden table.      0   \n1                   A juicy red apple in a fruit basket.      0   \n2                  An apple with a bite taken out of it.      0   \n3              A shiny green apple on a kitchen counter.      0   \n4        An apple orchard with trees full of ripe fruit.      0   \n...                                                  ...    ...   \n11976             A field of tulips in different colors.     92   \n11977               A colorful bouquet of mixed flowers.     92   \n11978     A single blue flower in a sea of green leaves.     92   \n11979             A garden bed full of blooming flowers.     92   \n11980  A bunch of daffodils announcing the arrival of...     92   \n\n                 filename  \n0         class_0_image_0  \n1         class_0_image_1  \n2         class_0_image_2  \n3         class_0_image_3  \n4         class_0_image_4  \n...                   ...  \n11976  class_92_image_594  \n11977  class_92_image_595  \n11978  class_92_image_596  \n11979  class_92_image_597  \n11980  class_92_image_598  \n\n[11981 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>class</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>An apple on a wooden table.</td>\n      <td>0</td>\n      <td>class_0_image_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A juicy red apple in a fruit basket.</td>\n      <td>0</td>\n      <td>class_0_image_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>An apple with a bite taken out of it.</td>\n      <td>0</td>\n      <td>class_0_image_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A shiny green apple on a kitchen counter.</td>\n      <td>0</td>\n      <td>class_0_image_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>An apple orchard with trees full of ripe fruit.</td>\n      <td>0</td>\n      <td>class_0_image_4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11976</th>\n      <td>A field of tulips in different colors.</td>\n      <td>92</td>\n      <td>class_92_image_594</td>\n    </tr>\n    <tr>\n      <th>11977</th>\n      <td>A colorful bouquet of mixed flowers.</td>\n      <td>92</td>\n      <td>class_92_image_595</td>\n    </tr>\n    <tr>\n      <th>11978</th>\n      <td>A single blue flower in a sea of green leaves.</td>\n      <td>92</td>\n      <td>class_92_image_596</td>\n    </tr>\n    <tr>\n      <th>11979</th>\n      <td>A garden bed full of blooming flowers.</td>\n      <td>92</td>\n      <td>class_92_image_597</td>\n    </tr>\n    <tr>\n      <th>11980</th>\n      <td>A bunch of daffodils announcing the arrival of...</td>\n      <td>92</td>\n      <td>class_92_image_598</td>\n    </tr>\n  </tbody>\n</table>\n<p>11981 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the LSTM and CNN models\nlstm_model = tf.keras.models.load_model('/kaggle/input/cifar100-20classes-lstm/cifar_100_20classes_net8_lstm.h5')\ncnn_model = tf.keras.models.load_model('/kaggle/input/cnn-models-fashion-cifar100/cifar_100_20classes_net13.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:15:50.364920Z","iopub.execute_input":"2024-04-15T16:15:50.365238Z","iopub.status.idle":"2024-04-15T16:15:50.932560Z","shell.execute_reply.started":"2024-04-15T16:15:50.365214Z","shell.execute_reply":"2024-04-15T16:15:50.931729Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom keras.utils import to_categorical\nfrom PIL import Image\n\ndef load_image(image_path, image_shape):\n    image = Image.open(image_path)\n    image = image.resize((image_shape[1], image_shape[0]))  # Resize to match the required shape\n    image = np.array(image) / 255.0  # Normalize pixel values to [0, 1]\n    return image","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:15:52.280921Z","iopub.execute_input":"2024-04-15T16:15:52.281715Z","iopub.status.idle":"2024-04-15T16:15:52.287350Z","shell.execute_reply.started":"2024-04-15T16:15:52.281682Z","shell.execute_reply":"2024-04-15T16:15:52.286334Z"},"trusted":true},"execution_count":136,"outputs":[]},{"cell_type":"code","source":"# Usage:\nimage_folder = '/kaggle/input/cifar100-20-classes-images/final'\ncaptions_df = pd.read_csv('/kaggle/input/cifar100captions-new/cifar100_20classes_mixing_new.csv')  # Assuming captions are stored in a CSV file\nnum_classes = 20  # Number of classes/categories\nimage_shape = (32, 32, 3)  # Define the shape of the images","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:15:52.888854Z","iopub.execute_input":"2024-04-15T16:15:52.889417Z","iopub.status.idle":"2024-04-15T16:15:52.913487Z","shell.execute_reply.started":"2024-04-15T16:15:52.889388Z","shell.execute_reply":"2024-04-15T16:15:52.912720Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"# Step 1: Load image data from the folder\nimages = []\nimage_filenames = []\nfor filename in os.listdir(image_folder):\n    if filename.endswith(\".jpg\"):  # Assuming images are in png format\n            image_path = os.path.join(image_folder, filename)\n            image = load_image(image_path, image_shape)\n            images.append(image)\n            image_filenames.append(os.path.splitext(filename)[0])  # Remove file extension\n\nimage_captions = []\nimage_classes = []","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:15:53.800932Z","iopub.execute_input":"2024-04-15T16:15:53.801721Z","iopub.status.idle":"2024-04-15T16:16:09.837463Z","shell.execute_reply.started":"2024-04-15T16:15:53.801689Z","shell.execute_reply":"2024-04-15T16:16:09.836079Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"image_classes","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:16:09.839105Z","iopub.execute_input":"2024-04-15T16:16:09.839786Z","iopub.status.idle":"2024-04-15T16:16:09.847827Z","shell.execute_reply.started":"2024-04-15T16:16:09.839748Z","shell.execute_reply":"2024-04-15T16:16:09.846867Z"},"trusted":true},"execution_count":139,"outputs":[{"execution_count":139,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"image_filenames[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:16:12.460974Z","iopub.execute_input":"2024-04-15T16:16:12.461420Z","iopub.status.idle":"2024-04-15T16:16:12.467639Z","shell.execute_reply.started":"2024-04-15T16:16:12.461389Z","shell.execute_reply":"2024-04-15T16:16:12.466600Z"},"trusted":true},"execution_count":140,"outputs":[{"execution_count":140,"output_type":"execute_result","data":{"text/plain":"'class_84_image_540'"},"metadata":{}}]},{"cell_type":"code","source":"filename","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:16:14.029136Z","iopub.execute_input":"2024-04-15T16:16:14.029720Z","iopub.status.idle":"2024-04-15T16:16:14.035277Z","shell.execute_reply.started":"2024-04-15T16:16:14.029691Z","shell.execute_reply":"2024-04-15T16:16:14.034312Z"},"trusted":true},"execution_count":141,"outputs":[{"execution_count":141,"output_type":"execute_result","data":{"text/plain":"'class_24_image_137.jpg'"},"metadata":{}}]},{"cell_type":"code","source":"\nclass_index = int(filename.split('_')[1])\nclass_index","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:16:14.220948Z","iopub.execute_input":"2024-04-15T16:16:14.221527Z","iopub.status.idle":"2024-04-15T16:16:14.226980Z","shell.execute_reply.started":"2024-04-15T16:16:14.221502Z","shell.execute_reply":"2024-04-15T16:16:14.225991Z"},"trusted":true},"execution_count":142,"outputs":[{"execution_count":142,"output_type":"execute_result","data":{"text/plain":"24"},"metadata":{}}]},{"cell_type":"code","source":"image_index = int(filename.split('_')[3].split('.')[0])\nimage_index","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:16:15.033314Z","iopub.execute_input":"2024-04-15T16:16:15.034197Z","iopub.status.idle":"2024-04-15T16:16:15.040303Z","shell.execute_reply.started":"2024-04-15T16:16:15.034165Z","shell.execute_reply":"2024-04-15T16:16:15.039332Z"},"trusted":true},"execution_count":143,"outputs":[{"execution_count":143,"output_type":"execute_result","data":{"text/plain":"137"},"metadata":{}}]},{"cell_type":"code","source":"image_filenames[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:16:15.348657Z","iopub.execute_input":"2024-04-15T16:16:15.348959Z","iopub.status.idle":"2024-04-15T16:16:15.355147Z","shell.execute_reply.started":"2024-04-15T16:16:15.348933Z","shell.execute_reply":"2024-04-15T16:16:15.354124Z"},"trusted":true},"execution_count":144,"outputs":[{"execution_count":144,"output_type":"execute_result","data":{"text/plain":"'class_84_image_540'"},"metadata":{}}]},{"cell_type":"code","source":"for filename in image_filenames:\n    #print(filename)\n    class_index = int(filename.split('_')[1])\n    #print(class_index)\n    image_index = int(filename.split('_')[3].split('.')[0])\n    #print(image_index)\n    row = captions_df[captions_df['filename'] == filename]\n    #print(row)\n    caption = row['caption']\n    image_captions.append(caption)\n    image_classes.append(class_index)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:16:16.730369Z","iopub.execute_input":"2024-04-15T16:16:16.731178Z","iopub.status.idle":"2024-04-15T16:16:45.571254Z","shell.execute_reply.started":"2024-04-15T16:16:16.731145Z","shell.execute_reply":"2024-04-15T16:16:45.570291Z"},"trusted":true},"execution_count":145,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\n\n# Display the image\nplt.imshow(images[2])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:16:48.400580Z","iopub.execute_input":"2024-04-15T16:16:48.400895Z","iopub.status.idle":"2024-04-15T16:16:48.589425Z","shell.execute_reply.started":"2024-04-15T16:16:48.400872Z","shell.execute_reply":"2024-04-15T16:16:48.588455Z"},"trusted":true},"execution_count":146,"outputs":[{"execution_count":146,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7d11d988cc70>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"image_captions[2]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:16:48.590856Z","iopub.execute_input":"2024-04-15T16:16:48.591117Z","iopub.status.idle":"2024-04-15T16:16:48.597674Z","shell.execute_reply.started":"2024-04-15T16:16:48.591094Z","shell.execute_reply":"2024-04-15T16:16:48.596838Z"},"trusted":true},"execution_count":147,"outputs":[{"execution_count":147,"output_type":"execute_result","data":{"text/plain":"10015    A tiger with a sense of pride in its posture.\nName: caption, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"image_classes[2]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:16:50.649271Z","iopub.execute_input":"2024-04-15T16:16:50.649624Z","iopub.status.idle":"2024-04-15T16:16:50.655332Z","shell.execute_reply.started":"2024-04-15T16:16:50.649597Z","shell.execute_reply":"2024-04-15T16:16:50.654492Z"},"trusted":true},"execution_count":148,"outputs":[{"execution_count":148,"output_type":"execute_result","data":{"text/plain":"88"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Assuming you have lists images, image_captions, and image_classes containing your data\n\n# Create an array of indices from 0 to the length of your data\nindices = np.arange(len(images))\n\n# Randomly select 20,000 indices for testing without replacement\ntesting_indices = np.random.choice(indices, size=2000, replace=False)\n\n# Use the remaining indices for training\ntraining_indices = np.setdiff1d(indices, testing_indices)\n\n# Use the selected indices to create the testing and training datasets\ntesting_cnn_data_selected = [images[i] for i in testing_indices]\ntraining_cnn_data_selected = [images[i] for i in training_indices]\n\ntesting_lstm_data_selected = [image_captions[i] for i in testing_indices]\ntraining_lstm_data_selected = [image_captions[i] for i in training_indices]\n\n# Create labels (y) for testing and training datasets\ntesting_labels = [image_classes[i] for i in testing_indices]\ntraining_labels = [image_classes[i] for i in training_indices]\n\n# Now testing_data_selected contains 20,000 randomly selected items for testing\n# and training_data_selected contains the remaining items for training\n# testing_labels and training_labels contain corresponding labels for testing and training datasets\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:16:52.261005Z","iopub.execute_input":"2024-04-15T16:16:52.261360Z","iopub.status.idle":"2024-04-15T16:16:52.314772Z","shell.execute_reply.started":"2024-04-15T16:16:52.261331Z","shell.execute_reply":"2024-04-15T16:16:52.314008Z"},"trusted":true},"execution_count":149,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\n\n# Display the image\nplt.imshow(training_cnn_data_selected[1])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:17:08.689204Z","iopub.execute_input":"2024-04-15T16:17:08.689566Z","iopub.status.idle":"2024-04-15T16:17:08.876542Z","shell.execute_reply.started":"2024-04-15T16:17:08.689536Z","shell.execute_reply":"2024-04-15T16:17:08.875663Z"},"trusted":true},"execution_count":150,"outputs":[{"execution_count":150,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7d11b7d3ceb0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxsklEQVR4nO3de3TU9Z3/8dfkMpP75EZukmAAARXBlgrmZ3WtsALd49HK7tG25yx2/enRRc8q223LnlZrd/fg2nNa2x6Kf6wr29+vqHVP0aNnq6tYwtoFW6gUURu5RAmSCwQyk0wyM8nM9/eHP7NNBX1/IPAh8fk4Z84hmTfvfL7z/c68883MvCYUBEEgAADOshzfCwAAfDIxgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXuT5XsAfy2azOnz4sEpLSxUKhXwvBwDgKAgC9ff3q6GhQTk5Jz/POecG0OHDh9XY2Oh7GQCA09TR0aGpU6ee9PozNoDWrVun7373u+rq6tL8+fP1ox/9SAsXLvzY/1daWipJavnzP1Fevm15RcVF5nVlkkPmWknKZEbMtUEm49Q7b8SegpSTdDsbzA3s9TUNdU69o5VlTvV11dXm2o5D7zn17uzsNtcuMhx/f6ihvspce+zYMafeHe/1ONUfS6TMtceTaafe2YKIubaj+5BT78IS+31zWl29U+9satBcW5oTduqdHuh3qj+vpsJcu+BT851679u711ybn++2neFce/0rv/pvc+3w8Ig2bdoy+nh+MmdkAD355JNavXq1HnnkES1atEgPP/ywli5dqra2NtXU1Hzk//3gz255+XnKC9uWlx/ON68tlLUPFEkKOcyUYMRtSOSF7AMoN3PmBlDY4faTpEjE7SAvKCg4Y73z8+1rLyi0r0OSiooKzbVDQ269IxH7g74khR1+WcnPOrVW1uE2z3W4vSUpz+HYCjsMQknKyH5fDjsOIA27HuP2tRcV248r197hsOsAcujtuO8lfezTKGfkRQjf+973dNttt+krX/mKLrroIj3yyCMqKirSv/7rv56JHwcAmIDGfQCl02nt3LlTS5Ys+Z8fkpOjJUuWaNu2bR+qT6VSisfjYy4AgMlv3AfQ0aNHlclkVFtbO+b7tbW16urq+lD92rVrFY1GRy+8AAEAPhm8vw9ozZo1isVio5eOjg7fSwIAnAXj/iKE6upq5ebmqrt77KuTuru7VVf34VdbRSIR5ydkAQAT37ifAYXDYS1YsECbN28e/V42m9XmzZvV0tIy3j8OADBBnZGXYa9evVorV67UZz7zGS1cuFAPP/ywEomEvvKVr5yJHwcAmIDOyAC66aabdOTIEd13333q6urSpZdequeff/5DL0wAAHxyhYIgsL/D7SyIx+OKRqNa8r+vM7+JrTBifxOg68TNkf1dfX29R5165wW55tqqSNSpdzKRNNce6XNbd0lpsVN989Qmc21Rkf2d85JUUmZ/B/r5TSePBDmRA/veMNfu3r3bqXd1vf02kaT+tP0d0cdT9tQESSqqrLT37nd7m0SkwOGNqHJ7s3XjFHtSxeymZqfeeYFbqkm0zH7cHuk67NT79T2/M9fm5ri9WXTGjFnm2vcOdZprU6m01v/o/ygWi6ms7OTJKd5fBQcA+GRiAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALw4I1lw46EvkVbesC0lKBYfNPctzHWL+whl7JEckTy3j5XIcYgeGXJYhyRlw/aYn7wie5SRJB06wQcLfpSeTnvUz+WXXe7U+8KLp5lrd+3a6dS7t8e+ndPOn+7Ue86ln3aqf/Y/XzTXxgaHnHr3DSXMteFw2Kl3PNZnrs0ZHnbqfVFtvbm2KM9t3YMD/U71bW/vM9ce7naL4oml0ubaeP9xp96Hj9v3fRDYH6+GjfuSMyAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF+dsFlyiP6HcfNvyUgl7blPeiD1XSZLmzpptri0pKnHq3fbmW+bautoap95BJmuuzQ3ZayWprrLCqX5mkz0n7cKZzU69j3YdMte+e8Ce1yVJ/TF7rtaUKVVOvXuPHXGqP3bcnqc3HLj9XllYUmquDaXd8toGenvNtYvmzXfqPbXGfp/ofLfDqfdQyp4vKUnvdNqPw1Qm5dQ7OWLLxJSkpENemyT19Q+YawsiRebakWFbdiVnQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAAL87ZKJ4i5SjXOB+n1k81973qM5c6rSOSa7+Jurvd4lXOu/JKc21xxG1XBQ6RQ5m0PY5DkvIc4z5qyqvNtUc62516Z3PtMSUXXWA/TiQpM1xnL851izPqO9rtVD931gXm2t5Ywql377E+c22QHXHqfeVlC8y1V3z6M069B2Jxc23vkR6n3u0d7zrV948kzbWZXLf7z3DIfowHOW7nFOFIobm2P2E/rjLDtuOEMyAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF+dsFtyFjY0KR8Km2k9deom5b4HcMrt+/8Yec23VlHqn3rMusOd7vf3mbqfeOdlBc219eYlT7/SQvbckKRUzl1ZFbfv8A/0ZezbZsFNnKTFk/x/FBcVOvSORiFN9eWm5uXZKhVteW6J6irk2Lz/XqXd9tT0H8JhjXlswkjHX9h476tT7nXfcMglV6HDcht0edkPGx0FJys13O65yHHIdU0n7/SEzQhYcAOAcNu4D6Nvf/rZCodCYy5w5c8b7xwAAJrgz8ie4iy++WC+99NL//JC8c/YvfQAAT87IZMjLy1NdncNnqQAAPnHOyHNAe/fuVUNDg6ZPn64vf/nLOnjw4ElrU6mU4vH4mAsAYPIb9wG0aNEibdiwQc8//7zWr1+v9vZ2XXnllerv7z9h/dq1axWNRkcvjY2N470kAMA5aNwH0PLly/UXf/EXmjdvnpYuXar/+I//UF9fn372s5+dsH7NmjWKxWKjl46OjvFeEgDgHHTGXx1QXl6uWbNmad++fSe8PhKJOL8nAgAw8Z3x9wENDAxo//79qq93e5MmAGByG/cB9NWvflWtra1655139N///d/6whe+oNzcXH3xi18c7x8FAJjAxv1PcIcOHdIXv/hF9fb2asqUKfrsZz+r7du3a8oUe9yHJC1pWaCiokJTrcsr5wb6jjmt44LmZnNtTn6BU+9Xtraaa491n/yVhCdy4bTzzLXT55zv1Pt3O3c61Z83a5a5NggXOfU+9PaJ/7R7Iq/uet2pd/cR+3FVWVbp1HtGk33/SFJhgf3P1EMOkSmSVFZuX3tVeZVT7yPd75lrs8NuEUJ5DhE19efVOPUeybnIqb433meuPRI77tQ7nbBHXw1mBpx6hyOl5toga48xC7K2mKRxH0BPPPHEeLcEAExCZMEBALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALw44x/HcKoOHjigAmP+VX5+vrlvtKTMaR2vv/WmufbtA+849Y45ZEItunSuU+/yCvt2HuvpceqdGow51ScG7NtZWOl2SObk2mvLHTLPJKmktNZcG3ZZiKT4MbdMwm6HPLD4gFseWH6ePWeuuKzYqXcmsGWCSZJC9qwxSQoX2LMXwxG3jMHGaec71X9qwaXm2oxCTr0PvWfP0/vVq79x6p2XYz8HOd5vP64yI7b9zhkQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMCLczaK51Bnj8JhW8ROgUMkx4tvtjqto+foEXNtUbTUqfef3XCdubYwL3DqffCdvebaQ3H7NkpSRYn99pakA+1vm2uD9w65rWVKk7l27swLnHr3x5Pm2uFUyqm3yt2OlUQiYa4tjMWdend1dZlrezuOOvXOBCPm2hzj/f0DFRUV9t4h++0nud0mklRVVWWunTVrjlPv2dOmmWsry+y3iSRt3vJf5toih/2TMUb8cAYEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8OKczYJLZYYVZGy17W3vmPseO3bMaR2FEXvu2WcunefU+9K5F5prO9oPOPWOltizxnJz3HLmKstLnOoHBu05XNlctzywgtyIuTYocNvOzNCwuTavOOrU+2hvr1P90JD9NiwvL3fqXT+1wVwbhLJOveOD/ebaopJip97dDjmN8WMDTr0jBWGn+qLCQnNtItbn1Ht3jz2XLi/ffn+QpIWfmm+uHUra8w7TqbT2bHv9Y+s4AwIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4cc5mwdXU1ZjzmKqrys19G6trndbRWDvFXHv4vXedeg91dZprC7NuGVx5WfvvFuVl9m2UpII8t8MmW2TPpyosdctUyy+ptBcPDDn17hm2Z3BFisqceue5Rd4pkDEYUVLI8V5dVGLPMSsuc8trm5JbZa4dztq3UZKyufZsv+Fht97hXLcbcerU88y10VLHzLtO+3F48FCHU+/0yEFzbUVltb1v2pajyBkQAMAL5wG0detWXXfddWpoaFAoFNLTTz895vogCHTfffepvr5ehYWFWrJkifbu3Tte6wUATBLOAyiRSGj+/Plat27dCa9/6KGH9MMf/lCPPPKIXn31VRUXF2vp0qVKJpOnvVgAwOTh/BzQ8uXLtXz58hNeFwSBHn74YX3zm9/U9ddfL0n6yU9+otraWj399NO6+eabT2+1AIBJY1yfA2pvb1dXV5eWLFky+r1oNKpFixZp27ZtJ/w/qVRK8Xh8zAUAMPmN6wDq6nr/1Rq1tWNfaVZbWzt63R9bu3atotHo6KWxsXE8lwQAOEd5fxXcmjVrFIvFRi8dHW4vIwQATEzjOoDq6uokSd3d3WO+393dPXrdH4tEIiorKxtzAQBMfuM6gJqbm1VXV6fNmzePfi8ej+vVV19VS0vLeP4oAMAE5/wquIGBAe3bt2/06/b2du3atUuVlZVqamrSPffco3/8x3/UBRdcoObmZn3rW99SQ0ODbrjhhvFcNwBggnMeQDt27NDnPve50a9Xr14tSVq5cqU2bNigr33ta0okErr99tvV19enz372s3r++edVUFDg9HPSw2mFjOdnjXX15r5XLFzotI7ezvfMtfHeXqfe9VPsETjDabconuFsrrk2v6jcqfeBd90ih6bPnmGuLSwqceodi9lfNVlWYI8EkqRwNmVfR7fbc5c5su8fSUoN2rezP37MqXe8r8dcW1hmj+2RpNSILZJFkpIjbu8VDEL22zAxOODUeyTP7Vh5s+135tqKqNvTDIURWySZJIXdlq3BwX5zbeehmLl2ZMQWfeQ8gK6++moFwckzmEKhkL7zne/oO9/5jmtrAMAniPdXwQEAPpkYQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC+co3jOloqiChUYs7umVNaY+/7y5Vandexve9Ncm07Zs8MkqWn2XHPtUI49D0qS8itP/PEXJ9IXcmqtkMPtLUmpvCJzbWGe23ZWlpSaa4vz3PL0ojOazLXDWbccs/6Rk8dZnXAtxfa7ame3WyZhRva1jIwMOvUOkglzbVmhW15kf8Ke71ZZ6haS5rh7VFhi759T4Nb8+KA926+81i1nrrqh3FybiNv3fTo9YqrjDAgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4MU5G8VzXn2Niops0Rz/9V9bzH1//9brTuvIjqTNtUUF9lgYSeobtEdb5Ba79e458q65trS4xKn39DkXO9XHjx0x1/YctddK0ozqqLk21efWuyTXHq8zpb7aqXdueYVT/dy5s8y1xx0iUySpLx4z1/b0dDn1jvf32Ytz3B6OMrJnSA0M26JhPuAWqiUlc+3xOkMZt+6lUfv9M1ru9jiROBY311bU29eRSg6b6jgDAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHhxzmbBvX1gtyKRsKn2nc63zX1Lamz5ch9Ip+030czmOU69U9msfR2DQ06902l7ht1wrls2VW+vW6ZaKGPLhZKkdMKeSyZJx3MHzLWFabfeyUy/uXYwYr+9JamswO13vyBjzxorcv21MpwxlzZfNNOp9Tvt+821/TH7vpSk/KJic206z+2h7kBvj1N9T8x+nyiosecXSlImz75/DvUdcuqd43Bc5WTtuXHptC17jzMgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAX52wUTzwRU2Qk31Q7+0J7PEgoL+S0jvy8QnPtBc1znXoXFdojOfa3v+vUu3na+ebawX57xIYkHel2iykJRuxRP7PPq3LqXR5Jmmu7O7udehc7RNTkxm3H6gfCVfYIFEkK5dtjZwpycp1679t30Fw7pbzSqffRri5zbUWxfRslKT1w3FxbXlXt1HtmnVt9ImuPbXrncIdT77yyUnNtboEtvuwDLo+GkfyIvW/IdgxyBgQA8IIBBADwwnkAbd26Vdddd50aGhoUCoX09NNPj7n+lltuUSgUGnNZtmzZeK0XADBJOA+gRCKh+fPna926dSetWbZsmTo7O0cvjz/++GktEgAw+Ti/CGH58uVavnz5R9ZEIhHV1dWd8qIAAJPfGXkOaMuWLaqpqdHs2bN15513qre396S1qVRK8Xh8zAUAMPmN+wBatmyZfvKTn2jz5s3653/+Z7W2tmr58uXKZE78kta1a9cqGo2OXhobG8d7SQCAc9C4vw/o5ptvHv33JZdconnz5mnGjBnasmWLFi9e/KH6NWvWaPXq1aNfx+NxhhAAfAKc8ZdhT58+XdXV1dq3b98Jr49EIiorKxtzAQBMfmd8AB06dEi9vb2qr68/0z8KADCBOP8JbmBgYMzZTHt7u3bt2qXKykpVVlbqgQce0IoVK1RXV6f9+/fra1/7mmbOnKmlS5eO68IBABOb8wDasWOHPve5z41+/cHzNytXrtT69eu1e/du/du//Zv6+vrU0NCga6+9Vv/wD/+gSMSeIyRJFeXVKnDMNbIoKS5yqs8G9pPEivIap96N05rNtSf7E+bJ5IbsOWb5+W45Zslk2qm+vqLcXDuz6Xyn3gPv/s5cmx6y58ZJUr5D/lpf2u2uVJrjljXWN2DPjqt1fA41ld9pX0fKLWeupr7JXJubTjj1LszY75sRjTj1rqtyy7wrLZplrq3sdMu86xm2rz02NOjUuzBiz7rMC9mP8VDIljLnPICuvvpqBcHJ7wwvvPCCa0sAwCcQWXAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC/G/fOAxsv0aTNVWFRgqu3stGdZpRIpp3WEC0rMtdGKKqfe0Qp73lTj+dOcend3d5try8vdcslqp7h93PqMenv/wc4DTr2TAwPm2lDILccsXGLP9sspneLUO6+k1qm+q7vDXFs04rad0+bMN9c21Eadeifjx821ie5+p95VxfYcs+SQ/TiRpHSf2+/mxWF7nuL8ZntunCTtO9Jnrh0sd2rtlNFZXm5vPjSYkvTLj63jDAgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4MU5G8Uzf+6nVFJSbKrtquky9z1wwC3qZUqdPXamoaHBqXf3kSPm2vNnXuDU++hxe6xJZb3bumc1ucUC9ex7w1xbUhh26t2XTpprQ/n22BFJqp8511x7fNgexSJJx4YyTvUzL7rYXFvbYI8QkqTSyFRzbX/Pe069wxF7lFWosMypd56GzbWlhUVOvY8dP+ZUnym2b+dIxu1hd87U6ebakgq3iKecPPv9LRy2RaNJ0sDAoO3nmzsCADCOGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC/O2Sy40MiwQiO2rKemhnpzX5daSSqvnmKuTWXd5vmO375mri0stuXifaDOIcOutKjQqXdP50Gn+trqUnNtzkDCqXcqPWSunTH7IqfeJVX2jLz+/qxT7/hg2ql+/qILzbXFJW6ZdwcPvG2u7Xz3sFPvaGnUXJsaOOrUO91vP1ZicbfeJZWVTvXJPPv9s3m6fV9KUn5Rubl2X3unU++mafacuVDWPi6GA1vWIWdAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvztkonnDOsCI5triS4dSguW9xsT0WRpJKC/LNtfvfanfqnejrN9fGe/uceodki8KQpPpStyie2c1ucUaZ2CFz7YG39zn1LiopMNfmFxU59d791l5zbTxwi79pPn+GU31Bfthc2763w6n3b3/zW3PteRVu9x/JFqclSYExvuUD9VNrzbXJd+yRTZIUH7KvW5Jq684z16bTbg+7uXn284Qct5tQRYVl9tpie204bItJ4gwIAOCF0wBau3atLrvsMpWWlqqmpkY33HCD2traxtQkk0mtWrVKVVVVKikp0YoVK9Td3T2uiwYATHxOA6i1tVWrVq3S9u3b9eKLL2p4eFjXXnutEon/Od2699579eyzz+qpp55Sa2urDh8+rBtvvHHcFw4AmNic/hj5/PPPj/l6w4YNqqmp0c6dO3XVVVcpFovp0Ucf1caNG3XNNddIkh577DFdeOGF2r59uy6//PLxWzkAYEI7reeAYrGYJKny/392xs6dOzU8PKwlS5aM1syZM0dNTU3atm3bCXukUinF4/ExFwDA5HfKAyibzeqee+7RFVdcoblz50qSurq6FA6HVV5ePqa2trZWXV1dJ+yzdu1aRaPR0UtjY+OpLgkAMIGc8gBatWqV9uzZoyeeeOK0FrBmzRrFYrHRS0eH20tIAQAT0ym9D+iuu+7Sc889p61bt2rq1Kmj36+rq1M6nVZfX9+Ys6Du7u6TfkR0JBJRJOL2HgoAwMTndAYUBIHuuusubdq0SS+//LKam5vHXL9gwQLl5+dr8+bNo99ra2vTwYMH1dLSMj4rBgBMCk5nQKtWrdLGjRv1zDPPqLS0dPR5nWg0qsLCQkWjUd16661avXq1KisrVVZWprvvvlstLS28Ag4AMIbTAFq/fr0k6eqrrx7z/ccee0y33HKLJOn73/++cnJytGLFCqVSKS1dulQ//vGPx2WxAIDJw2kABUHwsTUFBQVat26d1q1bd8qLkqThwT6lQylTbWGxPeOr0B7tJkkaTMTMtW+98bpT796eo+ba40ePOPWeMe3Ez7mdyPlVxU69s8ffc6o/3nXAXJsTuGVwpbIj9lrD8fuHDh2x3+Y98axT7xnTL3Cq//X235hrRxzzwGZdMNdcW5qbdOod77Jn++VF3J6S7u61339CEbdjPJV0O1YGM/YHlv6YWy5dXcSewXasz/54JUnJtC1vU5IiJfZnbDLGZ3fIggMAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeHFKH8dwNlSXFaq0xBaxE+TaN+NQx0GndRRV1JprY7HjTr3b3rJH98xssEfrSNKSRfPNtfn93U69OzvedqrPkz0uJ5Nyi3opiVaaa/uT9nVIUv+gPTIlJ6fQqfc77e1O9ZE8+0eWtPyvq51619aUm2vf3vUrp97xeJ+9ONHv1DsnsMcf5ZRUOPVODA441Q/32Y+VaKU9WkeStr5qj2FKJN1ifuaFw+baPXt/b1+H8b7DGRAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADAi3M2Cy5SXKaCkmJTbdfRXnPfIM+efSRJ+w4cMNe+3famU++6qlJz7eeXfNapd0muPfesq6vDqXeOAqf64cBen3HIPJOkknJ7Flw6p8Sp92WfnmGu7eg65tQ7dizmVD9jhn0thcUFTr3jibi5NuuQ6ydJOWH777i5gVtGWtwhe/G/Xt7u1PvdTrdcx/MvtGcvfnph1Kl3OhQy1+aE3e4/x2N95tp3DtpzNIeGUqY6zoAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF6cs1E8W3+7R0VFtkiR/sSguW9u2BbvM9o7Zo8pufwzn3LqPe+C6ebaKW7pKor3dppry6rtcTaS9Pa7/U71saQtlkOSCkrc4lgyskePnNfQ7NT7nYP2OJaXf/GiU+/EkP2YlaSunh5zbW6JWxxLPGbvXVtqj4WRpOYZM821qb4+p97prP0Ynz7HLYLr4oVVTvV9Dvvzt6/tcOvdZz8OCwsLnXqnW7eaaw8eskd2pdPDpjrOgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABenLNZcL9+bY8iEVt+UzozYu572cL/5bSOCy+ea65NxuyZTZI0lBgw1yYygVPvqto6c208mXTqnc51C6aL1tXbayvccunygnxzbSjXLQ8s6XC79B0/6tT7SK9bfSJlzyTs7Dvs1DsIhsy1Vy+c59S7MMd+3B7vPObUu6Rsirn2z2/6M6feQX6uU/1gKmGufedgu1Pv1177nbl2//79Tr07D9uPlZnN9uzKZDJtquMMCADghdMAWrt2rS677DKVlpaqpqZGN9xwg9ra2sbUXH311QqFQmMud9xxx7guGgAw8TkNoNbWVq1atUrbt2/Xiy++qOHhYV177bVKJMaeft52223q7OwcvTz00EPjumgAwMTn9BzQ888/P+brDRs2qKamRjt37tRVV101+v2ioiLV1dmfgwAAfPKc1nNAsVhMklRZOfaJ45/+9Keqrq7W3LlztWbNGg0OnvzDmlKplOLx+JgLAGDyO+VXwWWzWd1zzz264oorNHfu/7xS7Etf+pKmTZumhoYG7d69W1//+tfV1tamn//85yfss3btWj3wwAOnugwAwAR1ygNo1apV2rNnj1555ZUx37/99ttH/33JJZeovr5eixcv1v79+zVjxowP9VmzZo1Wr149+nU8HldjY+OpLgsAMEGc0gC666679Nxzz2nr1q2aOnXqR9YuWrRIkrRv374TDqBIJKJIxO0z7AEAE5/TAAqCQHfffbc2bdqkLVu2qLm5+WP/z65duyRJ9fX2NyMCACY/pwG0atUqbdy4Uc8884xKS0vV1dUlSYpGoyosLNT+/fu1ceNGff7zn1dVVZV2796te++9V1dddZXmzXN7BzUAYHJzGkDr16+X9P6bTf/QY489pltuuUXhcFgvvfSSHn74YSUSCTU2NmrFihX65je/OW4LBgBMDs5/gvsojY2Nam1tPa0FfWDevEtVVFRoqg2H7RlfdQ0NTuvIzw2ZaxMxt7y237y+21zbVGvPvZKkqcP2dduT9N5X3zjHqb7UId8tk8k69S7It+/7UMgt36uissxcu+zzi516xxxzA8OF9vy9cNS+bkk6//yPfh73DzVVR516v7J5s7m2vLDcqffcOns2WffRPqfeuQWOT48HKXNpJOzW+8I5s8y1M6d/+Hn2j3LsiP04rKyoNtcODtpyFMmCAwB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4ccqfB3SmlZQUmaN48vLsc3QklXBaR1mlPUbG9XOMDuzfa6793dvtTr1TQb65tqamxql3UaG9tyT19fWbawcGBpx658oeOVRVVeXUu8ohdubKKy5z6l1QYI8QkiTl22OE8orLnVq/99575tonn/x3p95D//9Tky2uuuLj0/X/UKSo2L6OVNqp92C8z6k+kz35pz5/SMgt/Molaiw3xy0OrLy83Fybzdpjsqy1nAEBALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvDhns+AG+o8rmxky1VZE7ZldORm3mdvdcdBcW1Pb4NR72rRZ5trK6ian3gWFEXNtNsct2y2TyTjVZ0eGzbUFYXvmmSQF9ngqjYy45YEVROx3j7xct9swm7XfJpJ07Mgxc21fe5dT7/+78Ulz7e5dO516//kXbjDXllW6ZfUFufb7cmLQLQPy0OEOp/rcPHsGW2VlhVPvQofsxd5jR5x6j6Ttd6CQ7PfNoeGUqY4zIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF+dsFE9ZaYmKiwpNtXk59oiI2LHjTuvIOkS9vDv0jlPvnLwCc224wB6tI0k9x+zRLfEch42U1Hz+VKf68vJyc21meMSpd8hh3w8lB516DybtcTn5DrEwkpTJ2KNbJKkgYrsvSNK7r+9x6n3okD1uauasC516l1VNsReHw069j/TZj3HX+KicHLf9mR+2x+Uc7bWvW3r/sdAqFAo59S4otB9XeXn2cRHKta2DMyAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAF+dsFtyxnuNKFg6Zavv6+sx9iwrtuUqSFInYM9iiFfZcJUnKzbPnNvUcfs+pdyKRMNcW1zrkdUkaGkw51Udy7IfZUMItry09Ys9rC+XZc+MkqbDYvj+TKbcMu+7DR53qk2n7bZ5MDTj1/tRn5ptrQ3lux3jKIZrssGNGWkHYvj/z3SLSlJVbVl8msP+A1LBb7xGHGLuSklKn3smU/bgaGOw31w4OJU11nAEBALxwGkDr16/XvHnzVFZWprKyMrW0tOgXv/jF6PXJZFKrVq1SVVWVSkpKtGLFCnV3d4/7ogEAE5/TAJo6daoefPBB7dy5Uzt27NA111yj66+/Xm+88YYk6d5779Wzzz6rp556Sq2trTp8+LBuvPHGM7JwAMDE5vQc0HXXXTfm63/6p3/S+vXrtX37dk2dOlWPPvqoNm7cqGuuuUaS9Nhjj+nCCy/U9u3bdfnll4/fqgEAE94pPweUyWT0xBNPKJFIqKWlRTt37tTw8LCWLFkyWjNnzhw1NTVp27ZtJ+2TSqUUj8fHXAAAk5/zAHr99ddVUlKiSCSiO+64Q5s2bdJFF12krq4uhcPhD336ZW1trbq6uk7ab+3atYpGo6OXxsZG540AAEw8zgNo9uzZ2rVrl1599VXdeeedWrlypd58881TXsCaNWsUi8VGLx0dHafcCwAwcTi/DygcDmvmzJmSpAULFug3v/mNfvCDH+imm25SOp1WX1/fmLOg7u5u1dXVnbRfJBJxeq8NAGByOO33AWWzWaVSKS1YsED5+fnavHnz6HVtbW06ePCgWlpaTvfHAAAmGaczoDVr1mj58uVqampSf3+/Nm7cqC1btuiFF15QNBrVrbfeqtWrV6uyslJlZWW6++671dLSwivgAAAf4jSAenp69Jd/+Zfq7OxUNBrVvHnz9MILL+hP//RPJUnf//73lZOToxUrViiVSmnp0qX68Y9/fEoLO3zwsAoiYVOtS8RKcijrtI7qmipzbcoh1kKSjsfs0SP9cbeYkhkXzDTXRkvLnXoPJ9220yUqaSRtj9aRpOGMPQKnrKLcqXcma49MyYTc/pgQOP71O5W0RxQVFhc49a6oiJprS6prnXpXVdeYa0ccj6tYvz1uKj/kdr93icmSpPyM/VgJhdx6p1L2+0Q4L9+pt9s67PsnnUqb6pzuBY8++uhHXl9QUKB169Zp3bp1Lm0BAJ9AZMEBALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8cE7DPtOC4P1Ii6QxykGSQiP2KJ5ce6kkaWgo6dDbrflgyt47mbTfHpI0OGjvnZcz5NR72DFyKGfEHpczkrbXStKIQxRPbthtO3OH7b0zcotXcdk/kttxmHSMtEk53NfyHHu7rNs1iiebttePnOEonhGnere1BA6RULmOMT/DGXvMz9CQ/fb+oPaDx/OTCQUfV3GWHTp0iA+lA4BJoKOjQ1OnTj3p9efcAMpmszp8+LBKS0vHhPbF43E1Njaqo6NDZWVlHld4ZrGdk8cnYRsltnOyGY/tDIJA/f39amhoUE7OyZ/pOef+BJeTk/ORE7OsrGxS7/wPsJ2TxydhGyW2c7I53e2MRj8+ZZ0XIQAAvGAAAQC8mDADKBKJ6P7771ckEvG9lDOK7Zw8PgnbKLGdk83Z3M5z7kUIAIBPhglzBgQAmFwYQAAALxhAAAAvGEAAAC8mzABat26dzj//fBUUFGjRokX69a9/7XtJ4+rb3/62QqHQmMucOXN8L+u0bN26Vdddd50aGhoUCoX09NNPj7k+CALdd999qq+vV2FhoZYsWaK9e/f6Wexp+LjtvOWWWz60b5ctW+Znsado7dq1uuyyy1RaWqqamhrdcMMNamtrG1OTTCa1atUqVVVVqaSkRCtWrFB3d7enFZ8ay3ZeffXVH9qfd9xxh6cVn5r169dr3rx5o282bWlp0S9+8YvR68/WvpwQA+jJJ5/U6tWrdf/99+u3v/2t5s+fr6VLl6qnp8f30sbVxRdfrM7OztHLK6+84ntJpyWRSGj+/Plat27dCa9/6KGH9MMf/lCPPPKIXn31VRUXF2vp0qVKJt2COn37uO2UpGXLlo3Zt48//vhZXOHpa21t1apVq7R9+3a9+OKLGh4e1rXXXqtEIjFac++99+rZZ5/VU089pdbWVh0+fFg33nijx1W7s2ynJN12221j9udDDz3kacWnZurUqXrwwQe1c+dO7dixQ9dcc42uv/56vfHGG5LO4r4MJoCFCxcGq1atGv06k8kEDQ0Nwdq1az2uanzdf//9wfz5830v44yRFGzatGn062w2G9TV1QXf/e53R7/X19cXRCKR4PHHH/ewwvHxx9sZBEGwcuXK4Prrr/eynjOlp6cnkBS0trYGQfD+vsvPzw+eeuqp0Zq33norkBRs27bN1zJP2x9vZxAEwZ/8yZ8Ef/M3f+NvUWdIRUVF8C//8i9ndV+e82dA6XRaO3fu1JIlS0a/l5OToyVLlmjbtm0eVzb+9u7dq4aGBk2fPl1f/vKXdfDgQd9LOmPa29vV1dU1Zr9Go1EtWrRo0u1XSdqyZYtqamo0e/Zs3Xnnnert7fW9pNMSi8UkSZWVlZKknTt3anh4eMz+nDNnjpqamib0/vzj7fzAT3/6U1VXV2vu3Llas2aNBgcHfSxvXGQyGT3xxBNKJBJqaWk5q/vynAsj/WNHjx5VJpNRbW3tmO/X1tbq97//vadVjb9FixZpw4YNmj17tjo7O/XAAw/oyiuv1J49e1RaWup7eeOuq6tLkk64Xz+4brJYtmyZbrzxRjU3N2v//v36+7//ey1fvlzbtm1z/gypc0E2m9U999yjK664QnPnzpX0/v4Mh8MqLy8fUzuR9+eJtlOSvvSlL2natGlqaGjQ7t279fWvf11tbW36+c9/7nG17l5//XW1tLQomUyqpKREmzZt0kUXXaRdu3adtX15zg+gT4rly5eP/nvevHlatGiRpk2bpp/97Ge69dZbPa4Mp+vmm28e/fcll1yiefPmacaMGdqyZYsWL17scWWnZtWqVdqzZ8+Ef47y45xsO2+//fbRf19yySWqr6/X4sWLtX//fs2YMeNsL/OUzZ49W7t27VIsFtO///u/a+XKlWptbT2razjn/wRXXV2t3NzcD70Co7u7W3V1dZ5WdeaVl5dr1qxZ2rdvn++lnBEf7LtP2n6VpOnTp6u6unpC7tu77rpLzz33nH75y1+O+diUuro6pdNp9fX1jamfqPvzZNt5IosWLZKkCbc/w+GwZs6cqQULFmjt2rWaP3++fvCDH5zVfXnOD6BwOKwFCxZo8+bNo9/LZrPavHmzWlpaPK7szBoYGND+/ftVX1/veylnRHNzs+rq6sbs13g8rldffXVS71fp/U/97e3tnVD7NggC3XXXXdq0aZNefvllNTc3j7l+wYIFys/PH7M/29radPDgwQm1Pz9uO09k165dkjSh9ueJZLNZpVKps7svx/UlDWfIE088EUQikWDDhg3Bm2++Gdx+++1BeXl50NXV5Xtp4+Zv//Zvgy1btgTt7e3Br371q2DJkiVBdXV10NPT43tpp6y/vz947bXXgtdeey2QFHzve98LXnvtteDdd98NgiAIHnzwwaC8vDx45plngt27dwfXX3990NzcHAwNDXleuZuP2s7+/v7gq1/9arBt27agvb09eOmll4JPf/rTwQUXXBAkk0nfSze78847g2g0GmzZsiXo7OwcvQwODo7W3HHHHUFTU1Pw8ssvBzt27AhaWlqClpYWj6t293HbuW/fvuA73/lOsGPHjqC9vT145plngunTpwdXXXWV55W7+cY3vhG0trYG7e3twe7du4NvfOMbQSgUCv7zP/8zCIKzty8nxAAKgiD40Y9+FDQ1NQXhcDhYuHBhsH37dt9LGlc33XRTUF9fH4TD4eC8884LbrrppmDfvn2+l3VafvnLXwaSPnRZuXJlEATvvxT7W9/6VlBbWxtEIpFg8eLFQVtbm99Fn4KP2s7BwcHg2muvDaZMmRLk5+cH06ZNC2677bYJ98vTibZPUvDYY4+N1gwNDQV//dd/HVRUVARFRUXBF77whaCzs9Pfok/Bx23nwYMHg6uuuiqorKwMIpFIMHPmzODv/u7vglgs5nfhjv7qr/4qmDZtWhAOh4MpU6YEixcvHh0+QXD29iUfxwAA8OKcfw4IADA5MYAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXvw/w4QuZ8tRb5MAAAAASUVORK5CYII="},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Sample testing_labels array\ntraining_labels = np.array(training_labels)\n\n# Define a mapping dictionary to map original labels to new labels (0 to 20)\nlabel_mapping = {}\nnew_label = 0\nfor label in sorted(np.unique(training_labels)):\n    label_mapping[label] = new_label\n    new_label += 1\n\n# Convert the testing_labels array using the mapping dictionary\nconverted_labels_training = np.array([label_mapping[label] for label in training_labels])\n\n# Print the converted labels\nprint(converted_labels_training)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:17:08.969107Z","iopub.execute_input":"2024-04-15T16:17:08.969813Z","iopub.status.idle":"2024-04-15T16:17:08.981686Z","shell.execute_reply.started":"2024-04-15T16:17:08.969785Z","shell.execute_reply":"2024-04-15T16:17:08.980669Z"},"trusted":true},"execution_count":151,"outputs":[{"name":"stdout","text":"[15 16  5 ... 18  1  8]\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Sample testing_labels array\ntesting_labels = np.array(testing_labels)\n\n# Define a mapping dictionary to map original labels to new labels (0 to 20)\nlabel_mapping = {}\nnew_label = 0\nfor label in sorted(np.unique(testing_labels)):\n    label_mapping[label] = new_label\n    new_label += 1\n\n# Convert the testing_labels array using the mapping dictionary\nconverted_labels_testing = np.array([label_mapping[label] for label in testing_labels])\n\n# Print the converted labels\nprint(converted_labels_testing)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:17:10.509279Z","iopub.execute_input":"2024-04-15T16:17:10.510225Z","iopub.status.idle":"2024-04-15T16:17:10.518091Z","shell.execute_reply.started":"2024-04-15T16:17:10.510191Z","shell.execute_reply":"2024-04-15T16:17:10.517007Z"},"trusted":true},"execution_count":152,"outputs":[{"name":"stdout","text":"[14 12 15 ...  7  7 15]\n","output_type":"stream"}]},{"cell_type":"code","source":"testing_labels[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:17:12.309041Z","iopub.execute_input":"2024-04-15T16:17:12.309389Z","iopub.status.idle":"2024-04-15T16:17:12.315397Z","shell.execute_reply.started":"2024-04-15T16:17:12.309360Z","shell.execute_reply":"2024-04-15T16:17:12.314490Z"},"trusted":true},"execution_count":153,"outputs":[{"execution_count":153,"output_type":"execute_result","data":{"text/plain":"array([78, 65, 84, 23, 36, 52, 92, 61, 90, 78])"},"metadata":{}}]},{"cell_type":"code","source":"converted_labels_testing[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:17:13.101052Z","iopub.execute_input":"2024-04-15T16:17:13.101608Z","iopub.status.idle":"2024-04-15T16:17:13.107898Z","shell.execute_reply.started":"2024-04-15T16:17:13.101579Z","shell.execute_reply":"2024-04-15T16:17:13.106783Z"},"trusted":true},"execution_count":154,"outputs":[{"execution_count":154,"output_type":"execute_result","data":{"text/plain":"array([14, 12, 15,  7,  9, 10, 19, 11, 17, 14])"},"metadata":{}}]},{"cell_type":"code","source":"testing_labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:17:16.001523Z","iopub.execute_input":"2024-04-15T16:17:16.002264Z","iopub.status.idle":"2024-04-15T16:17:16.008580Z","shell.execute_reply.started":"2024-04-15T16:17:16.002229Z","shell.execute_reply":"2024-04-15T16:17:16.007663Z"},"trusted":true},"execution_count":155,"outputs":[{"execution_count":155,"output_type":"execute_result","data":{"text/plain":"(2000,)"},"metadata":{}}]},{"cell_type":"code","source":"converted_labels_training[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:17:21.241117Z","iopub.execute_input":"2024-04-15T16:17:21.241764Z","iopub.status.idle":"2024-04-15T16:17:21.247579Z","shell.execute_reply.started":"2024-04-15T16:17:21.241733Z","shell.execute_reply":"2024-04-15T16:17:21.246609Z"},"trusted":true},"execution_count":156,"outputs":[{"execution_count":156,"output_type":"execute_result","data":{"text/plain":"array([15, 16,  5, 16, 11, 18, 13, 14, 15,  8])"},"metadata":{}}]},{"cell_type":"code","source":"training_lstm_data_selected[1]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:17:21.965279Z","iopub.execute_input":"2024-04-15T16:17:21.966034Z","iopub.status.idle":"2024-04-15T16:17:21.973588Z","shell.execute_reply.started":"2024-04-15T16:17:21.966001Z","shell.execute_reply":"2024-04-15T16:17:21.972503Z"},"trusted":true},"execution_count":157,"outputs":[{"execution_count":157,"output_type":"execute_result","data":{"text/plain":"10015    A tiger with a sense of pride in its posture.\nName: caption, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"## CNN ","metadata":{}},{"cell_type":"code","source":"# Convert labels to one-hot encoding\ntraining_labels=np.array(training_labels)\ntesting_labels=np.array(testing_labels)\ntraining_labels = tf.keras.utils.to_categorical(converted_labels_training, 20)\ntesting_labels = tf.keras.utils.to_categorical(converted_labels_testing, 20)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:17:44.022203Z","iopub.execute_input":"2024-04-15T16:17:44.022540Z","iopub.status.idle":"2024-04-15T16:17:44.029123Z","shell.execute_reply.started":"2024-04-15T16:17:44.022516Z","shell.execute_reply":"2024-04-15T16:17:44.028186Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_cnn_data_selected=np.array(training_cnn_data_selected)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:17:46.349479Z","iopub.execute_input":"2024-04-15T16:17:46.350153Z","iopub.status.idle":"2024-04-15T16:17:46.437565Z","shell.execute_reply.started":"2024-04-15T16:17:46.350122Z","shell.execute_reply":"2024-04-15T16:17:46.436639Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"code","source":"testing_cnn_data_selected=np.array(testing_cnn_data_selected)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:17:47.161032Z","iopub.execute_input":"2024-04-15T16:17:47.161478Z","iopub.status.idle":"2024-04-15T16:17:47.183827Z","shell.execute_reply.started":"2024-04-15T16:17:47.161430Z","shell.execute_reply":"2024-04-15T16:17:47.183092Z"},"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"code","source":"cnn_predictions = cnn_model.predict(testing_cnn_data_selected)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:17:48.921295Z","iopub.execute_input":"2024-04-15T16:17:48.922235Z","iopub.status.idle":"2024-04-15T16:17:49.341365Z","shell.execute_reply.started":"2024-04-15T16:17:48.922195Z","shell.execute_reply":"2024-04-15T16:17:49.340500Z"},"trusted":true},"execution_count":162,"outputs":[{"name":"stdout","text":"63/63 [==============================] - 0s 3ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#cnn_predictions","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:17:50.781508Z","iopub.execute_input":"2024-04-15T16:17:50.782311Z","iopub.status.idle":"2024-04-15T16:17:50.786116Z","shell.execute_reply.started":"2024-04-15T16:17:50.782278Z","shell.execute_reply":"2024-04-15T16:17:50.785112Z"},"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"training_cnn_data_selected.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:17:51.200748Z","iopub.execute_input":"2024-04-15T16:17:51.201481Z","iopub.status.idle":"2024-04-15T16:17:51.207107Z","shell.execute_reply.started":"2024-04-15T16:17:51.201452Z","shell.execute_reply":"2024-04-15T16:17:51.206202Z"},"trusted":true},"execution_count":164,"outputs":[{"execution_count":164,"output_type":"execute_result","data":{"text/plain":"(9984, 32, 32, 3)"},"metadata":{}}]},{"cell_type":"code","source":"training_cnn_data_selected.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:17:52.061238Z","iopub.execute_input":"2024-04-15T16:17:52.061603Z","iopub.status.idle":"2024-04-15T16:17:52.067581Z","shell.execute_reply.started":"2024-04-15T16:17:52.061575Z","shell.execute_reply":"2024-04-15T16:17:52.066739Z"},"trusted":true},"execution_count":165,"outputs":[{"execution_count":165,"output_type":"execute_result","data":{"text/plain":"(9984, 32, 32, 3)"},"metadata":{}}]},{"cell_type":"code","source":"cnn_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = cnn_model.fit(training_cnn_data_selected,\n                            training_labels,\n                            batch_size=32,\n                            epochs=30,\n                            validation_data=(testing_cnn_data_selected,testing_labels),\n                            shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:17:53.513298Z","iopub.execute_input":"2024-04-15T16:17:53.513977Z","iopub.status.idle":"2024-04-15T16:18:04.245489Z","shell.execute_reply.started":"2024-04-15T16:17:53.513944Z","shell.execute_reply":"2024-04-15T16:18:04.243918Z"},"trusted":true},"execution_count":166,"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"2024-04-15 16:17:54.863490: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_139/dropout_156/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"312/312 [==============================] - 4s 8ms/step - loss: 1.8092 - accuracy: 0.5223 - val_loss: 1.1888 - val_accuracy: 0.7030\nEpoch 2/30\n312/312 [==============================] - 2s 8ms/step - loss: 1.0876 - accuracy: 0.7337 - val_loss: 1.1166 - val_accuracy: 0.7225\nEpoch 3/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.9297 - accuracy: 0.7719 - val_loss: 1.1145 - val_accuracy: 0.7145\nEpoch 4/30\n169/312 [===============>..............] - ETA: 0s - loss: 0.8230 - accuracy: 0.8009","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[166], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cnn_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_cnn_data_selected\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtraining_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtesting_cnn_data_selected\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtesting_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1813\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1811\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m   1812\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m-> 1813\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m   1815\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/callbacks.py:1169\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/tf_utils.py:694\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/nest.py:631\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    547\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1066\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1066\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1068\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1106\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m-> 1106\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[1;32m   1107\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[1;32m   1108\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/tf_utils.py:687\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 687\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:394\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:360\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    359\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"predicted_labels = np.argmax(cnn_predictions, axis=1)\n\n# Calculate accuracy\ncnn_accuracy = np.mean(predicted_labels == testing_labels)\nprint(\"CNN Model Accuracy:\", cnn_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:00:25.911012Z","iopub.execute_input":"2024-04-15T16:00:25.911739Z","iopub.status.idle":"2024-04-15T16:00:26.285253Z","shell.execute_reply.started":"2024-04-15T16:00:25.911703Z","shell.execute_reply":"2024-04-15T16:00:26.284086Z"},"trusted":true},"execution_count":37,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[37], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(cnn_predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m cnn_accuracy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mpredicted_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtesting_labels\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN Model Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cnn_accuracy)\n","\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2000,) (2000,20) "],"ename":"ValueError","evalue":"operands could not be broadcast together with shapes (2000,) (2000,20) ","output_type":"error"}]},{"cell_type":"code","source":"df = pd.DataFrame({'caption': training_lstm_data_selected, 'class': training_labels})","metadata":{"execution":{"iopub.status.busy":"2024-04-15T16:01:20.570969Z","iopub.execute_input":"2024-04-15T16:01:20.571323Z","iopub.status.idle":"2024-04-15T16:01:21.391229Z","shell.execute_reply.started":"2024-04-15T16:01:20.571295Z","shell.execute_reply":"2024-04-15T16:01:21.389832Z"},"trusted":true},"execution_count":38,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcaption\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_lstm_data_selected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_labels\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:767\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    761\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    762\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    763\u001b[0m     )\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 767\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:664\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    662\u001b[0m         raw_lengths\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(val))\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: Per-column arrays must each be 1-dimensional"],"ename":"ValueError","evalue":"Per-column arrays must each be 1-dimensional","output_type":"error"}]},{"cell_type":"code","source":"df[20:30]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T08:50:05.937056Z","iopub.execute_input":"2024-04-15T08:50:05.937430Z","iopub.status.idle":"2024-04-15T08:50:05.952585Z","shell.execute_reply.started":"2024-04-15T08:50:05.937401Z","shell.execute_reply":"2024-04-15T08:50:05.951670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nfrom gensim.models import Word2Vec\n\ndef tokenize_text(text_data):\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(text_data)\n    return tokenizer\n\ndef train_word2vec(text_data, embedding_dim):\n    tokenized_text = [text.split() for text in text_data]\n    model = Word2Vec(sentences=tokenized_text, vector_size=embedding_dim, window=5, min_count=1, workers=4)\n    return model\n\ndef convert_text_to_vectors(text_data, word2vec_model, max_length):\n    vectors = []\n    for text in text_data:\n        words = text.split()\n        vec = []\n        for word in words:\n            if word in word2vec_model.wv:\n                vec.append(word2vec_model.wv[word])\n            else:\n                vec.append(np.zeros(word2vec_model.vector_size))  # Zero vector for out-of-vocabulary words\n        vectors.append(vec)\n    padded_vectors = pad_sequences(vectors, maxlen=max_length, padding='post')\n    return padded_vectors","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:45:51.554668Z","iopub.execute_input":"2024-03-21T14:45:51.555377Z","iopub.status.idle":"2024-03-21T14:45:51.564140Z","shell.execute_reply.started":"2024-03-21T14:45:51.555344Z","shell.execute_reply":"2024-03-21T14:45:51.563189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_words=10000\nembedding_dim=100\n\ntokenizer = tokenize_text(df['caption'].values)\nword2vec_model = train_word2vec(df['caption'].values, embedding_dim)\n\nmax_length = max(len(text.split()) for text in df['caption'].values)\n\n#x_vec = convert_text_to_vectors(df['caption'].values, word2vec_model, max_length)\n#class_mapping = {f'class_{i}': i for i in range(num_classes)}\n#df['class'] = df['class']\n\n#y = df['class'].values","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:45:53.634713Z","iopub.execute_input":"2024-03-21T14:45:53.635115Z","iopub.status.idle":"2024-03-21T14:45:54.714155Z","shell.execute_reply.started":"2024-03-21T14:45:53.635071Z","shell.execute_reply":"2024-03-21T14:45:54.713342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_train = convert_text_to_vectors(training_lstm_data_selected, word2vec_model, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:45:56.694645Z","iopub.execute_input":"2024-03-21T14:45:56.694998Z","iopub.status.idle":"2024-03-21T14:45:57.569712Z","shell.execute_reply.started":"2024-03-21T14:45:56.694972Z","shell.execute_reply":"2024-03-21T14:45:57.568922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_test = convert_text_to_vectors(testing_lstm_data_selected, word2vec_model, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:45:58.937648Z","iopub.execute_input":"2024-03-21T14:45:58.938380Z","iopub.status.idle":"2024-03-21T14:45:59.747078Z","shell.execute_reply.started":"2024-03-21T14:45:58.938347Z","shell.execute_reply":"2024-03-21T14:45:59.745983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_lstm_data_selected[2]","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:00.655214Z","iopub.execute_input":"2024-03-21T14:46:00.655699Z","iopub.status.idle":"2024-03-21T14:46:00.661467Z","shell.execute_reply.started":"2024-03-21T14:46:00.655669Z","shell.execute_reply":"2024-03-21T14:46:00.660568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_lstm_data_selected[0:2]","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:01.634690Z","iopub.execute_input":"2024-03-21T14:46:01.635351Z","iopub.status.idle":"2024-03-21T14:46:01.641625Z","shell.execute_reply.started":"2024-03-21T14:46:01.635320Z","shell.execute_reply":"2024-03-21T14:46:01.640656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_train=np.array(x_vec_train)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:02.779645Z","iopub.execute_input":"2024-03-21T14:46:02.780243Z","iopub.status.idle":"2024-03-21T14:46:02.842674Z","shell.execute_reply.started":"2024-03-21T14:46:02.780213Z","shell.execute_reply":"2024-03-21T14:46:02.841907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_test=np.array(x_vec_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:04.294656Z","iopub.execute_input":"2024-03-21T14:46:04.295536Z","iopub.status.idle":"2024-03-21T14:46:04.354746Z","shell.execute_reply.started":"2024-03-21T14:46:04.295502Z","shell.execute_reply":"2024-03-21T14:46:04.353720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_labels=np.array(training_labels)\ntesting_labels=np.array(testing_labels)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:08.669662Z","iopub.execute_input":"2024-03-21T14:46:08.670319Z","iopub.status.idle":"2024-03-21T14:46:08.678447Z","shell.execute_reply.started":"2024-03-21T14:46:08.670289Z","shell.execute_reply":"2024-03-21T14:46:08.677539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:10.154689Z","iopub.execute_input":"2024-03-21T14:46:10.155404Z","iopub.status.idle":"2024-03-21T14:46:10.173613Z","shell.execute_reply.started":"2024-03-21T14:46:10.155371Z","shell.execute_reply":"2024-03-21T14:46:10.172836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = lstm_model.fit(x_vec_train,\n                                training_labels,\n                                batch_size=32,\n                                epochs=1,\n                                validation_data=(x_vec_test,testing_labels),\n                                shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:11.554663Z","iopub.execute_input":"2024-03-21T14:46:11.555032Z","iopub.status.idle":"2024-03-21T14:46:22.387004Z","shell.execute_reply.started":"2024-03-21T14:46:11.555006Z","shell.execute_reply":"2024-03-21T14:46:22.386078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_predictions = lstm_model.predict(x_vec_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:27.194786Z","iopub.execute_input":"2024-03-21T14:46:27.195200Z","iopub.status.idle":"2024-03-21T14:46:29.654855Z","shell.execute_reply.started":"2024-03-21T14:46:27.195172Z","shell.execute_reply":"2024-03-21T14:46:29.654016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_labels = np.argmax(lstm_predictions, axis=1)\n\n# Calculate accuracy\nlstm_accuracy = np.mean(predicted_labels == testing_labels)\nprint(\"LSTM Model Accuracy:\", lstm_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:30.654923Z","iopub.execute_input":"2024-03-21T14:46:30.655259Z","iopub.status.idle":"2024-03-21T14:46:30.661512Z","shell.execute_reply.started":"2024-03-21T14:46:30.655234Z","shell.execute_reply":"2024-03-21T14:46:30.660534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(cnn_predictions)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:32.424701Z","iopub.execute_input":"2024-03-21T14:46:32.425095Z","iopub.status.idle":"2024-03-21T14:46:32.431215Z","shell.execute_reply.started":"2024-03-21T14:46:32.425061Z","shell.execute_reply":"2024-03-21T14:46:32.430314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(lstm_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:33.295312Z","iopub.execute_input":"2024-03-21T14:46:33.295675Z","iopub.status.idle":"2024-03-21T14:46:33.301948Z","shell.execute_reply.started":"2024-03-21T14:46:33.295647Z","shell.execute_reply":"2024-03-21T14:46:33.300887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LSTM is working and acc is 86.6%","metadata":{}},{"cell_type":"code","source":"# Step 5: Late Fusion Ensemble\nensemble_predictions = np.argmax(np.sum([cnn_predictions, lstm_predictions], axis=0), axis=1)\n\n# Step 6: Compare Predictions with Original Classes\naccuracy = np.mean(ensemble_predictions == testing_labels)\nprint(\"Ensemble Model Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:35.515217Z","iopub.execute_input":"2024-03-21T14:46:35.515937Z","iopub.status.idle":"2024-03-21T14:46:35.523656Z","shell.execute_reply.started":"2024-03-21T14:46:35.515905Z","shell.execute_reply":"2024-03-21T14:46:35.522651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AUTOMATE ENSEMBLE","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow as tf\n\n# Define the folder path\nfolder_path = '/kaggle/input/cnn-models/cnn'\n\n# Get a list of all files in the folder\nfile_list = os.listdir(folder_path)\n\n# Filter out only the .h5 files\nmodel_files = [file for file in file_list if file.endswith('.h5')]\n\n# Load each model\ncnn_models = []\nfor model_file in model_files[0:4]:\n    model_path = os.path.join(folder_path, model_file)\n    cnn_model = tf.keras.models.load_model(model_path)\n    cnn_models.append(cnn_model)\n\n# Now cnn_models list contains all the loaded CNN models\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:50.075341Z","iopub.execute_input":"2024-03-21T14:46:50.075701Z","iopub.status.idle":"2024-03-21T14:46:52.857385Z","shell.execute_reply.started":"2024-03-21T14:46:50.075672Z","shell.execute_reply":"2024-03-21T14:46:52.856344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train each model and track validation accuracy\nvalidation_accuracies = []\nfor lstm_model in top_lstm_models:\n    history = lstm_model.fit(x_vec_train,\n                             training_labels,\n                             batch_size=32,\n                             epochs=1,\n                             validation_data=(x_vec_test, testing_labels),\n                             shuffle=True)\n    \n    # Get the validation accuracy from the history\n    validation_accuracy = history.history['val_accuracy'][-1]\n    validation_accuracies.append(validation_accuracy)\n\n# Sort the models based on validation accuracy\nsorted_indices = sorted(range(len(validation_accuracies)), key=lambda i: validation_accuracies[i], reverse=True)\ntop_lstm_models = [lstm_models[i] for i in sorted_indices[:4]]  # Select the top 4 models\n\n# Train the top 4 LSTM models\nhistories = []\nfor lstm_model in top_lstm_models:\n    lstm_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    history = lstm_model.fit(x_vec_train,\n                             training_labels,\n                             batch_size=32,\n                             epochs=1,\n                             validation_data=(x_vec_test, testing_labels),\n                             shuffle=True)\n    histories.append(history)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:47:18.511846Z","iopub.execute_input":"2024-03-21T14:47:18.512756Z","iopub.status.idle":"2024-03-21T14:47:18.560206Z","shell.execute_reply.started":"2024-03-21T14:47:18.512723Z","shell.execute_reply":"2024-03-21T14:47:18.559035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the LSTM and CNN models\nlstm_model = tf.keras.models.load_model('/kaggle/input/lstm-parent-model-final/parent_0_model (1).h5')\ncnn_model = tf.keras.models.load_model('/kaggle/input/cnn-model-16layers/cnn_model_.h5')","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n# Assuming you have lists of predictions from the top LSTM and CNN models\ncnn_predictions = [model.predict(testing_cnn_data_selected) for model in cnn_models]\nlstm_predictions = [model.predict(x_vec_test) for model in top_lstm_models]\n\n# Combine predictions using majority voting\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:53:03.403505Z","iopub.execute_input":"2024-03-19T10:53:03.403861Z","iopub.status.idle":"2024-03-19T10:53:22.292528Z","shell.execute_reply.started":"2024-03-19T10:53:03.403834Z","shell.execute_reply":"2024-03-19T10:53:22.291675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Combine predictions using majority voting\ndef majority_voting(predictions):\n    combined_predictions = []\n    for sample_predictions in zip(*predictions):\n        sample_predictions_list = [tuple(prediction) for prediction in sample_predictions]\n        votes = Counter(sample_predictions_list)\n        majority_vote = votes.most_common(1)[0][0]\n        combined_predictions.append(majority_vote)\n    return combined_predictions\n\n\n\n\n# Combine LSTM and CNN predictions using majority voting\nensemble_predictions = majority_voting(lstm_predictions + cnn_predictions)\nensemble_classes = [prediction.index(max(prediction)) for prediction in ensemble_predictions]\n\n\npredicted_labels = np.argmax(lstm_predictions, axis=1)\n\n# Calculate accuracy\n#lstm_accuracy = np.mean(ensemble_predictions == testing_labels)\n#print(\"Ensemble Accuracy:\", lstm_accuracy)\n\n\n# Evaluate ensemble performance\nensemble_accuracy = accuracy_score(testing_labels, ensemble_classes)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:44:35.398346Z","iopub.execute_input":"2024-03-19T10:44:35.398744Z","iopub.status.idle":"2024-03-19T10:44:36.075712Z","shell.execute_reply.started":"2024-03-19T10:44:35.398715Z","shell.execute_reply":"2024-03-19T10:44:36.074856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.shape(lstm_predictions)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:55:15.363127Z","iopub.execute_input":"2024-03-19T10:55:15.363509Z","iopub.status.idle":"2024-03-19T10:55:15.370482Z","shell.execute_reply.started":"2024-03-19T10:55:15.363479Z","shell.execute_reply":"2024-03-19T10:55:15.369543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.shape(cnn_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:55:16.122988Z","iopub.execute_input":"2024-03-19T10:55:16.123352Z","iopub.status.idle":"2024-03-19T10:55:16.130424Z","shell.execute_reply.started":"2024-03-19T10:55:16.123323Z","shell.execute_reply":"2024-03-19T10:55:16.129477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_predictions","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:52:10.078728Z","iopub.execute_input":"2024-03-19T10:52:10.079125Z","iopub.status.idle":"2024-03-19T10:52:10.090250Z","shell.execute_reply.started":"2024-03-19T10:52:10.079096Z","shell.execute_reply":"2024-03-19T10:52:10.089236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Convert lists to NumPy arrays\nlstm_predictions_array = np.array(lstm_predictions)\ncnn_predictions_array = np.array(cnn_predictions)\n\n# Reshape LSTM and CNN predictions to (num_samples, sequence_length * num_classes)\nlstm_predictions_reshaped = lstm_predictions_array.reshape(lstm_predictions_array.shape[0], -1)\ncnn_predictions_reshaped = cnn_predictions_array.reshape(cnn_predictions_array.shape[0], -1)\n\n# Concatenate reshaped predictions\nx_train = np.concatenate((lstm_predictions_reshaped, cnn_predictions_reshaped), axis=1)\n\n# Assuming y_train contains ground truth labels with shape (num_samples,)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:59:20.963469Z","iopub.execute_input":"2024-03-19T10:59:20.964317Z","iopub.status.idle":"2024-03-19T10:59:20.972996Z","shell.execute_reply.started":"2024-03-19T10:59:20.964275Z","shell.execute_reply":"2024-03-19T10:59:20.972063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_predictions[0][0]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:24:14.712708Z","iopub.execute_input":"2024-03-19T11:24:14.713061Z","iopub.status.idle":"2024-03-19T11:24:14.720141Z","shell.execute_reply.started":"2024-03-19T11:24:14.713036Z","shell.execute_reply":"2024-03-19T11:24:14.718906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_pred = ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\n# Prepare Data\n# Assuming lstm_predictions, cnn_predictions, and correct_outputs contain the predictions and correct outputs\n# Concatenate LSTM and CNN predictions\nx_train = np.concatenate((lstm_predictions[0], cnn_predictions[0]), axis=1)\n\n# Calculate Weightage Distribution\n# For example, calculate the weightage based on accuracy\nlstm_accuracy = accuracy_score(lstm_predictions[0], testing_labels)\ncnn_accuracy = accuracy_score(cnn_predictions[0], testing_labels)\ntotal_accuracy = lstm_accuracy + cnn_accuracy\nlstm_weight = lstm_accuracy / total_accuracy\ncnn_weight = cnn_accuracy / total_accuracy\n\n# Prepare Target Weightage Distribution\ntarget_weightage = np.concatenate((lstm_weight, cnn_weight), axis=1)\n\n# Define Fusion Network Architecture\nfusion_network = tf.keras.Sequential([\n    tf.keras.layers.Dense(64, activation='relu', input_shape=(num_features,)),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(num_modalities, activation='softmax')  # Output layer for weightage distribution\n])\n\n# Compile Fusion Network\nfusion_network.compile(optimizer='adam', loss='categorical_crossentropy')\n\n# Train Fusion Network\nfusion_network.fit(x_train, target_weightage, epochs=10, batch_size=32, validation_split=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:23:48.952093Z","iopub.execute_input":"2024-03-19T11:23:48.952500Z","iopub.status.idle":"2024-03-19T11:23:49.046462Z","shell.execute_reply.started":"2024-03-19T11:23:48.952470Z","shell.execute_reply":"2024-03-19T11:23:49.045125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_classes = [prediction.index(max(prediction)) for prediction in ensemble_predictions]\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:35:02.178910Z","iopub.execute_input":"2024-03-19T10:35:02.179276Z","iopub.status.idle":"2024-03-19T10:35:02.204524Z","shell.execute_reply.started":"2024-03-19T10:35:02.179247Z","shell.execute_reply":"2024-03-19T10:35:02.203587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_classes[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:35:08.323066Z","iopub.execute_input":"2024-03-19T10:35:08.323779Z","iopub.status.idle":"2024-03-19T10:35:08.329716Z","shell.execute_reply.started":"2024-03-19T10:35:08.323742Z","shell.execute_reply":"2024-03-19T10:35:08.328534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CIFAR-10 class names\ncifar_10_classes = {\n    0: 'airplane',\n    1: 'automobile',\n    2: 'bird',\n    3: 'cat',\n    4: 'deer',\n    5: 'dog',\n    6: 'frog',\n    7: 'horse',\n    8: 'ship',\n    9: 'truck'\n}\n\n# Printing class names for the first 10 elements in image_classes\nprint(\"Class Names:\")\nfor class_index in image_classes[:10]:\n    print(cifar_10_classes[class_index])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T06:28:50.471687Z","iopub.execute_input":"2024-03-08T06:28:50.472061Z","iopub.status.idle":"2024-03-08T06:28:50.478728Z","shell.execute_reply.started":"2024-03-08T06:28:50.472033Z","shell.execute_reply":"2024-03-08T06:28:50.477485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_captions[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-03-08T06:25:59.692904Z","iopub.execute_input":"2024-03-08T06:25:59.693621Z","iopub.status.idle":"2024-03-08T06:25:59.700244Z","shell.execute_reply.started":"2024-03-08T06:25:59.693588Z","shell.execute_reply":"2024-03-08T06:25:59.699205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_classes[0:10]\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T06:26:19.538109Z","iopub.execute_input":"2024-03-08T06:26:19.538621Z","iopub.status.idle":"2024-03-08T06:26:19.546439Z","shell.execute_reply.started":"2024-03-08T06:26:19.538580Z","shell.execute_reply":"2024-03-08T06:26:19.545271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define the ensemble function\ndef ensemble(lstm_outputs, cnn_outputs):\n    # Add your ensemble code here\n    return lstm_outputs, cnn_outputs\n\n# Make predictions on the image and text data\nlstm_predictions = []\ncnn_predictions = []\nfor image_batch, text_batch in zip(image_generator, text_generator):\n    lstm_outputs = lstm_model.predict(text_batch)\n    cnn_outputs = cnn_model.predict(image_batch)\n    lstm_predictions.append(lstm_outputs)\n    cnn_predictions.append(cnn_outputs)\nlstm_predictions = np.vstack(lstm_predictions)\ncnn_predictions = np.vstack(cnn_predictions)\n\n# Ensemble the predictions using voting strategy\nensemble_predictions = ensemble(lstm_predictions, cnn_predictions)\n\n# Take the average of the probabilities from both models for each class\nensemble_predictions = (ensemble_predictions[0] + ensemble_predictions[1]) / 2\n\n# Select the class with the highest average probability as the final prediction\nfinal_predictions = np.argmax(ensemble_predictions, axis=1)","metadata":{},"execution_count":null,"outputs":[]}]}