{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7764647,"sourceType":"datasetVersion","datasetId":4541506},{"sourceId":7764682,"sourceType":"datasetVersion","datasetId":4541533},{"sourceId":7782124,"sourceType":"datasetVersion","datasetId":4554156},{"sourceId":7786353,"sourceType":"datasetVersion","datasetId":4557329},{"sourceId":7790157,"sourceType":"datasetVersion","datasetId":4559830},{"sourceId":7821267,"sourceType":"datasetVersion","datasetId":4582498},{"sourceId":7822287,"sourceType":"datasetVersion","datasetId":4583259},{"sourceId":7822850,"sourceType":"datasetVersion","datasetId":4583639},{"sourceId":8122636,"sourceType":"datasetVersion","datasetId":4799764},{"sourceId":8122723,"sourceType":"datasetVersion","datasetId":4799820},{"sourceId":8123082,"sourceType":"datasetVersion","datasetId":4800104},{"sourceId":8123791,"sourceType":"datasetVersion","datasetId":4800633},{"sourceId":8133541,"sourceType":"datasetVersion","datasetId":4807680},{"sourceId":8133742,"sourceType":"datasetVersion","datasetId":4807836},{"sourceId":8133790,"sourceType":"datasetVersion","datasetId":4807873}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### UTILITIES\nfrom keras.datasets import cifar10\nfrom keras.utils import to_categorical\nimport pickle\nimport sys\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nimport numpy as np\n\ndef load_dataset(batch_size, num_classes, epochs):\n    (x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n\n    # Select a random subset of 4500 images for training\n    random_indices = np.random.choice(len(x_train_full), size=50000, replace=False)\n    x_train = x_train_full[random_indices]\n    y_train = y_train_full[random_indices]\n\n    # Normalize and one-hot encode the labels\n    x_train = x_train.astype('float32') / 255\n    x_test = x_test.astype('float32') / 255\n    y_train = to_categorical(y_train, num_classes)\n    y_test = to_categorical(y_test, num_classes)\n\n    # Randomly select 500 images for validation\n    random_indices = np.random.choice(len(x_test), size=10000, replace=False)\n    x_val = x_test[random_indices]\n    y_val = y_test[random_indices]\n\n    dataset = {\n        'batch_size': batch_size,\n        'num_classes': num_classes,\n        'epochs': epochs,\n        'x_train': x_train,\n        'y_train': y_train,\n        'x_val': x_val,\n        'y_val': y_val,\n        'x_test': x_test,  \n        'y_test': y_test\n    }\n\n    return dataset\n\n\ndef save_network(network):\n    #object_file = open(network.name + '.obj', 'wb')\n    #pickle.dump(network, object_file)\n    #tf.keras.models.save_model(network, network.name)\n\n    model_path = network.name + '_model.h5'\n    tf.keras.models.save_model(network.model, model_path)\n\n    # Save the rest of the network information\n    network_info = {\n        'name': network.name,\n        'block_list': network.block_list,\n        'fitness': network.fitness\n    }\n    network_info_path = network.name + '_info.pkl'\n    with open(network_info_path, 'wb') as info_file:\n        pickle.dump(network_info, info_file)\n\n\ndef load_network(name):\n    model_path = name + '_model.h5'\n    loaded_model = tf.keras.models.load_model(model_path)\n\n    # Load the network information\n    info_path = name + '_info.pkl'\n    with open(info_path, 'rb') as info_file:\n        network_info = pickle.load(info_file)\n\n    # Create a new Network instance\n    loaded_network = Network(0)  # Update with appropriate 'it' value\n\n    # Set the attributes of the loaded network\n    loaded_network.name = network_info['name']\n    loaded_network.block_list = network_info['block_list']\n    loaded_network.fitness = network_info['fitness']\n    loaded_network.model = loaded_model\n\n    return loaded_network\n\n\n\ndef order_indexes(self):\n    i = 0\n    for block in self.block_list:\n        block.index = i\n        i += 1\n\n\ndef plot_training(history):                                           # plot diagnostic learning curves\n    plt.figure(figsize=[8, 6])  # accuracy curves\n    plt.plot(history.history['accuracy'], 'r', linewidth=3.0)\n    plt.plot(history.history['val_accuracy'], 'b', linewidth=3.0)  # <-- Change 'val_acc' to 'val_accuracy'\n    plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n    plt.xlabel('Epochs ', fontsize=16)\n    plt.ylabel('Accuracy', fontsize=16)\n    plt.title('Accuracy Curves', fontsize=16)\n\n    filename = sys.argv[0].split('/')[-1]\n    plt.savefig(filename + '_acc_plot.png')\n    plt.close()\n\n\n\ndef plot_statistics(stats):\n    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# fitness curves\n    plt.plot([s[0] for s in stats], 'r', linewidth=3.0)\n    plt.plot([stats[0][0]] * len(stats), 'b', linewidth=3.0)\n    plt.legend(['BestFitness', 'InitialFitness'], fontsize=18)\n    plt.xlabel('Generations', fontsize=16)\n    plt.ylabel('FitnessValue', fontsize=16)\n    plt.title('Fitness Curve', fontsize=16)\n    filename = sys.argv[0].split('/')[-1]\n    plt.savefig(filename + '_fitness_plot.png')\n\n    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# parameters curves\n    plt.plot([s[1] for s in stats], 'r', linewidth=3.0)\n    plt.plot([stats[0][1]] * len(stats), 'b', linewidth=3.0)\n    plt.legend(['BestParamsNum', 'InitialParamsNum'], fontsize=18)\n    plt.xlabel('Generations', fontsize=16)\n    plt.ylabel('ParamsNum', fontsize=16)\n    plt.title('Parameters Curve', fontsize=16)\n    filename = sys.argv[0].split('/')[-1]\n    plt.savefig(filename + '_params_plot.png')\n    plt.close()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:08.865544Z","iopub.execute_input":"2024-03-21T14:35:08.866376Z","iopub.status.idle":"2024-03-21T14:35:21.633023Z","shell.execute_reply.started":"2024-03-21T14:35:08.866339Z","shell.execute_reply":"2024-03-21T14:35:21.631981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INOUT\nimport os\ndef compute_parent(dataset):\n    if os.path.isfile('parent_0.h5'):\n        daddy = load_network('parent_0')\n        model = tf.keras.models.load_model('parent_0.h5')\n        print(\"Loading parent_0\")\n        print(\"SUMMARY OF\", daddy.name)\n        print(model.summary())\n        print(\"FITNESS:\", daddy.fitness)\n        return daddy\n\n    daddy = Network(0)\n    \n    \n    #INI BLOCK\n    layerList1 = [\n        Convolutional(filters=32, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(0, 0, layerList1, layerList2))\n    \n    #MIDDLE BLOCK 1\n    layerList1 = [\n        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 1, layerList1, layerList2))\n\n     #MIDDLE BLOCK 2\n    layerList1 = [\n        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 2, layerList1, layerList2))\n\n    \n    #MIDDLE BLOCK 3\n    layerList1 = [\n        Convolutional(filters=256, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=256, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 3, layerList1, layerList2))\n    \n    \n    \n    #MIDDLE BLOCK 4\n    layerList1 = [\n        Convolutional(filters=512, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=512, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 4, layerList1, layerList2))\n    \n    \n    \n    #FULLY CONNECTED LAYER\n    layerList1 = [\n        FlattenLayer(),\n        FullyConnected(units=128, num_classes=dataset['num_classes'])\n    ]\n    layerList2 = []\n    daddy.block_list.append(Block(2, 5, layerList1, layerList2))\n    \n    \n\n    model = daddy.build_model()\n    print(\"Type of model_final:\", type(model))\n    daddy.train_and_evaluate(model, dataset)\n    return daddy","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:25.599146Z","iopub.execute_input":"2024-03-21T14:35:25.599778Z","iopub.status.idle":"2024-03-21T14:35:25.621856Z","shell.execute_reply.started":"2024-03-21T14:35:25.599747Z","shell.execute_reply":"2024-03-21T14:35:25.620860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NETWORK\nimport tensorflow as tf\nimport os\nimport pickle\nfrom keras.callbacks import Callback\nfrom keras.models import Sequential\nfrom random import randint, choice\nfrom copy import deepcopy\n\n\nclass Network:\n    __slots__ = ('name', 'block_list', 'fitness', 'model')\n\n    def __init__(self, it):\n        self.name = 'parent_' + str(it) if it == 0 else 'net_' + str(it)\n        self.block_list = []\n        self.fitness = None\n        self.model = None\n\n    \"\"\"def build_model(self):\n        model = Sequential()                                # create model\n        for block in self.block_list:\n            for layer in block.get_layers():                # build model\n                try:\n                    layer.build_layer(model)\n                except:\n                    print(\"\\nINDIVIDUAL ABORTED, CREATING A NEW ONE\\n\")\n                    return -1\n        return model\"\"\"\n    def build_model(self):\n        model = Sequential()              \n        print(\"The block is:\")\n        print(self.block_list)                 # create model\n        for block in self.block_list:\n            #print(\"Building block type:\", block.type)\n            #print(\"TOTAL :::\")\n            #print(block.get_layer_name())\n            for layer in block.get_layers():                # build model\n                #print(\"Adding layer:\", layer.name)\n                try:\n                    layer.build_layer(model)\n                    print(\"Layer added successfully.\")\n                except Exception as e:\n                    print(\"Error occurred while adding layer:\", e)\n                    print(\"Returning None.\")\n                    return -1\n        print(\"Model successfully built.\")\n        return model\n\n    def train_and_evaluate(self, model, dataset):\n        print(\"Training\", self.name)\n        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n        try:\n            history = model.fit(dataset['x_train'],\n                                dataset['y_train'],\n                                batch_size=dataset['batch_size'],\n                                epochs=dataset['epochs'],\n                                validation_data=(dataset['x_val'], dataset['y_val']),\n                                shuffle=True)\n        except Exception as e:\n            print(\"An error occurred during model training:\", e)\n            return -1\n            # You can choose to handle the error in a specific way here, like logging it or taking corrective actions.\n\n\n        # Extract metrics from the training history\n        training_loss = history.history['loss'][-1]\n        training_accuracy = history.history['accuracy'][-1]\n        validation_loss = history.history['val_loss'][-1]\n        validation_accuracy = history.history['val_accuracy'][-1]\n\n        # Additional metrics (you can customize this based on your needs)\n        classification_error_rate = 1.0 - validation_accuracy\n\n        self.model = model  # Save the model\n        self.fitness = validation_loss  # Use validation loss as fitness\n\n        # Print metrics\n        print(\"SUMMARY OF\", self.name)\n        print(\"Training Loss:\", training_loss)\n        print(\"Training Accuracy:\", training_accuracy)\n        print(\"Validation Loss:\", validation_loss)\n        print(\"Validation Accuracy:\", validation_accuracy)\n        print(\"Classification Error Rate:\", classification_error_rate)\n\n        tf.keras.models.save_model(model, self.name + '.h5')         # save model\n        #model.save(self.name + '.h5')                       # save model\n        save_network(self)                                  # save topology, model and fitness\n\n    def asexual_reproduction(self, it, dataset):\n\n        # if the individual already exists, just load it\n        if os.path.isfile('net_' + str(it) + '.h5'):\n            print(\"\\n-------------------------------------\")\n            print(\"Loading individual net_\" + str(it))\n            print(\"--------------------------------------\\n\")\n            individual = load_network('net_' + str(it))\n            model = tf.keras.models.load_model(individual.name + '.h5')\n            print(\"SUMMARY OF\", individual.name)\n            print(model.summary())\n            print(\"FITNESS: \", individual.fitness)\n            return individual\n\n        # otherwise, create the individual by mutating the parent\n        individual = Network(it)\n\n        print(\"\\n-------------------------------------\")\n        print(\"\\nCreating individual\", individual.name)\n        print(\"--------------------------------------\\n\")\n\n        individual.block_list = deepcopy(self.block_list)           # copy the layer list from parent\n\n        print(\"----->Strong Mutation\")\n        individual.block_mutation(dataset)                          # mutate a block\n        individual.layer_mutation(dataset)                          # mutate a layer\n        individual.parameters_mutation()                            # mutate some parameters\n\n        model = individual.build_model()\n        \n        if model == -1:\n            return self.asexual_reproduction(it, dataset)\n        \n        if(individual.train_and_evaluate(model, dataset)==-1):\n            return self.asexual_reproduction(it, dataset)\n        else:\n            return individual\n            \n\n    def block_mutation(self, dataset):\n        try:\n            print(\"Block Mutation\")\n\n            print([(block.index, block.type) for block in self.block_list])\n\n            # block list containing all the blocks with type = 1\n            bl = [block.index for block in self.block_list if block.type == 1]\n\n            if len(bl) == 0:\n                print(\"Creating a new block with two Convolutional layers and a Pooling layer\")\n                self.block_list[1].index = 2\n                layerList1 = [\n                    Convolutional(filters=pow(2, randint(5, 8)),\n                                  filter_size=(3, 3),\n                                  stride_size=(1, 1),\n                                  padding='same',\n                                  input_shape=dataset['x_train'].shape[1:]),\n                    Convolutional(filters=pow(2, randint(5, 8)),\n                                  filter_size=(3, 3),\n                                  stride_size=(1, 1),\n                                  padding='same',\n                                  input_shape=dataset['x_train'].shape[1:])\n                ]\n                layerList2 = [\n                    Pooling(pool_size=(2, 2),\n                            stride_size=(2, 2),\n                            padding='same')\n                ]\n                b = Block(1, 1, layerList1, layerList2)\n                self.block_list.insert(1, b)\n                return\n\n            block_idx = randint(1, max(bl))         # pick a random block among all the blocks with type = 1\n            block_type_idx = randint(0, 1)          # 1 -> Conv2D; 0 -> Pooling or Dropout\n            mutation_type = randint(0, 1)           # 1 -> remove; 0 -> add\n\n            # list of layers of the selected block\n            layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n            length = len(layerList)\n\n            if mutation_type:                                       # remove\n                if length == 1:\n                    del self.block_list[block_idx]\n                elif block_type_idx:\n                    pos = randint(0, length - 1)\n                    print(\"Removing a Conv2D layer at\", pos)\n                    del layerList[pos]\n                else:\n                    pos = randint(0, length - 1)\n                    print(\"Removing a Pooling/Dropout layer at\", pos)\n                    del layerList[pos]\n            else:                                                   # add\n                if block_type_idx:\n                    print(\"Inserting a Convolutional layer\")\n                    layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                          filter_size=(3, 3),\n                                          stride_size=(1, 1),\n                                          padding='same',\n                                          input_shape=dataset['x_train'].shape[1:])\n                    layerList.insert(randint(0, length - 1), layer)\n                else:\n                    if randint(0, 1):                               # 1 -> Pooling; 0 -> Dropout\n                        print(\"Inserting a Pooling layer\")\n                        layer = Pooling(pool_size=(2, 2),\n                                        stride_size=(2, 2),\n                                        padding='same')\n                        layerList.insert(randint(0, length - 1), layer)\n                    else:\n                        print(\"Inserting a Dropout layer\")\n                        rate = choice([0.15, 0.25, 0.35, 0.50])\n                        layer = Dropout(rate=rate)\n                        layerList.insert(randint(0, length - 1), layer)\n        except Exception as e:\n            print(f\"An error occurred during block mutation: {e}\")\n            return None\n\n                    \n                    \n                    \n                    \n                    \n\n    \"\"\"def layer_mutation(self, dataset):\n        print(\"Layer Mutation\")\n\n        # pick a random block among all the blocks with type = 1\n        bl = [block.index for block in self.block_list if block.type == 1]\n\n        if len(bl) == 0:\n            return\n\n        block_idx = randint(1, max(bl))\n        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n\n        # list of layers of the selected block\n        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n\n        if len(layerList) == 0:\n            if block_type_idx:\n                layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                      filter_size=(3, 3),\n                                      stride_size=(1, 1),\n                                      padding='same',\n                                      input_shape=dataset['x_train'].shape[1:])\n                self.block_list[block_idx].layerList1.append(layer)\n                return\n            else:\n                layer = Pooling(pool_size=(2, 2),\n                                stride_size=(2, 2),\n                                padding='same')\n                self.block_list[block_idx].layerList2.append(layer)\n\n        idx = randint(0, len(layerList) - 1)\n        layer = layerList[idx]\n\n        if layer.name == 'Conv2D':\n            print(\"Splitting Conv2D layer at index\", idx)\n            layer.filters = int(layer.filters * 0.5)\n            layerList.insert(idx, deepcopy(layer))\n        elif layer.name == 'MaxPooling2D' or layer.name == 'AveragePooling2D':\n            print(\"Changing Pooling layer at index\", idx, \"with Conv2D layer\")\n            del layerList[idx]\n            conv_layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                       filter_size=(3, 3),\n                                       stride_size=(2, 2),\n                                       padding=layer.padding,\n                                       input_shape=dataset['x_train'].shape[1:])\n            layerList.insert(idx, conv_layer)\"\"\"\n    \n    def layer_mutation(self, dataset):\n        print(\"Layer Mutation\")\n\n        # Determine the maximum number of layers that can be added or removed\n        max_layers_to_add = 16 - sum(len(block.layerList1) + len(block.layerList2) for block in self.block_list)\n        max_layers_to_remove = sum(len(block.layerList1) + len(block.layerList2) - 1 for block in self.block_list)\n\n        if max_layers_to_add == 0 and max_layers_to_remove == 0:\n            return\n\n        # Pick a random block among all the blocks with type = 1\n        bl = [block.index for block in self.block_list if block.type == 1]\n\n        if len(bl) == 0:\n            return\n\n        block_idx = randint(1, max(bl))\n        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n\n        # List of layers of the selected block\n        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n\n        if len(layerList) == 0:\n            if block_type_idx:\n                layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                      filter_size=(3, 3),\n                                      stride_size=(1, 1),\n                                      padding='same',\n                                      input_shape=dataset['x_train'].shape[1:])\n                self.block_list[block_idx].layerList1.append(layer)\n            else:\n                layer = Pooling(pool_size=(2, 2),\n                                stride_size=(2, 2),\n                                padding='same')\n                self.block_list[block_idx].layerList2.append(layer)\n        else:\n            # Randomly choose whether to add or remove a layer\n            add_layer = bool(randint(0, 1))\n\n            if add_layer and max_layers_to_add > 0:\n                # Add a layer\n                layer = self.create_random_layer(dataset)\n                layerList.insert(randint(0, len(layerList)), layer)\n            elif not add_layer and max_layers_to_remove > 0:\n                # Remove a layer\n                idx = randint(0, len(layerList) - 1)\n                del layerList[idx]\n\n        # Ensure the total number of layers in the block doesn't exceed 16\n        if len(self.block_list[block_idx].layerList1) + len(self.block_list[block_idx].layerList2) > 16:\n            # Remove a random layer to maintain the total count of 16 layers\n            block_layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n            del block_layerList[randint(0, len(block_layerList) - 1)]\n\n    def create_random_layer(self, dataset):\n        # Create a random layer (Conv2D or Pooling)\n        if randint(0, 1):\n            # Conv2D layer\n            return Convolutional(filters=pow(2, randint(5, 8)),\n                                 filter_size=(3, 3),\n                                 stride_size=(1, 1),\n                                 padding='same',\n                                 input_shape=dataset['x_train'].shape[1:])\n        else:\n            # Pooling layer\n            return Pooling(pool_size=(2, 2),\n                           stride_size=(2, 2),\n                           padding='same')\n\n            \n            \n            \n            \n            \n            \n            \n            \n\n    def parameters_mutation(self):\n        print(\"Parameters Mutation\")\n        for block in self.block_list:\n            for layer in block.get_layers():\n                if randint(0, 1):\n                    layer.mutate_parameters()\n\n    def save_network_info(self, info_filename):\n        network_info = {\n            'name': self.name,\n            'block_list': self.block_list,\n            'fitness': self.fitness\n        }\n\n        with open(info_filename, 'wb') as info_file:\n            pickle.dump(network_info, info_file)\n\n    def load_network_info(self, info_filename):\n        with open(info_filename, 'rb') as info_file:\n            network_info = pickle.load(info_file)\n\n        self.name = network_info['name']\n        self.block_list = network_info['block_list']\n        self.fitness = network_info['fitness']\n\n    def save_model(self, model_filename):\n        self.model.save(model_filename)\n\n    def load_model(self, model_filename):\n        self.model = tf.keras.models.load_model(model_filename)\n\n    def save_network(self, network_info_filename, model_filename):\n        # Save non-model attributes\n        self.save_network_info(network_info_filename)\n\n        # Save the model separately\n        self.save_model(model_filename)\n\n    def load_network(self, network_info_filename, model_filename):\n        # Load non-model attributes\n        self.load_network_info(network_info_filename)\n\n        # Load the model separately\n        self.load_model(model_filename)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:27.022012Z","iopub.execute_input":"2024-03-21T14:35:27.022374Z","iopub.status.idle":"2024-03-21T14:35:27.078711Z","shell.execute_reply.started":"2024-03-21T14:35:27.022345Z","shell.execute_reply":"2024-03-21T14:35:27.077468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TOPOLOGY\n\nimport keras.layers\nfrom random import randint\n\n\nclass Block:\n\t__slots__ = ('type', 'index', 'layerList1', 'layerList2')\n\n\tdef __init__(self, type, index, layerList1, layerList2):\n\t\tself.type = type\t\t\t\t\t\t\t\t\t\t# 0 -> initial layer; 1 -> mid layers; 2 -> final layer\n\t\tself.index = index\t\t\t\t\t\t\t\t\t\t# block index among all the blocks\n\t\tself.layerList1 = layerList1\t\t\t\t\t\t\t# Convolutional layers\n\t\tself.layerList2 = layerList2\t\t\t\t\t\t\t# Pooling and Dropout layers\n\n\tdef get_layers(self):\n\t\treturn self.layerList1 + self.layerList2\n\n\tdef get_size(self):\n\t\treturn len(self.get_layers())\n\n\nclass Convolutional:\n\t# __slots__ = ('name', 'filters', 'padding', 'filter_size', 'stride_size', 'input_shape')\n\n\tdef __init__(self, filters, padding, filter_size, stride_size, input_shape):\n\t\tself.name = 'Conv2D'\n\t\tself.filters = filters\n\t\tself.padding = padding\n\t\tself.filter_size = filter_size\n\t\tself.stride_size = stride_size\n\t\tself.input_shape = input_shape\n\n\tdef build_layer(self, model):\n\t\ttry:\n\t\t\tmodel.add(keras.layers.Conv2D(filters=self.filters,\n\t\t\t\t\t\t\t\t\t\t\tkernel_size=self.filter_size,\n\t\t\t\t\t\t\t\t\t\t\tstrides=self.stride_size,\n\t\t\t\t\t\t\t\t\t\t\tpadding=self.padding,\n\t\t\t\t\t\t\t\t\t\t\tactivation='relu',\n\t\t\t\t\t\t\t\t\t\t\tkernel_initializer='he_uniform',\n\t\t\t\t\t\t\t\t\t\t\tinput_shape=self.input_shape))\n\t\texcept ValueError as e:\n\t\t\tprint(\"Error occurred while adding layer:\", e)\n\t\t\tprint(\"Skipping current architecture.\")\n\t\t\treturn  # Skip adding this layer\n\tdef mutate_parameters(self):\n\t\tmutation = randint(0, 2)  # Adjusted the number of mutations\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tif mutation == 0 and self.filters >= 64:  # Adjusted the filter reduction threshold\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters = int(self.filters / 2)\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 1 and self.filters <= 256:  # Adjusted the filter increase threshold\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters *= 2\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 2:\n\t\t\tif self.padding == 'valid':\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'same'\n\t\t\t\tprint(\"to \", self.padding)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'valid'\n\t\t\t\tprint(\"to \", self.padding)\n\n        \n\n        \n\n\n\t\"\"\"def mutate_parameters(self):\n\t\tmutation = randint(0, 4)\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tif mutation == 0 and self.filters >= 32:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters = int(self.filters / 2)\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 1 and self.filters >= 32:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters = int(self.filters / 2)\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 2 and self.filters <= 512:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters *= 2\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 3 and self.filters <= 512:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters *= 2\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 4:\n\t\t\tif self.padding == 'valid':\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'same'\n\t\t\t\tprint(\"to \", self.padding)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'valid'\n\t\t\t\tprint(\"to \", self.padding)\n\"\"\"\n    \n\n'''\nelif mutation is 4:\n\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n\tprint(\"to \", self.stride_size, \" and \", end=\"\")\n\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n\tprint(\"to \", self.stride_size)\n'''\n\n\nclass Pooling:\n\t__slots__ = ('name', 'pool_size', 'stride_size', 'padding')\n\n\tdef __init__(self, pool_size, stride_size, padding):\n\t\tself.name = 'MaxPooling2D'\n\t\tself.pool_size = pool_size\n\t\tself.stride_size = stride_size\n\t\tself.padding = padding\n\n\tdef build_layer(self, model):\n\t\tif self.name == 'MaxPooling2D':\n\t\t\tmodel.add(keras.layers.MaxPooling2D(self.pool_size, self.stride_size, self.padding))\n\t\telif self.name == 'AveragePooling2D':\n\t\t\tmodel.add(keras.layers.AveragePooling2D(self.pool_size, self.stride_size, self.padding))\n\n\tdef mutate_parameters(self):\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tmutation = randint(0, 1)\n\t\tif mutation == 0:\n\t\t\tif self.padding == 'valid':\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'same'\n\t\t\t\tprint(\"to \", self.padding)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'valid'\n\t\t\t\tprint(\"to \", self.padding)\n\t\telif mutation == 1:\n\t\t\tif self.name == 'MaxPooling2D':\n\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n\t\t\t\tself.name = 'AveragePooling2D'\n\t\t\t\tprint(\"to \", self.name)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n\t\t\t\tself.name = 'MaxPooling2D'\n\t\t\t\tprint(\"to \", self.name)\n\n\n'''\nif mutation is 0:\n\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n\tprint(\"to \", self.stride_size)\n'''\n\n\nclass FullyConnected:\n\t__slots__ = ('name', 'units', 'num_classes')\n\n\tdef __init__(self, units, num_classes):\n\t\tself.name = \"FullyConnected\"\n\t\tself.units = units\n\t\tself.num_classes = num_classes\n\n\tdef build_layer(self, model):\n\t\tmodel.add(keras.layers.Flatten())\n\t\tmodel.add(keras.layers.Dense(self.units, activation='relu', kernel_initializer='he_uniform'))\n\t\tmodel.add(keras.layers.Dense(self.num_classes, activation='softmax'))\n\n\tdef mutate_parameters(self):\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tmutation = randint(0, 2)\n\t\tif mutation == 0:\n\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n\t\t\tself.units *= 2\n\t\t\tprint(\"to \", self.units)\n\t\telif mutation == 1:\n\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n\t\t\tself.units *= 2\n\t\t\tprint(\"to \", self.units)\n\t\telif mutation == 2:\n\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n\t\t\tself.units /= 2\n\t\t\tprint(\"to \", self.units)\n\n\n'''\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(self.num_classes, activation='softmax'))\n'''\n\n\nclass Dropout:\n\t__slots__ = ('name', 'rate')\n\n\tdef __init__(self, rate):\n\t\tself.name = \"Dropout\"\n\t\tself.rate = rate\n\n\tdef build_layer(self, model):\n\t\tmodel.add(keras.layers.Dropout(self.rate))\n\n\tdef mutate_parameters(self):\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tmutation = randint(0, 3)\n\t\tif mutation == 0 and self.rate <= 0.85:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate + 0.10\n\t\t\tprint(\"to \", self.rate)\n\t\telif mutation == 1 and self.rate <= 0.90:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate + 0.05\n\t\t\tprint(\"to \", self.rate)\n\t\telif mutation == 2 and self.rate >= 0.15:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate - 0.10\n\t\t\tprint(\"to \", self.rate)\n\t\telif mutation == 3 and self.rate >= 0.10:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate - 0.05\n\t\t\tprint(\"to \", self.rate)\n\nclass FlattenLayer:\n    def __init__(self):\n        self.name = 'Flatten'\n\n    def build_layer(self, model):\n        model.add(keras.layers.Flatten())\n\n    def mutate_parameters(self):\n        # The Flatten layer does not have any parameters to mutate\n        pass\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:28.087245Z","iopub.execute_input":"2024-03-21T14:35:28.087711Z","iopub.status.idle":"2024-03-21T14:35:28.125784Z","shell.execute_reply.started":"2024-03-21T14:35:28.087683Z","shell.execute_reply":"2024-03-21T14:35:28.124727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"# MAIN\n\nimport tensorflow as tf\ntf.compat.v1.enable_eager_execution()\nimport os\nfrom copy import deepcopy\nfrom random import sample\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)      # suppress messages from Tensorflow\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\n\ndef initialize_population(population_size, dataset):\n    print(\"----->Initializing Population\")\n    daddy = compute_parent(dataset)                                 # load parent from input\n    population = [daddy]\n    for it in range(1, population_size):\n        population.append(daddy.asexual_reproduction(it, dataset))\n\n    # sort population on ascending order based on fitness\n    return sorted(population, key=lambda cnn: cnn.fitness)\n\n\ndef selection(k, population, num_population):\n    if k == 0:                                              # elitism selection\n        print(\"----->Elitism selection\")\n        return population[0], population[1]\n    elif k == 1:                                            # tournament selection\n        print(\"----->Tournament selection\")\n        i = randint(0, num_population - 1)\n        j = i\n        while j < num_population - 1:\n            j += 1\n            if randint(1, 100) <= 50:\n                return population[i], population[j]\n        return population[i], population[0]\n    else:                                                   # proportionate selection\n        print(\"----->Proportionate selection\")\n        cum_sum = 0\n        for i in range(num_population):\n            cum_sum += population[i].fitness\n        perc_range = []\n        for i in range(num_population):\n            count = 100 - int(100 * population[i].fitness / cum_sum)\n            for j in range(count):\n                perc_range.append(i)\n        i, j = sample(range(1, len(perc_range)), 2)\n        while i == j:\n            i, j = sample(range(1, len(perc_range)), 2)\n        return population[perc_range[i]], population[perc_range[j]]\n\n\ndef crossover(parent1, parent2, it):\n    print(\"----->Crossover\")\n    child = Network(it)\n\n    first, second = None, None\n    if randint(0, 1):\n        first = parent1\n        second = parent2\n    else:\n        first = parent2\n        second = parent1\n\n    child.block_list = deepcopy(first.block_list[:randint(1, len(first.block_list) - 1)]) \\\n                       + deepcopy(second.block_list[randint(1, len(second.block_list) - 1):])\n\n    order_indexes(child)                            # order the indexes of the blocks\n\n    return child\n\n\ndef genetic_algorithm(num_population, num_generation, num_offspring, dataset, early_stopping_generations=3):\n    print(\"Genetic Algorithm\")\n\n    population = initialize_population(num_population, dataset)\n\n    print(\"\\n-------------------------------------\")\n    print(\"Initial Population:\")\n    for cnn in population:\n        print(cnn.name, ': ', cnn.fitness)\n    print(\"--------------------------------------\\n\")\n\n    # for printing statistics about fitness and the number of parameters of the best individual\n    stats = [(population[0].fitness, population[0].model.count_params())]\n\n    # Initialize a variable to keep track of consecutive generations with the same best fitness\n    consecutive_same_fitness = 0\n\n    for gen in range(1, num_generation + 1):\n        '''\n            k is the selection parameter:\n                k = 0 -> elitism selection\n                k = 1 -> tournament selection\n                k = 2 -> proportionate selection\n        '''\n        k = randint(0, 2)\n\n        print(\"\\n------------------------------------\")\n        print(\"Generation -----------------------------------------------------------------------------------\", gen)\n        print(\"-------------------------------------\")\n\n        for c in range(num_offspring):\n\n            print(\"\\nCreating Child\", c)\n\n            parent1, parent2 = selection(k, population, num_population)                 # selection\n            print(\"Selected\", parent1.name, \"and\", parent2.name, \"for reproduction\")\n\n            child = crossover(parent1, parent2, c + num_population)                     # crossover\n            print(\"Child has been created\")\n\n            print(\"----->Soft Mutation\")\n            child.layer_mutation(dataset)                                               # mutation\n            child.parameters_mutation()\n            print(\"Child has been mutated\")\n            model = child.build_model()  \n            # evaluation\n            if model==-1:\n                pass\n            else:\n                if(child.train_and_evaluate(model,dataset)==-1):\n                    model=-1  \n            #if(child.train_and_evaluate(model,dataset)==-1):\n                    #model=-1  # evaluation\n\n            while model == -1:\n                child = crossover(parent1, parent2, c + num_population)\n                child.block_mutation(dataset)\n                child.layer_mutation(dataset)\n                child.parameters_mutation()\n                model = child.build_model()\n                if(model==-1):\n                    pass\n                else:\n                    if(child.train_and_evaluate(model,dataset)==-1):\n                        model=-1\n\n            #child.train_and_evaluate(model, dataset)\n\n            if child.fitness < population[-1].fitness:                                  # evolve population\n                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"replaces parent \", end=\"\")\n                print(population[-1].name, \"with fitness\", population[-1].fitness)\n                name = population[-1].name\n\n                child.save_network(\"child_model_info.pkl\", \"child_model.h5\")\n                population[-1].load_network(\"child_model_info.pkl\", \"child_model.h5\")\n\n                population[-1].name = name\n                population = sorted(population, key=lambda net: net.fitness)\n            else:\n                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"is discarded\")\n        \n        if gen >= 3 and all(population[i].fitness == population[i + 1].fitness for i in range(-3, -1)):\n            consecutive_same_fitness += 1\n            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n        if consecutive_same_fitness >= 3:\n            print(\"Stopping the algorithm as the best fitness has remained the same for the last 3 generations.\")\n            break\n    else:\n        consecutive_same_fitness = 0\n        \n       #Check if the best fitness has remained the same for the last early_stopping_generations generations\n        if all(population[i].fitness == population[i + 1].fitness for i in range(-early_stopping_generations, -1)):\n            consecutive_same_fitness += 1\n            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n            if consecutive_same_fitness == early_stopping_generations:\n                print(f\"Stopping the algorithm as the best fitness has remained the same for {early_stopping_generations} generations.\")\n        else:\n            consecutive_same_fitness = 0\n        stats.append((population[0].fitness, population[0].model.count_params()))\n\n    print(\"\\n\\n-------------------------------------\")\n    print(\"Final Population\")\n    print(\"-------------------------------------\\n\")\n    for cnn in population:\n        print(cnn.name, ': ', cnn.fitness)\n\n    print(\"\\n-------------------------------------\")\n    print(\"Stats\")\n    for i in range(len(stats)):\n        print(\"Best individual at generation\", i + 1, \"has fitness\", stats[i][0], \"and parameters\", stats[i][1])\n    print(\"-------------------------------------\\n\")\n\n    # plot the fitness and the number of parameters of the best individual at each iteration\n    plot_statistics(stats)\n\n    return population[0]\n\n\n\ndef main():    \n        #with strategy.scope():\n        #from tensorflow.python.client import device_lib\n        #print(device_lib.list_local_devices())\n        #batch_size = 8\n        #batch_size = batch_size * strategy.num_replicas_in_sync\n        batch_size = 32                       # the number of training examples in one forward/backward pass\n        num_classes = 10                        # number of cifar-10 dataset classes\n        epochs =20              # number of forward and backward passes of all the training examples\n\n        '''\n            dataset contains the hyper parameters for loading data and the dataset:\n                dataset = {\n                    'batch_size': batch_size,\n                    'num_classes': num_classes,\n                    'epochs': epochs,\n                    'x_train': x_train,\n                    'x_test': x_test,\n                    'y_train': y_train,\n                    'y_test': y_test\n                }\n        '''\n        dataset = load_dataset(batch_size, num_classes, epochs)\n\n        num_population = 10\n        num_generation = 20\n        num_offspring = 4\n\n        # plot the best model obtained\n        optCNN = genetic_algorithm(num_population, num_generation, num_offspring, dataset)\n\n        # plot the training and validation loss and accuracy\n        num_epoch = 20\n        model = optCNN.build_model()\n        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n        history = model.fit(dataset['x_train'],\n                            dataset['y_train'],\n                            batch_size=dataset['batch_size'],\n                            epochs=num_epoch,\n                            validation_data=(dataset['x_test'], dataset['y_test']),\n                            shuffle=True)\n        optCNN.model = model                                        # model\n        optCNN.fitness = history.history['val_loss'][-1]            # fitness\n\n        print(\"\\n\\n-------------------------------------\")\n        print(\"The Final CNN has been evolved successfully in the individual\", optCNN.name)\n        print(\"-------------------------------------\\n\")\n        daddy = load_network('parent_0')\n        model = tf.keras.models.load_model('parent_0.h5')\n        print(\"\\n\\n-------------------------------------\")\n        print(\"Summary of initial CNN\")\n        print(model.summary())\n        print(\"Fitness of initial CNN:\", daddy.fitness)\n\n        print(\"\\n\\n-------------------------------------\")\n        print(\"Summary of evolved individual\")\n        print(optCNN.model.summary())\n        print(\"Fitness of the evolved individual:\", optCNN.fitness)\n        print(\"-------------------------------------\\n\")\n\n        plot_training(history)\n\n\nif __name__ == '__main__':\n    main()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:34:10.099189Z","iopub.execute_input":"2024-03-19T09:34:10.099594Z","iopub.status.idle":"2024-03-19T09:34:10.118001Z","shell.execute_reply.started":"2024-03-19T09:34:10.099563Z","shell.execute_reply":"2024-03-19T09:34:10.116664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"## To remove a folder\n# Clear output folder\nimport os\n\ndef remove_folder_contents(folder):\n    for the_file in os.listdir(folder):\n        file_path = os.path.join(folder, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                remove_folder_contents(file_path)\n                os.rmdir(file_path)\n        except Exception as e:\n            print(e)\n\nfolder_path = '/kaggle/working'\nremove_folder_contents(folder_path)\nos.rmdir(folder_path)\"\"\"\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:34:11.054431Z","iopub.execute_input":"2024-03-19T09:34:11.054798Z","iopub.status.idle":"2024-03-19T09:34:11.061017Z","shell.execute_reply.started":"2024-03-19T09:34:11.054771Z","shell.execute_reply":"2024-03-19T09:34:11.059840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport tensorflow as tf\nimport numpy as np\n\n# Set the paths to the datasets\nimage_dir = '/kaggle/input/cifar100-20-classes-images/final'\ncsv_file = '/kaggle/input/d/devasundersj/cifar100-20classes-mixing-new-latest/cifar100_20classes_mixing_new_latest.csv'","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:44:12.479533Z","iopub.execute_input":"2024-04-17T10:44:12.480330Z","iopub.status.idle":"2024-04-17T10:44:12.485213Z","shell.execute_reply.started":"2024-04-17T10:44:12.480282Z","shell.execute_reply":"2024-04-17T10:44:12.484149Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# Load the image and text data\nimage_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\ndata = pd.read_csv(csv_file)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:44:13.215657Z","iopub.execute_input":"2024-04-17T10:44:13.216073Z","iopub.status.idle":"2024-04-17T10:44:13.254058Z","shell.execute_reply.started":"2024-04-17T10:44:13.216043Z","shell.execute_reply":"2024-04-17T10:44:13.253097Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:44:13.749092Z","iopub.execute_input":"2024-04-17T10:44:13.749507Z","iopub.status.idle":"2024-04-17T10:44:13.762197Z","shell.execute_reply.started":"2024-04-17T10:44:13.749476Z","shell.execute_reply":"2024-04-17T10:44:13.761225Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"                                                 caption  class  \\\n0                            An apple on a wooden table.      0   \n1                   A juicy red apple in a fruit basket.      0   \n2                  An apple with a bite taken out of it.      0   \n3              A shiny green apple on a kitchen counter.      0   \n4        An apple orchard with trees full of ripe fruit.      0   \n...                                                  ...    ...   \n11979             A field of tulips in different colors.     92   \n11980               A colorful bouquet of mixed flowers.     92   \n11981     A single blue flower in a sea of green leaves.     92   \n11982             A garden bed full of blooming flowers.     92   \n11983  A bunch of daffodils announcing the arrival of...     92   \n\n                 filename  \n0         class_0_image_0  \n1         class_0_image_1  \n2         class_0_image_2  \n3         class_0_image_3  \n4         class_0_image_4  \n...                   ...  \n11979  class_92_image_594  \n11980  class_92_image_595  \n11981  class_92_image_596  \n11982  class_92_image_597  \n11983  class_92_image_598  \n\n[11984 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>class</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>An apple on a wooden table.</td>\n      <td>0</td>\n      <td>class_0_image_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A juicy red apple in a fruit basket.</td>\n      <td>0</td>\n      <td>class_0_image_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>An apple with a bite taken out of it.</td>\n      <td>0</td>\n      <td>class_0_image_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A shiny green apple on a kitchen counter.</td>\n      <td>0</td>\n      <td>class_0_image_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>An apple orchard with trees full of ripe fruit.</td>\n      <td>0</td>\n      <td>class_0_image_4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11979</th>\n      <td>A field of tulips in different colors.</td>\n      <td>92</td>\n      <td>class_92_image_594</td>\n    </tr>\n    <tr>\n      <th>11980</th>\n      <td>A colorful bouquet of mixed flowers.</td>\n      <td>92</td>\n      <td>class_92_image_595</td>\n    </tr>\n    <tr>\n      <th>11981</th>\n      <td>A single blue flower in a sea of green leaves.</td>\n      <td>92</td>\n      <td>class_92_image_596</td>\n    </tr>\n    <tr>\n      <th>11982</th>\n      <td>A garden bed full of blooming flowers.</td>\n      <td>92</td>\n      <td>class_92_image_597</td>\n    </tr>\n    <tr>\n      <th>11983</th>\n      <td>A bunch of daffodils announcing the arrival of...</td>\n      <td>92</td>\n      <td>class_92_image_598</td>\n    </tr>\n  </tbody>\n</table>\n<p>11984 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the LSTM and CNN models\nlstm_model = tf.keras.models.load_model('/kaggle/input/cifar-100-randomclass-lstmmodel/net_1_lstm_cifar200_20_random.h5')\ncnn_model = tf.keras.models.load_model('/kaggle/input/cnn-models-fashion-cifar100/cifar_100_20classes_net13.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:44:14.656041Z","iopub.execute_input":"2024-04-17T10:44:14.656421Z","iopub.status.idle":"2024-04-17T10:44:15.186310Z","shell.execute_reply.started":"2024-04-17T10:44:14.656380Z","shell.execute_reply":"2024-04-17T10:44:15.185443Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom keras.utils import to_categorical\nfrom PIL import Image\n\ndef load_image(image_path, image_shape):\n    image = Image.open(image_path)\n    image = image.resize((image_shape[1], image_shape[0]))  # Resize to match the required shape\n    image = np.array(image) / 255.0  # Normalize pixel values to [0, 1]\n    return image","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:44:16.252300Z","iopub.execute_input":"2024-04-17T10:44:16.253492Z","iopub.status.idle":"2024-04-17T10:44:16.262097Z","shell.execute_reply.started":"2024-04-17T10:44:16.253442Z","shell.execute_reply":"2024-04-17T10:44:16.260779Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# Usage:\nimage_folder = '/kaggle/input/cifar100-20-classes-images/final'\ncaptions_df = pd.read_csv('/kaggle/input/d/devasundersj/cifar100-20classes-mixing-new-latest/cifar100_20classes_mixing_new_latest.csv')  # Assuming captions are stored in a CSV file\nnum_classes = 20  # Number of classes/categories\nimage_shape = (32, 32, 3)  # Define the shape of the images","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:44:17.555995Z","iopub.execute_input":"2024-04-17T10:44:17.556641Z","iopub.status.idle":"2024-04-17T10:44:17.582738Z","shell.execute_reply.started":"2024-04-17T10:44:17.556604Z","shell.execute_reply":"2024-04-17T10:44:17.581623Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"# Step 1: Load image data from the folder\nimages = []\nimage_filenames = []\nfor filename in os.listdir(image_folder):\n    if filename.endswith(\".jpg\"):  # Assuming images are in png format\n            image_path = os.path.join(image_folder, filename)\n            image = load_image(image_path, image_shape)\n            images.append(image)\n            image_filenames.append(os.path.splitext(filename)[0])  # Remove file extension\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:44:18.279442Z","iopub.execute_input":"2024-04-17T10:44:18.279893Z","iopub.status.idle":"2024-04-17T10:44:27.838958Z","shell.execute_reply.started":"2024-04-17T10:44:18.279859Z","shell.execute_reply":"2024-04-17T10:44:27.837991Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"image_filenames[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:44:35.802741Z","iopub.execute_input":"2024-04-17T10:44:35.803627Z","iopub.status.idle":"2024-04-17T10:44:35.809868Z","shell.execute_reply.started":"2024-04-17T10:44:35.803587Z","shell.execute_reply":"2024-04-17T10:44:35.808814Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"'class_84_image_540'"},"metadata":{}}]},{"cell_type":"code","source":"captions_df['caption']","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:44:36.905717Z","iopub.execute_input":"2024-04-17T10:44:36.906118Z","iopub.status.idle":"2024-04-17T10:44:36.914499Z","shell.execute_reply.started":"2024-04-17T10:44:36.906088Z","shell.execute_reply":"2024-04-17T10:44:36.913380Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"0                              An apple on a wooden table.\n1                     A juicy red apple in a fruit basket.\n2                    An apple with a bite taken out of it.\n3                A shiny green apple on a kitchen counter.\n4          An apple orchard with trees full of ripe fruit.\n                               ...                        \n11979               A field of tulips in different colors.\n11980                 A colorful bouquet of mixed flowers.\n11981       A single blue flower in a sea of green leaves.\n11982               A garden bed full of blooming flowers.\n11983    A bunch of daffodils announcing the arrival of...\nName: caption, Length: 11984, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"filename","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:44:37.580665Z","iopub.execute_input":"2024-04-17T10:44:37.581499Z","iopub.status.idle":"2024-04-17T10:44:37.587567Z","shell.execute_reply.started":"2024-04-17T10:44:37.581464Z","shell.execute_reply":"2024-04-17T10:44:37.586558Z"},"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"'class_24_image_137.jpg'"},"metadata":{}}]},{"cell_type":"code","source":"\nclass_index = int(filename.split('_')[1])\nclass_index","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:44:38.232164Z","iopub.execute_input":"2024-04-17T10:44:38.232563Z","iopub.status.idle":"2024-04-17T10:44:38.239160Z","shell.execute_reply.started":"2024-04-17T10:44:38.232534Z","shell.execute_reply":"2024-04-17T10:44:38.238262Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"24"},"metadata":{}}]},{"cell_type":"code","source":"image_index = int(filename.split('_')[3].split('.')[0])\nimage_index","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:44:39.315447Z","iopub.execute_input":"2024-04-17T10:44:39.316453Z","iopub.status.idle":"2024-04-17T10:44:39.323695Z","shell.execute_reply.started":"2024-04-17T10:44:39.316407Z","shell.execute_reply":"2024-04-17T10:44:39.322779Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"137"},"metadata":{}}]},{"cell_type":"code","source":"image_filenames[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:44:40.010570Z","iopub.execute_input":"2024-04-17T10:44:40.010967Z","iopub.status.idle":"2024-04-17T10:44:40.017426Z","shell.execute_reply.started":"2024-04-17T10:44:40.010935Z","shell.execute_reply":"2024-04-17T10:44:40.016525Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"'class_84_image_540'"},"metadata":{}}]},{"cell_type":"code","source":"len(image_filenames)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:44:40.658153Z","iopub.execute_input":"2024-04-17T10:44:40.658948Z","iopub.status.idle":"2024-04-17T10:44:40.665590Z","shell.execute_reply.started":"2024-04-17T10:44:40.658911Z","shell.execute_reply":"2024-04-17T10:44:40.664502Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"11984"},"metadata":{}}]},{"cell_type":"code","source":"image_captions = []\nimage_classes = []\nfor filename in image_filenames:\n    #print(filename)\n    class_index = int(filename.split('_')[1])\n    #print(class_index)\n    image_index = int(filename.split('_')[3].split('.')[0])\n    #print(image_index)\n    row = captions_df[captions_df['filename'] == filename]\n    #print(row)\n    try:\n        caption = row['caption'].values[0]\n    except:\n        print(filename)\n    \n    image_captions.append(caption)\n    image_classes.append(class_index)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:44:41.352397Z","iopub.execute_input":"2024-04-17T10:44:41.353175Z","iopub.status.idle":"2024-04-17T10:45:13.301184Z","shell.execute_reply.started":"2024-04-17T10:44:41.353144Z","shell.execute_reply":"2024-04-17T10:45:13.299944Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"captions_df['filename'][600:650]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:15.368946Z","iopub.execute_input":"2024-04-17T10:45:15.369640Z","iopub.status.idle":"2024-04-17T10:45:15.377718Z","shell.execute_reply.started":"2024-04-17T10:45:15.369608Z","shell.execute_reply":"2024-04-17T10:45:15.376727Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"600     class_2_image_1\n601     class_2_image_2\n602     class_2_image_3\n603     class_2_image_4\n604     class_2_image_5\n605     class_2_image_6\n606     class_2_image_7\n607     class_2_image_8\n608     class_2_image_9\n609    class_2_image_10\n610    class_2_image_11\n611    class_2_image_12\n612    class_2_image_13\n613    class_2_image_14\n614    class_2_image_15\n615    class_2_image_16\n616    class_2_image_17\n617    class_2_image_18\n618    class_2_image_19\n619    class_2_image_20\n620    class_2_image_21\n621    class_2_image_22\n622    class_2_image_23\n623    class_2_image_24\n624    class_2_image_25\n625    class_2_image_26\n626    class_2_image_27\n627    class_2_image_28\n628    class_2_image_29\n629    class_2_image_30\n630    class_2_image_31\n631    class_2_image_32\n632    class_2_image_33\n633    class_2_image_34\n634    class_2_image_35\n635    class_2_image_36\n636    class_2_image_37\n637    class_2_image_38\n638    class_2_image_39\n639    class_2_image_40\n640    class_2_image_41\n641    class_2_image_42\n642    class_2_image_43\n643    class_2_image_44\n644    class_2_image_45\n645    class_2_image_46\n646    class_2_image_47\n647    class_2_image_48\n648    class_2_image_49\n649    class_2_image_50\nName: filename, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"len(image_captions)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:16.179470Z","iopub.execute_input":"2024-04-17T10:45:16.179986Z","iopub.status.idle":"2024-04-17T10:45:16.186573Z","shell.execute_reply.started":"2024-04-17T10:45:16.179952Z","shell.execute_reply":"2024-04-17T10:45:16.185538Z"},"trusted":true},"execution_count":85,"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"11984"},"metadata":{}}]},{"cell_type":"code","source":"image_filenames[34]\n#image_captions[34]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:17.020874Z","iopub.execute_input":"2024-04-17T10:45:17.021223Z","iopub.status.idle":"2024-04-17T10:45:17.027581Z","shell.execute_reply.started":"2024-04-17T10:45:17.021195Z","shell.execute_reply":"2024-04-17T10:45:17.026535Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"'class_2_image_478'"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\n\n# Display the image\nplt.imshow(images[2])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:17.675226Z","iopub.execute_input":"2024-04-17T10:45:17.675915Z","iopub.status.idle":"2024-04-17T10:45:17.897657Z","shell.execute_reply.started":"2024-04-17T10:45:17.675884Z","shell.execute_reply":"2024-04-17T10:45:17.896675Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7dac4bbacee0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"image_captions[2]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:18.470863Z","iopub.execute_input":"2024-04-17T10:45:18.471236Z","iopub.status.idle":"2024-04-17T10:45:18.477554Z","shell.execute_reply.started":"2024-04-17T10:45:18.471204Z","shell.execute_reply":"2024-04-17T10:45:18.476683Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"'A tiger with a sense of pride in its posture.'"},"metadata":{}}]},{"cell_type":"code","source":"image_classes[2]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:19.282490Z","iopub.execute_input":"2024-04-17T10:45:19.283237Z","iopub.status.idle":"2024-04-17T10:45:19.290220Z","shell.execute_reply.started":"2024-04-17T10:45:19.283193Z","shell.execute_reply":"2024-04-17T10:45:19.289030Z"},"trusted":true},"execution_count":89,"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"88"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Assuming you have lists images, image_captions, and image_classes containing your data\n\n# Create an array of indices from 0 to the length of your data\nindices = np.arange(len(images))\n\n# Randomly select 20,000 indices for testing without replacement\ntesting_indices = np.random.choice(indices, size=2000, replace=False)\n\n# Use the remaining indices for training\ntraining_indices = np.setdiff1d(indices, testing_indices)\n\n# Use the selected indices to create the testing and training datasets\ntesting_cnn_data_selected = [images[i] for i in testing_indices]\ntraining_cnn_data_selected = [images[i] for i in training_indices]\n\ntesting_lstm_data_selected = [image_captions[i] for i in testing_indices]\ntraining_lstm_data_selected = [image_captions[i] for i in training_indices]\n\n# Create labels (y) for testing and training datasets\ntesting_labels = [image_classes[i] for i in testing_indices]\ntraining_labels = [image_classes[i] for i in training_indices]\n\n# Now testing_data_selected contains 20,000 randomly selected items for testing\n# and training_data_selected contains the remaining items for training\n# testing_labels and training_labels contain corresponding labels for testing and training datasets\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:19.923506Z","iopub.execute_input":"2024-04-17T10:45:19.924570Z","iopub.status.idle":"2024-04-17T10:45:19.953260Z","shell.execute_reply.started":"2024-04-17T10:45:19.924524Z","shell.execute_reply":"2024-04-17T10:45:19.952199Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\n\n# Display the image\nplt.imshow(training_cnn_data_selected[1])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:21.469440Z","iopub.execute_input":"2024-04-17T10:45:21.470136Z","iopub.status.idle":"2024-04-17T10:45:21.697672Z","shell.execute_reply.started":"2024-04-17T10:45:21.470104Z","shell.execute_reply":"2024-04-17T10:45:21.696683Z"},"trusted":true},"execution_count":91,"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7dac4b8c83a0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Sample testing_labels array\ntraining_labels = np.array(training_labels)\n\n# Define a mapping dictionary to map original labels to new labels (0 to 20)\nlabel_mapping = {}\nnew_label = 0\nfor label in sorted(np.unique(training_labels)):\n    label_mapping[label] = new_label\n    new_label += 1\n\n# Convert the testing_labels array using the mapping dictionary\nconverted_labels_training = np.array([label_mapping[label] for label in training_labels])\n\n# Print the converted labels\nprint(converted_labels_training)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:22.258836Z","iopub.execute_input":"2024-04-17T10:45:22.259209Z","iopub.status.idle":"2024-04-17T10:45:22.271779Z","shell.execute_reply.started":"2024-04-17T10:45:22.259179Z","shell.execute_reply":"2024-04-17T10:45:22.270722Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"[15 15 16 ... 18  1  8]\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Sample testing_labels array\ntesting_labels = np.array(testing_labels)\n\n# Define a mapping dictionary to map original labels to new labels (0 to 20)\nlabel_mapping = {}\nnew_label = 0\nfor label in sorted(np.unique(testing_labels)):\n    label_mapping[label] = new_label\n    new_label += 1\n\n# Convert the testing_labels array using the mapping dictionary\nconverted_labels_testing = np.array([label_mapping[label] for label in testing_labels])\n\n# Print the converted labels\nprint(converted_labels_testing)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:23.228424Z","iopub.execute_input":"2024-04-17T10:45:23.229101Z","iopub.status.idle":"2024-04-17T10:45:23.236987Z","shell.execute_reply.started":"2024-04-17T10:45:23.229067Z","shell.execute_reply":"2024-04-17T10:45:23.236130Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"[15 18 12 ...  9 13  2]\n","output_type":"stream"}]},{"cell_type":"code","source":"testing_labels[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:24.133658Z","iopub.execute_input":"2024-04-17T10:45:24.134054Z","iopub.status.idle":"2024-04-17T10:45:24.140660Z","shell.execute_reply.started":"2024-04-17T10:45:24.134022Z","shell.execute_reply":"2024-04-17T10:45:24.139667Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"array([84, 91, 65, 92, 61, 13, 92,  2, 36,  5])"},"metadata":{}}]},{"cell_type":"code","source":"converted_labels_testing[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:25.014974Z","iopub.execute_input":"2024-04-17T10:45:25.015362Z","iopub.status.idle":"2024-04-17T10:45:25.022312Z","shell.execute_reply.started":"2024-04-17T10:45:25.015329Z","shell.execute_reply":"2024-04-17T10:45:25.021167Z"},"trusted":true},"execution_count":95,"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"array([15, 18, 12, 19, 11,  5, 19,  1,  9,  2])"},"metadata":{}}]},{"cell_type":"code","source":"testing_labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:25.773331Z","iopub.execute_input":"2024-04-17T10:45:25.773946Z","iopub.status.idle":"2024-04-17T10:45:25.780983Z","shell.execute_reply.started":"2024-04-17T10:45:25.773914Z","shell.execute_reply":"2024-04-17T10:45:25.779965Z"},"trusted":true},"execution_count":96,"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"(2000,)"},"metadata":{}}]},{"cell_type":"code","source":"converted_labels_training[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:26.501414Z","iopub.execute_input":"2024-04-17T10:45:26.502163Z","iopub.status.idle":"2024-04-17T10:45:26.509325Z","shell.execute_reply.started":"2024-04-17T10:45:26.502128Z","shell.execute_reply":"2024-04-17T10:45:26.508064Z"},"trusted":true},"execution_count":97,"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"array([15, 15, 16,  5, 11, 18, 13, 15, 19,  8])"},"metadata":{}}]},{"cell_type":"code","source":"training_lstm_data_selected[1]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:27.256936Z","iopub.execute_input":"2024-04-17T10:45:27.257367Z","iopub.status.idle":"2024-04-17T10:45:27.263865Z","shell.execute_reply.started":"2024-04-17T10:45:27.257336Z","shell.execute_reply":"2024-04-17T10:45:27.262747Z"},"trusted":true},"execution_count":98,"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"'A table with a typewriter and papers.'"},"metadata":{}}]},{"cell_type":"markdown","source":"## CNN ","metadata":{}},{"cell_type":"code","source":"# Convert labels to one-hot encoding\ntraining_labels=np.array(training_labels)\ntesting_labels=np.array(testing_labels)\ntraining_labels = tf.keras.utils.to_categorical(converted_labels_training, 20)\ntesting_labels = tf.keras.utils.to_categorical(converted_labels_testing, 20)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:28.704044Z","iopub.execute_input":"2024-04-17T10:45:28.704831Z","iopub.status.idle":"2024-04-17T10:45:28.710793Z","shell.execute_reply.started":"2024-04-17T10:45:28.704799Z","shell.execute_reply":"2024-04-17T10:45:28.709772Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_cnn_data_selected=np.array(training_cnn_data_selected)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:29.610430Z","iopub.execute_input":"2024-04-17T10:45:29.611111Z","iopub.status.idle":"2024-04-17T10:45:29.697329Z","shell.execute_reply.started":"2024-04-17T10:45:29.611076Z","shell.execute_reply":"2024-04-17T10:45:29.696374Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"testing_cnn_data_selected=np.array(testing_cnn_data_selected)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:30.220969Z","iopub.execute_input":"2024-04-17T10:45:30.221345Z","iopub.status.idle":"2024-04-17T10:45:30.245084Z","shell.execute_reply.started":"2024-04-17T10:45:30.221314Z","shell.execute_reply":"2024-04-17T10:45:30.244173Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"training_cnn_data_selected.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:30.551916Z","iopub.execute_input":"2024-04-17T10:45:30.552273Z","iopub.status.idle":"2024-04-17T10:45:30.559107Z","shell.execute_reply.started":"2024-04-17T10:45:30.552249Z","shell.execute_reply":"2024-04-17T10:45:30.558128Z"},"trusted":true},"execution_count":102,"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"(9984, 32, 32, 3)"},"metadata":{}}]},{"cell_type":"code","source":"training_cnn_data_selected.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:45:30.788112Z","iopub.execute_input":"2024-04-17T10:45:30.788525Z","iopub.status.idle":"2024-04-17T10:45:30.794757Z","shell.execute_reply.started":"2024-04-17T10:45:30.788495Z","shell.execute_reply":"2024-04-17T10:45:30.793895Z"},"trusted":true},"execution_count":103,"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"(9984, 32, 32, 3)"},"metadata":{}}]},{"cell_type":"code","source":"tf.config.experimental_run_functions_eagerly(False)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:46:18.548366Z","iopub.execute_input":"2024-04-17T10:46:18.549452Z","iopub.status.idle":"2024-04-17T10:46:18.554676Z","shell.execute_reply.started":"2024-04-17T10:46:18.549395Z","shell.execute_reply":"2024-04-17T10:46:18.553606Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"cnn_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = cnn_model.fit(training_cnn_data_selected,\n                            training_labels,\n                            batch_size=32,\n                            epochs=30,\n                            validation_data=(testing_cnn_data_selected,testing_labels),\n                            shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:46:19.786478Z","iopub.execute_input":"2024-04-17T10:46:19.786898Z","iopub.status.idle":"2024-04-17T10:47:30.757996Z","shell.execute_reply.started":"2024-04-17T10:46:19.786865Z","shell.execute_reply":"2024-04-17T10:47:30.757008Z"},"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"2024-04-17 10:46:21.232911: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_139/dropout_156/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"312/312 [==============================] - 5s 8ms/step - loss: 1.3519 - accuracy: 0.6682 - val_loss: 1.0733 - val_accuracy: 0.7020\nEpoch 2/30\n312/312 [==============================] - 2s 7ms/step - loss: 1.0076 - accuracy: 0.7511 - val_loss: 0.9942 - val_accuracy: 0.7480\nEpoch 3/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.9022 - accuracy: 0.7808 - val_loss: 0.9258 - val_accuracy: 0.7825\nEpoch 4/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.8252 - accuracy: 0.7995 - val_loss: 0.9466 - val_accuracy: 0.7840\nEpoch 5/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.7826 - accuracy: 0.8136 - val_loss: 0.9358 - val_accuracy: 0.7810\nEpoch 6/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.7266 - accuracy: 0.8274 - val_loss: 0.9365 - val_accuracy: 0.7865\nEpoch 7/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.7185 - accuracy: 0.8303 - val_loss: 1.0177 - val_accuracy: 0.7630\nEpoch 8/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.7028 - accuracy: 0.8386 - val_loss: 0.9764 - val_accuracy: 0.7740\nEpoch 9/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.7095 - accuracy: 0.8353 - val_loss: 1.2629 - val_accuracy: 0.7515\nEpoch 10/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.7068 - accuracy: 0.8371 - val_loss: 1.2159 - val_accuracy: 0.7585\nEpoch 11/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.6636 - accuracy: 0.8455 - val_loss: 1.1606 - val_accuracy: 0.7475\nEpoch 12/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.6814 - accuracy: 0.8521 - val_loss: 1.0655 - val_accuracy: 0.7585\nEpoch 13/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.6221 - accuracy: 0.8586 - val_loss: 1.3344 - val_accuracy: 0.6955\nEpoch 14/30\n312/312 [==============================] - 2s 8ms/step - loss: 0.6830 - accuracy: 0.8516 - val_loss: 1.2895 - val_accuracy: 0.7505\nEpoch 15/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.6039 - accuracy: 0.8670 - val_loss: 1.1308 - val_accuracy: 0.7600\nEpoch 16/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.6776 - accuracy: 0.8518 - val_loss: 2.0226 - val_accuracy: 0.7215\nEpoch 17/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.6475 - accuracy: 0.8621 - val_loss: 1.6070 - val_accuracy: 0.7400\nEpoch 18/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.6367 - accuracy: 0.8617 - val_loss: 1.5496 - val_accuracy: 0.7530\nEpoch 19/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.6925 - accuracy: 0.8581 - val_loss: 1.6026 - val_accuracy: 0.7180\nEpoch 20/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.6536 - accuracy: 0.8609 - val_loss: 1.8220 - val_accuracy: 0.7400\nEpoch 21/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.6681 - accuracy: 0.8597 - val_loss: 1.4993 - val_accuracy: 0.7130\nEpoch 22/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.6431 - accuracy: 0.8681 - val_loss: 1.2794 - val_accuracy: 0.7150\nEpoch 23/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.7015 - accuracy: 0.8588 - val_loss: 1.6438 - val_accuracy: 0.7345\nEpoch 24/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.6586 - accuracy: 0.8572 - val_loss: 1.5845 - val_accuracy: 0.7310\nEpoch 25/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.7209 - accuracy: 0.8524 - val_loss: 1.3415 - val_accuracy: 0.7070\nEpoch 26/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.7606 - accuracy: 0.8480 - val_loss: 1.5153 - val_accuracy: 0.7570\nEpoch 27/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.7205 - accuracy: 0.8501 - val_loss: 1.8830 - val_accuracy: 0.7300\nEpoch 28/30\n312/312 [==============================] - 2s 8ms/step - loss: 0.7294 - accuracy: 0.8508 - val_loss: 2.6116 - val_accuracy: 0.6565\nEpoch 29/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.7423 - accuracy: 0.8524 - val_loss: 1.6704 - val_accuracy: 0.6885\nEpoch 30/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.7333 - accuracy: 0.8572 - val_loss: 2.1085 - val_accuracy: 0.6890\n","output_type":"stream"}]},{"cell_type":"code","source":"testing_labels = np.argmax(testing_labels, axis=1)\ntraining_labels = np.argmax(training_labels, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:32.801616Z","iopub.execute_input":"2024-04-17T10:47:32.802031Z","iopub.status.idle":"2024-04-17T10:47:32.808629Z","shell.execute_reply.started":"2024-04-17T10:47:32.801995Z","shell.execute_reply":"2024-04-17T10:47:32.807503Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"cnn_predictions = cnn_model.predict(testing_cnn_data_selected)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:33.630137Z","iopub.execute_input":"2024-04-17T10:47:33.630505Z","iopub.status.idle":"2024-04-17T10:47:34.046745Z","shell.execute_reply.started":"2024-04-17T10:47:33.630474Z","shell.execute_reply":"2024-04-17T10:47:34.045775Z"},"trusted":true},"execution_count":108,"outputs":[{"name":"stdout","text":"63/63 [==============================] - 0s 2ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"predicted_labels = np.argmax(cnn_predictions, axis=1)\n\n# Calculate accuracy\ncnn_accuracy = np.mean(predicted_labels == testing_labels)\nprint(\"CNN Model Accuracy:\", cnn_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:34.317616Z","iopub.execute_input":"2024-04-17T10:47:34.318023Z","iopub.status.idle":"2024-04-17T10:47:34.324332Z","shell.execute_reply.started":"2024-04-17T10:47:34.317993Z","shell.execute_reply":"2024-04-17T10:47:34.323252Z"},"trusted":true},"execution_count":109,"outputs":[{"name":"stdout","text":"CNN Model Accuracy: 0.689\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.DataFrame({'caption': training_lstm_data_selected, 'class': training_labels})","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:35.131911Z","iopub.execute_input":"2024-04-17T10:47:35.132665Z","iopub.status.idle":"2024-04-17T10:47:35.138696Z","shell.execute_reply.started":"2024-04-17T10:47:35.132634Z","shell.execute_reply":"2024-04-17T10:47:35.137608Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"df[20:30]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:36.167688Z","iopub.execute_input":"2024-04-17T10:47:36.168129Z","iopub.status.idle":"2024-04-17T10:47:36.178639Z","shell.execute_reply.started":"2024-04-17T10:47:36.168098Z","shell.execute_reply":"2024-04-17T10:47:36.177510Z"},"trusted":true},"execution_count":111,"outputs":[{"execution_count":111,"output_type":"execute_result","data":{"text/plain":"                                              caption  class\n20  Passengers settle into their seats, preparing ...     17\n21                Wispy clouds float gently overhead.      7\n22   A group of cows gathers around the watering h...      6\n23           A bunch of flowers in a vase with water.     19\n24        A close up of a table with a bowl of fruit.     15\n25  An image showing a cozy cot nestled next to a ...      2\n26        White flowers with a bee collecting nectar.     19\n27  A ceramic plate with an abstract design displa...     11\n28   A cow with a gentle demeanor approaches the w...      6\n29               Fish swimming in a river with rocks.     18","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20</th>\n      <td>Passengers settle into their seats, preparing ...</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Wispy clouds float gently overhead.</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>A group of cows gathers around the watering h...</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>A bunch of flowers in a vase with water.</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>A close up of a table with a bowl of fruit.</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>An image showing a cozy cot nestled next to a ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>White flowers with a bee collecting nectar.</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>A ceramic plate with an abstract design displa...</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>A cow with a gentle demeanor approaches the w...</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Fish swimming in a river with rocks.</td>\n      <td>18</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nfrom gensim.models import Word2Vec\n\ndef tokenize_text(text_data):\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(text_data)\n    return tokenizer\n\ndef train_word2vec(text_data, embedding_dim):\n    tokenized_text = [text.split() for text in text_data]\n    model = Word2Vec(sentences=tokenized_text, vector_size=embedding_dim, window=5, min_count=1, workers=4)\n    return model\n\ndef convert_text_to_vectors(text_data, word2vec_model, max_length):\n    vectors = []\n    for text in text_data:\n        words = text.split()\n        vec = []\n        for word in words:\n            if word in word2vec_model.wv:\n                vec.append(word2vec_model.wv[word])\n            else:\n                vec.append(np.zeros(word2vec_model.vector_size))  # Zero vector for out-of-vocabulary words\n        vectors.append(vec)\n    padded_vectors = pad_sequences(vectors, maxlen=max_length, padding='post')\n    return padded_vectors","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:36.578297Z","iopub.execute_input":"2024-04-17T10:47:36.578997Z","iopub.status.idle":"2024-04-17T10:47:36.588730Z","shell.execute_reply.started":"2024-04-17T10:47:36.578963Z","shell.execute_reply":"2024-04-17T10:47:36.587640Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"df['caption'][147]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:37.364818Z","iopub.execute_input":"2024-04-17T10:47:37.365621Z","iopub.status.idle":"2024-04-17T10:47:37.371886Z","shell.execute_reply.started":"2024-04-17T10:47:37.365587Z","shell.execute_reply":"2024-04-17T10:47:37.370824Z"},"trusted":true},"execution_count":113,"outputs":[{"execution_count":113,"output_type":"execute_result","data":{"text/plain":"'A sleepy cat dozes off in a warm lap.'"},"metadata":{}}]},{"cell_type":"code","source":"max_words=10000\nembedding_dim=10\n\ntokenizer = tokenize_text(df['caption'].values)\nword2vec_model = train_word2vec(df['caption'].values, embedding_dim)\n\nmax_length = max(len(text.split()) for text in df['caption'].values)\n\n#x_vec = convert_text_to_vectors(df['caption'].values, word2vec_model, max_length)\n#class_mapping = {f'class_{i}': i for i in range(num_classes)}\n#df['class'] = df['class']\n\n#y = df['class'].values","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:38.186287Z","iopub.execute_input":"2024-04-17T10:47:38.186663Z","iopub.status.idle":"2024-04-17T10:47:39.028150Z","shell.execute_reply.started":"2024-04-17T10:47:38.186633Z","shell.execute_reply":"2024-04-17T10:47:39.027299Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"x_vec_train = convert_text_to_vectors(training_lstm_data_selected, word2vec_model, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:39.153041Z","iopub.execute_input":"2024-04-17T10:47:39.153461Z","iopub.status.idle":"2024-04-17T10:47:39.588377Z","shell.execute_reply.started":"2024-04-17T10:47:39.153417Z","shell.execute_reply":"2024-04-17T10:47:39.587480Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"x_vec_test = convert_text_to_vectors(testing_lstm_data_selected, word2vec_model, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:40.211020Z","iopub.execute_input":"2024-04-17T10:47:40.211381Z","iopub.status.idle":"2024-04-17T10:47:40.303184Z","shell.execute_reply.started":"2024-04-17T10:47:40.211352Z","shell.execute_reply":"2024-04-17T10:47:40.302097Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"training_lstm_data_selected[2]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:40.443958Z","iopub.execute_input":"2024-04-17T10:47:40.444877Z","iopub.status.idle":"2024-04-17T10:47:40.450671Z","shell.execute_reply.started":"2024-04-17T10:47:40.444840Z","shell.execute_reply":"2024-04-17T10:47:40.449677Z"},"trusted":true},"execution_count":117,"outputs":[{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"'A tiger with a sense of pride in its posture.'"},"metadata":{}}]},{"cell_type":"code","source":"training_lstm_data_selected[0:2]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:40.897809Z","iopub.execute_input":"2024-04-17T10:47:40.898920Z","iopub.status.idle":"2024-04-17T10:47:40.905499Z","shell.execute_reply.started":"2024-04-17T10:47:40.898878Z","shell.execute_reply":"2024-04-17T10:47:40.904523Z"},"trusted":true},"execution_count":118,"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"['A wooden table with a fruit bowl in the center.',\n 'A table with a typewriter and papers.']"},"metadata":{}}]},{"cell_type":"code","source":"x_vec_train=np.array(x_vec_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:41.001907Z","iopub.execute_input":"2024-04-17T10:47:41.002480Z","iopub.status.idle":"2024-04-17T10:47:41.010440Z","shell.execute_reply.started":"2024-04-17T10:47:41.002450Z","shell.execute_reply":"2024-04-17T10:47:41.009580Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"x_vec_test=np.array(x_vec_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:41.304150Z","iopub.execute_input":"2024-04-17T10:47:41.304536Z","iopub.status.idle":"2024-04-17T10:47:41.309510Z","shell.execute_reply.started":"2024-04-17T10:47:41.304506Z","shell.execute_reply":"2024-04-17T10:47:41.308466Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"training_labels=np.array(training_labels)\ntesting_labels=np.array(testing_labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:41.585070Z","iopub.execute_input":"2024-04-17T10:47:41.585723Z","iopub.status.idle":"2024-04-17T10:47:41.590723Z","shell.execute_reply.started":"2024-04-17T10:47:41.585674Z","shell.execute_reply":"2024-04-17T10:47:41.589678Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"lstm_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:42.451818Z","iopub.execute_input":"2024-04-17T10:47:42.452606Z","iopub.status.idle":"2024-04-17T10:47:42.465354Z","shell.execute_reply.started":"2024-04-17T10:47:42.452574Z","shell.execute_reply":"2024-04-17T10:47:42.464472Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"x_vec_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:43.083655Z","iopub.execute_input":"2024-04-17T10:47:43.084520Z","iopub.status.idle":"2024-04-17T10:47:43.091381Z","shell.execute_reply.started":"2024-04-17T10:47:43.084489Z","shell.execute_reply":"2024-04-17T10:47:43.089521Z"},"trusted":true},"execution_count":123,"outputs":[{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"(9984, 24, 10)"},"metadata":{}}]},{"cell_type":"code","source":"training_labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:44.129848Z","iopub.execute_input":"2024-04-17T10:47:44.130225Z","iopub.status.idle":"2024-04-17T10:47:44.136605Z","shell.execute_reply.started":"2024-04-17T10:47:44.130194Z","shell.execute_reply":"2024-04-17T10:47:44.135531Z"},"trusted":true},"execution_count":124,"outputs":[{"execution_count":124,"output_type":"execute_result","data":{"text/plain":"(9984,)"},"metadata":{}}]},{"cell_type":"code","source":"x_vec_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:45.329067Z","iopub.execute_input":"2024-04-17T10:47:45.330092Z","iopub.status.idle":"2024-04-17T10:47:45.337098Z","shell.execute_reply.started":"2024-04-17T10:47:45.330056Z","shell.execute_reply":"2024-04-17T10:47:45.336240Z"},"trusted":true},"execution_count":125,"outputs":[{"execution_count":125,"output_type":"execute_result","data":{"text/plain":"(2000, 24, 10)"},"metadata":{}}]},{"cell_type":"code","source":"training_labels = tf.keras.utils.to_categorical(converted_labels_training, 20)\ntesting_labels = tf.keras.utils.to_categorical(converted_labels_testing, 20)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:46.597567Z","iopub.execute_input":"2024-04-17T10:47:46.598509Z","iopub.status.idle":"2024-04-17T10:47:46.603655Z","shell.execute_reply.started":"2024-04-17T10:47:46.598472Z","shell.execute_reply":"2024-04-17T10:47:46.602738Z"},"trusted":true},"execution_count":126,"outputs":[]},{"cell_type":"markdown","source":"tf.config.experimental_run_functions_eagerly(True)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:42:13.306635Z","iopub.execute_input":"2024-04-17T10:42:13.307041Z","iopub.status.idle":"2024-04-17T10:42:13.312125Z","shell.execute_reply.started":"2024-04-17T10:42:13.307008Z","shell.execute_reply":"2024-04-17T10:42:13.311037Z"}}},{"cell_type":"code","source":"history = lstm_model.fit(x_vec_train,\n                                training_labels,\n                                batch_size=32,\n                                epochs=30,\n                                validation_data=(x_vec_test,testing_labels),\n                                shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:47.778261Z","iopub.execute_input":"2024-04-17T10:47:47.778908Z","iopub.status.idle":"2024-04-17T10:49:11.204677Z","shell.execute_reply.started":"2024-04-17T10:47:47.778873Z","shell.execute_reply":"2024-04-17T10:49:11.203660Z"},"trusted":true},"execution_count":127,"outputs":[{"name":"stdout","text":"Epoch 1/30\n312/312 [==============================] - 4s 7ms/step - loss: 2.6785 - accuracy: 0.2334 - val_loss: 1.7004 - val_accuracy: 0.4445\nEpoch 2/30\n312/312 [==============================] - 2s 6ms/step - loss: 1.7313 - accuracy: 0.4498 - val_loss: 1.3763 - val_accuracy: 0.5755\nEpoch 3/30\n312/312 [==============================] - 2s 6ms/step - loss: 1.4125 - accuracy: 0.5674 - val_loss: 1.1658 - val_accuracy: 0.6365\nEpoch 4/30\n312/312 [==============================] - 2s 7ms/step - loss: 1.2551 - accuracy: 0.6252 - val_loss: 0.9677 - val_accuracy: 0.7025\nEpoch 5/30\n312/312 [==============================] - 2s 6ms/step - loss: 1.1123 - accuracy: 0.6598 - val_loss: 0.8889 - val_accuracy: 0.7250\nEpoch 6/30\n312/312 [==============================] - 2s 6ms/step - loss: 1.0146 - accuracy: 0.6947 - val_loss: 0.8136 - val_accuracy: 0.7465\nEpoch 7/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.9189 - accuracy: 0.7215 - val_loss: 0.7942 - val_accuracy: 0.7430\nEpoch 8/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.8903 - accuracy: 0.7372 - val_loss: 0.7463 - val_accuracy: 0.7665\nEpoch 9/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.8353 - accuracy: 0.7565 - val_loss: 0.6592 - val_accuracy: 0.7850\nEpoch 10/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.7920 - accuracy: 0.7693 - val_loss: 0.6521 - val_accuracy: 0.7965\nEpoch 11/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.7636 - accuracy: 0.7781 - val_loss: 0.6295 - val_accuracy: 0.8025\nEpoch 12/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.7265 - accuracy: 0.7893 - val_loss: 0.8198 - val_accuracy: 0.7495\nEpoch 13/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.6938 - accuracy: 0.7992 - val_loss: 0.5903 - val_accuracy: 0.8280\nEpoch 14/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.6656 - accuracy: 0.8108 - val_loss: 0.6364 - val_accuracy: 0.8065\nEpoch 15/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.6524 - accuracy: 0.8161 - val_loss: 0.7071 - val_accuracy: 0.7870\nEpoch 16/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.6278 - accuracy: 0.8235 - val_loss: 0.6055 - val_accuracy: 0.8170\nEpoch 17/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.6115 - accuracy: 0.8261 - val_loss: 0.5243 - val_accuracy: 0.8385\nEpoch 18/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.5841 - accuracy: 0.8364 - val_loss: 0.5116 - val_accuracy: 0.8430\nEpoch 19/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.5675 - accuracy: 0.8417 - val_loss: 0.5059 - val_accuracy: 0.8455\nEpoch 20/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.5478 - accuracy: 0.8477 - val_loss: 0.6725 - val_accuracy: 0.8155\nEpoch 21/30\n312/312 [==============================] - 2s 7ms/step - loss: 0.5442 - accuracy: 0.8519 - val_loss: 0.4533 - val_accuracy: 0.8590\nEpoch 22/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.5213 - accuracy: 0.8536 - val_loss: 0.4507 - val_accuracy: 0.8630\nEpoch 23/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.5112 - accuracy: 0.8551 - val_loss: 0.4632 - val_accuracy: 0.8700\nEpoch 24/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.4940 - accuracy: 0.8645 - val_loss: 0.5244 - val_accuracy: 0.8395\nEpoch 25/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.4833 - accuracy: 0.8670 - val_loss: 0.4195 - val_accuracy: 0.8765\nEpoch 26/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.4803 - accuracy: 0.8693 - val_loss: 0.4027 - val_accuracy: 0.8810\nEpoch 27/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.4759 - accuracy: 0.8731 - val_loss: 0.4700 - val_accuracy: 0.8635\nEpoch 28/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.4636 - accuracy: 0.8802 - val_loss: 0.4224 - val_accuracy: 0.8750\nEpoch 29/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.4377 - accuracy: 0.8837 - val_loss: 0.4055 - val_accuracy: 0.8820\nEpoch 30/30\n312/312 [==============================] - 2s 6ms/step - loss: 0.4502 - accuracy: 0.8777 - val_loss: 0.4030 - val_accuracy: 0.8860\n","output_type":"stream"}]},{"cell_type":"code","source":"x_vec_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:18.625338Z","iopub.execute_input":"2024-04-17T10:49:18.625933Z","iopub.status.idle":"2024-04-17T10:49:18.632128Z","shell.execute_reply.started":"2024-04-17T10:49:18.625900Z","shell.execute_reply":"2024-04-17T10:49:18.631213Z"},"trusted":true},"execution_count":128,"outputs":[{"execution_count":128,"output_type":"execute_result","data":{"text/plain":"(2000, 24, 10)"},"metadata":{}}]},{"cell_type":"code","source":"lstm_predictions = lstm_model.predict(x_vec_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:19.598520Z","iopub.execute_input":"2024-04-17T10:49:19.598925Z","iopub.status.idle":"2024-04-17T10:49:20.134549Z","shell.execute_reply.started":"2024-04-17T10:49:19.598895Z","shell.execute_reply":"2024-04-17T10:49:20.133524Z"},"trusted":true},"execution_count":129,"outputs":[{"name":"stdout","text":"63/63 [==============================] - 0s 3ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"predicted_labels = np.argmax(lstm_predictions, axis=1)\n\n# Calculate accuracy\nlstm_accuracy = np.mean(predicted_labels == testing_labels)\nprint(\"LSTM Model Accuracy:\", lstm_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:51:04.191705Z","iopub.execute_input":"2024-04-17T10:51:04.192444Z","iopub.status.idle":"2024-04-17T10:51:04.198848Z","shell.execute_reply.started":"2024-04-17T10:51:04.192410Z","shell.execute_reply":"2024-04-17T10:51:04.197631Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stdout","text":"LSTM Model Accuracy: 0.886\n","output_type":"stream"}]},{"cell_type":"code","source":"predicted_labels","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:32.851581Z","iopub.execute_input":"2024-04-17T10:49:32.852498Z","iopub.status.idle":"2024-04-17T10:49:32.859151Z","shell.execute_reply.started":"2024-04-17T10:49:32.852460Z","shell.execute_reply":"2024-04-17T10:49:32.858068Z"},"trusted":true},"execution_count":131,"outputs":[{"execution_count":131,"output_type":"execute_result","data":{"text/plain":"array([15, 18, 12, ...,  9, 13,  2])"},"metadata":{}}]},{"cell_type":"code","source":"testing_labels","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:37.168435Z","iopub.execute_input":"2024-04-17T10:49:37.169150Z","iopub.status.idle":"2024-04-17T10:49:37.176328Z","shell.execute_reply.started":"2024-04-17T10:49:37.169115Z","shell.execute_reply":"2024-04-17T10:49:37.175289Z"},"trusted":true},"execution_count":132,"outputs":[{"execution_count":132,"output_type":"execute_result","data":{"text/plain":"array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"len(cnn_predictions)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:41.558654Z","iopub.execute_input":"2024-04-17T10:49:41.559057Z","iopub.status.idle":"2024-04-17T10:49:41.565249Z","shell.execute_reply.started":"2024-04-17T10:49:41.559026Z","shell.execute_reply":"2024-04-17T10:49:41.564317Z"},"trusted":true},"execution_count":133,"outputs":[{"execution_count":133,"output_type":"execute_result","data":{"text/plain":"2000"},"metadata":{}}]},{"cell_type":"code","source":"len(lstm_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:42.194281Z","iopub.execute_input":"2024-04-17T10:49:42.194685Z","iopub.status.idle":"2024-04-17T10:49:42.201481Z","shell.execute_reply.started":"2024-04-17T10:49:42.194652Z","shell.execute_reply":"2024-04-17T10:49:42.200290Z"},"trusted":true},"execution_count":134,"outputs":[{"execution_count":134,"output_type":"execute_result","data":{"text/plain":"2000"},"metadata":{}}]},{"cell_type":"code","source":"lstm_predictions[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:43.885474Z","iopub.execute_input":"2024-04-17T10:49:43.886373Z","iopub.status.idle":"2024-04-17T10:49:43.893437Z","shell.execute_reply.started":"2024-04-17T10:49:43.886338Z","shell.execute_reply":"2024-04-17T10:49:43.892313Z"},"trusted":true},"execution_count":135,"outputs":[{"execution_count":135,"output_type":"execute_result","data":{"text/plain":"array([9.83072005e-06, 1.38123016e-06, 1.44096948e-05, 1.91554045e-06,\n       1.13989856e-07, 1.08048084e-06, 6.07343509e-07, 5.79055470e-09,\n       8.60960154e-06, 1.97093386e-09, 5.94858779e-03, 5.79317420e-05,\n       1.85883528e-05, 2.08153469e-05, 1.24518760e-06, 9.93853927e-01,\n       4.80617359e-07, 4.40618624e-06, 8.83937048e-08, 5.57691819e-05],\n      dtype=float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"## LSTM is working and acc is 86.6% (Cifar 10) - VitGpt2 model\n## LSTM is working and acc is 93.6% (Cifar 100 - 20 random classes) - Manually generated captions","metadata":{}},{"cell_type":"code","source":"cnn_predictions[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:48.061817Z","iopub.execute_input":"2024-04-17T10:49:48.062424Z","iopub.status.idle":"2024-04-17T10:49:48.069345Z","shell.execute_reply.started":"2024-04-17T10:49:48.062392Z","shell.execute_reply":"2024-04-17T10:49:48.068428Z"},"trusted":true},"execution_count":136,"outputs":[{"execution_count":136,"output_type":"execute_result","data":{"text/plain":"array([1.5605792e-07, 6.1407650e-07, 2.8094586e-03, 7.5734725e-09,\n       3.6179326e-06, 1.0954192e-07, 1.2119324e-05, 9.5738395e-09,\n       5.5669389e-06, 3.3082672e-11, 3.3077107e-08, 1.5863124e-08,\n       1.5333503e-09, 1.4261224e-08, 9.1088532e-09, 9.9716777e-01,\n       1.3310893e-07, 1.1027579e-08, 3.5578270e-07, 5.0337579e-08],\n      dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"cnn_predictions.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:49.295504Z","iopub.execute_input":"2024-04-17T10:49:49.296383Z","iopub.status.idle":"2024-04-17T10:49:49.302289Z","shell.execute_reply.started":"2024-04-17T10:49:49.296345Z","shell.execute_reply":"2024-04-17T10:49:49.301253Z"},"trusted":true},"execution_count":137,"outputs":[{"execution_count":137,"output_type":"execute_result","data":{"text/plain":"(2000, 20)"},"metadata":{}}]},{"cell_type":"code","source":"lstm_predictions.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:50.802356Z","iopub.execute_input":"2024-04-17T10:49:50.803069Z","iopub.status.idle":"2024-04-17T10:49:50.809496Z","shell.execute_reply.started":"2024-04-17T10:49:50.803033Z","shell.execute_reply":"2024-04-17T10:49:50.808565Z"},"trusted":true},"execution_count":138,"outputs":[{"execution_count":138,"output_type":"execute_result","data":{"text/plain":"(2000, 20)"},"metadata":{}}]},{"cell_type":"code","source":"testing_labels","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:50:08.441341Z","iopub.execute_input":"2024-04-17T10:50:08.441770Z","iopub.status.idle":"2024-04-17T10:50:08.449613Z","shell.execute_reply.started":"2024-04-17T10:50:08.441739Z","shell.execute_reply":"2024-04-17T10:50:08.448495Z"},"trusted":true},"execution_count":140,"outputs":[{"execution_count":140,"output_type":"execute_result","data":{"text/plain":"array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"# Step 5: Late Fusion Ensemble\ntesting_labels = np.argmax(testing_labels, axis=1)\n\nensemble_predictions = np.argmax(np.sum([cnn_predictions, lstm_predictions], axis=0), axis=1)\n\n# Step 6: Compare Predictions with Original Classes\naccuracy = np.mean(ensemble_predictions == testing_labels)\nprint(\"Ensemble Model Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:50:44.454947Z","iopub.execute_input":"2024-04-17T10:50:44.455382Z","iopub.status.idle":"2024-04-17T10:50:44.463474Z","shell.execute_reply.started":"2024-04-17T10:50:44.455353Z","shell.execute_reply":"2024-04-17T10:50:44.462349Z"},"trusted":true},"execution_count":141,"outputs":[{"name":"stdout","text":"Ensemble Model Accuracy: 0.902\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## AUTOMATE ENSEMBLE","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow as tf\n\n# Define the folder path\nfolder_path = '/kaggle/input/cnn-models/cnn'\n\n# Get a list of all files in the folder\nfile_list = os.listdir(folder_path)\n\n# Filter out only the .h5 files\nmodel_files = [file for file in file_list if file.endswith('.h5')]\n\n# Load each model\ncnn_models = []\nfor model_file in model_files[0:4]:\n    model_path = os.path.join(folder_path, model_file)\n    cnn_model = tf.keras.models.load_model(model_path)\n    cnn_models.append(cnn_model)\n\n# Now cnn_models list contains all the loaded CNN models\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:50.075341Z","iopub.execute_input":"2024-03-21T14:46:50.075701Z","iopub.status.idle":"2024-03-21T14:46:52.857385Z","shell.execute_reply.started":"2024-03-21T14:46:50.075672Z","shell.execute_reply":"2024-03-21T14:46:52.856344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train each model and track validation accuracy\nvalidation_accuracies = []\nfor lstm_model in top_lstm_models:\n    history = lstm_model.fit(x_vec_train,\n                             training_labels,\n                             batch_size=32,\n                             epochs=1,\n                             validation_data=(x_vec_test, testing_labels),\n                             shuffle=True)\n    \n    # Get the validation accuracy from the history\n    validation_accuracy = history.history['val_accuracy'][-1]\n    validation_accuracies.append(validation_accuracy)\n\n# Sort the models based on validation accuracy\nsorted_indices = sorted(range(len(validation_accuracies)), key=lambda i: validation_accuracies[i], reverse=True)\ntop_lstm_models = [lstm_models[i] for i in sorted_indices[:4]]  # Select the top 4 models\n\n# Train the top 4 LSTM models\nhistories = []\nfor lstm_model in top_lstm_models:\n    lstm_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    history = lstm_model.fit(x_vec_train,\n                             training_labels,\n                             batch_size=32,\n                             epochs=1,\n                             validation_data=(x_vec_test, testing_labels),\n                             shuffle=True)\n    histories.append(history)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:47:18.511846Z","iopub.execute_input":"2024-03-21T14:47:18.512756Z","iopub.status.idle":"2024-03-21T14:47:18.560206Z","shell.execute_reply.started":"2024-03-21T14:47:18.512723Z","shell.execute_reply":"2024-03-21T14:47:18.559035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the LSTM and CNN models\nlstm_model = tf.keras.models.load_model('/kaggle/input/lstm-parent-model-final/parent_0_model (1).h5')\ncnn_model = tf.keras.models.load_model('/kaggle/input/cnn-model-16layers/cnn_model_.h5')","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n# Assuming you have lists of predictions from the top LSTM and CNN models\ncnn_predictions = [model.predict(testing_cnn_data_selected) for model in cnn_models]\nlstm_predictions = [model.predict(x_vec_test) for model in top_lstm_models]\n\n# Combine predictions using majority voting\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:53:03.403505Z","iopub.execute_input":"2024-03-19T10:53:03.403861Z","iopub.status.idle":"2024-03-19T10:53:22.292528Z","shell.execute_reply.started":"2024-03-19T10:53:03.403834Z","shell.execute_reply":"2024-03-19T10:53:22.291675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Combine predictions using majority voting\ndef majority_voting(predictions):\n    combined_predictions = []\n    for sample_predictions in zip(*predictions):\n        sample_predictions_list = [tuple(prediction) for prediction in sample_predictions]\n        votes = Counter(sample_predictions_list)\n        majority_vote = votes.most_common(1)[0][0]\n        combined_predictions.append(majority_vote)\n    return combined_predictions\n\n\n\n\n# Combine LSTM and CNN predictions using majority voting\nensemble_predictions = majority_voting(lstm_predictions + cnn_predictions)\nensemble_classes = [prediction.index(max(prediction)) for prediction in ensemble_predictions]\n\n\npredicted_labels = np.argmax(lstm_predictions, axis=1)\n\n# Calculate accuracy\n#lstm_accuracy = np.mean(ensemble_predictions == testing_labels)\n#print(\"Ensemble Accuracy:\", lstm_accuracy)\n\n\n# Evaluate ensemble performance\nensemble_accuracy = accuracy_score(testing_labels, ensemble_classes)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:44:35.398346Z","iopub.execute_input":"2024-03-19T10:44:35.398744Z","iopub.status.idle":"2024-03-19T10:44:36.075712Z","shell.execute_reply.started":"2024-03-19T10:44:35.398715Z","shell.execute_reply":"2024-03-19T10:44:36.074856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.shape(lstm_predictions)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:55:15.363127Z","iopub.execute_input":"2024-03-19T10:55:15.363509Z","iopub.status.idle":"2024-03-19T10:55:15.370482Z","shell.execute_reply.started":"2024-03-19T10:55:15.363479Z","shell.execute_reply":"2024-03-19T10:55:15.369543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.shape(cnn_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:55:16.122988Z","iopub.execute_input":"2024-03-19T10:55:16.123352Z","iopub.status.idle":"2024-03-19T10:55:16.130424Z","shell.execute_reply.started":"2024-03-19T10:55:16.123323Z","shell.execute_reply":"2024-03-19T10:55:16.129477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_predictions","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:52:10.078728Z","iopub.execute_input":"2024-03-19T10:52:10.079125Z","iopub.status.idle":"2024-03-19T10:52:10.090250Z","shell.execute_reply.started":"2024-03-19T10:52:10.079096Z","shell.execute_reply":"2024-03-19T10:52:10.089236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Convert lists to NumPy arrays\nlstm_predictions_array = np.array(lstm_predictions)\ncnn_predictions_array = np.array(cnn_predictions)\n\n# Reshape LSTM and CNN predictions to (num_samples, sequence_length * num_classes)\nlstm_predictions_reshaped = lstm_predictions_array.reshape(lstm_predictions_array.shape[0], -1)\ncnn_predictions_reshaped = cnn_predictions_array.reshape(cnn_predictions_array.shape[0], -1)\n\n# Concatenate reshaped predictions\nx_train = np.concatenate((lstm_predictions_reshaped, cnn_predictions_reshaped), axis=1)\n\n# Assuming y_train contains ground truth labels with shape (num_samples,)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:59:20.963469Z","iopub.execute_input":"2024-03-19T10:59:20.964317Z","iopub.status.idle":"2024-03-19T10:59:20.972996Z","shell.execute_reply.started":"2024-03-19T10:59:20.964275Z","shell.execute_reply":"2024-03-19T10:59:20.972063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_predictions[0][0]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:24:14.712708Z","iopub.execute_input":"2024-03-19T11:24:14.713061Z","iopub.status.idle":"2024-03-19T11:24:14.720141Z","shell.execute_reply.started":"2024-03-19T11:24:14.713036Z","shell.execute_reply":"2024-03-19T11:24:14.718906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_pred = ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\n# Prepare Data\n# Assuming lstm_predictions, cnn_predictions, and correct_outputs contain the predictions and correct outputs\n# Concatenate LSTM and CNN predictions\nx_train = np.concatenate((lstm_predictions[0], cnn_predictions[0]), axis=1)\n\n# Calculate Weightage Distribution\n# For example, calculate the weightage based on accuracy\nlstm_accuracy = accuracy_score(lstm_predictions[0], testing_labels)\ncnn_accuracy = accuracy_score(cnn_predictions[0], testing_labels)\ntotal_accuracy = lstm_accuracy + cnn_accuracy\nlstm_weight = lstm_accuracy / total_accuracy\ncnn_weight = cnn_accuracy / total_accuracy\n\n# Prepare Target Weightage Distribution\ntarget_weightage = np.concatenate((lstm_weight, cnn_weight), axis=1)\n\n# Define Fusion Network Architecture\nfusion_network = tf.keras.Sequential([\n    tf.keras.layers.Dense(64, activation='relu', input_shape=(num_features,)),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(num_modalities, activation='softmax')  # Output layer for weightage distribution\n])\n\n# Compile Fusion Network\nfusion_network.compile(optimizer='adam', loss='categorical_crossentropy')\n\n# Train Fusion Network\nfusion_network.fit(x_train, target_weightage, epochs=10, batch_size=32, validation_split=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:23:48.952093Z","iopub.execute_input":"2024-03-19T11:23:48.952500Z","iopub.status.idle":"2024-03-19T11:23:49.046462Z","shell.execute_reply.started":"2024-03-19T11:23:48.952470Z","shell.execute_reply":"2024-03-19T11:23:49.045125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_classes = [prediction.index(max(prediction)) for prediction in ensemble_predictions]\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:35:02.178910Z","iopub.execute_input":"2024-03-19T10:35:02.179276Z","iopub.status.idle":"2024-03-19T10:35:02.204524Z","shell.execute_reply.started":"2024-03-19T10:35:02.179247Z","shell.execute_reply":"2024-03-19T10:35:02.203587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_classes[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:35:08.323066Z","iopub.execute_input":"2024-03-19T10:35:08.323779Z","iopub.status.idle":"2024-03-19T10:35:08.329716Z","shell.execute_reply.started":"2024-03-19T10:35:08.323742Z","shell.execute_reply":"2024-03-19T10:35:08.328534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CIFAR-10 class names\ncifar_10_classes = {\n    0: 'airplane',\n    1: 'automobile',\n    2: 'bird',\n    3: 'cat',\n    4: 'deer',\n    5: 'dog',\n    6: 'frog',\n    7: 'horse',\n    8: 'ship',\n    9: 'truck'\n}\n\n# Printing class names for the first 10 elements in image_classes\nprint(\"Class Names:\")\nfor class_index in image_classes[:10]:\n    print(cifar_10_classes[class_index])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T06:28:50.471687Z","iopub.execute_input":"2024-03-08T06:28:50.472061Z","iopub.status.idle":"2024-03-08T06:28:50.478728Z","shell.execute_reply.started":"2024-03-08T06:28:50.472033Z","shell.execute_reply":"2024-03-08T06:28:50.477485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_captions[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-03-08T06:25:59.692904Z","iopub.execute_input":"2024-03-08T06:25:59.693621Z","iopub.status.idle":"2024-03-08T06:25:59.700244Z","shell.execute_reply.started":"2024-03-08T06:25:59.693588Z","shell.execute_reply":"2024-03-08T06:25:59.699205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_classes[0:10]\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T06:26:19.538109Z","iopub.execute_input":"2024-03-08T06:26:19.538621Z","iopub.status.idle":"2024-03-08T06:26:19.546439Z","shell.execute_reply.started":"2024-03-08T06:26:19.538580Z","shell.execute_reply":"2024-03-08T06:26:19.545271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define the ensemble function\ndef ensemble(lstm_outputs, cnn_outputs):\n    # Add your ensemble code here\n    return lstm_outputs, cnn_outputs\n\n# Make predictions on the image and text data\nlstm_predictions = []\ncnn_predictions = []\nfor image_batch, text_batch in zip(image_generator, text_generator):\n    lstm_outputs = lstm_model.predict(text_batch)\n    cnn_outputs = cnn_model.predict(image_batch)\n    lstm_predictions.append(lstm_outputs)\n    cnn_predictions.append(cnn_outputs)\nlstm_predictions = np.vstack(lstm_predictions)\ncnn_predictions = np.vstack(cnn_predictions)\n\n# Ensemble the predictions using voting strategy\nensemble_predictions = ensemble(lstm_predictions, cnn_predictions)\n\n# Take the average of the probabilities from both models for each class\nensemble_predictions = (ensemble_predictions[0] + ensemble_predictions[1]) / 2\n\n# Select the class with the highest average probability as the final prediction\nfinal_predictions = np.argmax(ensemble_predictions, axis=1)","metadata":{},"execution_count":null,"outputs":[]}]}