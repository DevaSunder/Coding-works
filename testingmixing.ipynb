{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8153205,"sourceType":"datasetVersion","datasetId":4822379},{"sourceId":8175461,"sourceType":"datasetVersion","datasetId":4839281},{"sourceId":8175464,"sourceType":"datasetVersion","datasetId":4839283},{"sourceId":8194523,"sourceType":"datasetVersion","datasetId":4853536},{"sourceId":8194667,"sourceType":"datasetVersion","datasetId":4853652}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### UTILITIES\nfrom keras.datasets import cifar10\nfrom keras.utils import to_categorical\nimport pickle\nimport sys\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nimport numpy as np\n\ndef load_dataset(batch_size, num_classes, epochs):\n    (x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n\n    # Select a random subset of 4500 images for training\n    random_indices = np.random.choice(len(x_train_full), size=50000, replace=False)\n    x_train = x_train_full[random_indices]\n    y_train = y_train_full[random_indices]\n\n    # Normalize and one-hot encode the labels\n    x_train = x_train.astype('float32') / 255\n    x_test = x_test.astype('float32') / 255\n    y_train = to_categorical(y_train, num_classes)\n    y_test = to_categorical(y_test, num_classes)\n\n    # Randomly select 500 images for validation\n    random_indices = np.random.choice(len(x_test), size=10000, replace=False)\n    x_val = x_test[random_indices]\n    y_val = y_test[random_indices]\n\n    dataset = {\n        'batch_size': batch_size,\n        'num_classes': num_classes,\n        'epochs': epochs,\n        'x_train': x_train,\n        'y_train': y_train,\n        'x_val': x_val,\n        'y_val': y_val,\n        'x_test': x_test,  \n        'y_test': y_test\n    }\n\n    return dataset\n\n\ndef save_network(network):\n    #object_file = open(network.name + '.obj', 'wb')\n    #pickle.dump(network, object_file)\n    #tf.keras.models.save_model(network, network.name)\n\n    model_path = network.name + '_model.h5'\n    tf.keras.models.save_model(network.model, model_path)\n\n    # Save the rest of the network information\n    network_info = {\n        'name': network.name,\n        'block_list': network.block_list,\n        'fitness': network.fitness\n    }\n    network_info_path = network.name + '_info.pkl'\n    with open(network_info_path, 'wb') as info_file:\n        pickle.dump(network_info, info_file)\n\n\ndef load_network(name):\n    model_path = name + '_model.h5'\n    loaded_model = tf.keras.models.load_model(model_path)\n\n    # Load the network information\n    info_path = name + '_info.pkl'\n    with open(info_path, 'rb') as info_file:\n        network_info = pickle.load(info_file)\n\n    # Create a new Network instance\n    loaded_network = Network(0)  # Update with appropriate 'it' value\n\n    # Set the attributes of the loaded network\n    loaded_network.name = network_info['name']\n    loaded_network.block_list = network_info['block_list']\n    loaded_network.fitness = network_info['fitness']\n    loaded_network.model = loaded_model\n\n    return loaded_network\n\n\n\ndef order_indexes(self):\n    i = 0\n    for block in self.block_list:\n        block.index = i\n        i += 1\n\n\ndef plot_training(history):                                           # plot diagnostic learning curves\n    plt.figure(figsize=[8, 6])  # accuracy curves\n    plt.plot(history.history['accuracy'], 'r', linewidth=3.0)\n    plt.plot(history.history['val_accuracy'], 'b', linewidth=3.0)  # <-- Change 'val_acc' to 'val_accuracy'\n    plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n    plt.xlabel('Epochs ', fontsize=16)\n    plt.ylabel('Accuracy', fontsize=16)\n    plt.title('Accuracy Curves', fontsize=16)\n\n    filename = sys.argv[0].split('/')[-1]\n    plt.savefig(filename + '_acc_plot.png')\n    plt.close()\n\n\n\ndef plot_statistics(stats):\n    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# fitness curves\n    plt.plot([s[0] for s in stats], 'r', linewidth=3.0)\n    plt.plot([stats[0][0]] * len(stats), 'b', linewidth=3.0)\n    plt.legend(['BestFitness', 'InitialFitness'], fontsize=18)\n    plt.xlabel('Generations', fontsize=16)\n    plt.ylabel('FitnessValue', fontsize=16)\n    plt.title('Fitness Curve', fontsize=16)\n    filename = sys.argv[0].split('/')[-1]\n    plt.savefig(filename + '_fitness_plot.png')\n\n    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# parameters curves\n    plt.plot([s[1] for s in stats], 'r', linewidth=3.0)\n    plt.plot([stats[0][1]] * len(stats), 'b', linewidth=3.0)\n    plt.legend(['BestParamsNum', 'InitialParamsNum'], fontsize=18)\n    plt.xlabel('Generations', fontsize=16)\n    plt.ylabel('ParamsNum', fontsize=16)\n    plt.title('Parameters Curve', fontsize=16)\n    filename = sys.argv[0].split('/')[-1]\n    plt.savefig(filename + '_params_plot.png')\n    plt.close()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:08.865544Z","iopub.execute_input":"2024-03-21T14:35:08.866376Z","iopub.status.idle":"2024-03-21T14:35:21.633023Z","shell.execute_reply.started":"2024-03-21T14:35:08.866339Z","shell.execute_reply":"2024-03-21T14:35:21.631981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# INOUT\nimport os\ndef compute_parent(dataset):\n    if os.path.isfile('parent_0.h5'):\n        daddy = load_network('parent_0')\n        model = tf.keras.models.load_model('parent_0.h5')\n        print(\"Loading parent_0\")\n        print(\"SUMMARY OF\", daddy.name)\n        print(model.summary())\n        print(\"FITNESS:\", daddy.fitness)\n        return daddy\n\n    daddy = Network(0)\n    \n    \n    #INI BLOCK\n    layerList1 = [\n        Convolutional(filters=32, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(0, 0, layerList1, layerList2))\n    \n    #MIDDLE BLOCK 1\n    layerList1 = [\n        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 1, layerList1, layerList2))\n\n     #MIDDLE BLOCK 2\n    layerList1 = [\n        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 2, layerList1, layerList2))\n\n    \n    #MIDDLE BLOCK 3\n    layerList1 = [\n        Convolutional(filters=256, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=256, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 3, layerList1, layerList2))\n    \n    \n    \n    #MIDDLE BLOCK 4\n    layerList1 = [\n        Convolutional(filters=512, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=512, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 4, layerList1, layerList2))\n    \n    \n    \n    #FULLY CONNECTED LAYER\n    layerList1 = [\n        FlattenLayer(),\n        FullyConnected(units=128, num_classes=dataset['num_classes'])\n    ]\n    layerList2 = []\n    daddy.block_list.append(Block(2, 5, layerList1, layerList2))\n    \n    \n\n    model = daddy.build_model()\n    print(\"Type of model_final:\", type(model))\n    daddy.train_and_evaluate(model, dataset)\n    return daddy","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:25.599146Z","iopub.execute_input":"2024-03-21T14:35:25.599778Z","iopub.status.idle":"2024-03-21T14:35:25.621856Z","shell.execute_reply.started":"2024-03-21T14:35:25.599747Z","shell.execute_reply":"2024-03-21T14:35:25.620860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NETWORK\nimport tensorflow as tf\nimport os\nimport pickle\nfrom keras.callbacks import Callback\nfrom keras.models import Sequential\nfrom random import randint, choice\nfrom copy import deepcopy\n\n\nclass Network:\n    __slots__ = ('name', 'block_list', 'fitness', 'model')\n\n    def __init__(self, it):\n        self.name = 'parent_' + str(it) if it == 0 else 'net_' + str(it)\n        self.block_list = []\n        self.fitness = None\n        self.model = None\n\n    \"\"\"def build_model(self):\n        model = Sequential()                                # create model\n        for block in self.block_list:\n            for layer in block.get_layers():                # build model\n                try:\n                    layer.build_layer(model)\n                except:\n                    print(\"\\nINDIVIDUAL ABORTED, CREATING A NEW ONE\\n\")\n                    return -1\n        return model\"\"\"\n    def build_model(self):\n        model = Sequential()              \n        print(\"The block is:\")\n        print(self.block_list)                 # create model\n        for block in self.block_list:\n            #print(\"Building block type:\", block.type)\n            #print(\"TOTAL :::\")\n            #print(block.get_layer_name())\n            for layer in block.get_layers():                # build model\n                #print(\"Adding layer:\", layer.name)\n                try:\n                    layer.build_layer(model)\n                    print(\"Layer added successfully.\")\n                except Exception as e:\n                    print(\"Error occurred while adding layer:\", e)\n                    print(\"Returning None.\")\n                    return -1\n        print(\"Model successfully built.\")\n        return model\n\n    def train_and_evaluate(self, model, dataset):\n        print(\"Training\", self.name)\n        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n        try:\n            history = model.fit(dataset['x_train'],\n                                dataset['y_train'],\n                                batch_size=dataset['batch_size'],\n                                epochs=dataset['epochs'],\n                                validation_data=(dataset['x_val'], dataset['y_val']),\n                                shuffle=True)\n        except Exception as e:\n            print(\"An error occurred during model training:\", e)\n            return -1\n            # You can choose to handle the error in a specific way here, like logging it or taking corrective actions.\n\n\n        # Extract metrics from the training history\n        training_loss = history.history['loss'][-1]\n        training_accuracy = history.history['accuracy'][-1]\n        validation_loss = history.history['val_loss'][-1]\n        validation_accuracy = history.history['val_accuracy'][-1]\n\n        # Additional metrics (you can customize this based on your needs)\n        classification_error_rate = 1.0 - validation_accuracy\n\n        self.model = model  # Save the model\n        self.fitness = validation_loss  # Use validation loss as fitness\n\n        # Print metrics\n        print(\"SUMMARY OF\", self.name)\n        print(\"Training Loss:\", training_loss)\n        print(\"Training Accuracy:\", training_accuracy)\n        print(\"Validation Loss:\", validation_loss)\n        print(\"Validation Accuracy:\", validation_accuracy)\n        print(\"Classification Error Rate:\", classification_error_rate)\n\n        tf.keras.models.save_model(model, self.name + '.h5')         # save model\n        #model.save(self.name + '.h5')                       # save model\n        save_network(self)                                  # save topology, model and fitness\n\n    def asexual_reproduction(self, it, dataset):\n\n        # if the individual already exists, just load it\n        if os.path.isfile('net_' + str(it) + '.h5'):\n            print(\"\\n-------------------------------------\")\n            print(\"Loading individual net_\" + str(it))\n            print(\"--------------------------------------\\n\")\n            individual = load_network('net_' + str(it))\n            model = tf.keras.models.load_model(individual.name + '.h5')\n            print(\"SUMMARY OF\", individual.name)\n            print(model.summary())\n            print(\"FITNESS: \", individual.fitness)\n            return individual\n\n        # otherwise, create the individual by mutating the parent\n        individual = Network(it)\n\n        print(\"\\n-------------------------------------\")\n        print(\"\\nCreating individual\", individual.name)\n        print(\"--------------------------------------\\n\")\n\n        individual.block_list = deepcopy(self.block_list)           # copy the layer list from parent\n\n        print(\"----->Strong Mutation\")\n        individual.block_mutation(dataset)                          # mutate a block\n        individual.layer_mutation(dataset)                          # mutate a layer\n        individual.parameters_mutation()                            # mutate some parameters\n\n        model = individual.build_model()\n        \n        if model == -1:\n            return self.asexual_reproduction(it, dataset)\n        \n        if(individual.train_and_evaluate(model, dataset)==-1):\n            return self.asexual_reproduction(it, dataset)\n        else:\n            return individual\n            \n\n    def block_mutation(self, dataset):\n        try:\n            print(\"Block Mutation\")\n\n            print([(block.index, block.type) for block in self.block_list])\n\n            # block list containing all the blocks with type = 1\n            bl = [block.index for block in self.block_list if block.type == 1]\n\n            if len(bl) == 0:\n                print(\"Creating a new block with two Convolutional layers and a Pooling layer\")\n                self.block_list[1].index = 2\n                layerList1 = [\n                    Convolutional(filters=pow(2, randint(5, 8)),\n                                  filter_size=(3, 3),\n                                  stride_size=(1, 1),\n                                  padding='same',\n                                  input_shape=dataset['x_train'].shape[1:]),\n                    Convolutional(filters=pow(2, randint(5, 8)),\n                                  filter_size=(3, 3),\n                                  stride_size=(1, 1),\n                                  padding='same',\n                                  input_shape=dataset['x_train'].shape[1:])\n                ]\n                layerList2 = [\n                    Pooling(pool_size=(2, 2),\n                            stride_size=(2, 2),\n                            padding='same')\n                ]\n                b = Block(1, 1, layerList1, layerList2)\n                self.block_list.insert(1, b)\n                return\n\n            block_idx = randint(1, max(bl))         # pick a random block among all the blocks with type = 1\n            block_type_idx = randint(0, 1)          # 1 -> Conv2D; 0 -> Pooling or Dropout\n            mutation_type = randint(0, 1)           # 1 -> remove; 0 -> add\n\n            # list of layers of the selected block\n            layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n            length = len(layerList)\n\n            if mutation_type:                                       # remove\n                if length == 1:\n                    del self.block_list[block_idx]\n                elif block_type_idx:\n                    pos = randint(0, length - 1)\n                    print(\"Removing a Conv2D layer at\", pos)\n                    del layerList[pos]\n                else:\n                    pos = randint(0, length - 1)\n                    print(\"Removing a Pooling/Dropout layer at\", pos)\n                    del layerList[pos]\n            else:                                                   # add\n                if block_type_idx:\n                    print(\"Inserting a Convolutional layer\")\n                    layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                          filter_size=(3, 3),\n                                          stride_size=(1, 1),\n                                          padding='same',\n                                          input_shape=dataset['x_train'].shape[1:])\n                    layerList.insert(randint(0, length - 1), layer)\n                else:\n                    if randint(0, 1):                               # 1 -> Pooling; 0 -> Dropout\n                        print(\"Inserting a Pooling layer\")\n                        layer = Pooling(pool_size=(2, 2),\n                                        stride_size=(2, 2),\n                                        padding='same')\n                        layerList.insert(randint(0, length - 1), layer)\n                    else:\n                        print(\"Inserting a Dropout layer\")\n                        rate = choice([0.15, 0.25, 0.35, 0.50])\n                        layer = Dropout(rate=rate)\n                        layerList.insert(randint(0, length - 1), layer)\n        except Exception as e:\n            print(f\"An error occurred during block mutation: {e}\")\n            return None\n\n                    \n                    \n                    \n                    \n                    \n\n    \"\"\"def layer_mutation(self, dataset):\n        print(\"Layer Mutation\")\n\n        # pick a random block among all the blocks with type = 1\n        bl = [block.index for block in self.block_list if block.type == 1]\n\n        if len(bl) == 0:\n            return\n\n        block_idx = randint(1, max(bl))\n        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n\n        # list of layers of the selected block\n        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n\n        if len(layerList) == 0:\n            if block_type_idx:\n                layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                      filter_size=(3, 3),\n                                      stride_size=(1, 1),\n                                      padding='same',\n                                      input_shape=dataset['x_train'].shape[1:])\n                self.block_list[block_idx].layerList1.append(layer)\n                return\n            else:\n                layer = Pooling(pool_size=(2, 2),\n                                stride_size=(2, 2),\n                                padding='same')\n                self.block_list[block_idx].layerList2.append(layer)\n\n        idx = randint(0, len(layerList) - 1)\n        layer = layerList[idx]\n\n        if layer.name == 'Conv2D':\n            print(\"Splitting Conv2D layer at index\", idx)\n            layer.filters = int(layer.filters * 0.5)\n            layerList.insert(idx, deepcopy(layer))\n        elif layer.name == 'MaxPooling2D' or layer.name == 'AveragePooling2D':\n            print(\"Changing Pooling layer at index\", idx, \"with Conv2D layer\")\n            del layerList[idx]\n            conv_layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                       filter_size=(3, 3),\n                                       stride_size=(2, 2),\n                                       padding=layer.padding,\n                                       input_shape=dataset['x_train'].shape[1:])\n            layerList.insert(idx, conv_layer)\"\"\"\n    \n    def layer_mutation(self, dataset):\n        print(\"Layer Mutation\")\n\n        # Determine the maximum number of layers that can be added or removed\n        max_layers_to_add = 16 - sum(len(block.layerList1) + len(block.layerList2) for block in self.block_list)\n        max_layers_to_remove = sum(len(block.layerList1) + len(block.layerList2) - 1 for block in self.block_list)\n\n        if max_layers_to_add == 0 and max_layers_to_remove == 0:\n            return\n\n        # Pick a random block among all the blocks with type = 1\n        bl = [block.index for block in self.block_list if block.type == 1]\n\n        if len(bl) == 0:\n            return\n\n        block_idx = randint(1, max(bl))\n        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n\n        # List of layers of the selected block\n        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n\n        if len(layerList) == 0:\n            if block_type_idx:\n                layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                      filter_size=(3, 3),\n                                      stride_size=(1, 1),\n                                      padding='same',\n                                      input_shape=dataset['x_train'].shape[1:])\n                self.block_list[block_idx].layerList1.append(layer)\n            else:\n                layer = Pooling(pool_size=(2, 2),\n                                stride_size=(2, 2),\n                                padding='same')\n                self.block_list[block_idx].layerList2.append(layer)\n        else:\n            # Randomly choose whether to add or remove a layer\n            add_layer = bool(randint(0, 1))\n\n            if add_layer and max_layers_to_add > 0:\n                # Add a layer\n                layer = self.create_random_layer(dataset)\n                layerList.insert(randint(0, len(layerList)), layer)\n            elif not add_layer and max_layers_to_remove > 0:\n                # Remove a layer\n                idx = randint(0, len(layerList) - 1)\n                del layerList[idx]\n\n        # Ensure the total number of layers in the block doesn't exceed 16\n        if len(self.block_list[block_idx].layerList1) + len(self.block_list[block_idx].layerList2) > 16:\n            # Remove a random layer to maintain the total count of 16 layers\n            block_layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n            del block_layerList[randint(0, len(block_layerList) - 1)]\n\n    def create_random_layer(self, dataset):\n        # Create a random layer (Conv2D or Pooling)\n        if randint(0, 1):\n            # Conv2D layer\n            return Convolutional(filters=pow(2, randint(5, 8)),\n                                 filter_size=(3, 3),\n                                 stride_size=(1, 1),\n                                 padding='same',\n                                 input_shape=dataset['x_train'].shape[1:])\n        else:\n            # Pooling layer\n            return Pooling(pool_size=(2, 2),\n                           stride_size=(2, 2),\n                           padding='same')\n\n            \n            \n            \n            \n            \n            \n            \n            \n\n    def parameters_mutation(self):\n        print(\"Parameters Mutation\")\n        for block in self.block_list:\n            for layer in block.get_layers():\n                if randint(0, 1):\n                    layer.mutate_parameters()\n\n    def save_network_info(self, info_filename):\n        network_info = {\n            'name': self.name,\n            'block_list': self.block_list,\n            'fitness': self.fitness\n        }\n\n        with open(info_filename, 'wb') as info_file:\n            pickle.dump(network_info, info_file)\n\n    def load_network_info(self, info_filename):\n        with open(info_filename, 'rb') as info_file:\n            network_info = pickle.load(info_file)\n\n        self.name = network_info['name']\n        self.block_list = network_info['block_list']\n        self.fitness = network_info['fitness']\n\n    def save_model(self, model_filename):\n        self.model.save(model_filename)\n\n    def load_model(self, model_filename):\n        self.model = tf.keras.models.load_model(model_filename)\n\n    def save_network(self, network_info_filename, model_filename):\n        # Save non-model attributes\n        self.save_network_info(network_info_filename)\n\n        # Save the model separately\n        self.save_model(model_filename)\n\n    def load_network(self, network_info_filename, model_filename):\n        # Load non-model attributes\n        self.load_network_info(network_info_filename)\n\n        # Load the model separately\n        self.load_model(model_filename)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:27.022012Z","iopub.execute_input":"2024-03-21T14:35:27.022374Z","iopub.status.idle":"2024-03-21T14:35:27.078711Z","shell.execute_reply.started":"2024-03-21T14:35:27.022345Z","shell.execute_reply":"2024-03-21T14:35:27.077468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TOPOLOGY\n\nimport keras.layers\nfrom random import randint\n\n\nclass Block:\n\t__slots__ = ('type', 'index', 'layerList1', 'layerList2')\n\n\tdef __init__(self, type, index, layerList1, layerList2):\n\t\tself.type = type\t\t\t\t\t\t\t\t\t\t# 0 -> initial layer; 1 -> mid layers; 2 -> final layer\n\t\tself.index = index\t\t\t\t\t\t\t\t\t\t# block index among all the blocks\n\t\tself.layerList1 = layerList1\t\t\t\t\t\t\t# Convolutional layers\n\t\tself.layerList2 = layerList2\t\t\t\t\t\t\t# Pooling and Dropout layers\n\n\tdef get_layers(self):\n\t\treturn self.layerList1 + self.layerList2\n\n\tdef get_size(self):\n\t\treturn len(self.get_layers())\n\n\nclass Convolutional:\n\t# __slots__ = ('name', 'filters', 'padding', 'filter_size', 'stride_size', 'input_shape')\n\n\tdef __init__(self, filters, padding, filter_size, stride_size, input_shape):\n\t\tself.name = 'Conv2D'\n\t\tself.filters = filters\n\t\tself.padding = padding\n\t\tself.filter_size = filter_size\n\t\tself.stride_size = stride_size\n\t\tself.input_shape = input_shape\n\n\tdef build_layer(self, model):\n\t\ttry:\n\t\t\tmodel.add(keras.layers.Conv2D(filters=self.filters,\n\t\t\t\t\t\t\t\t\t\t\tkernel_size=self.filter_size,\n\t\t\t\t\t\t\t\t\t\t\tstrides=self.stride_size,\n\t\t\t\t\t\t\t\t\t\t\tpadding=self.padding,\n\t\t\t\t\t\t\t\t\t\t\tactivation='relu',\n\t\t\t\t\t\t\t\t\t\t\tkernel_initializer='he_uniform',\n\t\t\t\t\t\t\t\t\t\t\tinput_shape=self.input_shape))\n\t\texcept ValueError as e:\n\t\t\tprint(\"Error occurred while adding layer:\", e)\n\t\t\tprint(\"Skipping current architecture.\")\n\t\t\treturn  # Skip adding this layer\n\tdef mutate_parameters(self):\n\t\tmutation = randint(0, 2)  # Adjusted the number of mutations\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tif mutation == 0 and self.filters >= 64:  # Adjusted the filter reduction threshold\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters = int(self.filters / 2)\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 1 and self.filters <= 256:  # Adjusted the filter increase threshold\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters *= 2\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 2:\n\t\t\tif self.padding == 'valid':\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'same'\n\t\t\t\tprint(\"to \", self.padding)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'valid'\n\t\t\t\tprint(\"to \", self.padding)\n\n        \n\n        \n\n\n\t\"\"\"def mutate_parameters(self):\n\t\tmutation = randint(0, 4)\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tif mutation == 0 and self.filters >= 32:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters = int(self.filters / 2)\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 1 and self.filters >= 32:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters = int(self.filters / 2)\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 2 and self.filters <= 512:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters *= 2\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 3 and self.filters <= 512:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters *= 2\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 4:\n\t\t\tif self.padding == 'valid':\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'same'\n\t\t\t\tprint(\"to \", self.padding)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'valid'\n\t\t\t\tprint(\"to \", self.padding)\n\"\"\"\n    \n\n'''\nelif mutation is 4:\n\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n\tprint(\"to \", self.stride_size, \" and \", end=\"\")\n\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n\tprint(\"to \", self.stride_size)\n'''\n\n\nclass Pooling:\n\t__slots__ = ('name', 'pool_size', 'stride_size', 'padding')\n\n\tdef __init__(self, pool_size, stride_size, padding):\n\t\tself.name = 'MaxPooling2D'\n\t\tself.pool_size = pool_size\n\t\tself.stride_size = stride_size\n\t\tself.padding = padding\n\n\tdef build_layer(self, model):\n\t\tif self.name == 'MaxPooling2D':\n\t\t\tmodel.add(keras.layers.MaxPooling2D(self.pool_size, self.stride_size, self.padding))\n\t\telif self.name == 'AveragePooling2D':\n\t\t\tmodel.add(keras.layers.AveragePooling2D(self.pool_size, self.stride_size, self.padding))\n\n\tdef mutate_parameters(self):\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tmutation = randint(0, 1)\n\t\tif mutation == 0:\n\t\t\tif self.padding == 'valid':\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'same'\n\t\t\t\tprint(\"to \", self.padding)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'valid'\n\t\t\t\tprint(\"to \", self.padding)\n\t\telif mutation == 1:\n\t\t\tif self.name == 'MaxPooling2D':\n\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n\t\t\t\tself.name = 'AveragePooling2D'\n\t\t\t\tprint(\"to \", self.name)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n\t\t\t\tself.name = 'MaxPooling2D'\n\t\t\t\tprint(\"to \", self.name)\n\n\n'''\nif mutation is 0:\n\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n\tprint(\"to \", self.stride_size)\n'''\n\n\nclass FullyConnected:\n\t__slots__ = ('name', 'units', 'num_classes')\n\n\tdef __init__(self, units, num_classes):\n\t\tself.name = \"FullyConnected\"\n\t\tself.units = units\n\t\tself.num_classes = num_classes\n\n\tdef build_layer(self, model):\n\t\tmodel.add(keras.layers.Flatten())\n\t\tmodel.add(keras.layers.Dense(self.units, activation='relu', kernel_initializer='he_uniform'))\n\t\tmodel.add(keras.layers.Dense(self.num_classes, activation='softmax'))\n\n\tdef mutate_parameters(self):\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tmutation = randint(0, 2)\n\t\tif mutation == 0:\n\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n\t\t\tself.units *= 2\n\t\t\tprint(\"to \", self.units)\n\t\telif mutation == 1:\n\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n\t\t\tself.units *= 2\n\t\t\tprint(\"to \", self.units)\n\t\telif mutation == 2:\n\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n\t\t\tself.units /= 2\n\t\t\tprint(\"to \", self.units)\n\n\n'''\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(self.num_classes, activation='softmax'))\n'''\n\n\nclass Dropout:\n\t__slots__ = ('name', 'rate')\n\n\tdef __init__(self, rate):\n\t\tself.name = \"Dropout\"\n\t\tself.rate = rate\n\n\tdef build_layer(self, model):\n\t\tmodel.add(keras.layers.Dropout(self.rate))\n\n\tdef mutate_parameters(self):\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tmutation = randint(0, 3)\n\t\tif mutation == 0 and self.rate <= 0.85:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate + 0.10\n\t\t\tprint(\"to \", self.rate)\n\t\telif mutation == 1 and self.rate <= 0.90:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate + 0.05\n\t\t\tprint(\"to \", self.rate)\n\t\telif mutation == 2 and self.rate >= 0.15:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate - 0.10\n\t\t\tprint(\"to \", self.rate)\n\t\telif mutation == 3 and self.rate >= 0.10:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate - 0.05\n\t\t\tprint(\"to \", self.rate)\n\nclass FlattenLayer:\n    def __init__(self):\n        self.name = 'Flatten'\n\n    def build_layer(self, model):\n        model.add(keras.layers.Flatten())\n\n    def mutate_parameters(self):\n        # The Flatten layer does not have any parameters to mutate\n        pass\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:28.087245Z","iopub.execute_input":"2024-03-21T14:35:28.087711Z","iopub.status.idle":"2024-03-21T14:35:28.125784Z","shell.execute_reply.started":"2024-03-21T14:35:28.087683Z","shell.execute_reply":"2024-03-21T14:35:28.124727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"# MAIN\n\nimport tensorflow as tf\ntf.compat.v1.enable_eager_execution()\nimport os\nfrom copy import deepcopy\nfrom random import sample\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)      # suppress messages from Tensorflow\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\n\ndef initialize_population(population_size, dataset):\n    print(\"----->Initializing Population\")\n    daddy = compute_parent(dataset)                                 # load parent from input\n    population = [daddy]\n    for it in range(1, population_size):\n        population.append(daddy.asexual_reproduction(it, dataset))\n\n    # sort population on ascending order based on fitness\n    return sorted(population, key=lambda cnn: cnn.fitness)\n\n\ndef selection(k, population, num_population):\n    if k == 0:                                              # elitism selection\n        print(\"----->Elitism selection\")\n        return population[0], population[1]\n    elif k == 1:                                            # tournament selection\n        print(\"----->Tournament selection\")\n        i = randint(0, num_population - 1)\n        j = i\n        while j < num_population - 1:\n            j += 1\n            if randint(1, 100) <= 50:\n                return population[i], population[j]\n        return population[i], population[0]\n    else:                                                   # proportionate selection\n        print(\"----->Proportionate selection\")\n        cum_sum = 0\n        for i in range(num_population):\n            cum_sum += population[i].fitness\n        perc_range = []\n        for i in range(num_population):\n            count = 100 - int(100 * population[i].fitness / cum_sum)\n            for j in range(count):\n                perc_range.append(i)\n        i, j = sample(range(1, len(perc_range)), 2)\n        while i == j:\n            i, j = sample(range(1, len(perc_range)), 2)\n        return population[perc_range[i]], population[perc_range[j]]\n\n\ndef crossover(parent1, parent2, it):\n    print(\"----->Crossover\")\n    child = Network(it)\n\n    first, second = None, None\n    if randint(0, 1):\n        first = parent1\n        second = parent2\n    else:\n        first = parent2\n        second = parent1\n\n    child.block_list = deepcopy(first.block_list[:randint(1, len(first.block_list) - 1)]) \\\n                       + deepcopy(second.block_list[randint(1, len(second.block_list) - 1):])\n\n    order_indexes(child)                            # order the indexes of the blocks\n\n    return child\n\n\ndef genetic_algorithm(num_population, num_generation, num_offspring, dataset, early_stopping_generations=3):\n    print(\"Genetic Algorithm\")\n\n    population = initialize_population(num_population, dataset)\n\n    print(\"\\n-------------------------------------\")\n    print(\"Initial Population:\")\n    for cnn in population:\n        print(cnn.name, ': ', cnn.fitness)\n    print(\"--------------------------------------\\n\")\n\n    # for printing statistics about fitness and the number of parameters of the best individual\n    stats = [(population[0].fitness, population[0].model.count_params())]\n\n    # Initialize a variable to keep track of consecutive generations with the same best fitness\n    consecutive_same_fitness = 0\n\n    for gen in range(1, num_generation + 1):\n        '''\n            k is the selection parameter:\n                k = 0 -> elitism selection\n                k = 1 -> tournament selection\n                k = 2 -> proportionate selection\n        '''\n        k = randint(0, 2)\n\n        print(\"\\n------------------------------------\")\n        print(\"Generation -----------------------------------------------------------------------------------\", gen)\n        print(\"-------------------------------------\")\n\n        for c in range(num_offspring):\n\n            print(\"\\nCreating Child\", c)\n\n            parent1, parent2 = selection(k, population, num_population)                 # selection\n            print(\"Selected\", parent1.name, \"and\", parent2.name, \"for reproduction\")\n\n            child = crossover(parent1, parent2, c + num_population)                     # crossover\n            print(\"Child has been created\")\n\n            print(\"----->Soft Mutation\")\n            child.layer_mutation(dataset)                                               # mutation\n            child.parameters_mutation()\n            print(\"Child has been mutated\")\n            model = child.build_model()  \n            # evaluation\n            if model==-1:\n                pass\n            else:\n                if(child.train_and_evaluate(model,dataset)==-1):\n                    model=-1  \n            #if(child.train_and_evaluate(model,dataset)==-1):\n                    #model=-1  # evaluation\n\n            while model == -1:\n                child = crossover(parent1, parent2, c + num_population)\n                child.block_mutation(dataset)\n                child.layer_mutation(dataset)\n                child.parameters_mutation()\n                model = child.build_model()\n                if(model==-1):\n                    pass\n                else:\n                    if(child.train_and_evaluate(model,dataset)==-1):\n                        model=-1\n\n            #child.train_and_evaluate(model, dataset)\n\n            if child.fitness < population[-1].fitness:                                  # evolve population\n                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"replaces parent \", end=\"\")\n                print(population[-1].name, \"with fitness\", population[-1].fitness)\n                name = population[-1].name\n\n                child.save_network(\"child_model_info.pkl\", \"child_model.h5\")\n                population[-1].load_network(\"child_model_info.pkl\", \"child_model.h5\")\n\n                population[-1].name = name\n                population = sorted(population, key=lambda net: net.fitness)\n            else:\n                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"is discarded\")\n        \n        if gen >= 3 and all(population[i].fitness == population[i + 1].fitness for i in range(-3, -1)):\n            consecutive_same_fitness += 1\n            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n        if consecutive_same_fitness >= 3:\n            print(\"Stopping the algorithm as the best fitness has remained the same for the last 3 generations.\")\n            break\n    else:\n        consecutive_same_fitness = 0\n        \n       #Check if the best fitness has remained the same for the last early_stopping_generations generations\n        if all(population[i].fitness == population[i + 1].fitness for i in range(-early_stopping_generations, -1)):\n            consecutive_same_fitness += 1\n            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n            if consecutive_same_fitness == early_stopping_generations:\n                print(f\"Stopping the algorithm as the best fitness has remained the same for {early_stopping_generations} generations.\")\n        else:\n            consecutive_same_fitness = 0\n        stats.append((population[0].fitness, population[0].model.count_params()))\n\n    print(\"\\n\\n-------------------------------------\")\n    print(\"Final Population\")\n    print(\"-------------------------------------\\n\")\n    for cnn in population:\n        print(cnn.name, ': ', cnn.fitness)\n\n    print(\"\\n-------------------------------------\")\n    print(\"Stats\")\n    for i in range(len(stats)):\n        print(\"Best individual at generation\", i + 1, \"has fitness\", stats[i][0], \"and parameters\", stats[i][1])\n    print(\"-------------------------------------\\n\")\n\n    # plot the fitness and the number of parameters of the best individual at each iteration\n    plot_statistics(stats)\n\n    return population[0]\n\n\n\ndef main():    \n        #with strategy.scope():\n        #from tensorflow.python.client import device_lib\n        #print(device_lib.list_local_devices())\n        #batch_size = 8\n        #batch_size = batch_size * strategy.num_replicas_in_sync\n        batch_size = 32                       # the number of training examples in one forward/backward pass\n        num_classes = 10                        # number of cifar-10 dataset classes\n        epochs =20              # number of forward and backward passes of all the training examples\n\n        '''\n            dataset contains the hyper parameters for loading data and the dataset:\n                dataset = {\n                    'batch_size': batch_size,\n                    'num_classes': num_classes,\n                    'epochs': epochs,\n                    'x_train': x_train,\n                    'x_test': x_test,\n                    'y_train': y_train,\n                    'y_test': y_test\n                }\n        '''\n        dataset = load_dataset(batch_size, num_classes, epochs)\n\n        num_population = 10\n        num_generation = 20\n        num_offspring = 4\n\n        # plot the best model obtained\n        optCNN = genetic_algorithm(num_population, num_generation, num_offspring, dataset)\n\n        # plot the training and validation loss and accuracy\n        num_epoch = 20\n        model = optCNN.build_model()\n        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n        history = model.fit(dataset['x_train'],\n                            dataset['y_train'],\n                            batch_size=dataset['batch_size'],\n                            epochs=num_epoch,\n                            validation_data=(dataset['x_test'], dataset['y_test']),\n                            shuffle=True)\n        optCNN.model = model                                        # model\n        optCNN.fitness = history.history['val_loss'][-1]            # fitness\n\n        print(\"\\n\\n-------------------------------------\")\n        print(\"The Final CNN has been evolved successfully in the individual\", optCNN.name)\n        print(\"-------------------------------------\\n\")\n        daddy = load_network('parent_0')\n        model = tf.keras.models.load_model('parent_0.h5')\n        print(\"\\n\\n-------------------------------------\")\n        print(\"Summary of initial CNN\")\n        print(model.summary())\n        print(\"Fitness of initial CNN:\", daddy.fitness)\n\n        print(\"\\n\\n-------------------------------------\")\n        print(\"Summary of evolved individual\")\n        print(optCNN.model.summary())\n        print(\"Fitness of the evolved individual:\", optCNN.fitness)\n        print(\"-------------------------------------\\n\")\n\n        plot_training(history)\n\n\nif __name__ == '__main__':\n    main()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:34:10.099189Z","iopub.execute_input":"2024-03-19T09:34:10.099594Z","iopub.status.idle":"2024-03-19T09:34:10.118001Z","shell.execute_reply.started":"2024-03-19T09:34:10.099563Z","shell.execute_reply":"2024-03-19T09:34:10.116664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"## To remove a folder\n# Clear output folder\nimport os\n\ndef remove_folder_contents(folder):\n    for the_file in os.listdir(folder):\n        file_path = os.path.join(folder, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                remove_folder_contents(file_path)\n                os.rmdir(file_path)\n        except Exception as e:\n            print(e)\n\nfolder_path = '/kaggle/working'\nremove_folder_contents(folder_path)\nos.rmdir(folder_path)\"\"\"\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:34:11.054431Z","iopub.execute_input":"2024-03-19T09:34:11.054798Z","iopub.status.idle":"2024-03-19T09:34:11.061017Z","shell.execute_reply.started":"2024-03-19T09:34:11.054771Z","shell.execute_reply":"2024-03-19T09:34:11.059840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport tensorflow as tf\nimport numpy as np\n\n# Set the paths to the datasets\nimage_dir = '/kaggle/input/fashion-mnist-images-new'\ncsv_file = '/kaggle/input/fashion-mnist-captions-new/Fashion_mnist_captions_new.csv'","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:36:53.059931Z","iopub.execute_input":"2024-04-22T20:36:53.060313Z","iopub.status.idle":"2024-04-22T20:36:53.065360Z","shell.execute_reply.started":"2024-04-22T20:36:53.060286Z","shell.execute_reply":"2024-04-22T20:36:53.064333Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# Load the image and text data\nimage_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\ndata = pd.read_csv(csv_file)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:36:53.727872Z","iopub.execute_input":"2024-04-22T20:36:53.728705Z","iopub.status.idle":"2024-04-22T20:36:53.752048Z","shell.execute_reply.started":"2024-04-22T20:36:53.728672Z","shell.execute_reply":"2024-04-22T20:36:53.751287Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:36:54.638890Z","iopub.execute_input":"2024-04-22T20:36:54.639698Z","iopub.status.idle":"2024-04-22T20:36:54.651033Z","shell.execute_reply.started":"2024-04-22T20:36:54.639664Z","shell.execute_reply":"2024-04-22T20:36:54.650137Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"                                                caption  class  \\\n0          A plain white T-shirt with a round neckline.      0   \n1            A graphic-print T-shirt in shades of blue.      0   \n2           A striped T-shirt featuring vibrant colors.      0   \n3            A fitted black T-shirt with short sleeves.      0   \n4              A casual gray T-shirt with a V-neckline.      0   \n...                                                 ...    ...   \n4993  Ankle boot featuring a sleek and streamlined s...      9   \n4994  Ankle boot crafted with attention to detail an...      9   \n4995           Ankle boot designed for all-day comfort.      9   \n4996      Ankle boot with a sleek and modern aesthetic.      9   \n4997  Ankle boot featuring a minimalist yet stylish ...      9   \n\n               filename  \n0       class_0_image_0  \n1       class_0_image_1  \n2       class_0_image_2  \n3       class_0_image_3  \n4       class_0_image_4  \n...                 ...  \n4993  class_9_image_495  \n4994  class_9_image_496  \n4995  class_9_image_497  \n4996  class_9_image_498  \n4997  class_9_image_499  \n\n[4998 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>class</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A plain white T-shirt with a round neckline.</td>\n      <td>0</td>\n      <td>class_0_image_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A graphic-print T-shirt in shades of blue.</td>\n      <td>0</td>\n      <td>class_0_image_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A striped T-shirt featuring vibrant colors.</td>\n      <td>0</td>\n      <td>class_0_image_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A fitted black T-shirt with short sleeves.</td>\n      <td>0</td>\n      <td>class_0_image_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A casual gray T-shirt with a V-neckline.</td>\n      <td>0</td>\n      <td>class_0_image_4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4993</th>\n      <td>Ankle boot featuring a sleek and streamlined s...</td>\n      <td>9</td>\n      <td>class_9_image_495</td>\n    </tr>\n    <tr>\n      <th>4994</th>\n      <td>Ankle boot crafted with attention to detail an...</td>\n      <td>9</td>\n      <td>class_9_image_496</td>\n    </tr>\n    <tr>\n      <th>4995</th>\n      <td>Ankle boot designed for all-day comfort.</td>\n      <td>9</td>\n      <td>class_9_image_497</td>\n    </tr>\n    <tr>\n      <th>4996</th>\n      <td>Ankle boot with a sleek and modern aesthetic.</td>\n      <td>9</td>\n      <td>class_9_image_498</td>\n    </tr>\n    <tr>\n      <th>4997</th>\n      <td>Ankle boot featuring a minimalist yet stylish ...</td>\n      <td>9</td>\n      <td>class_9_image_499</td>\n    </tr>\n  </tbody>\n</table>\n<p>4998 rows  3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the LSTM and CNN models\nlstm_model = tf.keras.models.load_model('/kaggle/input/fashion-mnist-lstm-model/fashion_mnist_lstm.h5')\ncnn_model = tf.keras.models.load_model('/kaggle/input/fashion-mnist-cnn-nw/fashion_mnist_cnn_nw.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:36:56.152805Z","iopub.execute_input":"2024-04-22T20:36:56.153527Z","iopub.status.idle":"2024-04-22T20:36:56.740589Z","shell.execute_reply.started":"2024-04-22T20:36:56.153497Z","shell.execute_reply":"2024-04-22T20:36:56.739789Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom keras.utils import to_categorical\nfrom PIL import Image\n\ndef load_image(image_path, image_shape):\n    image = Image.open(image_path)\n    image = image.resize((image_shape[1], image_shape[0]))  # Resize to match the required shape\n    image = np.array(image) / 255.0  # Normalize pixel values to [0, 1]\n    return image","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:36:57.448720Z","iopub.execute_input":"2024-04-22T20:36:57.449569Z","iopub.status.idle":"2024-04-22T20:36:57.455363Z","shell.execute_reply.started":"2024-04-22T20:36:57.449539Z","shell.execute_reply":"2024-04-22T20:36:57.454344Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Usage:\nimage_folder = '/kaggle/input/fashion-mnist-images-new'\ncaptions_df = pd.read_csv('/kaggle/input/fashion-mnist-captions-new/Fashion_mnist_captions_new.csv')  # Assuming captions are stored in a CSV file\nnum_classes = 10  # Number of classes/categories\nimage_shape = (28,28)  # Define the shape of the images","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:37:38.629577Z","iopub.execute_input":"2024-04-22T20:37:38.629949Z","iopub.status.idle":"2024-04-22T20:37:38.643761Z","shell.execute_reply.started":"2024-04-22T20:37:38.629920Z","shell.execute_reply":"2024-04-22T20:37:38.643028Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"# Step 1: Load image data from the folder\nimages = []\nimage_filenames = []\nfor filename in os.listdir(image_folder):\n    if filename.endswith(\".png\"):  # Assuming images are in png format\n            image_path = os.path.join(image_folder, filename)\n            image = load_image(image_path, image_shape)\n            images.append(image)\n            image_filenames.append(os.path.splitext(filename)[0])  # Remove file extension\n\n\nimages = []\nimage_filenames = []\n\n# Iterate through each class folder\nfor class_folder in range(10):  # Assuming class folders are named class_0 to class_9\n    class_folder_path = os.path.join(image_folder, f\"class_{class_folder}\")\n\n    # Iterate\n    through each image file in the class folder\n    for filename in os.listdir(class_folder_path):\n        if filename.endswith(\".png\"):  # Assuming images are in png format\n            image_path = os.path.join(class_folder_path, filename)\n            image = load_image(image_path, image_shape)  # Assuming load_image function is defined elsewhere\n            images.append(image)\n            image_filenames.append(os.path.splitext(filename)[0])\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:37:39.894692Z","iopub.execute_input":"2024-04-22T20:37:39.895409Z","iopub.status.idle":"2024-04-22T20:37:39.902202Z","shell.execute_reply.started":"2024-04-22T20:37:39.895375Z","shell.execute_reply":"2024-04-22T20:37:39.901254Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"'# Step 1: Load image data from the folder\\nimages = []\\nimage_filenames = []\\nfor filename in os.listdir(image_folder):\\n    if filename.endswith(\".png\"):  # Assuming images are in png format\\n            image_path = os.path.join(image_folder, filename)\\n            image = load_image(image_path, image_shape)\\n            images.append(image)\\n            image_filenames.append(os.path.splitext(filename)[0])  # Remove file extension\\n\\n\\nimages = []\\nimage_filenames = []\\n\\n# Iterate through each class folder\\nfor class_folder in range(10):  # Assuming class folders are named class_0 to class_9\\n    class_folder_path = os.path.join(image_folder, f\"class_{class_folder}\")\\n\\n    # Iterate\\n    through each image file in the class folder\\n    for filename in os.listdir(class_folder_path):\\n        if filename.endswith(\".png\"):  # Assuming images are in png format\\n            image_path = os.path.join(class_folder_path, filename)\\n            image = load_image(image_path, image_shape)  # Assuming load_image function is defined elsewhere\\n            images.append(image)\\n            image_filenames.append(os.path.splitext(filename)[0])'"},"metadata":{}}]},{"cell_type":"markdown","source":"import os\nfrom multiprocessing import Pool\nfrom functools import partial\n\"\"\"\n\ndef load_image_from_folder(class_folder_path, image_shape):\n    images = []\n    image_filenames = []\n\n    for filename in os.listdir(class_folder_path):\n        if filename.endswith(\".jpg\"):  \n            image_path = os.path.join(class_folder_path, filename)\n            image = load_image(image_path, image_shape)  \n            images.append(image)\n            image_filenames.append(os.path.splitext(filename)[0])\n\n    return images, image_filenames\n\n# Assuming the load_image function is defined elsewhere\ndef load_image(image_path, image_shape):\n    image = Image.open(image_path)\n    image = image.resize((image_shape[1], image_shape[0]))  # Resize to match the required shape\n    image = np.array(image) / 255.0  # Normalize pixel values to [0, 1]\n    return image\n\n\ndef load_image_from_folder(folder_path, image_shape):\n    images = []\n    labels = []\n    image_filenames=[]\n    for label, class_folder in enumerate(sorted(os.listdir(folder_path))):\n        class_path = os.path.join(folder_path, class_folder)\n        for filename in os.listdir(class_path):\n            img_path = os.path.join(class_path, filename)\n            image_filenames.append(os.path.splitext(filename)[0])\n            img = cv2.imread(img_path)\n            img = cv2.resize(img, image_shape)\n            images.append(img)\n            labels.append(label)\n\n    images = np.array(images)\n    #labels = np.array(labels)\n    #print(labels)\n    return images, image_filenames\n\nimport os\nimport numpy as np\nimport cv2\n\ndef load_images_from_folder(folder_path, image_size):\n    images = []\n    labels = []\n\n    # Iterate over each subfolder (class) in the main folder\n    for label, class_folder in enumerate(sorted(os.listdir(folder_path))):\n        class_path = os.path.join(folder_path, class_folder)\n        print(class_path)\n        print(input(\"hi\"))\n        # Iterate over each image file in the current class folder\n        for filename in os.listdir(class_path):\n            img_path = os.path.join(class_path, filename)\n            img = cv2.imread(img_path)  # Read image using OpenCV\n            img = cv2.resize(img, image_size)  # Resize image to specified size\n            images.append(img)  # Append image to images list\n            labels.append(label)  # Append corresponding label to labels list\n\n    # Convert images and labels lists to numpy arrays\n    images = np.array(images)\n    labels = np.array(labels)\n\n    return images, labels\n\n\n\n\nimage_folder = image_dir\nimage_shape = (28,28)  # Define your image shape\n\nnum_classes = 10  # Assuming there are 10 classes\npool = Pool()  # Create a multiprocessing Pool\n\n# Use partial to pass fixed arguments to the load_image_from_folder function\nload_partial = partial(load_image_from_folder, image_shape=image_shape)\n\n# Map the function to process each class folder in parallel\nresults = pool.map(load_partial, [os.path.join(image_folder, f\"class_{i}\") for i in range(num_classes)])\n\n# Combine the results\nimages = []\nimage_filenames = []\nfor class_images, class_filenames in results:\n    images.extend(class_images)\n    image_filenames.extend(class_filenames)\n\npool.close()\npool.join()\"\"\"\n\n# Now you have all images and their filenames loaded efficiently\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T19:56:07.533739Z","iopub.execute_input":"2024-04-22T19:56:07.534502Z","iopub.status.idle":"2024-04-22T19:56:07.811263Z","shell.execute_reply.started":"2024-04-22T19:56:07.534460Z","shell.execute_reply":"2024-04-22T19:56:07.809582Z"}}},{"cell_type":"code","source":"def load_images_from_folder(folder_path, image_size):\n    images = []\n    labels = []\n    image_filenames=[]\n    for label, class_folder in enumerate(sorted(os.listdir(folder_path))):\n        class_path = os.path.join(folder_path, class_folder)\n        for filename in os.listdir(class_path):\n            img_path = os.path.join(class_path, filename)\n            img = cv2.imread(img_path)\n            img = cv2.resize(img, image_size)\n            images.append(img)\n            labels.append(label)\n            image_filenames.append(filename)\n\n    images = np.array(images)\n    labels = np.array(labels)\n    print(labels)\n    return images, image_filenames\n\nimages,image_filenames=load_images_from_folder(image_dir, image_shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:37:41.238481Z","iopub.execute_input":"2024-04-22T20:37:41.238813Z","iopub.status.idle":"2024-04-22T20:38:07.078055Z","shell.execute_reply.started":"2024-04-22T20:37:41.238788Z","shell.execute_reply":"2024-04-22T20:38:07.077134Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"[0 0 0 ... 9 9 9]\n","output_type":"stream"}]},{"cell_type":"code","source":"image_filenames[0:20]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:38:21.654350Z","iopub.execute_input":"2024-04-22T20:38:21.655236Z","iopub.status.idle":"2024-04-22T20:38:21.661625Z","shell.execute_reply.started":"2024-04-22T20:38:21.655193Z","shell.execute_reply":"2024-04-22T20:38:21.660671Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"['class_0_image_65.jpg',\n 'class_0_image_460.jpg',\n 'class_0_image_417.jpg',\n 'class_0_image_238.jpg',\n 'class_0_image_283.jpg',\n 'class_0_image_372.jpg',\n 'class_0_image_219.jpg',\n 'class_0_image_98.jpg',\n 'class_0_image_281.jpg',\n 'class_0_image_413.jpg',\n 'class_0_image_351.jpg',\n 'class_0_image_74.jpg',\n 'class_0_image_432.jpg',\n 'class_0_image_101.jpg',\n 'class_0_image_379.jpg',\n 'class_0_image_138.jpg',\n 'class_0_image_310.jpg',\n 'class_0_image_352.jpg',\n 'class_0_image_369.jpg',\n 'class_0_image_188.jpg']"},"metadata":{}}]},{"cell_type":"code","source":"image_filenames = [filename.replace(\".jpg\", \"\") for filename in image_filenames]\n\n# Print the modified filenames\nprint(image_filenames[0:5])","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:38:27.483116Z","iopub.execute_input":"2024-04-22T20:38:27.483835Z","iopub.status.idle":"2024-04-22T20:38:27.489764Z","shell.execute_reply.started":"2024-04-22T20:38:27.483806Z","shell.execute_reply":"2024-04-22T20:38:27.488847Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"['class_0_image_65', 'class_0_image_460', 'class_0_image_417', 'class_0_image_238', 'class_0_image_283']\n","output_type":"stream"}]},{"cell_type":"code","source":"image_filenames[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:38:28.407900Z","iopub.execute_input":"2024-04-22T20:38:28.408767Z","iopub.status.idle":"2024-04-22T20:38:28.414325Z","shell.execute_reply.started":"2024-04-22T20:38:28.408735Z","shell.execute_reply":"2024-04-22T20:38:28.413384Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"'class_0_image_65'"},"metadata":{}}]},{"cell_type":"code","source":"captions_df['caption']","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:38:30.309780Z","iopub.execute_input":"2024-04-22T20:38:30.310497Z","iopub.status.idle":"2024-04-22T20:38:30.318078Z","shell.execute_reply.started":"2024-04-22T20:38:30.310463Z","shell.execute_reply":"2024-04-22T20:38:30.317022Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"0            A plain white T-shirt with a round neckline.\n1              A graphic-print T-shirt in shades of blue.\n2             A striped T-shirt featuring vibrant colors.\n3              A fitted black T-shirt with short sleeves.\n4                A casual gray T-shirt with a V-neckline.\n                              ...                        \n4993    Ankle boot featuring a sleek and streamlined s...\n4994    Ankle boot crafted with attention to detail an...\n4995             Ankle boot designed for all-day comfort.\n4996        Ankle boot with a sleek and modern aesthetic.\n4997    Ankle boot featuring a minimalist yet stylish ...\nName: caption, Length: 4998, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"image_filenames[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:38:31.186811Z","iopub.execute_input":"2024-04-22T20:38:31.187569Z","iopub.status.idle":"2024-04-22T20:38:31.193149Z","shell.execute_reply.started":"2024-04-22T20:38:31.187536Z","shell.execute_reply":"2024-04-22T20:38:31.192140Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"'class_0_image_65'"},"metadata":{}}]},{"cell_type":"code","source":"len(image_filenames)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:38:32.064951Z","iopub.execute_input":"2024-04-22T20:38:32.065868Z","iopub.status.idle":"2024-04-22T20:38:32.071261Z","shell.execute_reply.started":"2024-04-22T20:38:32.065836Z","shell.execute_reply":"2024-04-22T20:38:32.070322Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"4998"},"metadata":{}}]},{"cell_type":"code","source":"image_captions = []\nimage_classes = []\nfor filename in image_filenames:\n    #print(filename)\n    class_index = int(filename.split('_')[1])\n    #print(class_index)\n    image_index = int(filename.split('_')[3].split('.')[0])\n    #print(image_index)\n    row = captions_df[captions_df['filename'] == filename]\n    #print(row)\n    try:\n        caption = row['caption'].values[0]\n    except:\n        print(filename)\n    \n    image_captions.append(caption)\n    image_classes.append(class_index)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:38:33.328447Z","iopub.execute_input":"2024-04-22T20:38:33.329430Z","iopub.status.idle":"2024-04-22T20:38:39.499104Z","shell.execute_reply.started":"2024-04-22T20:38:33.329395Z","shell.execute_reply":"2024-04-22T20:38:39.498327Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"captions_df['filename'][600:650]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:38:42.015179Z","iopub.execute_input":"2024-04-22T20:38:42.015555Z","iopub.status.idle":"2024-04-22T20:38:42.023827Z","shell.execute_reply.started":"2024-04-22T20:38:42.015525Z","shell.execute_reply":"2024-04-22T20:38:42.022885Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"600    class_1_image_101\n601    class_1_image_102\n602    class_1_image_103\n603    class_1_image_104\n604    class_1_image_105\n605    class_1_image_106\n606    class_1_image_107\n607    class_1_image_108\n608    class_1_image_109\n609    class_1_image_110\n610    class_1_image_111\n611    class_1_image_112\n612    class_1_image_113\n613    class_1_image_114\n614    class_1_image_115\n615    class_1_image_116\n616    class_1_image_117\n617    class_1_image_118\n618    class_1_image_119\n619    class_1_image_120\n620    class_1_image_121\n621    class_1_image_122\n622    class_1_image_123\n623    class_1_image_124\n624    class_1_image_125\n625    class_1_image_126\n626    class_1_image_127\n627    class_1_image_128\n628    class_1_image_129\n629    class_1_image_130\n630    class_1_image_131\n631    class_1_image_132\n632    class_1_image_133\n633    class_1_image_134\n634    class_1_image_135\n635    class_1_image_136\n636    class_1_image_137\n637    class_1_image_138\n638    class_1_image_139\n639    class_1_image_140\n640    class_1_image_141\n641    class_1_image_142\n642    class_1_image_143\n643    class_1_image_144\n644    class_1_image_145\n645    class_1_image_146\n646    class_1_image_147\n647    class_1_image_148\n648    class_1_image_149\n649    class_1_image_150\nName: filename, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"len(image_captions)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:38:45.641973Z","iopub.execute_input":"2024-04-22T20:38:45.642803Z","iopub.status.idle":"2024-04-22T20:38:45.648140Z","shell.execute_reply.started":"2024-04-22T20:38:45.642770Z","shell.execute_reply":"2024-04-22T20:38:45.647303Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"4998"},"metadata":{}}]},{"cell_type":"code","source":"image_filenames[34]\n#image_captions[34]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:38:46.592620Z","iopub.execute_input":"2024-04-22T20:38:46.593214Z","iopub.status.idle":"2024-04-22T20:38:46.598748Z","shell.execute_reply.started":"2024-04-22T20:38:46.593176Z","shell.execute_reply":"2024-04-22T20:38:46.597860Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"'class_0_image_274'"},"metadata":{}}]},{"cell_type":"code","source":"images[0].size","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:38:47.550332Z","iopub.execute_input":"2024-04-22T20:38:47.551069Z","iopub.status.idle":"2024-04-22T20:38:47.556610Z","shell.execute_reply.started":"2024-04-22T20:38:47.551037Z","shell.execute_reply":"2024-04-22T20:38:47.555732Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"2352"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\n\n# Display the image\nplt.imshow(images[2])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:38:49.638816Z","iopub.execute_input":"2024-04-22T20:38:49.639611Z","iopub.status.idle":"2024-04-22T20:38:49.858946Z","shell.execute_reply.started":"2024-04-22T20:38:49.639581Z","shell.execute_reply":"2024-04-22T20:38:49.858023Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7de575ece140>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgCUlEQVR4nO3dfWyV9fnH8U9b6GmB9pRS+jQKFkRwAjVD6BjKD0cH7RYjwh8+ZQFjMGIxInMaFhV1y+owcUZT8Z8N1Ag6E4FIIkZBSnTABsKY22yg6QZIW5SlPVDo8/37o7Gu8uT3y+m5Tsv7ldwJPedcva/zPXf59PTc5zoJQRAEAgAgxhKtGwAAXJkIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgYZN3At3V1den48eNKS0tTQkKCdTsAAEdBEOjUqVPKz89XYuKFn+fEXQAdP35cBQUF1m0AAC7T0aNHNWrUqAteH3cBlJaWZt0C4sxNN93kXPOzn/3Ma19Hjx51runo6HCuGTlypHNNKBRyrvHpTZK2bNniXLNv3z6vfcUzn7/CMN3sG5f6/7zPAqiyslLPPfec6uvrVVRUpJdeeknTp0+/ZF0s/+zmu69YHWAc/N0GDXI/TFNSUrz25fOffFJSknONT3+xDCCf+zQQ8TN4eS61fn1yEsJbb72lFStWaNWqVfr0009VVFSkefPm6cSJE32xOwBAP9QnAfT8889ryZIluueee/T9739fr7zyioYMGaI//vGPfbE7AEA/FPUAamtr0759+1RSUvLNThITVVJSol27dp1z+9bWVkUikV4bAGDgi3oAffXVV+rs7FROTk6vy3NyclRfX3/O7SsqKhQOh3s2zoADgCuD+RtRV65cqaampp7N5ywkAED/E/Wz4LKyspSUlKSGhoZelzc0NCg3N/ec24dCIa+zewAA/VvUnwElJydr6tSp2rZtW89lXV1d2rZtm2bMmBHt3QEA+qk+eR/QihUrtGjRIt1www2aPn26XnjhBTU3N+uee+7pi90BAPqhPgmg22+/XV9++aWefPJJ1dfX6/rrr9fWrVvPOTEBAHDlSgji7G27kUhE4XDYuo0ryk9+8hOvuoceesi5ZubMmc41Pu9GT09Pd67x3derr77qXDNnzhznmovN1LqQrq4u5xpJFx0gGU2ff/65c81vf/tb55rXX3/duQaXr6mp6aI/i+ZnwQEArkwEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMMIw0jt14443ONc8++6xzTVFRkXONJLW3tzvXdHR0ONecOXPGucZnqKgkr2OvsbHRuSYzM9O5xodPb5Lf4zRokPtw/SFDhjjXJCcnO9f87W9/c66RpNLSUuea5uZm5xqf4a++g2ZjiWGkAIC4RAABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwcUVPw/admOyzZD6TgmtqapxrfKYLRyIR5xrJb4Kvz9olJSU51/ist+Q3YXjYsGHONZ2dnc41Po+Tz9pJsZu07HM8+Exhz83Nda6RpLq6OueaiRMneu1rIGIaNgAgLhFAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDhN7FxgIjlMNJnnnnGuWb48OHONfX19c41KSkpzjWS3zBSnzX3GT7p+9j63KfGxsaY7CcUCjnX+Kyd5NefT43PUFafdfAZKipJWVlZzjU///nPnWtef/1155pY/v/VV3gGBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwERCEE+T6SRFIhGFw2HrNqLuH//4h3NNRkaGc01XV1dMaiS/oYY+AxR9+vMZcin5DWYdNMh9pm9bW1tM9tPS0uJcI/kNFvXhMyzV57jzGWAq+R2vI0aMcK4ZOnSoc01/0NTUpPT09AtezzMgAIAJAggAYCLqAfTUU08pISGh1zZx4sRo7wYA0M/1yQfSXXfddfrwww+/2YnH364BAANbnyTDoEGDlJub2xffGgAwQPTJa0CHDh1Sfn6+xo4dq7vvvltHjhy54G1bW1sViUR6bQCAgS/qAVRcXKx169Zp69atWrNmjWpra3XTTTfp1KlT5719RUWFwuFwz1ZQUBDtlgAAcajP3wfU2NioMWPG6Pnnn9e99957zvWtra1qbW3t+ToSiQzIEOJ9QN14H1A33gfUjfcBdbtS3wfU52cHZGRk6JprrtHhw4fPe30oFPI+OAAA/Vef/5pz+vRp1dTUKC8vr693BQDoR6IeQI888oiqqqr073//W3/+85912223KSkpSXfeeWe0dwUA6Mei/ie4Y8eO6c4779TJkyc1cuRI3Xjjjdq9e7dGjhwZ7V0BAPqxqAfQm2++Ge1vGXcWLVrkXHPVVVc51zQ0NDjXJCcnO9f48nntzqc/nxdok5KSnGskvxfFT5486Vzj8z45n+NhzJgxzjVS95/OXfm8YO+zdj6PkU9vktTR0eFc878nVX1XPn8h2rBhg3NNvGEWHADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABN9/omoriKRiMLhsHUbF1VTU+NcM2zYMOcan6GGPp9k6Tu40+eTSn0GSf73v/91rnnvvfecaySpubnZuWbSpEnONT4DVrdu3epcc/fddzvXSNL+/fuda3wGzZaVlTnX+Hya7ODBg51rpNj+PLnKz8+PyX4ux6U+EZVnQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE4OsG7D0ox/9yKsuNTXVueb06dPONT4TtFtaWpxrfKYLS9K6deuca/7617861/jcp2nTpjnXSNLkyZOdawoLC51rdu7c6VyTkpLiXPPGG28410jSkCFDnGv+/ve/O9f4TBIfP368c01HR4dzjST5fFhAJBJxrhk+fLhzzQMPPOBcI0kvv/yyV11f4BkQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE1f0MNLnnnvOqy4cDjvXnD171rnGZ4Di0KFDnWt8hp5K0ty5c2Oyr1Ao5Fxz2223OddI0ieffOJc88UXXzjX+AzC9Rl6mpGR4VwjSe+9955zTVNTk3PNqFGjnGt8fpaSkpKcayQpMdH9d3Sf+/Tll1861/gcD/GGZ0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMJARBEFg38b8ikYjXsM9YWr9+vXPNvHnznGtSU1OdawYNcp8v29nZ6VwjSQcPHnSuSU9Pd67xGbroM8hVkk6dOuVck5KS4lzj82Pnc598epOko0ePOtckJCQ41/gMz/U5xnNycpxrJKm+vt655v3333eueeihh5xrTp8+7VwTa01NTRf9mecZEADABAEEADDhHEA7d+7ULbfcovz8fCUkJGjTpk29rg+CQE8++aTy8vKUmpqqkpISHTp0KFr9AgAGCOcAam5uVlFRkSorK897/erVq/Xiiy/qlVde0Z49ezR06FDNmzdPLS0tl90sAGDgcH41r6ysTGVlZee9LggCvfDCC3r88cd16623SpJee+015eTkaNOmTbrjjjsur1sAwIAR1deAamtrVV9fr5KSkp7LwuGwiouLtWvXrvPWtLa2KhKJ9NoAAANfVAPo61MWv33KY05OzgVPZ6yoqFA4HO7ZCgoKotkSACBOmZ8Ft3LlSjU1NfVsPu8/AAD0P1ENoNzcXElSQ0NDr8sbGhp6rvu2UCik9PT0XhsAYOCLagAVFhYqNzdX27Zt67ksEoloz549mjFjRjR3BQDo55zPgjt9+rQOHz7c83Vtba0OHDigzMxMjR49WsuXL9dvfvMbjR8/XoWFhXriiSeUn5+v+fPnR7NvAEA/5xxAe/fu1c0339zz9YoVKyRJixYt0rp16/Too4+qublZ9913nxobG3XjjTdq69at3jOpAAADE8NIYyQrK8u55qmnnnKuueGGG5xrEhP9/hI7duxY55rW1lbnGt9hqbHis35tbW0x2Y/vj3dycnJManyGvw4ZMsS55q233nKukfyGhOIbDCMFAMQlAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJK3oadkJCglddnC3ZZXv88ce96latWuVcc+zYMeeaUCjkXBPLx8jnOOrq6uqDTqK3H58J5D41aWlpzjV1dXXONddff71zDS4f07ABAHGJAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAiUHWDVjyHVjpM3zSpyYpKcm5pr293blm8ODBzjW++0pM5HeeWPIduOvzOHV0dMRkP8OHD3euiSWfNR9oA46/K/43AACYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYOKKHkbqy2dwoE+N7yBJV21tbV51DF2MrVgOcvUZLOrD5xhKT0/vg06ih5+L745nQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwwjBTKyMjwqovlcEz4DayM5WPU1dXlXNPZ2RmT/SA+8T8IAMAEAQQAMOEcQDt37tQtt9yi/Px8JSQkaNOmTb2uX7x4sRISEnptpaWl0eoXADBAOAdQc3OzioqKVFlZecHblJaWqq6urmfbsGHDZTUJABh4nE9CKCsrU1lZ2UVvEwqFlJub690UAGDg65PXgHbs2KHs7GxNmDBBS5cu1cmTJy9429bWVkUikV4bAGDgi3oAlZaW6rXXXtO2bdv0u9/9TlVVVSorK7vg6ZYVFRUKh8M9W0FBQbRbAgDEoai/D+iOO+7o+ffkyZM1ZcoUjRs3Tjt27NCcOXPOuf3KlSu1YsWKnq8jkQghBABXgD4/DXvs2LHKysrS4cOHz3t9KBRSenp6rw0AMPD1eQAdO3ZMJ0+eVF5eXl/vCgDQjzj/Ce706dO9ns3U1tbqwIEDyszMVGZmpp5++mktXLhQubm5qqmp0aOPPqqrr75a8+bNi2rjAID+zTmA9u7dq5tvvrnn669fv1m0aJHWrFmjgwcP6tVXX1VjY6Py8/M1d+5c/frXv1YoFIpe1wCAfs85gGbPnn3RoYjvv//+ZTWE2MvOzvaq8xmOiW4+a+czhDMpKcm5xreuo6PDucbnPqWkpDjXID4xCw4AYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYCLqH8mN/ufUqVMx21dCQkLM9hXP4n0dEhPdfzcdNMj9v5OWlhbnGp/eEJ94JAEAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJhgGGkci9XAyra2tpjsx1e8D+706S9W98l3Pz4DP5OSkpxr2tvbnWtSU1OdayZMmOBcI0nV1dVedfhueAYEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABMNI41gQBNYtXFRXV5d1C+gjPoNFffgc4z411157rXON5DeMNN6H58YTngEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwTDSOBarYZ8jR470qvMZCukzqHEgDneM1X3q6OjwqguFQs41PgNM29ranGt8fi6mTJniXCNJmzZtcq7xWYfOzk7nmoGAZ0AAABMEEADAhFMAVVRUaNq0aUpLS1N2drbmz59/zudltLS0qLy8XCNGjNCwYcO0cOFCNTQ0RLVpAED/5xRAVVVVKi8v1+7du/XBBx+ovb1dc+fOVXNzc89tHn74Yb377rt6++23VVVVpePHj2vBggVRbxwA0L85nYSwdevWXl+vW7dO2dnZ2rdvn2bNmqWmpib94Q9/0Pr16/XjH/9YkrR27Vpde+212r17t374wx9Gr3MAQL92Wa8BNTU1SZIyMzMlSfv27VN7e7tKSkp6bjNx4kSNHj1au3btOu/3aG1tVSQS6bUBAAY+7wDq6urS8uXLNXPmTE2aNEmSVF9fr+TkZGVkZPS6bU5Ojurr68/7fSoqKhQOh3u2goIC35YAAP2IdwCVl5frs88+05tvvnlZDaxcuVJNTU0929GjRy/r+wEA+gevN6IuW7ZMW7Zs0c6dOzVq1Kiey3Nzc9XW1qbGxsZez4IaGhqUm5t73u8VCoW83vQGAOjfnJ4BBUGgZcuWaePGjdq+fbsKCwt7XT916lQNHjxY27Zt67msurpaR44c0YwZM6LTMQBgQHB6BlReXq7169dr8+bNSktL63ldJxwOKzU1VeFwWPfee69WrFihzMxMpaen68EHH9SMGTM4Aw4A0ItTAK1Zs0aSNHv27F6Xr127VosXL5Yk/f73v1diYqIWLlyo1tZWzZs3Ty+//HJUmgUADBxOAfRdhk+mpKSosrJSlZWV3k2hm8+wTx/jx4/3qvMZoDgQB4sORD6PU0pKinPN/76J/btqb293rvEduOsjVkOEBwJmwQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATHh9Iirc+UwXjtU07HHjxnnV+Uwl9lmHWE4XjtW0bp/H1qfG9/74TDr3+WTjpKQk5xqf3mI5DbujoyNm++rveAYEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABMNIYySeh5F+8cUXXnX5+fnONYMGuR9ysVy7WK15YqL7734+Q1l9h5HGatCszzBSH+FwOCb7gRueAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDBMFIoJSXFq85ncKfPwEqfwZ2xHEbqO/DTVSzXwYfPoFmfGp/71Nzc7FyDvsczIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYYRhojsRpY6WPw4MFedZ2dnc41HR0dManxXW+fulgO/HQVy9589pWUlORc43M8+AxyRd/jUQEAmCCAAAAmnAKooqJC06ZNU1pamrKzszV//nxVV1f3us3s2bOVkJDQa7v//vuj2jQAoP9zCqCqqiqVl5dr9+7d+uCDD9Te3q65c+ee82FPS5YsUV1dXc+2evXqqDYNAOj/nE5C2Lp1a6+v161bp+zsbO3bt0+zZs3quXzIkCHKzc2NTocAgAHpsl4DampqkiRlZmb2uvyNN95QVlaWJk2apJUrV+rMmTMX/B6tra2KRCK9NgDAwOd9GnZXV5eWL1+umTNnatKkST2X33XXXRozZozy8/N18OBBPfbYY6qurtY777xz3u9TUVGhp59+2rcNAEA/lRB4vlFg6dKleu+99/Txxx9r1KhRF7zd9u3bNWfOHB0+fFjjxo075/rW1la1trb2fB2JRFRQUODTUlzzeb+Dz/tsfNTU1HjVpaamOtfwPqDYimVvPsdDW1ubc43PY7R3717nGklasGCBVx26NTU1KT09/YLXez0DWrZsmbZs2aKdO3deNHwkqbi4WJIuGEChUEihUMinDQBAP+YUQEEQ6MEHH9TGjRu1Y8cOFRYWXrLmwIEDkqS8vDyvBgEAA5NTAJWXl2v9+vXavHmz0tLSVF9fL0kKh8NKTU1VTU2N1q9fr5/+9KcaMWKEDh48qIcfflizZs3SlClT+uQOAAD6J6cAWrNmjaTuN5v+r7Vr12rx4sVKTk7Whx9+qBdeeEHNzc0qKCjQwoUL9fjjj0etYQDAwOD8J7iLKSgoUFVV1WU1BAC4MjANO0ZiNQ170CD3h3TkyJFe+0pOTnau6erqcq7xObsK/cPZs2eda3x+lkpLS51rYmmgnX35XTGMFABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAmGkcaIzxBOHz4fX/3iiy967auhocG5xucjmH3Wzne9fQY8+qy5j1gOrExJSXGu8enPZ3ju0KFDnWsSE/ldOx7xqAAATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADARNzNgvOdXRXv4vl+tbS0eNX5zHVjFpy/WM6C85md5tOfz+PkMz8u3mfBxfP/D5fjUvcrIYize37s2DEVFBRYtwEAuExHjx7VqFGjLnh93AVQV1eXjh8/rrS0tHN+o4pEIiooKNDRo0eVnp5u1KE91qEb69CNdejGOnSLh3UIgkCnTp1Sfn7+RZ99xt2f4BITEy+amJKUnp5+RR9gX2MdurEO3ViHbqxDN+t1CIfDl7xNfP9hFAAwYBFAAAAT/SqAQqGQVq1apVAoZN2KKdahG+vQjXXoxjp060/rEHcnIQAArgz96hkQAGDgIIAAACYIIACACQIIAGCi3wRQZWWlrrrqKqWkpKi4uFh/+ctfrFuKuaeeekoJCQm9tokTJ1q31ed27typW265Rfn5+UpISNCmTZt6XR8EgZ588knl5eUpNTVVJSUlOnTokE2zfehS67B48eJzjo/S0lKbZvtIRUWFpk2bprS0NGVnZ2v+/Pmqrq7udZuWlhaVl5drxIgRGjZsmBYuXKiGhgajjvvGd1mH2bNnn3M83H///UYdn1+/CKC33npLK1as0KpVq/Tpp5+qqKhI8+bN04kTJ6xbi7nrrrtOdXV1PdvHH39s3VKfa25uVlFRkSorK897/erVq/Xiiy/qlVde0Z49ezR06FDNmzfPe8hqvLrUOkhSaWlpr+Njw4YNMeyw71VVVam8vFy7d+/WBx98oPb2ds2dO1fNzc09t3n44Yf17rvv6u2331ZVVZWOHz+uBQsWGHYdfd9lHSRpyZIlvY6H1atXG3V8AUE/MH369KC8vLzn687OziA/Pz+oqKgw7Cr2Vq1aFRQVFVm3YUpSsHHjxp6vu7q6gtzc3OC5557ruayxsTEIhULBhg0bDDqMjW+vQxAEwaJFi4Jbb73VpB8rJ06cCCQFVVVVQRB0P/aDBw8O3n777Z7b/Otf/wokBbt27bJqs899ex2CIAj+7//+L3jooYfsmvoO4v4ZUFtbm/bt26eSkpKeyxITE1VSUqJdu3YZdmbj0KFDys/P19ixY3X33XfryJEj1i2Zqq2tVX19fa/jIxwOq7i4+Io8Pnbs2KHs7GxNmDBBS5cu1cmTJ61b6lNNTU2SpMzMTEnSvn371N7e3ut4mDhxokaPHj2gj4dvr8PX3njjDWVlZWnSpElauXKlzpw5Y9HeBcXdMNJv++qrr9TZ2amcnJxel+fk5Ojzzz836spGcXGx1q1bpwkTJqiurk5PP/20brrpJn322WdKS0uzbs9EfX29JJ33+Pj6uitFaWmpFixYoMLCQtXU1OhXv/qVysrKtGvXLiUlJVm3F3VdXV1avny5Zs6cqUmTJknqPh6Sk5OVkZHR67YD+Xg43zpI0l133aUxY8YoPz9fBw8e1GOPPabq6mq98847ht32FvcBhG+UlZX1/HvKlCkqLi7WmDFj9Kc//Un33nuvYWeIB3fccUfPvydPnqwpU6Zo3Lhx2rFjh+bMmWPYWd8oLy/XZ599dkW8DnoxF1qH++67r+ffkydPVl5enubMmaOamhqNGzcu1m2eV9z/CS4rK0tJSUnnnMXS0NCg3Nxco67iQ0ZGhq655hodPnzYuhUzXx8DHB/nGjt2rLKysgbk8bFs2TJt2bJFH330Ua+Pb8nNzVVbW5saGxt73X6gHg8XWofzKS4ulqS4Oh7iPoCSk5M1depUbdu2reeyrq4ubdu2TTNmzDDszN7p06dVU1OjvLw861bMFBYWKjc3t9fxEYlEtGfPniv++Dh27JhOnjw5oI6PIAi0bNkybdy4Udu3b1dhYWGv66dOnarBgwf3Oh6qq6t15MiRAXU8XGodzufAgQOSFF/Hg/VZEN/Fm2++GYRCoWDdunXBP//5z+C+++4LMjIygvr6euvWYuoXv/hFsGPHjqC2tjb45JNPgpKSkiArKys4ceKEdWt96tSpU8H+/fuD/fv3B5KC559/Pti/f3/wn//8JwiCIHj22WeDjIyMYPPmzcHBgweDW2+9NSgsLAzOnj1r3Hl0XWwdTp06FTzyyCPBrl27gtra2uDDDz8MfvCDHwTjx48PWlparFuPmqVLlwbhcDjYsWNHUFdX17OdOXOm5zb3339/MHr06GD79u3B3r17gxkzZgQzZsww7Dr6LrUOhw8fDp555plg7969QW1tbbB58+Zg7NixwaxZs4w7761fBFAQBMFLL70UjB49OkhOTg6mT58e7N6927qlmLv99tuDvLy8IDk5Ofje974X3H777cHhw4et2+pzH330USDpnG3RokVBEHSfiv3EE08EOTk5QSgUCubMmRNUV1fbNt0HLrYOZ86cCebOnRuMHDkyGDx4cDBmzJhgyZIlA+6XtPPdf0nB2rVre25z9uzZ4IEHHgiGDx8eDBkyJLjtttuCuro6u6b7wKXW4ciRI8GsWbOCzMzMIBQKBVdffXXwy1/+MmhqarJt/Fv4OAYAgIm4fw0IADAwEUAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMPH/2zW222JcGs8AAAAASUVORK5CYII="},"metadata":{}}]},{"cell_type":"code","source":"image_captions[2]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:38:53.444048Z","iopub.execute_input":"2024-04-22T20:38:53.444417Z","iopub.status.idle":"2024-04-22T20:38:53.451074Z","shell.execute_reply.started":"2024-04-22T20:38:53.444389Z","shell.execute_reply":"2024-04-22T20:38:53.450167Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"'A T-shirt with a minimalist design.'"},"metadata":{}}]},{"cell_type":"code","source":"image_classes[2]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:38:54.638457Z","iopub.execute_input":"2024-04-22T20:38:54.639148Z","iopub.status.idle":"2024-04-22T20:38:54.644731Z","shell.execute_reply.started":"2024-04-22T20:38:54.639116Z","shell.execute_reply":"2024-04-22T20:38:54.643713Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Assuming you have lists images, image_captions, and image_classes containing your data\n\n# Create an array of indices from 0 to the length of your data\nindices = np.arange(len(images))\n\n# Randomly select 20,000 indices for testing without replacement\ntesting_indices = np.random.choice(indices, size=2000, replace=False)\n\n# Use the remaining indices for training\ntraining_indices = np.setdiff1d(indices, testing_indices)\n\n# Use the selected indices to create the testing and training datasets\ntesting_cnn_data_selected = [images[i] for i in testing_indices]\ntraining_cnn_data_selected = [images[i] for i in training_indices]\n\ntesting_lstm_data_selected = [image_captions[i] for i in testing_indices]\ntraining_lstm_data_selected = [image_captions[i] for i in training_indices]\n\n# Create labels (y) for testing and training datasets\ntesting_labels = [image_classes[i] for i in testing_indices]\ntraining_labels = [image_classes[i] for i in training_indices]\n\n# Now testing_data_selected contains 20,000 randomly selected items for testing\n# and training_data_selected contains the remaining items for training\n# testing_labels and training_labels contain corresponding labels for testing and training datasets\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:47.129509Z","iopub.execute_input":"2024-04-22T20:40:47.130275Z","iopub.status.idle":"2024-04-22T20:40:47.144902Z","shell.execute_reply.started":"2024-04-22T20:40:47.130243Z","shell.execute_reply":"2024-04-22T20:40:47.144020Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\n\n# Display the image\nplt.imshow(training_cnn_data_selected[1])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:48.230701Z","iopub.execute_input":"2024-04-22T20:40:48.231610Z","iopub.status.idle":"2024-04-22T20:40:48.409975Z","shell.execute_reply.started":"2024-04-22T20:40:48.231578Z","shell.execute_reply":"2024-04-22T20:40:48.409026Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x7de57581f490>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Sample testing_labels array\ntraining_labels = np.array(training_labels)\n\n# Define a mapping dictionary to map original labels to new labels (0 to 20)\nlabel_mapping = {}\nnew_label = 0\nfor label in sorted(np.unique(training_labels)):\n    label_mapping[label] = new_label\n    new_label += 1\n\n# Convert the testing_labels array using the mapping dictionary\nconverted_labels_training = np.array([label_mapping[label] for label in training_labels])\n\n# Print the converted labels\nprint(converted_labels_training)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:48.571054Z","iopub.execute_input":"2024-04-22T20:40:48.571686Z","iopub.status.idle":"2024-04-22T20:40:48.579952Z","shell.execute_reply.started":"2024-04-22T20:40:48.571649Z","shell.execute_reply":"2024-04-22T20:40:48.579036Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"[0 0 0 ... 9 9 9]\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Sample testing_labels array\ntesting_labels = np.array(testing_labels)\n\n# Define a mapping dictionary to map original labels to new labels (0 to 20)\nlabel_mapping = {}\nnew_label = 0\nfor label in sorted(np.unique(testing_labels)):\n    label_mapping[label] = new_label\n    new_label += 1\n\n# Convert the testing_labels array using the mapping dictionary\nconverted_labels_testing = np.array([label_mapping[label] for label in testing_labels])\n\n# Print the converted labels\nprint(converted_labels_testing)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:48.791885Z","iopub.execute_input":"2024-04-22T20:40:48.792751Z","iopub.status.idle":"2024-04-22T20:40:48.800975Z","shell.execute_reply.started":"2024-04-22T20:40:48.792720Z","shell.execute_reply":"2024-04-22T20:40:48.799902Z"},"trusted":true},"execution_count":83,"outputs":[{"name":"stdout","text":"[3 1 6 ... 9 9 6]\n","output_type":"stream"}]},{"cell_type":"code","source":"testing_labels[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:48.974022Z","iopub.execute_input":"2024-04-22T20:40:48.974402Z","iopub.status.idle":"2024-04-22T20:40:48.981009Z","shell.execute_reply.started":"2024-04-22T20:40:48.974371Z","shell.execute_reply":"2024-04-22T20:40:48.979918Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"array([3, 1, 6, 1, 5, 8, 1, 6, 0, 1])"},"metadata":{}}]},{"cell_type":"code","source":"converted_labels_testing[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:49.608604Z","iopub.execute_input":"2024-04-22T20:40:49.609006Z","iopub.status.idle":"2024-04-22T20:40:49.615215Z","shell.execute_reply.started":"2024-04-22T20:40:49.608957Z","shell.execute_reply":"2024-04-22T20:40:49.614288Z"},"trusted":true},"execution_count":85,"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"array([3, 1, 6, 1, 5, 8, 1, 6, 0, 1])"},"metadata":{}}]},{"cell_type":"code","source":"testing_labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:49.909660Z","iopub.execute_input":"2024-04-22T20:40:49.910557Z","iopub.status.idle":"2024-04-22T20:40:49.915854Z","shell.execute_reply.started":"2024-04-22T20:40:49.910520Z","shell.execute_reply":"2024-04-22T20:40:49.915034Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"(2000,)"},"metadata":{}}]},{"cell_type":"code","source":"converted_labels_training[450:460]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:50.326805Z","iopub.execute_input":"2024-04-22T20:40:50.327496Z","iopub.status.idle":"2024-04-22T20:40:50.333519Z","shell.execute_reply.started":"2024-04-22T20:40:50.327463Z","shell.execute_reply":"2024-04-22T20:40:50.332631Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"},"metadata":{}}]},{"cell_type":"code","source":"training_lstm_data_selected[1]","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:50.769411Z","iopub.execute_input":"2024-04-22T20:40:50.770357Z","iopub.status.idle":"2024-04-22T20:40:50.776616Z","shell.execute_reply.started":"2024-04-22T20:40:50.770315Z","shell.execute_reply":"2024-04-22T20:40:50.775671Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"'A T-shirt with a cropped hem.'"},"metadata":{}}]},{"cell_type":"markdown","source":"## CNN ","metadata":{}},{"cell_type":"code","source":"# Convert labels to one-hot encoding\ntraining_labels=np.array(training_labels)\ntesting_labels=np.array(testing_labels)\ntraining_labels = tf.keras.utils.to_categorical(converted_labels_training, 10)\ntesting_labels = tf.keras.utils.to_categorical(converted_labels_testing, 10)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:52.083663Z","iopub.execute_input":"2024-04-22T20:40:52.084513Z","iopub.status.idle":"2024-04-22T20:40:52.089787Z","shell.execute_reply.started":"2024-04-22T20:40:52.084481Z","shell.execute_reply":"2024-04-22T20:40:52.088800Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_cnn_data_selected=np.array(training_cnn_data_selected)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:53.457088Z","iopub.execute_input":"2024-04-22T20:40:53.457475Z","iopub.status.idle":"2024-04-22T20:40:53.465868Z","shell.execute_reply.started":"2024-04-22T20:40:53.457446Z","shell.execute_reply":"2024-04-22T20:40:53.465099Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"testing_cnn_data_selected=np.array(testing_cnn_data_selected)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:53.802362Z","iopub.execute_input":"2024-04-22T20:40:53.803032Z","iopub.status.idle":"2024-04-22T20:40:53.810311Z","shell.execute_reply.started":"2024-04-22T20:40:53.802999Z","shell.execute_reply":"2024-04-22T20:40:53.809516Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"training_cnn_data_selected.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:54.046445Z","iopub.execute_input":"2024-04-22T20:40:54.047191Z","iopub.status.idle":"2024-04-22T20:40:54.052929Z","shell.execute_reply.started":"2024-04-22T20:40:54.047160Z","shell.execute_reply":"2024-04-22T20:40:54.051870Z"},"trusted":true},"execution_count":92,"outputs":[{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"(2998, 28, 28, 3)"},"metadata":{}}]},{"cell_type":"code","source":"training_cnn_data_selected.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:54.239750Z","iopub.execute_input":"2024-04-22T20:40:54.240102Z","iopub.status.idle":"2024-04-22T20:40:54.246127Z","shell.execute_reply.started":"2024-04-22T20:40:54.240076Z","shell.execute_reply":"2024-04-22T20:40:54.245122Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"(2998, 28, 28, 3)"},"metadata":{}}]},{"cell_type":"code","source":"tf.config.experimental_run_functions_eagerly(False)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:54.438498Z","iopub.execute_input":"2024-04-22T20:40:54.439349Z","iopub.status.idle":"2024-04-22T20:40:54.443405Z","shell.execute_reply.started":"2024-04-22T20:40:54.439313Z","shell.execute_reply":"2024-04-22T20:40:54.442408Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"training_labels","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:54.908169Z","iopub.execute_input":"2024-04-22T20:40:54.908551Z","iopub.status.idle":"2024-04-22T20:40:54.915468Z","shell.execute_reply.started":"2024-04-22T20:40:54.908525Z","shell.execute_reply":"2024-04-22T20:40:54.914502Z"},"trusted":true},"execution_count":95,"outputs":[{"execution_count":95,"output_type":"execute_result","data":{"text/plain":"array([[1., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 1.],\n       [0., 0., 0., ..., 0., 0., 1.],\n       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"training_labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:55.118787Z","iopub.execute_input":"2024-04-22T20:40:55.119623Z","iopub.status.idle":"2024-04-22T20:40:55.125099Z","shell.execute_reply.started":"2024-04-22T20:40:55.119591Z","shell.execute_reply":"2024-04-22T20:40:55.124210Z"},"trusted":true},"execution_count":96,"outputs":[{"execution_count":96,"output_type":"execute_result","data":{"text/plain":"(2998, 10)"},"metadata":{}}]},{"cell_type":"markdown","source":"training_cnn_data_selected = np.expand_dims(training_cnn_data_selected, axis=-1)\ntesting_cnn_data_selected = np.expand_dims(testing_cnn_data_selected, axis=-1)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:39:19.497298Z","iopub.execute_input":"2024-04-22T20:39:19.497632Z","iopub.status.idle":"2024-04-22T20:39:19.502323Z","shell.execute_reply.started":"2024-04-22T20:39:19.497608Z","shell.execute_reply":"2024-04-22T20:39:19.501286Z"}}},{"cell_type":"code","source":"cnn_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = cnn_model.fit(training_cnn_data_selected,\n                            training_labels,\n                            batch_size=32,\n                            epochs=30,\n                            validation_data=(testing_cnn_data_selected,testing_labels),\n                            shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T20:40:56.369970Z","iopub.execute_input":"2024-04-22T20:40:56.370653Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/30\n94/94 [==============================] - 3s 13ms/step - loss: 1.9764 - accuracy: 0.2272 - val_loss: 1.9598 - val_accuracy: 0.2365\nEpoch 2/30\n94/94 [==============================] - 1s 10ms/step - loss: 1.9729 - accuracy: 0.2282 - val_loss: 1.9593 - val_accuracy: 0.2365\nEpoch 3/30\n94/94 [==============================] - 1s 10ms/step - loss: 1.9720 - accuracy: 0.2268 - val_loss: 1.9590 - val_accuracy: 0.2300\nEpoch 4/30\n94/94 [==============================] - 1s 10ms/step - loss: 1.9721 - accuracy: 0.2322 - val_loss: 1.9586 - val_accuracy: 0.2300\nEpoch 5/30\n94/94 [==============================] - 1s 10ms/step - loss: 1.9737 - accuracy: 0.2322 - val_loss: 1.9585 - val_accuracy: 0.2300\nEpoch 6/30\n94/94 [==============================] - 1s 10ms/step - loss: 1.9707 - accuracy: 0.2332 - val_loss: 1.9584 - val_accuracy: 0.2300\nEpoch 7/30\n94/94 [==============================] - 1s 10ms/step - loss: 1.9735 - accuracy: 0.2322 - val_loss: 1.9582 - val_accuracy: 0.2300\nEpoch 8/30\n94/94 [==============================] - 1s 10ms/step - loss: 1.9724 - accuracy: 0.2325 - val_loss: 1.9581 - val_accuracy: 0.2300\nEpoch 9/30\n94/94 [==============================] - 1s 10ms/step - loss: 1.9710 - accuracy: 0.2328 - val_loss: 1.9581 - val_accuracy: 0.2300\nEpoch 10/30\n94/94 [==============================] - 1s 10ms/step - loss: 1.9710 - accuracy: 0.2328 - val_loss: 1.9581 - val_accuracy: 0.2300\nEpoch 11/30\n85/94 [==========================>...] - ETA: 0s - loss: 1.9671 - accuracy: 0.2338","output_type":"stream"},{"name":"stderr","text":"Exception ignored in: <Finalize object, dead>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/util.py\", line 224, in __call__\n    res = self._callback(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 695, in _terminate_pool\n    cls._help_stuff_finish(inqueue, task_handler, len(pool))\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 675, in _help_stuff_finish\n    inqueue._rlock.acquire()\nKeyboardInterrupt: \nProcess ForkPoolWorker-55:\nProcess ForkPoolWorker-52:\nProcess ForkPoolWorker-48:\nProcess ForkPoolWorker-46:\nProcess ForkPoolWorker-36:\nProcess ForkPoolWorker-33:\nProcess ForkPoolWorker-59:\nProcess ForkPoolWorker-51:\nProcess ForkPoolWorker-47:\nProcess ForkPoolWorker-39:\nProcess ForkPoolWorker-43:\nProcess ForkPoolWorker-44:\nProcess ForkPoolWorker-45:\nProcess ForkPoolWorker-40:\nProcess ForkPoolWorker-58:\nTraceback (most recent call last):\nTraceback (most recent call last):\nTraceback (most recent call last):\nProcess ForkPoolWorker-57:\nTraceback (most recent call last):\nTraceback (most recent call last):\nProcess ForkPoolWorker-54:\nProcess ForkPoolWorker-42:\nProcess ForkPoolWorker-38:\nProcess ForkPoolWorker-34:\nTraceback (most recent call last):\nTraceback (most recent call last):\nProcess ForkPoolWorker-35:\nProcess ForkPoolWorker-37:\nProcess ForkPoolWorker-53:\nProcess ForkPoolWorker-50:\nTraceback (most recent call last):\nTraceback (most recent call last):\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\nTraceback (most recent call last):\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\nTraceback (most recent call last):\nProcess ForkPoolWorker-41:\nTraceback (most recent call last):\nProcess ForkPoolWorker-49:\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\nProcess ForkPoolWorker-56:\nTraceback (most recent call last):\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\n  File \"/opt/conda/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n    task = get()\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 365, in get\n    res = self._reader.recv_bytes()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 364, in get\n    with self._rlock:\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\nKeyboardInterrupt\nKeyboardInterrupt\nKeyboardInterrupt\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\nKeyboardInterrupt\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\nKeyboardInterrupt\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\nKeyboardInterrupt\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n    buf = self._recv_bytes(maxlength)\nKeyboardInterrupt\nKeyboardInterrupt\nKeyboardInterrupt\nKeyboardInterrupt\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n    return self._semlock.__enter__()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n    buf = self._recv(4)\nKeyboardInterrupt\nKeyboardInterrupt\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n    chunk = read(handle, remaining)\nKeyboardInterrupt\n","output_type":"stream"}]},{"cell_type":"code","source":"testing_labels = np.argmax(testing_labels, axis=1)\ntraining_labels = np.argmax(training_labels, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:32.801616Z","iopub.execute_input":"2024-04-17T10:47:32.802031Z","iopub.status.idle":"2024-04-17T10:47:32.808629Z","shell.execute_reply.started":"2024-04-17T10:47:32.801995Z","shell.execute_reply":"2024-04-17T10:47:32.807503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_predictions = cnn_model.predict(testing_cnn_data_selected)","metadata":{"execution":{"iopub.status.busy":"2024-04-22T13:20:36.044720Z","iopub.execute_input":"2024-04-22T13:20:36.045626Z","iopub.status.idle":"2024-04-22T13:20:36.209280Z","shell.execute_reply.started":"2024-04-22T13:20:36.045592Z","shell.execute_reply":"2024-04-22T13:20:36.208007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_labels = np.argmax(cnn_predictions, axis=1)\n\n# Calculate accuracy\ncnn_accuracy = np.mean(predicted_labels == testing_labels)\nprint(\"CNN Model Accuracy:\", cnn_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:34.317616Z","iopub.execute_input":"2024-04-17T10:47:34.318023Z","iopub.status.idle":"2024-04-17T10:47:34.324332Z","shell.execute_reply.started":"2024-04-17T10:47:34.317993Z","shell.execute_reply":"2024-04-17T10:47:34.323252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({'caption': training_lstm_data_selected, 'class': training_labels})","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:35.131911Z","iopub.execute_input":"2024-04-17T10:47:35.132665Z","iopub.status.idle":"2024-04-17T10:47:35.138696Z","shell.execute_reply.started":"2024-04-17T10:47:35.132634Z","shell.execute_reply":"2024-04-17T10:47:35.137608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[20:30]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:36.167688Z","iopub.execute_input":"2024-04-17T10:47:36.168129Z","iopub.status.idle":"2024-04-17T10:47:36.178639Z","shell.execute_reply.started":"2024-04-17T10:47:36.168098Z","shell.execute_reply":"2024-04-17T10:47:36.177510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nfrom gensim.models import Word2Vec\n\ndef tokenize_text(text_data):\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(text_data)\n    return tokenizer\n\ndef train_word2vec(text_data, embedding_dim):\n    tokenized_text = [text.split() for text in text_data]\n    model = Word2Vec(sentences=tokenized_text, vector_size=embedding_dim, window=5, min_count=1, workers=4)\n    return model\n\ndef convert_text_to_vectors(text_data, word2vec_model, max_length):\n    vectors = []\n    for text in text_data:\n        words = text.split()\n        vec = []\n        for word in words:\n            if word in word2vec_model.wv:\n                vec.append(word2vec_model.wv[word])\n            else:\n                vec.append(np.zeros(word2vec_model.vector_size))  # Zero vector for out-of-vocabulary words\n        vectors.append(vec)\n    padded_vectors = pad_sequences(vectors, maxlen=max_length, padding='post')\n    return padded_vectors","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:36.578297Z","iopub.execute_input":"2024-04-17T10:47:36.578997Z","iopub.status.idle":"2024-04-17T10:47:36.588730Z","shell.execute_reply.started":"2024-04-17T10:47:36.578963Z","shell.execute_reply":"2024-04-17T10:47:36.587640Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['caption'][147]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:37.364818Z","iopub.execute_input":"2024-04-17T10:47:37.365621Z","iopub.status.idle":"2024-04-17T10:47:37.371886Z","shell.execute_reply.started":"2024-04-17T10:47:37.365587Z","shell.execute_reply":"2024-04-17T10:47:37.370824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_words=10000\nembedding_dim=10\n\ntokenizer = tokenize_text(df['caption'].values)\nword2vec_model = train_word2vec(df['caption'].values, embedding_dim)\n\nmax_length = max(len(text.split()) for text in df['caption'].values)\n\n#x_vec = convert_text_to_vectors(df['caption'].values, word2vec_model, max_length)\n#class_mapping = {f'class_{i}': i for i in range(num_classes)}\n#df['class'] = df['class']\n\n#y = df['class'].values","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:38.186287Z","iopub.execute_input":"2024-04-17T10:47:38.186663Z","iopub.status.idle":"2024-04-17T10:47:39.028150Z","shell.execute_reply.started":"2024-04-17T10:47:38.186633Z","shell.execute_reply":"2024-04-17T10:47:39.027299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_train = convert_text_to_vectors(training_lstm_data_selected, word2vec_model, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:39.153041Z","iopub.execute_input":"2024-04-17T10:47:39.153461Z","iopub.status.idle":"2024-04-17T10:47:39.588377Z","shell.execute_reply.started":"2024-04-17T10:47:39.153417Z","shell.execute_reply":"2024-04-17T10:47:39.587480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_test = convert_text_to_vectors(testing_lstm_data_selected, word2vec_model, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:40.211020Z","iopub.execute_input":"2024-04-17T10:47:40.211381Z","iopub.status.idle":"2024-04-17T10:47:40.303184Z","shell.execute_reply.started":"2024-04-17T10:47:40.211352Z","shell.execute_reply":"2024-04-17T10:47:40.302097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_lstm_data_selected[2]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:40.443958Z","iopub.execute_input":"2024-04-17T10:47:40.444877Z","iopub.status.idle":"2024-04-17T10:47:40.450671Z","shell.execute_reply.started":"2024-04-17T10:47:40.444840Z","shell.execute_reply":"2024-04-17T10:47:40.449677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_lstm_data_selected[0:2]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:40.897809Z","iopub.execute_input":"2024-04-17T10:47:40.898920Z","iopub.status.idle":"2024-04-17T10:47:40.905499Z","shell.execute_reply.started":"2024-04-17T10:47:40.898878Z","shell.execute_reply":"2024-04-17T10:47:40.904523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_train=np.array(x_vec_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:41.001907Z","iopub.execute_input":"2024-04-17T10:47:41.002480Z","iopub.status.idle":"2024-04-17T10:47:41.010440Z","shell.execute_reply.started":"2024-04-17T10:47:41.002450Z","shell.execute_reply":"2024-04-17T10:47:41.009580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_test=np.array(x_vec_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:41.304150Z","iopub.execute_input":"2024-04-17T10:47:41.304536Z","iopub.status.idle":"2024-04-17T10:47:41.309510Z","shell.execute_reply.started":"2024-04-17T10:47:41.304506Z","shell.execute_reply":"2024-04-17T10:47:41.308466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_labels=np.array(training_labels)\ntesting_labels=np.array(testing_labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:41.585070Z","iopub.execute_input":"2024-04-17T10:47:41.585723Z","iopub.status.idle":"2024-04-17T10:47:41.590723Z","shell.execute_reply.started":"2024-04-17T10:47:41.585674Z","shell.execute_reply":"2024-04-17T10:47:41.589678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:42.451818Z","iopub.execute_input":"2024-04-17T10:47:42.452606Z","iopub.status.idle":"2024-04-17T10:47:42.465354Z","shell.execute_reply.started":"2024-04-17T10:47:42.452574Z","shell.execute_reply":"2024-04-17T10:47:42.464472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_train.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:43.083655Z","iopub.execute_input":"2024-04-17T10:47:43.084520Z","iopub.status.idle":"2024-04-17T10:47:43.091381Z","shell.execute_reply.started":"2024-04-17T10:47:43.084489Z","shell.execute_reply":"2024-04-17T10:47:43.089521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:44.129848Z","iopub.execute_input":"2024-04-17T10:47:44.130225Z","iopub.status.idle":"2024-04-17T10:47:44.136605Z","shell.execute_reply.started":"2024-04-17T10:47:44.130194Z","shell.execute_reply":"2024-04-17T10:47:44.135531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:45.329067Z","iopub.execute_input":"2024-04-17T10:47:45.330092Z","iopub.status.idle":"2024-04-17T10:47:45.337098Z","shell.execute_reply.started":"2024-04-17T10:47:45.330056Z","shell.execute_reply":"2024-04-17T10:47:45.336240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_labels = tf.keras.utils.to_categorical(converted_labels_training, 20)\ntesting_labels = tf.keras.utils.to_categorical(converted_labels_testing, 20)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:46.597567Z","iopub.execute_input":"2024-04-17T10:47:46.598509Z","iopub.status.idle":"2024-04-17T10:47:46.603655Z","shell.execute_reply.started":"2024-04-17T10:47:46.598472Z","shell.execute_reply":"2024-04-17T10:47:46.602738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"tf.config.experimental_run_functions_eagerly(True)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:42:13.306635Z","iopub.execute_input":"2024-04-17T10:42:13.307041Z","iopub.status.idle":"2024-04-17T10:42:13.312125Z","shell.execute_reply.started":"2024-04-17T10:42:13.307008Z","shell.execute_reply":"2024-04-17T10:42:13.311037Z"}}},{"cell_type":"code","source":"history = lstm_model.fit(x_vec_train,\n                                training_labels,\n                                batch_size=32,\n                                epochs=30,\n                                validation_data=(x_vec_test,testing_labels),\n                                shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:47:47.778261Z","iopub.execute_input":"2024-04-17T10:47:47.778908Z","iopub.status.idle":"2024-04-17T10:49:11.204677Z","shell.execute_reply.started":"2024-04-17T10:47:47.778873Z","shell.execute_reply":"2024-04-17T10:49:11.203660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_vec_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:18.625338Z","iopub.execute_input":"2024-04-17T10:49:18.625933Z","iopub.status.idle":"2024-04-17T10:49:18.632128Z","shell.execute_reply.started":"2024-04-17T10:49:18.625900Z","shell.execute_reply":"2024-04-17T10:49:18.631213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_predictions = lstm_model.predict(x_vec_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:19.598520Z","iopub.execute_input":"2024-04-17T10:49:19.598925Z","iopub.status.idle":"2024-04-17T10:49:20.134549Z","shell.execute_reply.started":"2024-04-17T10:49:19.598895Z","shell.execute_reply":"2024-04-17T10:49:20.133524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_labels = np.argmax(lstm_predictions, axis=1)\n\n# Calculate accuracy\nlstm_accuracy = np.mean(predicted_labels == testing_labels)\nprint(\"LSTM Model Accuracy:\", lstm_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:51:04.191705Z","iopub.execute_input":"2024-04-17T10:51:04.192444Z","iopub.status.idle":"2024-04-17T10:51:04.198848Z","shell.execute_reply.started":"2024-04-17T10:51:04.192410Z","shell.execute_reply":"2024-04-17T10:51:04.197631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_labels","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:32.851581Z","iopub.execute_input":"2024-04-17T10:49:32.852498Z","iopub.status.idle":"2024-04-17T10:49:32.859151Z","shell.execute_reply.started":"2024-04-17T10:49:32.852460Z","shell.execute_reply":"2024-04-17T10:49:32.858068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_labels","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:37.168435Z","iopub.execute_input":"2024-04-17T10:49:37.169150Z","iopub.status.idle":"2024-04-17T10:49:37.176328Z","shell.execute_reply.started":"2024-04-17T10:49:37.169115Z","shell.execute_reply":"2024-04-17T10:49:37.175289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(cnn_predictions)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:41.558654Z","iopub.execute_input":"2024-04-17T10:49:41.559057Z","iopub.status.idle":"2024-04-17T10:49:41.565249Z","shell.execute_reply.started":"2024-04-17T10:49:41.559026Z","shell.execute_reply":"2024-04-17T10:49:41.564317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(lstm_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:42.194281Z","iopub.execute_input":"2024-04-17T10:49:42.194685Z","iopub.status.idle":"2024-04-17T10:49:42.201481Z","shell.execute_reply.started":"2024-04-17T10:49:42.194652Z","shell.execute_reply":"2024-04-17T10:49:42.200290Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_predictions[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:43.885474Z","iopub.execute_input":"2024-04-17T10:49:43.886373Z","iopub.status.idle":"2024-04-17T10:49:43.893437Z","shell.execute_reply.started":"2024-04-17T10:49:43.886338Z","shell.execute_reply":"2024-04-17T10:49:43.892313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LSTM is working and acc is 86.6% (Cifar 10) - VitGpt2 model\n## LSTM is working and acc is 93.6% (Cifar 100 - 20 random classes) - Manually generated captions","metadata":{}},{"cell_type":"code","source":"cnn_predictions[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:48.061817Z","iopub.execute_input":"2024-04-17T10:49:48.062424Z","iopub.status.idle":"2024-04-17T10:49:48.069345Z","shell.execute_reply.started":"2024-04-17T10:49:48.062392Z","shell.execute_reply":"2024-04-17T10:49:48.068428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_predictions.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:49.295504Z","iopub.execute_input":"2024-04-17T10:49:49.296383Z","iopub.status.idle":"2024-04-17T10:49:49.302289Z","shell.execute_reply.started":"2024-04-17T10:49:49.296345Z","shell.execute_reply":"2024-04-17T10:49:49.301253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_predictions.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:49:50.802356Z","iopub.execute_input":"2024-04-17T10:49:50.803069Z","iopub.status.idle":"2024-04-17T10:49:50.809496Z","shell.execute_reply.started":"2024-04-17T10:49:50.803033Z","shell.execute_reply":"2024-04-17T10:49:50.808565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_labels","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:50:08.441341Z","iopub.execute_input":"2024-04-17T10:50:08.441770Z","iopub.status.idle":"2024-04-17T10:50:08.449613Z","shell.execute_reply.started":"2024-04-17T10:50:08.441739Z","shell.execute_reply":"2024-04-17T10:50:08.448495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 5: Late Fusion Ensemble\ntesting_labels = np.argmax(testing_labels, axis=1)\n\nensemble_predictions = np.argmax(np.sum([cnn_predictions, lstm_predictions], axis=0), axis=1)\n\n# Step 6: Compare Predictions with Original Classes\naccuracy = np.mean(ensemble_predictions == testing_labels)\nprint(\"Ensemble Model Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T10:50:44.454947Z","iopub.execute_input":"2024-04-17T10:50:44.455382Z","iopub.status.idle":"2024-04-17T10:50:44.463474Z","shell.execute_reply.started":"2024-04-17T10:50:44.455353Z","shell.execute_reply":"2024-04-17T10:50:44.462349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## AUTOMATE ENSEMBLE","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow as tf\n\n# Define the folder path\nfolder_path = '/kaggle/input/cnn-models/cnn'\n\n# Get a list of all files in the folder\nfile_list = os.listdir(folder_path)\n\n# Filter out only the .h5 files\nmodel_files = [file for file in file_list if file.endswith('.h5')]\n\n# Load each model\ncnn_models = []\nfor model_file in model_files[0:4]:\n    model_path = os.path.join(folder_path, model_file)\n    cnn_model = tf.keras.models.load_model(model_path)\n    cnn_models.append(cnn_model)\n\n# Now cnn_models list contains all the loaded CNN models\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:50.075341Z","iopub.execute_input":"2024-03-21T14:46:50.075701Z","iopub.status.idle":"2024-03-21T14:46:52.857385Z","shell.execute_reply.started":"2024-03-21T14:46:50.075672Z","shell.execute_reply":"2024-03-21T14:46:52.856344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train each model and track validation accuracy\nvalidation_accuracies = []\nfor lstm_model in top_lstm_models:\n    history = lstm_model.fit(x_vec_train,\n                             training_labels,\n                             batch_size=32,\n                             epochs=1,\n                             validation_data=(x_vec_test, testing_labels),\n                             shuffle=True)\n    \n    # Get the validation accuracy from the history\n    validation_accuracy = history.history['val_accuracy'][-1]\n    validation_accuracies.append(validation_accuracy)\n\n# Sort the models based on validation accuracy\nsorted_indices = sorted(range(len(validation_accuracies)), key=lambda i: validation_accuracies[i], reverse=True)\ntop_lstm_models = [lstm_models[i] for i in sorted_indices[:4]]  # Select the top 4 models\n\n# Train the top 4 LSTM models\nhistories = []\nfor lstm_model in top_lstm_models:\n    lstm_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    history = lstm_model.fit(x_vec_train,\n                             training_labels,\n                             batch_size=32,\n                             epochs=1,\n                             validation_data=(x_vec_test, testing_labels),\n                             shuffle=True)\n    histories.append(history)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:47:18.511846Z","iopub.execute_input":"2024-03-21T14:47:18.512756Z","iopub.status.idle":"2024-03-21T14:47:18.560206Z","shell.execute_reply.started":"2024-03-21T14:47:18.512723Z","shell.execute_reply":"2024-03-21T14:47:18.559035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load the LSTM and CNN models\nlstm_model = tf.keras.models.load_model('/kaggle/input/lstm-parent-model-final/parent_0_model (1).h5')\ncnn_model = tf.keras.models.load_model('/kaggle/input/cnn-model-16layers/cnn_model_.h5')","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n# Assuming you have lists of predictions from the top LSTM and CNN models\ncnn_predictions = [model.predict(testing_cnn_data_selected) for model in cnn_models]\nlstm_predictions = [model.predict(x_vec_test) for model in top_lstm_models]\n\n# Combine predictions using majority voting\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:53:03.403505Z","iopub.execute_input":"2024-03-19T10:53:03.403861Z","iopub.status.idle":"2024-03-19T10:53:22.292528Z","shell.execute_reply.started":"2024-03-19T10:53:03.403834Z","shell.execute_reply":"2024-03-19T10:53:22.291675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Combine predictions using majority voting\ndef majority_voting(predictions):\n    combined_predictions = []\n    for sample_predictions in zip(*predictions):\n        sample_predictions_list = [tuple(prediction) for prediction in sample_predictions]\n        votes = Counter(sample_predictions_list)\n        majority_vote = votes.most_common(1)[0][0]\n        combined_predictions.append(majority_vote)\n    return combined_predictions\n\n\n\n\n# Combine LSTM and CNN predictions using majority voting\nensemble_predictions = majority_voting(lstm_predictions + cnn_predictions)\nensemble_classes = [prediction.index(max(prediction)) for prediction in ensemble_predictions]\n\n\npredicted_labels = np.argmax(lstm_predictions, axis=1)\n\n# Calculate accuracy\n#lstm_accuracy = np.mean(ensemble_predictions == testing_labels)\n#print(\"Ensemble Accuracy:\", lstm_accuracy)\n\n\n# Evaluate ensemble performance\nensemble_accuracy = accuracy_score(testing_labels, ensemble_classes)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:44:35.398346Z","iopub.execute_input":"2024-03-19T10:44:35.398744Z","iopub.status.idle":"2024-03-19T10:44:36.075712Z","shell.execute_reply.started":"2024-03-19T10:44:35.398715Z","shell.execute_reply":"2024-03-19T10:44:36.074856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.shape(lstm_predictions)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:55:15.363127Z","iopub.execute_input":"2024-03-19T10:55:15.363509Z","iopub.status.idle":"2024-03-19T10:55:15.370482Z","shell.execute_reply.started":"2024-03-19T10:55:15.363479Z","shell.execute_reply":"2024-03-19T10:55:15.369543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.shape(cnn_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:55:16.122988Z","iopub.execute_input":"2024-03-19T10:55:16.123352Z","iopub.status.idle":"2024-03-19T10:55:16.130424Z","shell.execute_reply.started":"2024-03-19T10:55:16.123323Z","shell.execute_reply":"2024-03-19T10:55:16.129477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_predictions","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:52:10.078728Z","iopub.execute_input":"2024-03-19T10:52:10.079125Z","iopub.status.idle":"2024-03-19T10:52:10.090250Z","shell.execute_reply.started":"2024-03-19T10:52:10.079096Z","shell.execute_reply":"2024-03-19T10:52:10.089236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Convert lists to NumPy arrays\nlstm_predictions_array = np.array(lstm_predictions)\ncnn_predictions_array = np.array(cnn_predictions)\n\n# Reshape LSTM and CNN predictions to (num_samples, sequence_length * num_classes)\nlstm_predictions_reshaped = lstm_predictions_array.reshape(lstm_predictions_array.shape[0], -1)\ncnn_predictions_reshaped = cnn_predictions_array.reshape(cnn_predictions_array.shape[0], -1)\n\n# Concatenate reshaped predictions\nx_train = np.concatenate((lstm_predictions_reshaped, cnn_predictions_reshaped), axis=1)\n\n# Assuming y_train contains ground truth labels with shape (num_samples,)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:59:20.963469Z","iopub.execute_input":"2024-03-19T10:59:20.964317Z","iopub.status.idle":"2024-03-19T10:59:20.972996Z","shell.execute_reply.started":"2024-03-19T10:59:20.964275Z","shell.execute_reply":"2024-03-19T10:59:20.972063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_predictions[0][0]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:24:14.712708Z","iopub.execute_input":"2024-03-19T11:24:14.713061Z","iopub.status.idle":"2024-03-19T11:24:14.720141Z","shell.execute_reply.started":"2024-03-19T11:24:14.713036Z","shell.execute_reply":"2024-03-19T11:24:14.718906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_pred = ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\n# Prepare Data\n# Assuming lstm_predictions, cnn_predictions, and correct_outputs contain the predictions and correct outputs\n# Concatenate LSTM and CNN predictions\nx_train = np.concatenate((lstm_predictions[0], cnn_predictions[0]), axis=1)\n\n# Calculate Weightage Distribution\n# For example, calculate the weightage based on accuracy\nlstm_accuracy = accuracy_score(lstm_predictions[0], testing_labels)\ncnn_accuracy = accuracy_score(cnn_predictions[0], testing_labels)\ntotal_accuracy = lstm_accuracy + cnn_accuracy\nlstm_weight = lstm_accuracy / total_accuracy\ncnn_weight = cnn_accuracy / total_accuracy\n\n# Prepare Target Weightage Distribution\ntarget_weightage = np.concatenate((lstm_weight, cnn_weight), axis=1)\n\n# Define Fusion Network Architecture\nfusion_network = tf.keras.Sequential([\n    tf.keras.layers.Dense(64, activation='relu', input_shape=(num_features,)),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(num_modalities, activation='softmax')  # Output layer for weightage distribution\n])\n\n# Compile Fusion Network\nfusion_network.compile(optimizer='adam', loss='categorical_crossentropy')\n\n# Train Fusion Network\nfusion_network.fit(x_train, target_weightage, epochs=10, batch_size=32, validation_split=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:23:48.952093Z","iopub.execute_input":"2024-03-19T11:23:48.952500Z","iopub.status.idle":"2024-03-19T11:23:49.046462Z","shell.execute_reply.started":"2024-03-19T11:23:48.952470Z","shell.execute_reply":"2024-03-19T11:23:49.045125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_classes = [prediction.index(max(prediction)) for prediction in ensemble_predictions]\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:35:02.178910Z","iopub.execute_input":"2024-03-19T10:35:02.179276Z","iopub.status.idle":"2024-03-19T10:35:02.204524Z","shell.execute_reply.started":"2024-03-19T10:35:02.179247Z","shell.execute_reply":"2024-03-19T10:35:02.203587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble_classes[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:35:08.323066Z","iopub.execute_input":"2024-03-19T10:35:08.323779Z","iopub.status.idle":"2024-03-19T10:35:08.329716Z","shell.execute_reply.started":"2024-03-19T10:35:08.323742Z","shell.execute_reply":"2024-03-19T10:35:08.328534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CIFAR-10 class names\ncifar_10_classes = {\n    0: 'airplane',\n    1: 'automobile',\n    2: 'bird',\n    3: 'cat',\n    4: 'deer',\n    5: 'dog',\n    6: 'frog',\n    7: 'horse',\n    8: 'ship',\n    9: 'truck'\n}\n\n# Printing class names for the first 10 elements in image_classes\nprint(\"Class Names:\")\nfor class_index in image_classes[:10]:\n    print(cifar_10_classes[class_index])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T06:28:50.471687Z","iopub.execute_input":"2024-03-08T06:28:50.472061Z","iopub.status.idle":"2024-03-08T06:28:50.478728Z","shell.execute_reply.started":"2024-03-08T06:28:50.472033Z","shell.execute_reply":"2024-03-08T06:28:50.477485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_captions[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-03-08T06:25:59.692904Z","iopub.execute_input":"2024-03-08T06:25:59.693621Z","iopub.status.idle":"2024-03-08T06:25:59.700244Z","shell.execute_reply.started":"2024-03-08T06:25:59.693588Z","shell.execute_reply":"2024-03-08T06:25:59.699205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_classes[0:10]\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T06:26:19.538109Z","iopub.execute_input":"2024-03-08T06:26:19.538621Z","iopub.status.idle":"2024-03-08T06:26:19.546439Z","shell.execute_reply.started":"2024-03-08T06:26:19.538580Z","shell.execute_reply":"2024-03-08T06:26:19.545271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define the ensemble function\ndef ensemble(lstm_outputs, cnn_outputs):\n    # Add your ensemble code here\n    return lstm_outputs, cnn_outputs\n\n# Make predictions on the image and text data\nlstm_predictions = []\ncnn_predictions = []\nfor image_batch, text_batch in zip(image_generator, text_generator):\n    lstm_outputs = lstm_model.predict(text_batch)\n    cnn_outputs = cnn_model.predict(image_batch)\n    lstm_predictions.append(lstm_outputs)\n    cnn_predictions.append(cnn_outputs)\nlstm_predictions = np.vstack(lstm_predictions)\ncnn_predictions = np.vstack(cnn_predictions)\n\n# Ensemble the predictions using voting strategy\nensemble_predictions = ensemble(lstm_predictions, cnn_predictions)\n\n# Take the average of the probabilities from both models for each class\nensemble_predictions = (ensemble_predictions[0] + ensemble_predictions[1]) / 2\n\n# Select the class with the highest average probability as the final prediction\nfinal_predictions = np.argmax(ensemble_predictions, axis=1)","metadata":{},"execution_count":null,"outputs":[]}]}