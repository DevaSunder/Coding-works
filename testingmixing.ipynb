{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7764647,"sourceType":"datasetVersion","datasetId":4541506},{"sourceId":7764682,"sourceType":"datasetVersion","datasetId":4541533},{"sourceId":7782124,"sourceType":"datasetVersion","datasetId":4554156},{"sourceId":7786353,"sourceType":"datasetVersion","datasetId":4557329},{"sourceId":7790157,"sourceType":"datasetVersion","datasetId":4559830},{"sourceId":7821267,"sourceType":"datasetVersion","datasetId":4582498},{"sourceId":7821700,"sourceType":"datasetVersion","datasetId":4582823},{"sourceId":7822287,"sourceType":"datasetVersion","datasetId":4583259},{"sourceId":7822850,"sourceType":"datasetVersion","datasetId":4583639},{"sourceId":8122636,"sourceType":"datasetVersion","datasetId":4799764},{"sourceId":8122723,"sourceType":"datasetVersion","datasetId":4799820},{"sourceId":8123082,"sourceType":"datasetVersion","datasetId":4800104},{"sourceId":8123519,"sourceType":"datasetVersion","datasetId":4800420},{"sourceId":8123791,"sourceType":"datasetVersion","datasetId":4800633}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### UTILITIES\nfrom keras.datasets import cifar10\nfrom keras.utils import to_categorical\nimport pickle\nimport sys\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nimport numpy as np\n\ndef load_dataset(batch_size, num_classes, epochs):\n    (x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n\n    # Select a random subset of 4500 images for training\n    random_indices = np.random.choice(len(x_train_full), size=50000, replace=False)\n    x_train = x_train_full[random_indices]\n    y_train = y_train_full[random_indices]\n\n    # Normalize and one-hot encode the labels\n    x_train = x_train.astype('float32') / 255\n    x_test = x_test.astype('float32') / 255\n    y_train = to_categorical(y_train, num_classes)\n    y_test = to_categorical(y_test, num_classes)\n\n    # Randomly select 500 images for validation\n    random_indices = np.random.choice(len(x_test), size=10000, replace=False)\n    x_val = x_test[random_indices]\n    y_val = y_test[random_indices]\n\n    dataset = {\n        'batch_size': batch_size,\n        'num_classes': num_classes,\n        'epochs': epochs,\n        'x_train': x_train,\n        'y_train': y_train,\n        'x_val': x_val,\n        'y_val': y_val,\n        'x_test': x_test,  \n        'y_test': y_test\n    }\n\n    return dataset\n\n\ndef save_network(network):\n    #object_file = open(network.name + '.obj', 'wb')\n    #pickle.dump(network, object_file)\n    #tf.keras.models.save_model(network, network.name)\n\n    model_path = network.name + '_model.h5'\n    tf.keras.models.save_model(network.model, model_path)\n\n    # Save the rest of the network information\n    network_info = {\n        'name': network.name,\n        'block_list': network.block_list,\n        'fitness': network.fitness\n    }\n    network_info_path = network.name + '_info.pkl'\n    with open(network_info_path, 'wb') as info_file:\n        pickle.dump(network_info, info_file)\n\n\ndef load_network(name):\n    model_path = name + '_model.h5'\n    loaded_model = tf.keras.models.load_model(model_path)\n\n    # Load the network information\n    info_path = name + '_info.pkl'\n    with open(info_path, 'rb') as info_file:\n        network_info = pickle.load(info_file)\n\n    # Create a new Network instance\n    loaded_network = Network(0)  # Update with appropriate 'it' value\n\n    # Set the attributes of the loaded network\n    loaded_network.name = network_info['name']\n    loaded_network.block_list = network_info['block_list']\n    loaded_network.fitness = network_info['fitness']\n    loaded_network.model = loaded_model\n\n    return loaded_network\n\n\n\ndef order_indexes(self):\n    i = 0\n    for block in self.block_list:\n        block.index = i\n        i += 1\n\n\ndef plot_training(history):                                           # plot diagnostic learning curves\n    plt.figure(figsize=[8, 6])  # accuracy curves\n    plt.plot(history.history['accuracy'], 'r', linewidth=3.0)\n    plt.plot(history.history['val_accuracy'], 'b', linewidth=3.0)  # <-- Change 'val_acc' to 'val_accuracy'\n    plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n    plt.xlabel('Epochs ', fontsize=16)\n    plt.ylabel('Accuracy', fontsize=16)\n    plt.title('Accuracy Curves', fontsize=16)\n\n    filename = sys.argv[0].split('/')[-1]\n    plt.savefig(filename + '_acc_plot.png')\n    plt.close()\n\n\n\ndef plot_statistics(stats):\n    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# fitness curves\n    plt.plot([s[0] for s in stats], 'r', linewidth=3.0)\n    plt.plot([stats[0][0]] * len(stats), 'b', linewidth=3.0)\n    plt.legend(['BestFitness', 'InitialFitness'], fontsize=18)\n    plt.xlabel('Generations', fontsize=16)\n    plt.ylabel('FitnessValue', fontsize=16)\n    plt.title('Fitness Curve', fontsize=16)\n    filename = sys.argv[0].split('/')[-1]\n    plt.savefig(filename + '_fitness_plot.png')\n\n    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# parameters curves\n    plt.plot([s[1] for s in stats], 'r', linewidth=3.0)\n    plt.plot([stats[0][1]] * len(stats), 'b', linewidth=3.0)\n    plt.legend(['BestParamsNum', 'InitialParamsNum'], fontsize=18)\n    plt.xlabel('Generations', fontsize=16)\n    plt.ylabel('ParamsNum', fontsize=16)\n    plt.title('Parameters Curve', fontsize=16)\n    filename = sys.argv[0].split('/')[-1]\n    plt.savefig(filename + '_params_plot.png')\n    plt.close()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:08.865544Z","iopub.execute_input":"2024-03-21T14:35:08.866376Z","iopub.status.idle":"2024-03-21T14:35:21.633023Z","shell.execute_reply.started":"2024-03-21T14:35:08.866339Z","shell.execute_reply":"2024-03-21T14:35:21.631981Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-21 14:35:10.635125: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-21 14:35:10.635228: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-21 14:35:10.762805: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# INOUT\nimport os\ndef compute_parent(dataset):\n    if os.path.isfile('parent_0.h5'):\n        daddy = load_network('parent_0')\n        model = tf.keras.models.load_model('parent_0.h5')\n        print(\"Loading parent_0\")\n        print(\"SUMMARY OF\", daddy.name)\n        print(model.summary())\n        print(\"FITNESS:\", daddy.fitness)\n        return daddy\n\n    daddy = Network(0)\n    \n    \n    #INI BLOCK\n    layerList1 = [\n        Convolutional(filters=32, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(0, 0, layerList1, layerList2))\n    \n    #MIDDLE BLOCK 1\n    layerList1 = [\n        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 1, layerList1, layerList2))\n\n     #MIDDLE BLOCK 2\n    layerList1 = [\n        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 2, layerList1, layerList2))\n\n    \n    #MIDDLE BLOCK 3\n    layerList1 = [\n        Convolutional(filters=256, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=256, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 3, layerList1, layerList2))\n    \n    \n    \n    #MIDDLE BLOCK 4\n    layerList1 = [\n        Convolutional(filters=512, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:]),\n        Convolutional(filters=512, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n                      input_shape=dataset['x_train'].shape[1:])\n    ]\n    layerList2 = [\n        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n    ]\n    daddy.block_list.append(Block(1, 4, layerList1, layerList2))\n    \n    \n    \n    #FULLY CONNECTED LAYER\n    layerList1 = [\n        FlattenLayer(),\n        FullyConnected(units=128, num_classes=dataset['num_classes'])\n    ]\n    layerList2 = []\n    daddy.block_list.append(Block(2, 5, layerList1, layerList2))\n    \n    \n\n    model = daddy.build_model()\n    print(\"Type of model_final:\", type(model))\n    daddy.train_and_evaluate(model, dataset)\n    return daddy","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:25.599146Z","iopub.execute_input":"2024-03-21T14:35:25.599778Z","iopub.status.idle":"2024-03-21T14:35:25.621856Z","shell.execute_reply.started":"2024-03-21T14:35:25.599747Z","shell.execute_reply":"2024-03-21T14:35:25.620860Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# NETWORK\nimport tensorflow as tf\nimport os\nimport pickle\nfrom keras.callbacks import Callback\nfrom keras.models import Sequential\nfrom random import randint, choice\nfrom copy import deepcopy\n\n\nclass Network:\n    __slots__ = ('name', 'block_list', 'fitness', 'model')\n\n    def __init__(self, it):\n        self.name = 'parent_' + str(it) if it == 0 else 'net_' + str(it)\n        self.block_list = []\n        self.fitness = None\n        self.model = None\n\n    \"\"\"def build_model(self):\n        model = Sequential()                                # create model\n        for block in self.block_list:\n            for layer in block.get_layers():                # build model\n                try:\n                    layer.build_layer(model)\n                except:\n                    print(\"\\nINDIVIDUAL ABORTED, CREATING A NEW ONE\\n\")\n                    return -1\n        return model\"\"\"\n    def build_model(self):\n        model = Sequential()              \n        print(\"The block is:\")\n        print(self.block_list)                 # create model\n        for block in self.block_list:\n            #print(\"Building block type:\", block.type)\n            #print(\"TOTAL :::\")\n            #print(block.get_layer_name())\n            for layer in block.get_layers():                # build model\n                #print(\"Adding layer:\", layer.name)\n                try:\n                    layer.build_layer(model)\n                    print(\"Layer added successfully.\")\n                except Exception as e:\n                    print(\"Error occurred while adding layer:\", e)\n                    print(\"Returning None.\")\n                    return -1\n        print(\"Model successfully built.\")\n        return model\n\n    def train_and_evaluate(self, model, dataset):\n        print(\"Training\", self.name)\n        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n        try:\n            history = model.fit(dataset['x_train'],\n                                dataset['y_train'],\n                                batch_size=dataset['batch_size'],\n                                epochs=dataset['epochs'],\n                                validation_data=(dataset['x_val'], dataset['y_val']),\n                                shuffle=True)\n        except Exception as e:\n            print(\"An error occurred during model training:\", e)\n            return -1\n            # You can choose to handle the error in a specific way here, like logging it or taking corrective actions.\n\n\n        # Extract metrics from the training history\n        training_loss = history.history['loss'][-1]\n        training_accuracy = history.history['accuracy'][-1]\n        validation_loss = history.history['val_loss'][-1]\n        validation_accuracy = history.history['val_accuracy'][-1]\n\n        # Additional metrics (you can customize this based on your needs)\n        classification_error_rate = 1.0 - validation_accuracy\n\n        self.model = model  # Save the model\n        self.fitness = validation_loss  # Use validation loss as fitness\n\n        # Print metrics\n        print(\"SUMMARY OF\", self.name)\n        print(\"Training Loss:\", training_loss)\n        print(\"Training Accuracy:\", training_accuracy)\n        print(\"Validation Loss:\", validation_loss)\n        print(\"Validation Accuracy:\", validation_accuracy)\n        print(\"Classification Error Rate:\", classification_error_rate)\n\n        tf.keras.models.save_model(model, self.name + '.h5')         # save model\n        #model.save(self.name + '.h5')                       # save model\n        save_network(self)                                  # save topology, model and fitness\n\n    def asexual_reproduction(self, it, dataset):\n\n        # if the individual already exists, just load it\n        if os.path.isfile('net_' + str(it) + '.h5'):\n            print(\"\\n-------------------------------------\")\n            print(\"Loading individual net_\" + str(it))\n            print(\"--------------------------------------\\n\")\n            individual = load_network('net_' + str(it))\n            model = tf.keras.models.load_model(individual.name + '.h5')\n            print(\"SUMMARY OF\", individual.name)\n            print(model.summary())\n            print(\"FITNESS: \", individual.fitness)\n            return individual\n\n        # otherwise, create the individual by mutating the parent\n        individual = Network(it)\n\n        print(\"\\n-------------------------------------\")\n        print(\"\\nCreating individual\", individual.name)\n        print(\"--------------------------------------\\n\")\n\n        individual.block_list = deepcopy(self.block_list)           # copy the layer list from parent\n\n        print(\"----->Strong Mutation\")\n        individual.block_mutation(dataset)                          # mutate a block\n        individual.layer_mutation(dataset)                          # mutate a layer\n        individual.parameters_mutation()                            # mutate some parameters\n\n        model = individual.build_model()\n        \n        if model == -1:\n            return self.asexual_reproduction(it, dataset)\n        \n        if(individual.train_and_evaluate(model, dataset)==-1):\n            return self.asexual_reproduction(it, dataset)\n        else:\n            return individual\n            \n\n    def block_mutation(self, dataset):\n        try:\n            print(\"Block Mutation\")\n\n            print([(block.index, block.type) for block in self.block_list])\n\n            # block list containing all the blocks with type = 1\n            bl = [block.index for block in self.block_list if block.type == 1]\n\n            if len(bl) == 0:\n                print(\"Creating a new block with two Convolutional layers and a Pooling layer\")\n                self.block_list[1].index = 2\n                layerList1 = [\n                    Convolutional(filters=pow(2, randint(5, 8)),\n                                  filter_size=(3, 3),\n                                  stride_size=(1, 1),\n                                  padding='same',\n                                  input_shape=dataset['x_train'].shape[1:]),\n                    Convolutional(filters=pow(2, randint(5, 8)),\n                                  filter_size=(3, 3),\n                                  stride_size=(1, 1),\n                                  padding='same',\n                                  input_shape=dataset['x_train'].shape[1:])\n                ]\n                layerList2 = [\n                    Pooling(pool_size=(2, 2),\n                            stride_size=(2, 2),\n                            padding='same')\n                ]\n                b = Block(1, 1, layerList1, layerList2)\n                self.block_list.insert(1, b)\n                return\n\n            block_idx = randint(1, max(bl))         # pick a random block among all the blocks with type = 1\n            block_type_idx = randint(0, 1)          # 1 -> Conv2D; 0 -> Pooling or Dropout\n            mutation_type = randint(0, 1)           # 1 -> remove; 0 -> add\n\n            # list of layers of the selected block\n            layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n            length = len(layerList)\n\n            if mutation_type:                                       # remove\n                if length == 1:\n                    del self.block_list[block_idx]\n                elif block_type_idx:\n                    pos = randint(0, length - 1)\n                    print(\"Removing a Conv2D layer at\", pos)\n                    del layerList[pos]\n                else:\n                    pos = randint(0, length - 1)\n                    print(\"Removing a Pooling/Dropout layer at\", pos)\n                    del layerList[pos]\n            else:                                                   # add\n                if block_type_idx:\n                    print(\"Inserting a Convolutional layer\")\n                    layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                          filter_size=(3, 3),\n                                          stride_size=(1, 1),\n                                          padding='same',\n                                          input_shape=dataset['x_train'].shape[1:])\n                    layerList.insert(randint(0, length - 1), layer)\n                else:\n                    if randint(0, 1):                               # 1 -> Pooling; 0 -> Dropout\n                        print(\"Inserting a Pooling layer\")\n                        layer = Pooling(pool_size=(2, 2),\n                                        stride_size=(2, 2),\n                                        padding='same')\n                        layerList.insert(randint(0, length - 1), layer)\n                    else:\n                        print(\"Inserting a Dropout layer\")\n                        rate = choice([0.15, 0.25, 0.35, 0.50])\n                        layer = Dropout(rate=rate)\n                        layerList.insert(randint(0, length - 1), layer)\n        except Exception as e:\n            print(f\"An error occurred during block mutation: {e}\")\n            return None\n\n                    \n                    \n                    \n                    \n                    \n\n    \"\"\"def layer_mutation(self, dataset):\n        print(\"Layer Mutation\")\n\n        # pick a random block among all the blocks with type = 1\n        bl = [block.index for block in self.block_list if block.type == 1]\n\n        if len(bl) == 0:\n            return\n\n        block_idx = randint(1, max(bl))\n        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n\n        # list of layers of the selected block\n        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n\n        if len(layerList) == 0:\n            if block_type_idx:\n                layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                      filter_size=(3, 3),\n                                      stride_size=(1, 1),\n                                      padding='same',\n                                      input_shape=dataset['x_train'].shape[1:])\n                self.block_list[block_idx].layerList1.append(layer)\n                return\n            else:\n                layer = Pooling(pool_size=(2, 2),\n                                stride_size=(2, 2),\n                                padding='same')\n                self.block_list[block_idx].layerList2.append(layer)\n\n        idx = randint(0, len(layerList) - 1)\n        layer = layerList[idx]\n\n        if layer.name == 'Conv2D':\n            print(\"Splitting Conv2D layer at index\", idx)\n            layer.filters = int(layer.filters * 0.5)\n            layerList.insert(idx, deepcopy(layer))\n        elif layer.name == 'MaxPooling2D' or layer.name == 'AveragePooling2D':\n            print(\"Changing Pooling layer at index\", idx, \"with Conv2D layer\")\n            del layerList[idx]\n            conv_layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                       filter_size=(3, 3),\n                                       stride_size=(2, 2),\n                                       padding=layer.padding,\n                                       input_shape=dataset['x_train'].shape[1:])\n            layerList.insert(idx, conv_layer)\"\"\"\n    \n    def layer_mutation(self, dataset):\n        print(\"Layer Mutation\")\n\n        # Determine the maximum number of layers that can be added or removed\n        max_layers_to_add = 16 - sum(len(block.layerList1) + len(block.layerList2) for block in self.block_list)\n        max_layers_to_remove = sum(len(block.layerList1) + len(block.layerList2) - 1 for block in self.block_list)\n\n        if max_layers_to_add == 0 and max_layers_to_remove == 0:\n            return\n\n        # Pick a random block among all the blocks with type = 1\n        bl = [block.index for block in self.block_list if block.type == 1]\n\n        if len(bl) == 0:\n            return\n\n        block_idx = randint(1, max(bl))\n        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n\n        # List of layers of the selected block\n        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n\n        if len(layerList) == 0:\n            if block_type_idx:\n                layer = Convolutional(filters=pow(2, randint(5, 8)),\n                                      filter_size=(3, 3),\n                                      stride_size=(1, 1),\n                                      padding='same',\n                                      input_shape=dataset['x_train'].shape[1:])\n                self.block_list[block_idx].layerList1.append(layer)\n            else:\n                layer = Pooling(pool_size=(2, 2),\n                                stride_size=(2, 2),\n                                padding='same')\n                self.block_list[block_idx].layerList2.append(layer)\n        else:\n            # Randomly choose whether to add or remove a layer\n            add_layer = bool(randint(0, 1))\n\n            if add_layer and max_layers_to_add > 0:\n                # Add a layer\n                layer = self.create_random_layer(dataset)\n                layerList.insert(randint(0, len(layerList)), layer)\n            elif not add_layer and max_layers_to_remove > 0:\n                # Remove a layer\n                idx = randint(0, len(layerList) - 1)\n                del layerList[idx]\n\n        # Ensure the total number of layers in the block doesn't exceed 16\n        if len(self.block_list[block_idx].layerList1) + len(self.block_list[block_idx].layerList2) > 16:\n            # Remove a random layer to maintain the total count of 16 layers\n            block_layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n            del block_layerList[randint(0, len(block_layerList) - 1)]\n\n    def create_random_layer(self, dataset):\n        # Create a random layer (Conv2D or Pooling)\n        if randint(0, 1):\n            # Conv2D layer\n            return Convolutional(filters=pow(2, randint(5, 8)),\n                                 filter_size=(3, 3),\n                                 stride_size=(1, 1),\n                                 padding='same',\n                                 input_shape=dataset['x_train'].shape[1:])\n        else:\n            # Pooling layer\n            return Pooling(pool_size=(2, 2),\n                           stride_size=(2, 2),\n                           padding='same')\n\n            \n            \n            \n            \n            \n            \n            \n            \n\n    def parameters_mutation(self):\n        print(\"Parameters Mutation\")\n        for block in self.block_list:\n            for layer in block.get_layers():\n                if randint(0, 1):\n                    layer.mutate_parameters()\n\n    def save_network_info(self, info_filename):\n        network_info = {\n            'name': self.name,\n            'block_list': self.block_list,\n            'fitness': self.fitness\n        }\n\n        with open(info_filename, 'wb') as info_file:\n            pickle.dump(network_info, info_file)\n\n    def load_network_info(self, info_filename):\n        with open(info_filename, 'rb') as info_file:\n            network_info = pickle.load(info_file)\n\n        self.name = network_info['name']\n        self.block_list = network_info['block_list']\n        self.fitness = network_info['fitness']\n\n    def save_model(self, model_filename):\n        self.model.save(model_filename)\n\n    def load_model(self, model_filename):\n        self.model = tf.keras.models.load_model(model_filename)\n\n    def save_network(self, network_info_filename, model_filename):\n        # Save non-model attributes\n        self.save_network_info(network_info_filename)\n\n        # Save the model separately\n        self.save_model(model_filename)\n\n    def load_network(self, network_info_filename, model_filename):\n        # Load non-model attributes\n        self.load_network_info(network_info_filename)\n\n        # Load the model separately\n        self.load_model(model_filename)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:27.022012Z","iopub.execute_input":"2024-03-21T14:35:27.022374Z","iopub.status.idle":"2024-03-21T14:35:27.078711Z","shell.execute_reply.started":"2024-03-21T14:35:27.022345Z","shell.execute_reply":"2024-03-21T14:35:27.077468Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# TOPOLOGY\n\nimport keras.layers\nfrom random import randint\n\n\nclass Block:\n\t__slots__ = ('type', 'index', 'layerList1', 'layerList2')\n\n\tdef __init__(self, type, index, layerList1, layerList2):\n\t\tself.type = type\t\t\t\t\t\t\t\t\t\t# 0 -> initial layer; 1 -> mid layers; 2 -> final layer\n\t\tself.index = index\t\t\t\t\t\t\t\t\t\t# block index among all the blocks\n\t\tself.layerList1 = layerList1\t\t\t\t\t\t\t# Convolutional layers\n\t\tself.layerList2 = layerList2\t\t\t\t\t\t\t# Pooling and Dropout layers\n\n\tdef get_layers(self):\n\t\treturn self.layerList1 + self.layerList2\n\n\tdef get_size(self):\n\t\treturn len(self.get_layers())\n\n\nclass Convolutional:\n\t# __slots__ = ('name', 'filters', 'padding', 'filter_size', 'stride_size', 'input_shape')\n\n\tdef __init__(self, filters, padding, filter_size, stride_size, input_shape):\n\t\tself.name = 'Conv2D'\n\t\tself.filters = filters\n\t\tself.padding = padding\n\t\tself.filter_size = filter_size\n\t\tself.stride_size = stride_size\n\t\tself.input_shape = input_shape\n\n\tdef build_layer(self, model):\n\t\ttry:\n\t\t\tmodel.add(keras.layers.Conv2D(filters=self.filters,\n\t\t\t\t\t\t\t\t\t\t\tkernel_size=self.filter_size,\n\t\t\t\t\t\t\t\t\t\t\tstrides=self.stride_size,\n\t\t\t\t\t\t\t\t\t\t\tpadding=self.padding,\n\t\t\t\t\t\t\t\t\t\t\tactivation='relu',\n\t\t\t\t\t\t\t\t\t\t\tkernel_initializer='he_uniform',\n\t\t\t\t\t\t\t\t\t\t\tinput_shape=self.input_shape))\n\t\texcept ValueError as e:\n\t\t\tprint(\"Error occurred while adding layer:\", e)\n\t\t\tprint(\"Skipping current architecture.\")\n\t\t\treturn  # Skip adding this layer\n\tdef mutate_parameters(self):\n\t\tmutation = randint(0, 2)  # Adjusted the number of mutations\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tif mutation == 0 and self.filters >= 64:  # Adjusted the filter reduction threshold\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters = int(self.filters / 2)\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 1 and self.filters <= 256:  # Adjusted the filter increase threshold\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters *= 2\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 2:\n\t\t\tif self.padding == 'valid':\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'same'\n\t\t\t\tprint(\"to \", self.padding)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'valid'\n\t\t\t\tprint(\"to \", self.padding)\n\n        \n\n        \n\n\n\t\"\"\"def mutate_parameters(self):\n\t\tmutation = randint(0, 4)\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tif mutation == 0 and self.filters >= 32:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters = int(self.filters / 2)\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 1 and self.filters >= 32:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters = int(self.filters / 2)\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 2 and self.filters <= 512:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters *= 2\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 3 and self.filters <= 512:\n\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n\t\t\tself.filters *= 2\n\t\t\tprint(\"to \", self.filters)\n\t\telif mutation == 4:\n\t\t\tif self.padding == 'valid':\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'same'\n\t\t\t\tprint(\"to \", self.padding)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'valid'\n\t\t\t\tprint(\"to \", self.padding)\n\"\"\"\n    \n\n'''\nelif mutation is 4:\n\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n\tprint(\"to \", self.stride_size, \" and \", end=\"\")\n\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n\tprint(\"to \", self.stride_size)\n'''\n\n\nclass Pooling:\n\t__slots__ = ('name', 'pool_size', 'stride_size', 'padding')\n\n\tdef __init__(self, pool_size, stride_size, padding):\n\t\tself.name = 'MaxPooling2D'\n\t\tself.pool_size = pool_size\n\t\tself.stride_size = stride_size\n\t\tself.padding = padding\n\n\tdef build_layer(self, model):\n\t\tif self.name == 'MaxPooling2D':\n\t\t\tmodel.add(keras.layers.MaxPooling2D(self.pool_size, self.stride_size, self.padding))\n\t\telif self.name == 'AveragePooling2D':\n\t\t\tmodel.add(keras.layers.AveragePooling2D(self.pool_size, self.stride_size, self.padding))\n\n\tdef mutate_parameters(self):\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tmutation = randint(0, 1)\n\t\tif mutation == 0:\n\t\t\tif self.padding == 'valid':\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'same'\n\t\t\t\tprint(\"to \", self.padding)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n\t\t\t\tself.padding = 'valid'\n\t\t\t\tprint(\"to \", self.padding)\n\t\telif mutation == 1:\n\t\t\tif self.name == 'MaxPooling2D':\n\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n\t\t\t\tself.name = 'AveragePooling2D'\n\t\t\t\tprint(\"to \", self.name)\n\t\t\telse:\n\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n\t\t\t\tself.name = 'MaxPooling2D'\n\t\t\t\tprint(\"to \", self.name)\n\n\n'''\nif mutation is 0:\n\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n\tprint(\"to \", self.stride_size)\n'''\n\n\nclass FullyConnected:\n\t__slots__ = ('name', 'units', 'num_classes')\n\n\tdef __init__(self, units, num_classes):\n\t\tself.name = \"FullyConnected\"\n\t\tself.units = units\n\t\tself.num_classes = num_classes\n\n\tdef build_layer(self, model):\n\t\tmodel.add(keras.layers.Flatten())\n\t\tmodel.add(keras.layers.Dense(self.units, activation='relu', kernel_initializer='he_uniform'))\n\t\tmodel.add(keras.layers.Dense(self.num_classes, activation='softmax'))\n\n\tdef mutate_parameters(self):\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tmutation = randint(0, 2)\n\t\tif mutation == 0:\n\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n\t\t\tself.units *= 2\n\t\t\tprint(\"to \", self.units)\n\t\telif mutation == 1:\n\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n\t\t\tself.units *= 2\n\t\t\tprint(\"to \", self.units)\n\t\telif mutation == 2:\n\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n\t\t\tself.units /= 2\n\t\t\tprint(\"to \", self.units)\n\n\n'''\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(self.num_classes, activation='softmax'))\n'''\n\n\nclass Dropout:\n\t__slots__ = ('name', 'rate')\n\n\tdef __init__(self, rate):\n\t\tself.name = \"Dropout\"\n\t\tself.rate = rate\n\n\tdef build_layer(self, model):\n\t\tmodel.add(keras.layers.Dropout(self.rate))\n\n\tdef mutate_parameters(self):\n\t\tprint(\"Mutating\", self.name, \"layer:\")\n\t\tmutation = randint(0, 3)\n\t\tif mutation == 0 and self.rate <= 0.85:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate + 0.10\n\t\t\tprint(\"to \", self.rate)\n\t\telif mutation == 1 and self.rate <= 0.90:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate + 0.05\n\t\t\tprint(\"to \", self.rate)\n\t\telif mutation == 2 and self.rate >= 0.15:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate - 0.10\n\t\t\tprint(\"to \", self.rate)\n\t\telif mutation == 3 and self.rate >= 0.10:\n\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n\t\t\tself.rate = self.rate - 0.05\n\t\t\tprint(\"to \", self.rate)\n\nclass FlattenLayer:\n    def __init__(self):\n        self.name = 'Flatten'\n\n    def build_layer(self, model):\n        model.add(keras.layers.Flatten())\n\n    def mutate_parameters(self):\n        # The Flatten layer does not have any parameters to mutate\n        pass\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:35:28.087245Z","iopub.execute_input":"2024-03-21T14:35:28.087711Z","iopub.status.idle":"2024-03-21T14:35:28.125784Z","shell.execute_reply.started":"2024-03-21T14:35:28.087683Z","shell.execute_reply":"2024-03-21T14:35:28.124727Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"\"\"\"# MAIN\n\nimport tensorflow as tf\ntf.compat.v1.enable_eager_execution()\nimport os\nfrom copy import deepcopy\nfrom random import sample\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)      # suppress messages from Tensorflow\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\n\ndef initialize_population(population_size, dataset):\n    print(\"----->Initializing Population\")\n    daddy = compute_parent(dataset)                                 # load parent from input\n    population = [daddy]\n    for it in range(1, population_size):\n        population.append(daddy.asexual_reproduction(it, dataset))\n\n    # sort population on ascending order based on fitness\n    return sorted(population, key=lambda cnn: cnn.fitness)\n\n\ndef selection(k, population, num_population):\n    if k == 0:                                              # elitism selection\n        print(\"----->Elitism selection\")\n        return population[0], population[1]\n    elif k == 1:                                            # tournament selection\n        print(\"----->Tournament selection\")\n        i = randint(0, num_population - 1)\n        j = i\n        while j < num_population - 1:\n            j += 1\n            if randint(1, 100) <= 50:\n                return population[i], population[j]\n        return population[i], population[0]\n    else:                                                   # proportionate selection\n        print(\"----->Proportionate selection\")\n        cum_sum = 0\n        for i in range(num_population):\n            cum_sum += population[i].fitness\n        perc_range = []\n        for i in range(num_population):\n            count = 100 - int(100 * population[i].fitness / cum_sum)\n            for j in range(count):\n                perc_range.append(i)\n        i, j = sample(range(1, len(perc_range)), 2)\n        while i == j:\n            i, j = sample(range(1, len(perc_range)), 2)\n        return population[perc_range[i]], population[perc_range[j]]\n\n\ndef crossover(parent1, parent2, it):\n    print(\"----->Crossover\")\n    child = Network(it)\n\n    first, second = None, None\n    if randint(0, 1):\n        first = parent1\n        second = parent2\n    else:\n        first = parent2\n        second = parent1\n\n    child.block_list = deepcopy(first.block_list[:randint(1, len(first.block_list) - 1)]) \\\n                       + deepcopy(second.block_list[randint(1, len(second.block_list) - 1):])\n\n    order_indexes(child)                            # order the indexes of the blocks\n\n    return child\n\n\ndef genetic_algorithm(num_population, num_generation, num_offspring, dataset, early_stopping_generations=3):\n    print(\"Genetic Algorithm\")\n\n    population = initialize_population(num_population, dataset)\n\n    print(\"\\n-------------------------------------\")\n    print(\"Initial Population:\")\n    for cnn in population:\n        print(cnn.name, ': ', cnn.fitness)\n    print(\"--------------------------------------\\n\")\n\n    # for printing statistics about fitness and the number of parameters of the best individual\n    stats = [(population[0].fitness, population[0].model.count_params())]\n\n    # Initialize a variable to keep track of consecutive generations with the same best fitness\n    consecutive_same_fitness = 0\n\n    for gen in range(1, num_generation + 1):\n        '''\n            k is the selection parameter:\n                k = 0 -> elitism selection\n                k = 1 -> tournament selection\n                k = 2 -> proportionate selection\n        '''\n        k = randint(0, 2)\n\n        print(\"\\n------------------------------------\")\n        print(\"Generation -----------------------------------------------------------------------------------\", gen)\n        print(\"-------------------------------------\")\n\n        for c in range(num_offspring):\n\n            print(\"\\nCreating Child\", c)\n\n            parent1, parent2 = selection(k, population, num_population)                 # selection\n            print(\"Selected\", parent1.name, \"and\", parent2.name, \"for reproduction\")\n\n            child = crossover(parent1, parent2, c + num_population)                     # crossover\n            print(\"Child has been created\")\n\n            print(\"----->Soft Mutation\")\n            child.layer_mutation(dataset)                                               # mutation\n            child.parameters_mutation()\n            print(\"Child has been mutated\")\n            model = child.build_model()  \n            # evaluation\n            if model==-1:\n                pass\n            else:\n                if(child.train_and_evaluate(model,dataset)==-1):\n                    model=-1  \n            #if(child.train_and_evaluate(model,dataset)==-1):\n                    #model=-1  # evaluation\n\n            while model == -1:\n                child = crossover(parent1, parent2, c + num_population)\n                child.block_mutation(dataset)\n                child.layer_mutation(dataset)\n                child.parameters_mutation()\n                model = child.build_model()\n                if(model==-1):\n                    pass\n                else:\n                    if(child.train_and_evaluate(model,dataset)==-1):\n                        model=-1\n\n            #child.train_and_evaluate(model, dataset)\n\n            if child.fitness < population[-1].fitness:                                  # evolve population\n                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"replaces parent \", end=\"\")\n                print(population[-1].name, \"with fitness\", population[-1].fitness)\n                name = population[-1].name\n\n                child.save_network(\"child_model_info.pkl\", \"child_model.h5\")\n                population[-1].load_network(\"child_model_info.pkl\", \"child_model.h5\")\n\n                population[-1].name = name\n                population = sorted(population, key=lambda net: net.fitness)\n            else:\n                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"is discarded\")\n        \n        if gen >= 3 and all(population[i].fitness == population[i + 1].fitness for i in range(-3, -1)):\n            consecutive_same_fitness += 1\n            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n        if consecutive_same_fitness >= 3:\n            print(\"Stopping the algorithm as the best fitness has remained the same for the last 3 generations.\")\n            break\n    else:\n        consecutive_same_fitness = 0\n        \n       #Check if the best fitness has remained the same for the last early_stopping_generations generations\n        if all(population[i].fitness == population[i + 1].fitness for i in range(-early_stopping_generations, -1)):\n            consecutive_same_fitness += 1\n            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n            if consecutive_same_fitness == early_stopping_generations:\n                print(f\"Stopping the algorithm as the best fitness has remained the same for {early_stopping_generations} generations.\")\n        else:\n            consecutive_same_fitness = 0\n        stats.append((population[0].fitness, population[0].model.count_params()))\n\n    print(\"\\n\\n-------------------------------------\")\n    print(\"Final Population\")\n    print(\"-------------------------------------\\n\")\n    for cnn in population:\n        print(cnn.name, ': ', cnn.fitness)\n\n    print(\"\\n-------------------------------------\")\n    print(\"Stats\")\n    for i in range(len(stats)):\n        print(\"Best individual at generation\", i + 1, \"has fitness\", stats[i][0], \"and parameters\", stats[i][1])\n    print(\"-------------------------------------\\n\")\n\n    # plot the fitness and the number of parameters of the best individual at each iteration\n    plot_statistics(stats)\n\n    return population[0]\n\n\n\ndef main():    \n        #with strategy.scope():\n        #from tensorflow.python.client import device_lib\n        #print(device_lib.list_local_devices())\n        #batch_size = 8\n        #batch_size = batch_size * strategy.num_replicas_in_sync\n        batch_size = 32                       # the number of training examples in one forward/backward pass\n        num_classes = 10                        # number of cifar-10 dataset classes\n        epochs =20              # number of forward and backward passes of all the training examples\n\n        '''\n            dataset contains the hyper parameters for loading data and the dataset:\n                dataset = {\n                    'batch_size': batch_size,\n                    'num_classes': num_classes,\n                    'epochs': epochs,\n                    'x_train': x_train,\n                    'x_test': x_test,\n                    'y_train': y_train,\n                    'y_test': y_test\n                }\n        '''\n        dataset = load_dataset(batch_size, num_classes, epochs)\n\n        num_population = 10\n        num_generation = 20\n        num_offspring = 4\n\n        # plot the best model obtained\n        optCNN = genetic_algorithm(num_population, num_generation, num_offspring, dataset)\n\n        # plot the training and validation loss and accuracy\n        num_epoch = 20\n        model = optCNN.build_model()\n        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n        history = model.fit(dataset['x_train'],\n                            dataset['y_train'],\n                            batch_size=dataset['batch_size'],\n                            epochs=num_epoch,\n                            validation_data=(dataset['x_test'], dataset['y_test']),\n                            shuffle=True)\n        optCNN.model = model                                        # model\n        optCNN.fitness = history.history['val_loss'][-1]            # fitness\n\n        print(\"\\n\\n-------------------------------------\")\n        print(\"The Final CNN has been evolved successfully in the individual\", optCNN.name)\n        print(\"-------------------------------------\\n\")\n        daddy = load_network('parent_0')\n        model = tf.keras.models.load_model('parent_0.h5')\n        print(\"\\n\\n-------------------------------------\")\n        print(\"Summary of initial CNN\")\n        print(model.summary())\n        print(\"Fitness of initial CNN:\", daddy.fitness)\n\n        print(\"\\n\\n-------------------------------------\")\n        print(\"Summary of evolved individual\")\n        print(optCNN.model.summary())\n        print(\"Fitness of the evolved individual:\", optCNN.fitness)\n        print(\"-------------------------------------\\n\")\n\n        plot_training(history)\n\n\nif __name__ == '__main__':\n    main()\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:34:10.099189Z","iopub.execute_input":"2024-03-19T09:34:10.099594Z","iopub.status.idle":"2024-03-19T09:34:10.118001Z","shell.execute_reply.started":"2024-03-19T09:34:10.099563Z","shell.execute_reply":"2024-03-19T09:34:10.116664Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\"# MAIN\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"],"ename":"SyntaxError","evalue":"incomplete input (3420972760.py, line 1)","output_type":"error"}]},{"cell_type":"code","source":"\"\"\"## To remove a folder\n# Clear output folder\nimport os\n\ndef remove_folder_contents(folder):\n    for the_file in os.listdir(folder):\n        file_path = os.path.join(folder, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                remove_folder_contents(file_path)\n                os.rmdir(file_path)\n        except Exception as e:\n            print(e)\n\nfolder_path = '/kaggle/working'\nremove_folder_contents(folder_path)\nos.rmdir(folder_path)\"\"\"\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-03-19T09:34:11.054431Z","iopub.execute_input":"2024-03-19T09:34:11.054798Z","iopub.status.idle":"2024-03-19T09:34:11.061017Z","shell.execute_reply.started":"2024-03-19T09:34:11.054771Z","shell.execute_reply":"2024-03-19T09:34:11.059840Z"},"trusted":true},"execution_count":7,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[7], line 19\u001b[0;36m\u001b[0m\n\u001b[0;31m    os.rmdir(folder_path)\"\"\"\"\"\"\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"],"ename":"SyntaxError","evalue":"incomplete input (2683820672.py, line 19)","output_type":"error"}]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport tensorflow as tf\nimport numpy as np\n\n# Set the paths to the datasets\nimage_dir = '/kaggle/input/cifar100-20-classes-images/final'\ncsv_file = '/kaggle/input/cifar100captions-new/cifar100_20classes_mixing_new.csv'","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:56:58.732066Z","iopub.execute_input":"2024-04-15T09:56:58.732870Z","iopub.status.idle":"2024-04-15T09:57:10.518305Z","shell.execute_reply.started":"2024-04-15T09:56:58.732838Z","shell.execute_reply":"2024-04-15T09:57:10.517541Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-04-15 09:57:00.621189: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-15 09:57:00.621289: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-15 09:57:00.737118: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the image and text data\nimage_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\ndata = pd.read_csv(csv_file)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:57:10.519745Z","iopub.execute_input":"2024-04-15T09:57:10.520248Z","iopub.status.idle":"2024-04-15T09:57:10.891739Z","shell.execute_reply.started":"2024-04-15T09:57:10.520221Z","shell.execute_reply":"2024-04-15T09:57:10.890802Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:57:40.707014Z","iopub.execute_input":"2024-04-15T09:57:40.707711Z","iopub.status.idle":"2024-04-15T09:57:40.718153Z","shell.execute_reply.started":"2024-04-15T09:57:40.707680Z","shell.execute_reply":"2024-04-15T09:57:40.717249Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                 caption  class  \\\n0                            An apple on a wooden table.      0   \n1                   A juicy red apple in a fruit basket.      0   \n2                  An apple with a bite taken out of it.      0   \n3              A shiny green apple on a kitchen counter.      0   \n4        An apple orchard with trees full of ripe fruit.      0   \n...                                                  ...    ...   \n11976             A field of tulips in different colors.     92   \n11977               A colorful bouquet of mixed flowers.     92   \n11978     A single blue flower in a sea of green leaves.     92   \n11979             A garden bed full of blooming flowers.     92   \n11980  A bunch of daffodils announcing the arrival of...     92   \n\n                 filename  \n0         class_0_image_0  \n1         class_0_image_1  \n2         class_0_image_2  \n3         class_0_image_3  \n4         class_0_image_4  \n...                   ...  \n11976  class_92_image_594  \n11977  class_92_image_595  \n11978  class_92_image_596  \n11979  class_92_image_597  \n11980  class_92_image_598  \n\n[11981 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>class</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>An apple on a wooden table.</td>\n      <td>0</td>\n      <td>class_0_image_0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A juicy red apple in a fruit basket.</td>\n      <td>0</td>\n      <td>class_0_image_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>An apple with a bite taken out of it.</td>\n      <td>0</td>\n      <td>class_0_image_2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A shiny green apple on a kitchen counter.</td>\n      <td>0</td>\n      <td>class_0_image_3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>An apple orchard with trees full of ripe fruit.</td>\n      <td>0</td>\n      <td>class_0_image_4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11976</th>\n      <td>A field of tulips in different colors.</td>\n      <td>92</td>\n      <td>class_92_image_594</td>\n    </tr>\n    <tr>\n      <th>11977</th>\n      <td>A colorful bouquet of mixed flowers.</td>\n      <td>92</td>\n      <td>class_92_image_595</td>\n    </tr>\n    <tr>\n      <th>11978</th>\n      <td>A single blue flower in a sea of green leaves.</td>\n      <td>92</td>\n      <td>class_92_image_596</td>\n    </tr>\n    <tr>\n      <th>11979</th>\n      <td>A garden bed full of blooming flowers.</td>\n      <td>92</td>\n      <td>class_92_image_597</td>\n    </tr>\n    <tr>\n      <th>11980</th>\n      <td>A bunch of daffodils announcing the arrival of...</td>\n      <td>92</td>\n      <td>class_92_image_598</td>\n    </tr>\n  </tbody>\n</table>\n<p>11981 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Load the LSTM and CNN models\nlstm_model = tf.keras.models.load_model('/kaggle/input/cifar100-20classes-lstm/cifar_100_20classes_net8_lstm.h5')\ncnn_model = tf.keras.models.load_model('/kaggle/input/cnn-models-fashion-cifar100/cifar_100_20classes_net13.h5')","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:57:41.448516Z","iopub.execute_input":"2024-04-15T09:57:41.448910Z","iopub.status.idle":"2024-04-15T09:57:44.030248Z","shell.execute_reply.started":"2024-04-15T09:57:41.448875Z","shell.execute_reply":"2024-04-15T09:57:44.029248Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom keras.utils import to_categorical\nfrom PIL import Image\n\ndef load_image(image_path, image_shape):\n    image = Image.open(image_path)\n    image = image.resize((image_shape[1], image_shape[0]))  # Resize to match the required shape\n    image = np.array(image) / 255.0  # Normalize pixel values to [0, 1]\n    return image","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:57:44.031975Z","iopub.execute_input":"2024-04-15T09:57:44.032267Z","iopub.status.idle":"2024-04-15T09:57:44.037964Z","shell.execute_reply.started":"2024-04-15T09:57:44.032242Z","shell.execute_reply":"2024-04-15T09:57:44.037112Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Usage:\nimage_folder = '/kaggle/input/cifar100-20-classes-images/final'\ncaptions_df = pd.read_csv('/kaggle/input/cifar100captions-new/cifar100_20classes_mixing_new.csv')  # Assuming captions are stored in a CSV file\nnum_classes = 20  # Number of classes/categories\nimage_shape = (32, 32, 3)  # Define the shape of the images","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:57:44.039250Z","iopub.execute_input":"2024-04-15T09:57:44.039646Z","iopub.status.idle":"2024-04-15T09:57:44.071271Z","shell.execute_reply.started":"2024-04-15T09:57:44.039609Z","shell.execute_reply":"2024-04-15T09:57:44.070587Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Step 1: Load image data from the folder\nimages = []\nimage_filenames = []\nfor filename in os.listdir(image_folder):\n    if filename.endswith(\".jpg\"):  # Assuming images are in png format\n            image_path = os.path.join(image_folder, filename)\n            image = load_image(image_path, image_shape)\n            images.append(image)\n            image_filenames.append(os.path.splitext(filename)[0])  # Remove file extension\n\nimage_captions = []\nimage_classes = []","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:57:44.464698Z","iopub.execute_input":"2024-04-15T09:57:44.465323Z","iopub.status.idle":"2024-04-15T09:58:39.675450Z","shell.execute_reply.started":"2024-04-15T09:57:44.465292Z","shell.execute_reply":"2024-04-15T09:58:39.674405Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"image_classes","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:58:39.677426Z","iopub.execute_input":"2024-04-15T09:58:39.677858Z","iopub.status.idle":"2024-04-15T09:58:39.683719Z","shell.execute_reply.started":"2024-04-15T09:58:39.677825Z","shell.execute_reply":"2024-04-15T09:58:39.682837Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"image_filenames[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:58:39.684761Z","iopub.execute_input":"2024-04-15T09:58:39.685019Z","iopub.status.idle":"2024-04-15T09:58:39.696559Z","shell.execute_reply.started":"2024-04-15T09:58:39.684997Z","shell.execute_reply":"2024-04-15T09:58:39.695757Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'class_84_image_540'"},"metadata":{}}]},{"cell_type":"code","source":"filename","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:58:39.698568Z","iopub.execute_input":"2024-04-15T09:58:39.699272Z","iopub.status.idle":"2024-04-15T09:58:39.708177Z","shell.execute_reply.started":"2024-04-15T09:58:39.699240Z","shell.execute_reply":"2024-04-15T09:58:39.707321Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'class_24_image_137.jpg'"},"metadata":{}}]},{"cell_type":"code","source":"\nclass_index = int(filename.split('_')[1])\nclass_index","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:58:39.709255Z","iopub.execute_input":"2024-04-15T09:58:39.709594Z","iopub.status.idle":"2024-04-15T09:58:39.716965Z","shell.execute_reply.started":"2024-04-15T09:58:39.709570Z","shell.execute_reply":"2024-04-15T09:58:39.716173Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"24"},"metadata":{}}]},{"cell_type":"code","source":"image_index = int(filename.split('_')[3].split('.')[0])\nimage_index","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:58:39.717982Z","iopub.execute_input":"2024-04-15T09:58:39.718247Z","iopub.status.idle":"2024-04-15T09:58:39.726960Z","shell.execute_reply.started":"2024-04-15T09:58:39.718224Z","shell.execute_reply":"2024-04-15T09:58:39.726105Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"137"},"metadata":{}}]},{"cell_type":"code","source":"image_filenames[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:58:44.468608Z","iopub.execute_input":"2024-04-15T09:58:44.469496Z","iopub.status.idle":"2024-04-15T09:58:44.475210Z","shell.execute_reply.started":"2024-04-15T09:58:44.469462Z","shell.execute_reply":"2024-04-15T09:58:44.474253Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'class_84_image_540'"},"metadata":{}}]},{"cell_type":"code","source":"for filename in image_filenames:\n    #print(filename)\n    class_index = int(filename.split('_')[1])\n    #print(class_index)\n    image_index = int(filename.split('_')[3].split('.')[0])\n    #print(image_index)\n    row = captions_df[captions_df['filename'] == filename]\n    #print(row)\n    caption = row['caption']\n    image_captions.append(caption)\n    image_classes.append(class_index)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:58:57.468328Z","iopub.execute_input":"2024-04-15T09:58:57.468710Z","iopub.status.idle":"2024-04-15T09:59:25.444816Z","shell.execute_reply.started":"2024-04-15T09:58:57.468679Z","shell.execute_reply":"2024-04-15T09:59:25.443766Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\n\n# Display the image\nplt.imshow(images[2])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:59:35.538676Z","iopub.execute_input":"2024-04-15T09:59:35.539467Z","iopub.status.idle":"2024-04-15T09:59:35.988384Z","shell.execute_reply.started":"2024-04-15T09:59:35.539431Z","shell.execute_reply":"2024-04-15T09:59:35.987511Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x794b4dacb880>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"image_captions[2]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:59:38.293921Z","iopub.execute_input":"2024-04-15T09:59:38.294248Z","iopub.status.idle":"2024-04-15T09:59:38.301280Z","shell.execute_reply.started":"2024-04-15T09:59:38.294221Z","shell.execute_reply":"2024-04-15T09:59:38.300375Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"10015    A tiger with a sense of pride in its posture.\nName: caption, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"image_classes[2]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:59:40.597231Z","iopub.execute_input":"2024-04-15T09:59:40.597606Z","iopub.status.idle":"2024-04-15T09:59:40.603468Z","shell.execute_reply.started":"2024-04-15T09:59:40.597578Z","shell.execute_reply":"2024-04-15T09:59:40.602518Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"88"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Assuming you have lists images, image_captions, and image_classes containing your data\n\n# Create an array of indices from 0 to the length of your data\nindices = np.arange(len(images))\n\n# Randomly select 20,000 indices for testing without replacement\ntesting_indices = np.random.choice(indices, size=2000, replace=False)\n\n# Use the remaining indices for training\ntraining_indices = np.setdiff1d(indices, testing_indices)\n\n# Use the selected indices to create the testing and training datasets\ntesting_cnn_data_selected = [images[i] for i in testing_indices]\ntraining_cnn_data_selected = [images[i] for i in training_indices]\n\ntesting_lstm_data_selected = [image_captions[i] for i in testing_indices]\ntraining_lstm_data_selected = [image_captions[i] for i in training_indices]\n\n# Create labels (y) for testing and training datasets\ntesting_labels = [image_classes[i] for i in testing_indices]\ntraining_labels = [image_classes[i] for i in training_indices]\n\n# Now testing_data_selected contains 20,000 randomly selected items for testing\n# and training_data_selected contains the remaining items for training\n# testing_labels and training_labels contain corresponding labels for testing and training datasets\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:59:43.042758Z","iopub.execute_input":"2024-04-15T09:59:43.043116Z","iopub.status.idle":"2024-04-15T09:59:43.060891Z","shell.execute_reply.started":"2024-04-15T09:59:43.043087Z","shell.execute_reply":"2024-04-15T09:59:43.060174Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\n\n# Display the image\nplt.imshow(training_cnn_data_selected[1])\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:59:45.006677Z","iopub.execute_input":"2024-04-15T09:59:45.007370Z","iopub.status.idle":"2024-04-15T09:59:45.191810Z","shell.execute_reply.started":"2024-04-15T09:59:45.007322Z","shell.execute_reply":"2024-04-15T09:59:45.190959Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"<matplotlib.image.AxesImage at 0x794b4d9b4f10>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Sample testing_labels array\ntesting_labels = np.array(testing_labels)\n\n# Define a mapping dictionary to map original labels to new labels (0 to 20)\nlabel_mapping = {}\nnew_label = 0\nfor label in sorted(np.unique(testing_labels)):\n    label_mapping[label] = new_label\n    new_label += 1\n\n# Convert the testing_labels array using the mapping dictionary\nconverted_labels_testing = np.array([label_mapping[label] for label in testing_labels])\n\n# Print the converted labels\nprint(converted_labels_testing)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T10:00:18.853112Z","iopub.execute_input":"2024-04-15T10:00:18.853490Z","iopub.status.idle":"2024-04-15T10:00:18.861383Z","shell.execute_reply.started":"2024-04-15T10:00:18.853457Z","shell.execute_reply":"2024-04-15T10:00:18.860490Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"[ 3 11  2 ... 10  2  6]\n","output_type":"stream"}]},{"cell_type":"code","source":"testing_labels[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:59:59.761556Z","iopub.execute_input":"2024-04-15T09:59:59.762392Z","iopub.status.idle":"2024-04-15T09:59:59.768263Z","shell.execute_reply.started":"2024-04-15T09:59:59.762360Z","shell.execute_reply":"2024-04-15T09:59:59.767401Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"array([ 8, 61,  5, 84, 52, 92, 88, 76, 88, 88])"},"metadata":{}}]},{"cell_type":"code","source":"converted_labels_testing[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T10:00:31.073767Z","iopub.execute_input":"2024-04-15T10:00:31.074655Z","iopub.status.idle":"2024-04-15T10:00:31.080447Z","shell.execute_reply.started":"2024-04-15T10:00:31.074622Z","shell.execute_reply":"2024-04-15T10:00:31.079409Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"array([ 3, 11,  2, 15, 10, 19, 16, 13, 16, 16])"},"metadata":{}}]},{"cell_type":"code","source":"testing_labels.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:43:15.010893Z","iopub.execute_input":"2024-04-15T09:43:15.011607Z","iopub.status.idle":"2024-04-15T09:43:15.672230Z","shell.execute_reply.started":"2024-04-15T09:43:15.011579Z","shell.execute_reply":"2024-04-15T09:43:15.670847Z"},"trusted":true},"execution_count":22,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtesting_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"],"ename":"AttributeError","evalue":"'list' object has no attribute 'shape'","output_type":"error"}]},{"cell_type":"code","source":"training_labels[1]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:43:15.673079Z","iopub.status.idle":"2024-04-15T09:43:15.673415Z","shell.execute_reply.started":"2024-04-15T09:43:15.673253Z","shell.execute_reply":"2024-04-15T09:43:15.673266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_lstm_data_selected[1]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:43:18.741466Z","iopub.execute_input":"2024-04-15T09:43:18.741850Z","iopub.status.idle":"2024-04-15T09:43:18.748665Z","shell.execute_reply.started":"2024-04-15T09:43:18.741821Z","shell.execute_reply":"2024-04-15T09:43:18.747654Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"9515    A table with a typewriter and papers.\nName: caption, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"## CNN ","metadata":{}},{"cell_type":"code","source":"# Convert labels to one-hot encoding\ntraining_labels=np.array(training_labels)\ntesting_labels=np.array(testing_labels)\ntraining_labels = tf.keras.utils.to_categorical(training_labels, 20)\ntesting_labels = tf.keras.utils.to_categorical(testing_labels, 20)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:43:36.753959Z","iopub.execute_input":"2024-04-15T09:43:36.755024Z","iopub.status.idle":"2024-04-15T09:43:36.831974Z","shell.execute_reply.started":"2024-04-15T09:43:36.754984Z","shell.execute_reply":"2024-04-15T09:43:36.830713Z"},"trusted":true},"execution_count":24,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m training_labels\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(training_labels)\n\u001b[1;32m      3\u001b[0m testing_labels\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(testing_labels)\n\u001b[0;32m----> 4\u001b[0m training_labels \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m testing_labels \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(testing_labels, \u001b[38;5;241m20\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/np_utils.py:74\u001b[0m, in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     72\u001b[0m n \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     73\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n, num_classes), dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m---> 74\u001b[0m \u001b[43mcategorical\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     75\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m input_shape \u001b[38;5;241m+\u001b[39m (num_classes,)\n\u001b[1;32m     76\u001b[0m categorical \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(categorical, output_shape)\n","\u001b[0;31mIndexError\u001b[0m: index 84 is out of bounds for axis 1 with size 20"],"ename":"IndexError","evalue":"index 84 is out of bounds for axis 1 with size 20","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:29:56.832008Z","iopub.execute_input":"2024-04-15T09:29:56.832926Z","iopub.status.idle":"2024-04-15T09:29:56.838418Z","shell.execute_reply.started":"2024-04-15T09:29:56.832893Z","shell.execute_reply":"2024-04-15T09:29:56.837282Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"training_cnn_data_selected=np.array(training_cnn_data_selected)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:29:57.116018Z","iopub.execute_input":"2024-04-15T09:29:57.116393Z","iopub.status.idle":"2024-04-15T09:29:57.200623Z","shell.execute_reply.started":"2024-04-15T09:29:57.116364Z","shell.execute_reply":"2024-04-15T09:29:57.199830Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"testing_cnn_data_selected=np.array(testing_cnn_data_selected)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:29:57.317971Z","iopub.execute_input":"2024-04-15T09:29:57.318713Z","iopub.status.idle":"2024-04-15T09:29:57.342207Z","shell.execute_reply.started":"2024-04-15T09:29:57.318686Z","shell.execute_reply":"2024-04-15T09:29:57.341241Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"cnn_predictions = cnn_model.predict(testing_cnn_data_selected)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:18:51.683719Z","iopub.execute_input":"2024-04-15T09:18:51.684412Z","iopub.status.idle":"2024-04-15T09:18:52.358301Z","shell.execute_reply.started":"2024-04-15T09:18:51.684384Z","shell.execute_reply":"2024-04-15T09:18:52.357508Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"63/63 [==============================] - 1s 7ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#cnn_predictions","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:18:53.130820Z","iopub.execute_input":"2024-04-15T09:18:53.131855Z","iopub.status.idle":"2024-04-15T09:18:53.135886Z","shell.execute_reply.started":"2024-04-15T09:18:53.131825Z","shell.execute_reply":"2024-04-15T09:18:53.134805Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"training_cnn_data_selected.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:24:37.464155Z","iopub.execute_input":"2024-04-15T09:24:37.464503Z","iopub.status.idle":"2024-04-15T09:24:37.800149Z","shell.execute_reply.started":"2024-04-15T09:24:37.464475Z","shell.execute_reply":"2024-04-15T09:24:37.798804Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtraining_cnn_data_selected\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n","\u001b[0;31mNameError\u001b[0m: name 'training_cnn_data_selected' is not defined"],"ename":"NameError","evalue":"name 'training_cnn_data_selected' is not defined","output_type":"error"}]},{"cell_type":"code","source":"training_cnn_data_selected.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:19:24.171846Z","iopub.execute_input":"2024-04-15T09:19:24.172727Z","iopub.status.idle":"2024-04-15T09:19:24.178748Z","shell.execute_reply.started":"2024-04-15T09:19:24.172694Z","shell.execute_reply":"2024-04-15T09:19:24.177533Z"},"trusted":true},"execution_count":97,"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"(9984, 32, 32, 3)"},"metadata":{}}]},{"cell_type":"code","source":"cnn_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = cnn_model.fit(training_cnn_data_selected,\n                            training_labels,\n                            batch_size=32,\n                            epochs=30,\n                            validation_data=(testing_cnn_data_selected,testing_labels),\n                            shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:18:54.786248Z","iopub.execute_input":"2024-04-15T09:18:54.786576Z","iopub.status.idle":"2024-04-15T09:18:55.352941Z","shell.execute_reply.started":"2024-04-15T09:18:54.786551Z","shell.execute_reply":"2024-04-15T09:18:55.351652Z"},"trusted":true},"execution_count":95,"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[95], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m cnn_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_cnn_data_selected\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtraining_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtesting_cnn_data_selected\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtesting_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/tmp/__autograph_generated_filegzq7hb57.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 1) and (32, 20) are incompatible\n"],"ename":"ValueError","evalue":"in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (32, 1) and (32, 20) are incompatible\n","output_type":"error"}]},{"cell_type":"code","source":"predicted_labels = np.argmax(cnn_predictions, axis=1)\n\n# Calculate accuracy\ncnn_accuracy = np.mean(predicted_labels == testing_labels)\nprint(\"CNN Model Accuracy:\", cnn_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T09:19:01.484788Z","iopub.execute_input":"2024-04-15T09:19:01.485460Z","iopub.status.idle":"2024-04-15T09:19:01.490962Z","shell.execute_reply.started":"2024-04-15T09:19:01.485427Z","shell.execute_reply":"2024-04-15T09:19:01.489985Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"CNN Model Accuracy: 0.053\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.DataFrame({'caption': training_lstm_data_selected, 'class': training_labels})","metadata":{"execution":{"iopub.status.busy":"2024-04-15T08:50:04.585195Z","iopub.execute_input":"2024-04-15T08:50:04.585561Z","iopub.status.idle":"2024-04-15T08:50:04.728300Z","shell.execute_reply.started":"2024-04-15T08:50:04.585534Z","shell.execute_reply":"2024-04-15T08:50:04.727503Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"df[20:30]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T08:50:05.937056Z","iopub.execute_input":"2024-04-15T08:50:05.937430Z","iopub.status.idle":"2024-04-15T08:50:05.952585Z","shell.execute_reply.started":"2024-04-15T08:50:05.937401Z","shell.execute_reply":"2024-04-15T08:50:05.951670Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"                                              caption  class\n20  6064    A sturdy table with a chessboard set f...     52\n21  6994    A ceramic bowl of pho with noodles and...     61\n22  4500    The horizon meets the sky in a seamles...     23\n23  3929    A group of cows enjoys a lazy afternoo...     19\n24  9990    The majestic tiger with a sense of cal...     88\n25  10836    A fish with long fins gracefully swim...     91\n26  6113    A tree with orange leaves glowing in t...     52\n27  3983    A contented cow nuzzles affectionately...     19\n28  1553    Soft music played softly in the backgr...      5\n29  7592    A picture of a rabbit with a fluffy ta...     65","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>caption</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20</th>\n      <td>6064    A sturdy table with a chessboard set f...</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>6994    A ceramic bowl of pho with noodles and...</td>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>4500    The horizon meets the sky in a seamles...</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>3929    A group of cows enjoys a lazy afternoo...</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>9990    The majestic tiger with a sense of cal...</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>10836    A fish with long fins gracefully swim...</td>\n      <td>91</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>6113    A tree with orange leaves glowing in t...</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>3983    A contented cow nuzzles affectionately...</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>1553    Soft music played softly in the backgr...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>7592    A picture of a rabbit with a fluffy ta...</td>\n      <td>65</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\nfrom gensim.models import Word2Vec\n\ndef tokenize_text(text_data):\n    tokenizer = Tokenizer()\n    tokenizer.fit_on_texts(text_data)\n    return tokenizer\n\ndef train_word2vec(text_data, embedding_dim):\n    tokenized_text = [text.split() for text in text_data]\n    model = Word2Vec(sentences=tokenized_text, vector_size=embedding_dim, window=5, min_count=1, workers=4)\n    return model\n\ndef convert_text_to_vectors(text_data, word2vec_model, max_length):\n    vectors = []\n    for text in text_data:\n        words = text.split()\n        vec = []\n        for word in words:\n            if word in word2vec_model.wv:\n                vec.append(word2vec_model.wv[word])\n            else:\n                vec.append(np.zeros(word2vec_model.vector_size))  # Zero vector for out-of-vocabulary words\n        vectors.append(vec)\n    padded_vectors = pad_sequences(vectors, maxlen=max_length, padding='post')\n    return padded_vectors","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:45:51.554668Z","iopub.execute_input":"2024-03-21T14:45:51.555377Z","iopub.status.idle":"2024-03-21T14:45:51.564140Z","shell.execute_reply.started":"2024-03-21T14:45:51.555344Z","shell.execute_reply":"2024-03-21T14:45:51.563189Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"max_words=10000\nembedding_dim=100\n\ntokenizer = tokenize_text(df['caption'].values)\nword2vec_model = train_word2vec(df['caption'].values, embedding_dim)\n\nmax_length = max(len(text.split()) for text in df['caption'].values)\n\n#x_vec = convert_text_to_vectors(df['caption'].values, word2vec_model, max_length)\n#class_mapping = {f'class_{i}': i for i in range(num_classes)}\n#df['class'] = df['class']\n\n#y = df['class'].values","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:45:53.634713Z","iopub.execute_input":"2024-03-21T14:45:53.635115Z","iopub.status.idle":"2024-03-21T14:45:54.714155Z","shell.execute_reply.started":"2024-03-21T14:45:53.635071Z","shell.execute_reply":"2024-03-21T14:45:54.713342Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"x_vec_train = convert_text_to_vectors(training_lstm_data_selected, word2vec_model, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:45:56.694645Z","iopub.execute_input":"2024-03-21T14:45:56.694998Z","iopub.status.idle":"2024-03-21T14:45:57.569712Z","shell.execute_reply.started":"2024-03-21T14:45:56.694972Z","shell.execute_reply":"2024-03-21T14:45:57.568922Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"x_vec_test = convert_text_to_vectors(testing_lstm_data_selected, word2vec_model, max_length)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:45:58.937648Z","iopub.execute_input":"2024-03-21T14:45:58.938380Z","iopub.status.idle":"2024-03-21T14:45:59.747078Z","shell.execute_reply.started":"2024-03-21T14:45:58.938347Z","shell.execute_reply":"2024-03-21T14:45:59.745983Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"training_lstm_data_selected[2]","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:00.655214Z","iopub.execute_input":"2024-03-21T14:46:00.655699Z","iopub.status.idle":"2024-03-21T14:46:00.661467Z","shell.execute_reply.started":"2024-03-21T14:46:00.655669Z","shell.execute_reply":"2024-03-21T14:46:00.660568Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"'a small white airplane is on the runway'"},"metadata":{}}]},{"cell_type":"code","source":"training_lstm_data_selected[0:2]","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:01.634690Z","iopub.execute_input":"2024-03-21T14:46:01.635351Z","iopub.status.idle":"2024-03-21T14:46:01.641625Z","shell.execute_reply.started":"2024-03-21T14:46:01.635320Z","shell.execute_reply":"2024-03-21T14:46:01.640656Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"['an airplane flying in the sky over a lake',\n 'a boat on a body of water near a body of water']"},"metadata":{}}]},{"cell_type":"code","source":"x_vec_train=np.array(x_vec_train)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:02.779645Z","iopub.execute_input":"2024-03-21T14:46:02.780243Z","iopub.status.idle":"2024-03-21T14:46:02.842674Z","shell.execute_reply.started":"2024-03-21T14:46:02.780213Z","shell.execute_reply":"2024-03-21T14:46:02.841907Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"x_vec_test=np.array(x_vec_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:04.294656Z","iopub.execute_input":"2024-03-21T14:46:04.295536Z","iopub.status.idle":"2024-03-21T14:46:04.354746Z","shell.execute_reply.started":"2024-03-21T14:46:04.295502Z","shell.execute_reply":"2024-03-21T14:46:04.353720Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"training_labels=np.array(training_labels)\ntesting_labels=np.array(testing_labels)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:08.669662Z","iopub.execute_input":"2024-03-21T14:46:08.670319Z","iopub.status.idle":"2024-03-21T14:46:08.678447Z","shell.execute_reply.started":"2024-03-21T14:46:08.670289Z","shell.execute_reply":"2024-03-21T14:46:08.677539Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"lstm_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:10.154689Z","iopub.execute_input":"2024-03-21T14:46:10.155404Z","iopub.status.idle":"2024-03-21T14:46:10.173613Z","shell.execute_reply.started":"2024-03-21T14:46:10.155371Z","shell.execute_reply":"2024-03-21T14:46:10.172836Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"history = lstm_model.fit(x_vec_train,\n                                training_labels,\n                                batch_size=32,\n                                epochs=1,\n                                validation_data=(x_vec_test,testing_labels),\n                                shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:11.554663Z","iopub.execute_input":"2024-03-21T14:46:11.555032Z","iopub.status.idle":"2024-03-21T14:46:22.387004Z","shell.execute_reply.started":"2024-03-21T14:46:11.555006Z","shell.execute_reply":"2024-03-21T14:46:22.386078Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1711032375.258822      99 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"661/661 [==============================] - 11s 10ms/step - loss: 0.6423 - accuracy: 0.8032 - val_loss: 0.5087 - val_accuracy: 0.8399\n","output_type":"stream"}]},{"cell_type":"code","source":"lstm_predictions = lstm_model.predict(x_vec_test)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:27.194786Z","iopub.execute_input":"2024-03-21T14:46:27.195200Z","iopub.status.idle":"2024-03-21T14:46:29.654855Z","shell.execute_reply.started":"2024-03-21T14:46:27.195172Z","shell.execute_reply":"2024-03-21T14:46:29.654016Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"625/625 [==============================] - 2s 3ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"predicted_labels = np.argmax(lstm_predictions, axis=1)\n\n# Calculate accuracy\nlstm_accuracy = np.mean(predicted_labels == testing_labels)\nprint(\"LSTM Model Accuracy:\", lstm_accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:30.654923Z","iopub.execute_input":"2024-03-21T14:46:30.655259Z","iopub.status.idle":"2024-03-21T14:46:30.661512Z","shell.execute_reply.started":"2024-03-21T14:46:30.655234Z","shell.execute_reply":"2024-03-21T14:46:30.660534Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"LSTM Model Accuracy: 0.8399\n","output_type":"stream"}]},{"cell_type":"code","source":"len(cnn_predictions)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:32.424701Z","iopub.execute_input":"2024-03-21T14:46:32.425095Z","iopub.status.idle":"2024-03-21T14:46:32.431215Z","shell.execute_reply.started":"2024-03-21T14:46:32.425061Z","shell.execute_reply":"2024-03-21T14:46:32.430314Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"20000"},"metadata":{}}]},{"cell_type":"code","source":"len(lstm_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:33.295312Z","iopub.execute_input":"2024-03-21T14:46:33.295675Z","iopub.status.idle":"2024-03-21T14:46:33.301948Z","shell.execute_reply.started":"2024-03-21T14:46:33.295647Z","shell.execute_reply":"2024-03-21T14:46:33.300887Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"20000"},"metadata":{}}]},{"cell_type":"markdown","source":"## LSTM is working and acc is 86.6%","metadata":{}},{"cell_type":"code","source":"# Step 5: Late Fusion Ensemble\nensemble_predictions = np.argmax(np.sum([cnn_predictions, lstm_predictions], axis=0), axis=1)\n\n# Step 6: Compare Predictions with Original Classes\naccuracy = np.mean(ensemble_predictions == testing_labels)\nprint(\"Ensemble Model Accuracy:\", accuracy)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:35.515217Z","iopub.execute_input":"2024-03-21T14:46:35.515937Z","iopub.status.idle":"2024-03-21T14:46:35.523656Z","shell.execute_reply.started":"2024-03-21T14:46:35.515905Z","shell.execute_reply":"2024-03-21T14:46:35.522651Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"Ensemble Model Accuracy: 0.97905\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## AUTOMATE ENSEMBLE","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow as tf\n\n# Define the folder path\nfolder_path = '/kaggle/input/cnn-models/cnn'\n\n# Get a list of all files in the folder\nfile_list = os.listdir(folder_path)\n\n# Filter out only the .h5 files\nmodel_files = [file for file in file_list if file.endswith('.h5')]\n\n# Load each model\ncnn_models = []\nfor model_file in model_files[0:4]:\n    model_path = os.path.join(folder_path, model_file)\n    cnn_model = tf.keras.models.load_model(model_path)\n    cnn_models.append(cnn_model)\n\n# Now cnn_models list contains all the loaded CNN models\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:46:50.075341Z","iopub.execute_input":"2024-03-21T14:46:50.075701Z","iopub.status.idle":"2024-03-21T14:46:52.857385Z","shell.execute_reply.started":"2024-03-21T14:46:50.075672Z","shell.execute_reply":"2024-03-21T14:46:52.856344Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# Train each model and track validation accuracy\nvalidation_accuracies = []\nfor lstm_model in top_lstm_models:\n    history = lstm_model.fit(x_vec_train,\n                             training_labels,\n                             batch_size=32,\n                             epochs=1,\n                             validation_data=(x_vec_test, testing_labels),\n                             shuffle=True)\n    \n    # Get the validation accuracy from the history\n    validation_accuracy = history.history['val_accuracy'][-1]\n    validation_accuracies.append(validation_accuracy)\n\n# Sort the models based on validation accuracy\nsorted_indices = sorted(range(len(validation_accuracies)), key=lambda i: validation_accuracies[i], reverse=True)\ntop_lstm_models = [lstm_models[i] for i in sorted_indices[:4]]  # Select the top 4 models\n\n# Train the top 4 LSTM models\nhistories = []\nfor lstm_model in top_lstm_models:\n    lstm_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    history = lstm_model.fit(x_vec_train,\n                             training_labels,\n                             batch_size=32,\n                             epochs=1,\n                             validation_data=(x_vec_test, testing_labels),\n                             shuffle=True)\n    histories.append(history)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:47:18.511846Z","iopub.execute_input":"2024-03-21T14:47:18.512756Z","iopub.status.idle":"2024-03-21T14:47:18.560206Z","shell.execute_reply.started":"2024-03-21T14:47:18.512723Z","shell.execute_reply":"2024-03-21T14:47:18.559035Z"},"trusted":true},"execution_count":53,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[53], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train each model and track validation accuracy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m validation_accuracies \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lstm_model \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtop_lstm_models\u001b[49m:\n\u001b[1;32m      4\u001b[0m     history \u001b[38;5;241m=\u001b[39m lstm_model\u001b[38;5;241m.\u001b[39mfit(x_vec_train,\n\u001b[1;32m      5\u001b[0m                              training_labels,\n\u001b[1;32m      6\u001b[0m                              batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m      7\u001b[0m                              epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      8\u001b[0m                              validation_data\u001b[38;5;241m=\u001b[39m(x_vec_test, testing_labels),\n\u001b[1;32m      9\u001b[0m                              shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Get the validation accuracy from the history\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'top_lstm_models' is not defined"],"ename":"NameError","evalue":"name 'top_lstm_models' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"# Load the LSTM and CNN models\nlstm_model = tf.keras.models.load_model('/kaggle/input/lstm-parent-model-final/parent_0_model (1).h5')\ncnn_model = tf.keras.models.load_model('/kaggle/input/cnn-model-16layers/cnn_model_.h5')","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n# Assuming you have lists of predictions from the top LSTM and CNN models\ncnn_predictions = [model.predict(testing_cnn_data_selected) for model in cnn_models]\nlstm_predictions = [model.predict(x_vec_test) for model in top_lstm_models]\n\n# Combine predictions using majority voting\n\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:53:03.403505Z","iopub.execute_input":"2024-03-19T10:53:03.403861Z","iopub.status.idle":"2024-03-19T10:53:22.292528Z","shell.execute_reply.started":"2024-03-19T10:53:03.403834Z","shell.execute_reply":"2024-03-19T10:53:22.291675Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"625/625 [==============================] - 2s 2ms/step\n625/625 [==============================] - 2s 3ms/step\n625/625 [==============================] - 2s 3ms/step\n625/625 [==============================] - 2s 2ms/step\n625/625 [==============================] - 2s 3ms/step\n625/625 [==============================] - 1s 2ms/step\n625/625 [==============================] - 2s 3ms/step\n625/625 [==============================] - 2s 3ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Combine predictions using majority voting\ndef majority_voting(predictions):\n    combined_predictions = []\n    for sample_predictions in zip(*predictions):\n        sample_predictions_list = [tuple(prediction) for prediction in sample_predictions]\n        votes = Counter(sample_predictions_list)\n        majority_vote = votes.most_common(1)[0][0]\n        combined_predictions.append(majority_vote)\n    return combined_predictions\n\n\n\n\n# Combine LSTM and CNN predictions using majority voting\nensemble_predictions = majority_voting(lstm_predictions + cnn_predictions)\nensemble_classes = [prediction.index(max(prediction)) for prediction in ensemble_predictions]\n\n\npredicted_labels = np.argmax(lstm_predictions, axis=1)\n\n# Calculate accuracy\n#lstm_accuracy = np.mean(ensemble_predictions == testing_labels)\n#print(\"Ensemble Accuracy:\", lstm_accuracy)\n\n\n# Evaluate ensemble performance\nensemble_accuracy = accuracy_score(testing_labels, ensemble_classes)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:44:35.398346Z","iopub.execute_input":"2024-03-19T10:44:35.398744Z","iopub.status.idle":"2024-03-19T10:44:36.075712Z","shell.execute_reply.started":"2024-03-19T10:44:35.398715Z","shell.execute_reply":"2024-03-19T10:44:36.074856Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"np.shape(lstm_predictions)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:55:15.363127Z","iopub.execute_input":"2024-03-19T10:55:15.363509Z","iopub.status.idle":"2024-03-19T10:55:15.370482Z","shell.execute_reply.started":"2024-03-19T10:55:15.363479Z","shell.execute_reply":"2024-03-19T10:55:15.369543Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"(4, 20000, 10)"},"metadata":{}}]},{"cell_type":"code","source":"np.shape(cnn_predictions)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:55:16.122988Z","iopub.execute_input":"2024-03-19T10:55:16.123352Z","iopub.status.idle":"2024-03-19T10:55:16.130424Z","shell.execute_reply.started":"2024-03-19T10:55:16.123323Z","shell.execute_reply":"2024-03-19T10:55:16.129477Z"},"trusted":true},"execution_count":94,"outputs":[{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"(4, 20000, 10)"},"metadata":{}}]},{"cell_type":"code","source":"lstm_predictions","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:52:10.078728Z","iopub.execute_input":"2024-03-19T10:52:10.079125Z","iopub.status.idle":"2024-03-19T10:52:10.090250Z","shell.execute_reply.started":"2024-03-19T10:52:10.079096Z","shell.execute_reply":"2024-03-19T10:52:10.089236Z"},"trusted":true},"execution_count":86,"outputs":[{"execution_count":86,"output_type":"execute_result","data":{"text/plain":"[array([[1.0500182e-03, 7.2756712e-04, 8.6743692e-03, ..., 8.6253573e-04,\n         9.2142809e-04, 4.2994064e-04],\n        [3.1158917e-03, 1.0107377e-03, 5.3432882e-02, ..., 7.1005482e-04,\n         5.8939250e-04, 1.4139507e-03],\n        [6.4739637e-04, 4.4340538e-04, 1.1935643e-02, ..., 7.2597633e-03,\n         1.0047819e-03, 4.8198443e-04],\n        ...,\n        [7.5126131e-04, 2.3625196e-06, 9.7748739e-01, ..., 2.0774940e-05,\n         3.1036954e-05, 1.8191137e-06],\n        [9.3507930e-04, 8.5378176e-04, 6.8063508e-03, ..., 5.3317463e-03,\n         2.0499097e-03, 6.2001089e-04],\n        [9.9611855e-01, 8.6920452e-05, 4.3790817e-04, ..., 2.4751404e-05,\n         3.0618270e-03, 1.7060041e-04]], dtype=float32),\n array([[3.0478116e-04, 1.0509848e-04, 4.1723601e-03, ..., 5.8498152e-04,\n         4.6291953e-04, 3.8858803e-04],\n        [5.9350987e-04, 3.2037722e-05, 1.5119795e-02, ..., 2.2296028e-04,\n         9.6188676e-05, 4.9061880e-05],\n        [1.3632166e-04, 2.7375478e-05, 8.1506604e-04, ..., 4.9501710e-04,\n         8.0346908e-05, 6.8247697e-05],\n        ...,\n        [3.8410290e-04, 1.0143484e-05, 9.4791490e-01, ..., 1.9361218e-05,\n         1.0042376e-04, 1.4814128e-05],\n        [8.5703185e-05, 2.2064032e-05, 4.7322325e-04, ..., 2.8895159e-04,\n         6.1603067e-05, 6.0138806e-05],\n        [9.9750000e-01, 8.4706458e-05, 2.6658378e-04, ..., 3.7236932e-05,\n         1.9348504e-03, 4.0522664e-05]], dtype=float32),\n array([[5.9363199e-04, 4.8477470e-04, 4.5208782e-03, ..., 7.2925078e-04,\n         5.5642438e-04, 2.1198721e-04],\n        [1.3324335e-02, 2.2744443e-03, 5.2219793e-02, ..., 2.0095736e-03,\n         3.4958858e-03, 4.9093361e-03],\n        [1.4435416e-04, 1.2176770e-04, 1.9411300e-03, ..., 8.7442622e-04,\n         1.8399478e-04, 1.1567236e-04],\n        ...,\n        [8.3378085e-04, 5.4877000e-06, 9.4318479e-01, ..., 4.4401335e-05,\n         5.6842619e-05, 1.1361176e-05],\n        [8.1495680e-05, 6.5996333e-05, 1.1686066e-03, ..., 3.9235616e-04,\n         1.1746766e-04, 7.4033444e-05],\n        [9.9720418e-01, 7.9801590e-05, 4.5199296e-04, ..., 5.3695734e-05,\n         1.9097989e-03, 1.3423596e-04]], dtype=float32),\n array([[1.70434840e-04, 4.58778493e-04, 3.75381229e-03, ...,\n         4.98174108e-04, 1.41751239e-04, 1.53335990e-04],\n        [1.23405475e-02, 1.71942718e-03, 8.48021656e-02, ...,\n         3.23132589e-03, 1.07977074e-03, 2.54741358e-03],\n        [4.75367578e-03, 3.23833572e-03, 5.69487968e-03, ...,\n         1.37465941e-02, 5.94183430e-03, 2.25814991e-03],\n        ...,\n        [4.88288992e-04, 3.99795608e-05, 8.90399992e-01, ...,\n         1.97573798e-04, 1.16417359e-04, 6.99735247e-05],\n        [6.42580166e-03, 2.44049169e-03, 4.54501100e-02, ...,\n         8.46842024e-03, 2.12879176e-03, 1.74324505e-03],\n        [9.98565495e-01, 2.84965063e-05, 2.20813265e-04, ...,\n         4.12282752e-05, 9.78776719e-04, 2.98999330e-05]], dtype=float32)]"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Convert lists to NumPy arrays\nlstm_predictions_array = np.array(lstm_predictions)\ncnn_predictions_array = np.array(cnn_predictions)\n\n# Reshape LSTM and CNN predictions to (num_samples, sequence_length * num_classes)\nlstm_predictions_reshaped = lstm_predictions_array.reshape(lstm_predictions_array.shape[0], -1)\ncnn_predictions_reshaped = cnn_predictions_array.reshape(cnn_predictions_array.shape[0], -1)\n\n# Concatenate reshaped predictions\nx_train = np.concatenate((lstm_predictions_reshaped, cnn_predictions_reshaped), axis=1)\n\n# Assuming y_train contains ground truth labels with shape (num_samples,)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:59:20.963469Z","iopub.execute_input":"2024-03-19T10:59:20.964317Z","iopub.status.idle":"2024-03-19T10:59:20.972996Z","shell.execute_reply.started":"2024-03-19T10:59:20.964275Z","shell.execute_reply":"2024-03-19T10:59:20.972063Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"lstm_predictions[0][0]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:24:14.712708Z","iopub.execute_input":"2024-03-19T11:24:14.713061Z","iopub.status.idle":"2024-03-19T11:24:14.720141Z","shell.execute_reply.started":"2024-03-19T11:24:14.713036Z","shell.execute_reply":"2024-03-19T11:24:14.718906Z"},"trusted":true},"execution_count":110,"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"array([1.0500182e-03, 7.2756712e-04, 8.6743692e-03, 8.9050055e-01,\n       7.0836400e-03, 4.9098939e-02, 4.0651046e-02, 8.6253573e-04,\n       9.2142809e-04, 4.2994064e-04], dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"lstm_pred = ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\n# Prepare Data\n# Assuming lstm_predictions, cnn_predictions, and correct_outputs contain the predictions and correct outputs\n# Concatenate LSTM and CNN predictions\nx_train = np.concatenate((lstm_predictions[0], cnn_predictions[0]), axis=1)\n\n# Calculate Weightage Distribution\n# For example, calculate the weightage based on accuracy\nlstm_accuracy = accuracy_score(lstm_predictions[0], testing_labels)\ncnn_accuracy = accuracy_score(cnn_predictions[0], testing_labels)\ntotal_accuracy = lstm_accuracy + cnn_accuracy\nlstm_weight = lstm_accuracy / total_accuracy\ncnn_weight = cnn_accuracy / total_accuracy\n\n# Prepare Target Weightage Distribution\ntarget_weightage = np.concatenate((lstm_weight, cnn_weight), axis=1)\n\n# Define Fusion Network Architecture\nfusion_network = tf.keras.Sequential([\n    tf.keras.layers.Dense(64, activation='relu', input_shape=(num_features,)),\n    tf.keras.layers.Dense(32, activation='relu'),\n    tf.keras.layers.Dense(num_modalities, activation='softmax')  # Output layer for weightage distribution\n])\n\n# Compile Fusion Network\nfusion_network.compile(optimizer='adam', loss='categorical_crossentropy')\n\n# Train Fusion Network\nfusion_network.fit(x_train, target_weightage, epochs=10, batch_size=32, validation_split=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T11:23:48.952093Z","iopub.execute_input":"2024-03-19T11:23:48.952500Z","iopub.status.idle":"2024-03-19T11:23:49.046462Z","shell.execute_reply.started":"2024-03-19T11:23:48.952470Z","shell.execute_reply":"2024-03-19T11:23:49.045125Z"},"trusted":true},"execution_count":108,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[108], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m x_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((lstm_predictions[\u001b[38;5;241m0\u001b[39m], cnn_predictions[\u001b[38;5;241m0\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Calculate Weightage Distribution\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# For example, calculate the weightage based on accuracy\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m lstm_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_predictions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesting_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m cnn_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(cnn_predictions[\u001b[38;5;241m0\u001b[39m], testing_labels)\n\u001b[1;32m     13\u001b[0m total_accuracy \u001b[38;5;241m=\u001b[39m lstm_accuracy \u001b[38;5;241m+\u001b[39m cnn_accuracy\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[1;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    202\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     97\u001b[0m             type_true, type_pred\n\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    102\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n","\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous-multioutput and multiclass targets"],"ename":"ValueError","evalue":"Classification metrics can't handle a mix of continuous-multioutput and multiclass targets","output_type":"error"}]},{"cell_type":"code","source":"ensemble_classes = [prediction.index(max(prediction)) for prediction in ensemble_predictions]\n","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:35:02.178910Z","iopub.execute_input":"2024-03-19T10:35:02.179276Z","iopub.status.idle":"2024-03-19T10:35:02.204524Z","shell.execute_reply.started":"2024-03-19T10:35:02.179247Z","shell.execute_reply":"2024-03-19T10:35:02.203587Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"ensemble_classes[0]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T10:35:08.323066Z","iopub.execute_input":"2024-03-19T10:35:08.323779Z","iopub.status.idle":"2024-03-19T10:35:08.329716Z","shell.execute_reply.started":"2024-03-19T10:35:08.323742Z","shell.execute_reply":"2024-03-19T10:35:08.328534Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}]},{"cell_type":"code","source":"# CIFAR-10 class names\ncifar_10_classes = {\n    0: 'airplane',\n    1: 'automobile',\n    2: 'bird',\n    3: 'cat',\n    4: 'deer',\n    5: 'dog',\n    6: 'frog',\n    7: 'horse',\n    8: 'ship',\n    9: 'truck'\n}\n\n# Printing class names for the first 10 elements in image_classes\nprint(\"Class Names:\")\nfor class_index in image_classes[:10]:\n    print(cifar_10_classes[class_index])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T06:28:50.471687Z","iopub.execute_input":"2024-03-08T06:28:50.472061Z","iopub.status.idle":"2024-03-08T06:28:50.478728Z","shell.execute_reply.started":"2024-03-08T06:28:50.472033Z","shell.execute_reply":"2024-03-08T06:28:50.477485Z"},"trusted":true},"execution_count":82,"outputs":[{"name":"stdout","text":"Class Names:\ntruck\ncat\nairplane\nautomobile\nship\nfrog\ntruck\nairplane\ncat\nhorse\n","output_type":"stream"}]},{"cell_type":"code","source":"image_captions[0:10]","metadata":{"execution":{"iopub.status.busy":"2024-03-08T06:25:59.692904Z","iopub.execute_input":"2024-03-08T06:25:59.693621Z","iopub.status.idle":"2024-03-08T06:25:59.700244Z","shell.execute_reply.started":"2024-03-08T06:25:59.693588Z","shell.execute_reply":"2024-03-08T06:25:59.699205Z"},"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"['a tractor with a white background',\n 'a blurry blurry image of a cat',\n 'a small island with a lighthouse in the background',\n 'a blue and red car with a red background',\n 'a boat is in the water with people on it',\n 'a small green frog sitting on top of a wooden block',\n 'a truck driving down a road with trees in the background',\n 'a small plane is parked on the runway',\n 'adopt a dog in the uk',\n 'a white horse standing on a road at night']"},"metadata":{}}]},{"cell_type":"code","source":"image_classes[0:10]\n","metadata":{"execution":{"iopub.status.busy":"2024-03-08T06:26:19.538109Z","iopub.execute_input":"2024-03-08T06:26:19.538621Z","iopub.status.idle":"2024-03-08T06:26:19.546439Z","shell.execute_reply.started":"2024-03-08T06:26:19.538580Z","shell.execute_reply":"2024-03-08T06:26:19.545271Z"},"trusted":true},"execution_count":81,"outputs":[{"execution_count":81,"output_type":"execute_result","data":{"text/plain":"[9, 3, 0, 1, 8, 6, 9, 0, 3, 7]"},"metadata":{}}]},{"cell_type":"code","source":"\n# Define the ensemble function\ndef ensemble(lstm_outputs, cnn_outputs):\n    # Add your ensemble code here\n    return lstm_outputs, cnn_outputs\n\n# Make predictions on the image and text data\nlstm_predictions = []\ncnn_predictions = []\nfor image_batch, text_batch in zip(image_generator, text_generator):\n    lstm_outputs = lstm_model.predict(text_batch)\n    cnn_outputs = cnn_model.predict(image_batch)\n    lstm_predictions.append(lstm_outputs)\n    cnn_predictions.append(cnn_outputs)\nlstm_predictions = np.vstack(lstm_predictions)\ncnn_predictions = np.vstack(cnn_predictions)\n\n# Ensemble the predictions using voting strategy\nensemble_predictions = ensemble(lstm_predictions, cnn_predictions)\n\n# Take the average of the probabilities from both models for each class\nensemble_predictions = (ensemble_predictions[0] + ensemble_predictions[1]) / 2\n\n# Select the class with the highest average probability as the final prediction\nfinal_predictions = np.argmax(ensemble_predictions, axis=1)","metadata":{},"execution_count":null,"outputs":[]}]}