{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b183282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T09:37:43.068441Z",
     "iopub.status.busy": "2024-04-08T09:37:43.068127Z",
     "iopub.status.idle": "2024-04-08T09:37:55.425688Z",
     "shell.execute_reply": "2024-04-08T09:37:55.424896Z"
    },
    "papermill": {
     "duration": 12.366384,
     "end_time": "2024-04-08T09:37:55.428168",
     "exception": false,
     "start_time": "2024-04-08T09:37:43.061784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "### UTILITIES\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def load_images_from_folder(folder_path, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for label, class_folder in enumerate(sorted(os.listdir(folder_path))):\n",
    "        class_path = os.path.join(folder_path, class_folder)\n",
    "        for filename in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, image_size)\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "def load_dataset(batch_size, num_classes, epochs, image_size, data_dir):\n",
    "    x_train, y_train = load_images_from_folder(data_dir, image_size)\n",
    "\n",
    "    # Splitting the data into training and testing sets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Normalize pixel values to be between 0 and 1\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    # Randomly select 500 images for validation\n",
    "    random_indices = np.random.choice(len(x_test), size=2000, replace=False)\n",
    "    x_val = x_test[random_indices]\n",
    "    y_val = y_test[random_indices]\n",
    "\n",
    "    dataset = {\n",
    "        'batch_size': batch_size,\n",
    "        'num_classes': num_classes,\n",
    "        'epochs': epochs,\n",
    "        'x_train': x_train,\n",
    "        'y_train': y_train,\n",
    "        'x_val': x_val,\n",
    "        'y_val': y_val,\n",
    "        'x_test': x_test,  \n",
    "        'y_test': y_test\n",
    "    }\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def save_network(network):\n",
    "    #object_file = open(network.name + '.obj', 'wb')\n",
    "    #pickle.dump(network, object_file)\n",
    "    #tf.keras.models.save_model(network, network.name)\n",
    "\n",
    "    model_path = network.name + '_model.h5'\n",
    "    tf.keras.models.save_model(network.model, model_path)\n",
    "\n",
    "    # Save the rest of the network information\n",
    "    network_info = {\n",
    "        'name': network.name,\n",
    "        'block_list': network.block_list,\n",
    "        'fitness': network.fitness\n",
    "    }\n",
    "    network_info_path = network.name + '_info.pkl'\n",
    "    with open(network_info_path, 'wb') as info_file:\n",
    "        pickle.dump(network_info, info_file)\n",
    "\n",
    "\n",
    "def load_network(name):\n",
    "    model_path = name + '_model.h5'\n",
    "    loaded_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # Load the network information\n",
    "    info_path = name + '_info.pkl'\n",
    "    with open(info_path, 'rb') as info_file:\n",
    "        network_info = pickle.load(info_file)\n",
    "\n",
    "    # Create a new Network instance\n",
    "    loaded_network = Network(0)  # Update with appropriate 'it' value\n",
    "\n",
    "    # Set the attributes of the loaded network\n",
    "    loaded_network.name = network_info['name']\n",
    "    loaded_network.block_list = network_info['block_list']\n",
    "    loaded_network.fitness = network_info['fitness']\n",
    "    loaded_network.model = loaded_model\n",
    "\n",
    "    return loaded_network\n",
    "\n",
    "\n",
    "\n",
    "def order_indexes(self):\n",
    "    i = 0\n",
    "    for block in self.block_list:\n",
    "        block.index = i\n",
    "        i += 1\n",
    "\n",
    "\n",
    "def plot_training(history):                                           # plot diagnostic learning curves\n",
    "    plt.figure(figsize=[8, 6])  # accuracy curves\n",
    "    plt.plot(history.history['accuracy'], 'r', linewidth=3.0)\n",
    "    plt.plot(history.history['val_accuracy'], 'b', linewidth=3.0)  # <-- Change 'val_acc' to 'val_accuracy'\n",
    "    plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n",
    "    plt.xlabel('Epochs ', fontsize=16)\n",
    "    plt.ylabel('Accuracy', fontsize=16)\n",
    "    plt.title('Accuracy Curves', fontsize=16)\n",
    "\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_acc_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def plot_statistics(stats):\n",
    "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# fitness curves\n",
    "    plt.plot([s[0] for s in stats], 'r', linewidth=3.0)\n",
    "    plt.plot([stats[0][0]] * len(stats), 'b', linewidth=3.0)\n",
    "    plt.legend(['BestFitness', 'InitialFitness'], fontsize=18)\n",
    "    plt.xlabel('Generations', fontsize=16)\n",
    "    plt.ylabel('FitnessValue', fontsize=16)\n",
    "    plt.title('Fitness Curve', fontsize=16)\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_fitness_plot.png')\n",
    "\n",
    "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# parameters curves\n",
    "    plt.plot([s[1] for s in stats], 'r', linewidth=3.0)\n",
    "    plt.plot([stats[0][1]] * len(stats), 'b', linewidth=3.0)\n",
    "    plt.legend(['BestParamsNum', 'InitialParamsNum'], fontsize=18)\n",
    "    plt.xlabel('Generations', fontsize=16)\n",
    "    plt.ylabel('ParamsNum', fontsize=16)\n",
    "    plt.title('Parameters Curve', fontsize=16)\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_params_plot.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a7b0ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T09:37:55.438832Z",
     "iopub.status.busy": "2024-04-08T09:37:55.438320Z",
     "iopub.status.idle": "2024-04-08T09:37:55.456106Z",
     "shell.execute_reply": "2024-04-08T09:37:55.455284Z"
    },
    "papermill": {
     "duration": 0.025187,
     "end_time": "2024-04-08T09:37:55.457986",
     "exception": false,
     "start_time": "2024-04-08T09:37:55.432799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INOUT\n",
    "import os\n",
    "def compute_parent(dataset):\n",
    "    if os.path.isfile('parent_0.h5'):\n",
    "        daddy = load_network('parent_0')\n",
    "        model = tf.keras.models.load_model('parent_0.h5')\n",
    "        print(\"Loading parent_0\")\n",
    "        print(\"SUMMARY OF\", daddy.name)\n",
    "        print(model.summary())\n",
    "        print(\"FITNESS:\", daddy.fitness)\n",
    "        return daddy\n",
    "\n",
    "    daddy = Network(0)\n",
    "    \n",
    "    \n",
    "    #INI BLOCK\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=32, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:])\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(0, 0, layerList1, layerList2))\n",
    "    \n",
    "    #MIDDLE BLOCK 1\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(1, 1, layerList1, layerList2))\n",
    "\n",
    "     #MIDDLE BLOCK 2\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:])\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(1, 2, layerList1, layerList2))\n",
    "\n",
    "    \n",
    "    #MIDDLE BLOCK 3\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=256, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "        Convolutional(filters=256, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:])\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(1, 3, layerList1, layerList2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #MIDDLE BLOCK 4\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=512, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "        Convolutional(filters=512, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:])\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(1, 4, layerList1, layerList2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #FULLY CONNECTED LAYER\n",
    "    layerList1 = [\n",
    "        FlattenLayer(),\n",
    "        FullyConnected(units=128, num_classes=dataset['num_classes'])\n",
    "    ]\n",
    "    layerList2 = []\n",
    "    daddy.block_list.append(Block(2, 5, layerList1, layerList2))\n",
    "    \n",
    "    \n",
    "\n",
    "    model = daddy.build_model()\n",
    "    print(\"Type of model_final:\", type(model))\n",
    "    daddy.train_and_evaluate(model, dataset)\n",
    "    return daddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1636865b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T09:37:55.467441Z",
     "iopub.status.busy": "2024-04-08T09:37:55.467162Z",
     "iopub.status.idle": "2024-04-08T09:37:55.519075Z",
     "shell.execute_reply": "2024-04-08T09:37:55.518258Z"
    },
    "papermill": {
     "duration": 0.059018,
     "end_time": "2024-04-08T09:37:55.521070",
     "exception": false,
     "start_time": "2024-04-08T09:37:55.462052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NETWORK\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Sequential\n",
    "from random import randint, choice\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class Network:\n",
    "    __slots__ = ('name', 'block_list', 'fitness', 'model')\n",
    "\n",
    "    def __init__(self, it):\n",
    "        self.name = 'parent_' + str(it) if it == 0 else 'net_' + str(it)\n",
    "        self.block_list = []\n",
    "        self.fitness = None\n",
    "        self.model = None\n",
    "\n",
    "    \"\"\"def build_model(self):\n",
    "        model = Sequential()                                # create model\n",
    "        for block in self.block_list:\n",
    "            for layer in block.get_layers():                # build model\n",
    "                try:\n",
    "                    layer.build_layer(model)\n",
    "                except:\n",
    "                    print(\"\\nINDIVIDUAL ABORTED, CREATING A NEW ONE\\n\")\n",
    "                    return -1\n",
    "        return model\"\"\"\n",
    "    def build_model(self):\n",
    "        model = Sequential()              \n",
    "        print(\"The block is:\")\n",
    "        print(self.block_list)                 # create model\n",
    "        for block in self.block_list:\n",
    "            #print(\"Building block type:\", block.type)\n",
    "            #print(\"TOTAL :::\")\n",
    "            #print(block.get_layer_name())\n",
    "            for layer in block.get_layers():                # build model\n",
    "                #print(\"Adding layer:\", layer.name)\n",
    "                try:\n",
    "                    layer.build_layer(model)\n",
    "                    print(\"Layer added successfully.\")\n",
    "                except Exception as e:\n",
    "                    print(\"Error occurred while adding layer:\", e)\n",
    "                    print(\"Returning None.\")\n",
    "                    return -1\n",
    "        print(\"Model successfully built.\")\n",
    "        return model\n",
    "\n",
    "    def train_and_evaluate(self, model, dataset):\n",
    "        print(\"Training\", self.name)\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        try:\n",
    "            history = model.fit(dataset['x_train'],\n",
    "                                dataset['y_train'],\n",
    "                                batch_size=dataset['batch_size'],\n",
    "                                epochs=dataset['epochs'],\n",
    "                                validation_data=(dataset['x_val'], dataset['y_val']),\n",
    "                                shuffle=True)\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred during model training:\", e)\n",
    "            return -1\n",
    "            # You can choose to handle the error in a specific way here, like logging it or taking corrective actions.\n",
    "\n",
    "\n",
    "        # Extract metrics from the training history\n",
    "        training_loss = history.history['loss'][-1]\n",
    "        training_accuracy = history.history['accuracy'][-1]\n",
    "        validation_loss = history.history['val_loss'][-1]\n",
    "        validation_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "        # Additional metrics (you can customize this based on your needs)\n",
    "        classification_error_rate = 1.0 - validation_accuracy\n",
    "\n",
    "        self.model = model  # Save the model\n",
    "        self.fitness = validation_loss  # Use validation loss as fitness\n",
    "\n",
    "        # Print metrics\n",
    "        print(\"SUMMARY OF\", self.name)\n",
    "        print(\"Training Loss:\", training_loss)\n",
    "        print(\"Training Accuracy:\", training_accuracy)\n",
    "        print(\"Validation Loss:\", validation_loss)\n",
    "        print(\"Validation Accuracy:\", validation_accuracy)\n",
    "        print(\"Classification Error Rate:\", classification_error_rate)\n",
    "\n",
    "        tf.keras.models.save_model(model, self.name + '.h5')         # save model\n",
    "        #model.save(self.name + '.h5')                       # save model\n",
    "        save_network(self)                                  # save topology, model and fitness\n",
    "\n",
    "    def asexual_reproduction(self, it, dataset):\n",
    "\n",
    "        # if the individual already exists, just load it\n",
    "        if os.path.isfile('net_' + str(it) + '.h5'):\n",
    "            print(\"\\n-------------------------------------\")\n",
    "            print(\"Loading individual net_\" + str(it))\n",
    "            print(\"--------------------------------------\\n\")\n",
    "            individual = load_network('net_' + str(it))\n",
    "            model = tf.keras.models.load_model(individual.name + '.h5')\n",
    "            print(\"SUMMARY OF\", individual.name)\n",
    "            print(model.summary())\n",
    "            print(\"FITNESS: \", individual.fitness)\n",
    "            return individual\n",
    "\n",
    "        # otherwise, create the individual by mutating the parent\n",
    "        individual = Network(it)\n",
    "\n",
    "        print(\"\\n-------------------------------------\")\n",
    "        print(\"\\nCreating individual\", individual.name)\n",
    "        print(\"--------------------------------------\\n\")\n",
    "\n",
    "        individual.block_list = deepcopy(self.block_list)           # copy the layer list from parent\n",
    "\n",
    "        print(\"----->Strong Mutation\")\n",
    "        individual.block_mutation(dataset)                          # mutate a block\n",
    "        individual.layer_mutation(dataset)                          # mutate a layer\n",
    "        individual.parameters_mutation()                            # mutate some parameters\n",
    "\n",
    "        model = individual.build_model()\n",
    "        \n",
    "        if model == -1:\n",
    "            return self.asexual_reproduction(it, dataset)\n",
    "        \n",
    "        if(individual.train_and_evaluate(model, dataset)==-1):\n",
    "            return self.asexual_reproduction(it, dataset)\n",
    "        else:\n",
    "            return individual\n",
    "            \n",
    "\n",
    "    def block_mutation(self, dataset):\n",
    "        try:\n",
    "            print(\"Block Mutation\")\n",
    "\n",
    "            print([(block.index, block.type) for block in self.block_list])\n",
    "\n",
    "            # block list containing all the blocks with type = 1\n",
    "            bl = [block.index for block in self.block_list if block.type == 1]\n",
    "\n",
    "            if len(bl) == 0:\n",
    "                print(\"Creating a new block with two Convolutional layers and a Pooling layer\")\n",
    "                self.block_list[1].index = 2\n",
    "                layerList1 = [\n",
    "                    Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                  filter_size=(3, 3),\n",
    "                                  stride_size=(1, 1),\n",
    "                                  padding='same',\n",
    "                                  input_shape=dataset['x_train'].shape[1:]),\n",
    "                    Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                  filter_size=(3, 3),\n",
    "                                  stride_size=(1, 1),\n",
    "                                  padding='same',\n",
    "                                  input_shape=dataset['x_train'].shape[1:])\n",
    "                ]\n",
    "                layerList2 = [\n",
    "                    Pooling(pool_size=(2, 2),\n",
    "                            stride_size=(2, 2),\n",
    "                            padding='same')\n",
    "                ]\n",
    "                b = Block(1, 1, layerList1, layerList2)\n",
    "                self.block_list.insert(1, b)\n",
    "                return\n",
    "\n",
    "            block_idx = randint(1, max(bl))         # pick a random block among all the blocks with type = 1\n",
    "            block_type_idx = randint(0, 1)          # 1 -> Conv2D; 0 -> Pooling or Dropout\n",
    "            mutation_type = randint(0, 1)           # 1 -> remove; 0 -> add\n",
    "\n",
    "            # list of layers of the selected block\n",
    "            layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
    "            length = len(layerList)\n",
    "\n",
    "            if mutation_type:                                       # remove\n",
    "                if length == 1:\n",
    "                    del self.block_list[block_idx]\n",
    "                elif block_type_idx:\n",
    "                    pos = randint(0, length - 1)\n",
    "                    print(\"Removing a Conv2D layer at\", pos)\n",
    "                    del layerList[pos]\n",
    "                else:\n",
    "                    pos = randint(0, length - 1)\n",
    "                    print(\"Removing a Pooling/Dropout layer at\", pos)\n",
    "                    del layerList[pos]\n",
    "            else:                                                   # add\n",
    "                if block_type_idx:\n",
    "                    print(\"Inserting a Convolutional layer\")\n",
    "                    layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                          filter_size=(3, 3),\n",
    "                                          stride_size=(1, 1),\n",
    "                                          padding='same',\n",
    "                                          input_shape=dataset['x_train'].shape[1:])\n",
    "                    layerList.insert(randint(0, length - 1), layer)\n",
    "                else:\n",
    "                    if randint(0, 1):                               # 1 -> Pooling; 0 -> Dropout\n",
    "                        print(\"Inserting a Pooling layer\")\n",
    "                        layer = Pooling(pool_size=(2, 2),\n",
    "                                        stride_size=(2, 2),\n",
    "                                        padding='same')\n",
    "                        layerList.insert(randint(0, length - 1), layer)\n",
    "                    else:\n",
    "                        print(\"Inserting a Dropout layer\")\n",
    "                        rate = choice([0.15, 0.25, 0.35, 0.50])\n",
    "                        layer = Dropout(rate=rate)\n",
    "                        layerList.insert(randint(0, length - 1), layer)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during block mutation: {e}\")\n",
    "            return None\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "    \"\"\"def layer_mutation(self, dataset):\n",
    "        print(\"Layer Mutation\")\n",
    "\n",
    "        # pick a random block among all the blocks with type = 1\n",
    "        bl = [block.index for block in self.block_list if block.type == 1]\n",
    "\n",
    "        if len(bl) == 0:\n",
    "            return\n",
    "\n",
    "        block_idx = randint(1, max(bl))\n",
    "        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n",
    "\n",
    "        # list of layers of the selected block\n",
    "        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
    "\n",
    "        if len(layerList) == 0:\n",
    "            if block_type_idx:\n",
    "                layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                      filter_size=(3, 3),\n",
    "                                      stride_size=(1, 1),\n",
    "                                      padding='same',\n",
    "                                      input_shape=dataset['x_train'].shape[1:])\n",
    "                self.block_list[block_idx].layerList1.append(layer)\n",
    "                return\n",
    "            else:\n",
    "                layer = Pooling(pool_size=(2, 2),\n",
    "                                stride_size=(2, 2),\n",
    "                                padding='same')\n",
    "                self.block_list[block_idx].layerList2.append(layer)\n",
    "\n",
    "        idx = randint(0, len(layerList) - 1)\n",
    "        layer = layerList[idx]\n",
    "\n",
    "        if layer.name == 'Conv2D':\n",
    "            print(\"Splitting Conv2D layer at index\", idx)\n",
    "            layer.filters = int(layer.filters * 0.5)\n",
    "            layerList.insert(idx, deepcopy(layer))\n",
    "        elif layer.name == 'MaxPooling2D' or layer.name == 'AveragePooling2D':\n",
    "            print(\"Changing Pooling layer at index\", idx, \"with Conv2D layer\")\n",
    "            del layerList[idx]\n",
    "            conv_layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                       filter_size=(3, 3),\n",
    "                                       stride_size=(2, 2),\n",
    "                                       padding=layer.padding,\n",
    "                                       input_shape=dataset['x_train'].shape[1:])\n",
    "            layerList.insert(idx, conv_layer)\"\"\"\n",
    "    \n",
    "    def layer_mutation(self, dataset):\n",
    "        print(\"Layer Mutation\")\n",
    "\n",
    "        # Determine the maximum number of layers that can be added or removed\n",
    "        max_layers_to_add = 16 - sum(len(block.layerList1) + len(block.layerList2) for block in self.block_list)\n",
    "        max_layers_to_remove = sum(len(block.layerList1) + len(block.layerList2) - 1 for block in self.block_list)\n",
    "\n",
    "        if max_layers_to_add == 0 and max_layers_to_remove == 0:\n",
    "            return\n",
    "\n",
    "        # Pick a random block among all the blocks with type = 1\n",
    "        bl = [block.index for block in self.block_list if block.type == 1]\n",
    "\n",
    "        if len(bl) == 0:\n",
    "            return\n",
    "\n",
    "        block_idx = randint(1, max(bl))\n",
    "        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n",
    "\n",
    "        # List of layers of the selected block\n",
    "        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
    "\n",
    "        if len(layerList) == 0:\n",
    "            if block_type_idx:\n",
    "                layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                      filter_size=(3, 3),\n",
    "                                      stride_size=(1, 1),\n",
    "                                      padding='same',\n",
    "                                      input_shape=dataset['x_train'].shape[1:])\n",
    "                self.block_list[block_idx].layerList1.append(layer)\n",
    "            else:\n",
    "                layer = Pooling(pool_size=(2, 2),\n",
    "                                stride_size=(2, 2),\n",
    "                                padding='same')\n",
    "                self.block_list[block_idx].layerList2.append(layer)\n",
    "        else:\n",
    "            # Randomly choose whether to add or remove a layer\n",
    "            add_layer = bool(randint(0, 1))\n",
    "\n",
    "            if add_layer and max_layers_to_add > 0:\n",
    "                # Add a layer\n",
    "                layer = self.create_random_layer(dataset)\n",
    "                layerList.insert(randint(0, len(layerList)), layer)\n",
    "            elif not add_layer and max_layers_to_remove > 0:\n",
    "                # Remove a layer\n",
    "                idx = randint(0, len(layerList) - 1)\n",
    "                del layerList[idx]\n",
    "\n",
    "        # Ensure the total number of layers in the block doesn't exceed 16\n",
    "        if len(self.block_list[block_idx].layerList1) + len(self.block_list[block_idx].layerList2) > 16:\n",
    "            # Remove a random layer to maintain the total count of 16 layers\n",
    "            block_layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
    "            del block_layerList[randint(0, len(block_layerList) - 1)]\n",
    "\n",
    "    def create_random_layer(self, dataset):\n",
    "        # Create a random layer (Conv2D or Pooling)\n",
    "        if randint(0, 1):\n",
    "            # Conv2D layer\n",
    "            return Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                 filter_size=(3, 3),\n",
    "                                 stride_size=(1, 1),\n",
    "                                 padding='same',\n",
    "                                 input_shape=dataset['x_train'].shape[1:])\n",
    "        else:\n",
    "            # Pooling layer\n",
    "            return Pooling(pool_size=(2, 2),\n",
    "                           stride_size=(2, 2),\n",
    "                           padding='same')\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    def parameters_mutation(self):\n",
    "        print(\"Parameters Mutation\")\n",
    "        for block in self.block_list:\n",
    "            for layer in block.get_layers():\n",
    "                if randint(0, 1):\n",
    "                    layer.mutate_parameters()\n",
    "\n",
    "    def save_network_info(self, info_filename):\n",
    "        network_info = {\n",
    "            'name': self.name,\n",
    "            'block_list': self.block_list,\n",
    "            'fitness': self.fitness\n",
    "        }\n",
    "\n",
    "        with open(info_filename, 'wb') as info_file:\n",
    "            pickle.dump(network_info, info_file)\n",
    "\n",
    "    def load_network_info(self, info_filename):\n",
    "        with open(info_filename, 'rb') as info_file:\n",
    "            network_info = pickle.load(info_file)\n",
    "\n",
    "        self.name = network_info['name']\n",
    "        self.block_list = network_info['block_list']\n",
    "        self.fitness = network_info['fitness']\n",
    "\n",
    "    def save_model(self, model_filename):\n",
    "        self.model.save(model_filename)\n",
    "\n",
    "    def load_model(self, model_filename):\n",
    "        self.model = tf.keras.models.load_model(model_filename)\n",
    "\n",
    "    def save_network(self, network_info_filename, model_filename):\n",
    "        # Save non-model attributes\n",
    "        self.save_network_info(network_info_filename)\n",
    "\n",
    "        # Save the model separately\n",
    "        self.save_model(model_filename)\n",
    "\n",
    "    def load_network(self, network_info_filename, model_filename):\n",
    "        # Load non-model attributes\n",
    "        self.load_network_info(network_info_filename)\n",
    "\n",
    "        # Load the model separately\n",
    "        self.load_model(model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7409c7df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T09:37:55.530962Z",
     "iopub.status.busy": "2024-04-08T09:37:55.530431Z",
     "iopub.status.idle": "2024-04-08T09:37:55.562538Z",
     "shell.execute_reply": "2024-04-08T09:37:55.561700Z"
    },
    "papermill": {
     "duration": 0.039136,
     "end_time": "2024-04-08T09:37:55.564446",
     "exception": false,
     "start_time": "2024-04-08T09:37:55.525310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TOPOLOGY\n",
    "\n",
    "import keras.layers\n",
    "from random import randint\n",
    "\n",
    "\n",
    "class Block:\n",
    "\t__slots__ = ('type', 'index', 'layerList1', 'layerList2')\n",
    "\n",
    "\tdef __init__(self, type, index, layerList1, layerList2):\n",
    "\t\tself.type = type\t\t\t\t\t\t\t\t\t\t# 0 -> initial layer; 1 -> mid layers; 2 -> final layer\n",
    "\t\tself.index = index\t\t\t\t\t\t\t\t\t\t# block index among all the blocks\n",
    "\t\tself.layerList1 = layerList1\t\t\t\t\t\t\t# Convolutional layers\n",
    "\t\tself.layerList2 = layerList2\t\t\t\t\t\t\t# Pooling and Dropout layers\n",
    "\n",
    "\tdef get_layers(self):\n",
    "\t\treturn self.layerList1 + self.layerList2\n",
    "\n",
    "\tdef get_size(self):\n",
    "\t\treturn len(self.get_layers())\n",
    "\n",
    "\n",
    "class Convolutional:\n",
    "\t# __slots__ = ('name', 'filters', 'padding', 'filter_size', 'stride_size', 'input_shape')\n",
    "\n",
    "\tdef __init__(self, filters, padding, filter_size, stride_size, input_shape):\n",
    "\t\tself.name = 'Conv2D'\n",
    "\t\tself.filters = filters\n",
    "\t\tself.padding = padding\n",
    "\t\tself.filter_size = filter_size\n",
    "\t\tself.stride_size = stride_size\n",
    "\t\tself.input_shape = input_shape\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\ttry:\n",
    "\t\t\tmodel.add(keras.layers.Conv2D(filters=self.filters,\n",
    "\t\t\t\t\t\t\t\t\t\t\tkernel_size=self.filter_size,\n",
    "\t\t\t\t\t\t\t\t\t\t\tstrides=self.stride_size,\n",
    "\t\t\t\t\t\t\t\t\t\t\tpadding=self.padding,\n",
    "\t\t\t\t\t\t\t\t\t\t\tactivation='relu',\n",
    "\t\t\t\t\t\t\t\t\t\t\tkernel_initializer='he_uniform',\n",
    "\t\t\t\t\t\t\t\t\t\t\tinput_shape=self.input_shape))\n",
    "\t\texcept ValueError as e:\n",
    "\t\t\tprint(\"Error occurred while adding layer:\", e)\n",
    "\t\t\tprint(\"Skipping current architecture.\")\n",
    "\t\t\treturn  # Skip adding this layer\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tmutation = randint(0, 2)  # Adjusted the number of mutations\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tif mutation == 0 and self.filters >= 64:  # Adjusted the filter reduction threshold\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters = int(self.filters / 2)\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 1 and self.filters <= 256:  # Adjusted the filter increase threshold\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters *= 2\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 2:\n",
    "\t\t\tif self.padding == 'valid':\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'same'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'valid'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\t\"\"\"def mutate_parameters(self):\n",
    "\t\tmutation = randint(0, 4)\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tif mutation == 0 and self.filters >= 32:\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters = int(self.filters / 2)\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 1 and self.filters >= 32:\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters = int(self.filters / 2)\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 2 and self.filters <= 512:\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters *= 2\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 3 and self.filters <= 512:\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters *= 2\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 4:\n",
    "\t\t\tif self.padding == 'valid':\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'same'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'valid'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\"\"\"\n",
    "    \n",
    "\n",
    "'''\n",
    "elif mutation is 4:\n",
    "\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n",
    "\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n",
    "\tprint(\"to \", self.stride_size, \" and \", end=\"\")\n",
    "\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n",
    "\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n",
    "\tprint(\"to \", self.stride_size)\n",
    "'''\n",
    "\n",
    "\n",
    "class Pooling:\n",
    "\t__slots__ = ('name', 'pool_size', 'stride_size', 'padding')\n",
    "\n",
    "\tdef __init__(self, pool_size, stride_size, padding):\n",
    "\t\tself.name = 'MaxPooling2D'\n",
    "\t\tself.pool_size = pool_size\n",
    "\t\tself.stride_size = stride_size\n",
    "\t\tself.padding = padding\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\tif self.name == 'MaxPooling2D':\n",
    "\t\t\tmodel.add(keras.layers.MaxPooling2D(self.pool_size, self.stride_size, self.padding))\n",
    "\t\telif self.name == 'AveragePooling2D':\n",
    "\t\t\tmodel.add(keras.layers.AveragePooling2D(self.pool_size, self.stride_size, self.padding))\n",
    "\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tmutation = randint(0, 1)\n",
    "\t\tif mutation == 0:\n",
    "\t\t\tif self.padding == 'valid':\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'same'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'valid'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\telif mutation == 1:\n",
    "\t\t\tif self.name == 'MaxPooling2D':\n",
    "\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n",
    "\t\t\t\tself.name = 'AveragePooling2D'\n",
    "\t\t\t\tprint(\"to \", self.name)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n",
    "\t\t\t\tself.name = 'MaxPooling2D'\n",
    "\t\t\t\tprint(\"to \", self.name)\n",
    "\n",
    "\n",
    "'''\n",
    "if mutation is 0:\n",
    "\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n",
    "\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n",
    "\tprint(\"to \", self.stride_size)\n",
    "'''\n",
    "\n",
    "\n",
    "class FullyConnected:\n",
    "\t__slots__ = ('name', 'units', 'num_classes')\n",
    "\n",
    "\tdef __init__(self, units, num_classes):\n",
    "\t\tself.name = \"FullyConnected\"\n",
    "\t\tself.units = units\n",
    "\t\tself.num_classes = num_classes\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\tmodel.add(keras.layers.Flatten())\n",
    "\t\tmodel.add(keras.layers.Dense(self.units, activation='relu', kernel_initializer='he_uniform'))\n",
    "\t\tmodel.add(keras.layers.Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tmutation = randint(0, 2)\n",
    "\t\tif mutation == 0:\n",
    "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
    "\t\t\tself.units *= 2\n",
    "\t\t\tprint(\"to \", self.units)\n",
    "\t\telif mutation == 1:\n",
    "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
    "\t\t\tself.units *= 2\n",
    "\t\t\tprint(\"to \", self.units)\n",
    "\t\telif mutation == 2:\n",
    "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
    "\t\t\tself.units /= 2\n",
    "\t\t\tprint(\"to \", self.units)\n",
    "\n",
    "\n",
    "'''\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(self.num_classes, activation='softmax'))\n",
    "'''\n",
    "\n",
    "\n",
    "class Dropout:\n",
    "\t__slots__ = ('name', 'rate')\n",
    "\n",
    "\tdef __init__(self, rate):\n",
    "\t\tself.name = \"Dropout\"\n",
    "\t\tself.rate = rate\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\tmodel.add(keras.layers.Dropout(self.rate))\n",
    "\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tmutation = randint(0, 3)\n",
    "\t\tif mutation == 0 and self.rate <= 0.85:\n",
    "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate + 0.10\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\t\telif mutation == 1 and self.rate <= 0.90:\n",
    "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate + 0.05\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\t\telif mutation == 2 and self.rate >= 0.15:\n",
    "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate - 0.10\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\t\telif mutation == 3 and self.rate >= 0.10:\n",
    "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate - 0.05\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\n",
    "class FlattenLayer:\n",
    "    def __init__(self):\n",
    "        self.name = 'Flatten'\n",
    "\n",
    "    def build_layer(self, model):\n",
    "        model.add(keras.layers.Flatten())\n",
    "\n",
    "    def mutate_parameters(self):\n",
    "        # The Flatten layer does not have any parameters to mutate\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21976695",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T09:37:55.574471Z",
     "iopub.status.busy": "2024-04-08T09:37:55.574184Z",
     "iopub.status.idle": "2024-04-08T11:40:59.119968Z",
     "shell.execute_reply": "2024-04-08T11:40:59.119039Z"
    },
    "papermill": {
     "duration": 7383.553516,
     "end_time": "2024-04-08T11:40:59.122125",
     "exception": false,
     "start_time": "2024-04-08T09:37:55.568609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic Algorithm\n",
      "----->Initializing Population\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4cb9c5db40>, <__main__.Block object at 0x7d4cb9c71a00>, <__main__.Block object at 0x7d4cb98dd3c0>, <__main__.Block object at 0x7d4cb99423c0>, <__main__.Block object at 0x7d4cb99425c0>, <__main__.Block object at 0x7d4cb9942800>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Type of model_final: <class 'keras.src.engine.sequential.Sequential'>\n",
      "Training parent_0\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 9s 12ms/step - loss: 2.9596 - accuracy: 0.1191 - val_loss: 2.6640 - val_accuracy: 0.1790\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.2677 - accuracy: 0.3126 - val_loss: 2.2696 - val_accuracy: 0.3410\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.9186 - accuracy: 0.4206 - val_loss: 2.2526 - val_accuracy: 0.3765\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.6589 - accuracy: 0.5071 - val_loss: 1.6276 - val_accuracy: 0.5115\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.4764 - accuracy: 0.5719 - val_loss: 1.7008 - val_accuracy: 0.4980\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.2554 - accuracy: 0.6277 - val_loss: 1.5876 - val_accuracy: 0.5575\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0892 - accuracy: 0.6694 - val_loss: 1.6429 - val_accuracy: 0.5455\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.9705 - accuracy: 0.7170 - val_loss: 1.7890 - val_accuracy: 0.5355\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.8402 - accuracy: 0.7547 - val_loss: 2.0340 - val_accuracy: 0.5370\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.8584 - accuracy: 0.7828 - val_loss: 1.9498 - val_accuracy: 0.5600\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.7600 - accuracy: 0.8050 - val_loss: 2.4652 - val_accuracy: 0.5095\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.6987 - accuracy: 0.8110 - val_loss: 1.8124 - val_accuracy: 0.5480\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.6764 - accuracy: 0.8247 - val_loss: 2.0125 - val_accuracy: 0.5670\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.7234 - accuracy: 0.8218 - val_loss: 3.5131 - val_accuracy: 0.5385\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.7836 - accuracy: 0.8340 - val_loss: 5.0546 - val_accuracy: 0.4640\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.7793 - accuracy: 0.8297 - val_loss: 3.7982 - val_accuracy: 0.5610\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0227 - accuracy: 0.8351 - val_loss: 3.7286 - val_accuracy: 0.5200\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.1560 - accuracy: 0.8268 - val_loss: 2.3164 - val_accuracy: 0.4880\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.8713 - accuracy: 0.8271 - val_loss: 7.5933 - val_accuracy: 0.4665\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.7985 - accuracy: 0.8322 - val_loss: 2.2832 - val_accuracy: 0.5465\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.1176 - accuracy: 0.8385 - val_loss: 5.8072 - val_accuracy: 0.4670\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.9222 - accuracy: 0.8368 - val_loss: 5.2795 - val_accuracy: 0.5405\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.2279 - accuracy: 0.8407 - val_loss: 4.8269 - val_accuracy: 0.5365\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.7651 - accuracy: 0.8404 - val_loss: 3.1310 - val_accuracy: 0.5355\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0311 - accuracy: 0.8274 - val_loss: 2.7750 - val_accuracy: 0.4900\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.9189 - accuracy: 0.8225 - val_loss: 3.6419 - val_accuracy: 0.5365\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0232 - accuracy: 0.8086 - val_loss: 4.5578 - val_accuracy: 0.5640\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.1142 - accuracy: 0.7896 - val_loss: 3.3874 - val_accuracy: 0.5010\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.1865 - accuracy: 0.7543 - val_loss: 2.8547 - val_accuracy: 0.4990\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.2280 - accuracy: 0.7742 - val_loss: 8.1282 - val_accuracy: 0.4970\n",
      "SUMMARY OF parent_0\n",
      "Training Loss: 1.2279741764068604\n",
      "Training Accuracy: 0.774173378944397\n",
      "Validation Loss: 8.12821102142334\n",
      "Validation Accuracy: 0.4970000088214874\n",
      "Classification Error Rate: 0.5029999911785126\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_1\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c8c778440>, <__main__.Block object at 0x7d4c8ff42500>, <__main__.Block object at 0x7d4c8ffe3f00>, <__main__.Block object at 0x7d4c8ff154c0>, <__main__.Block object at 0x7d4ca00cb9c0>, <__main__.Block object at 0x7d4ca008d740>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26/67157677.py:86: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model, self.name + '.h5')         # save model\n",
      "/tmp/ipykernel_26/2505184454.py:68: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(network.model, model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_1\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 6s 9ms/step - loss: 3.0480 - accuracy: 0.0607 - val_loss: 2.8799 - val_accuracy: 0.0860\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.7153 - accuracy: 0.1736 - val_loss: 4.3095 - val_accuracy: 0.1025\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.2768 - accuracy: 0.3291 - val_loss: 4.5161 - val_accuracy: 0.1055\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.9245 - accuracy: 0.4332 - val_loss: 2.1763 - val_accuracy: 0.3850\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.7203 - accuracy: 0.4897 - val_loss: 2.2253 - val_accuracy: 0.3965\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.5142 - accuracy: 0.5494 - val_loss: 1.6521 - val_accuracy: 0.4900\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.3316 - accuracy: 0.6038 - val_loss: 1.9213 - val_accuracy: 0.4795\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1800 - accuracy: 0.6537 - val_loss: 2.2020 - val_accuracy: 0.4525\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.9376 - accuracy: 0.7120 - val_loss: 1.9317 - val_accuracy: 0.4920\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8507 - accuracy: 0.7564 - val_loss: 2.1322 - val_accuracy: 0.4885\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.7445 - accuracy: 0.8005 - val_loss: 2.4472 - val_accuracy: 0.5105\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6121 - accuracy: 0.8226 - val_loss: 2.6462 - val_accuracy: 0.5190\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5944 - accuracy: 0.8472 - val_loss: 2.7534 - val_accuracy: 0.5090\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5919 - accuracy: 0.8616 - val_loss: 3.0255 - val_accuracy: 0.5465\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5353 - accuracy: 0.8590 - val_loss: 2.9190 - val_accuracy: 0.4865\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5278 - accuracy: 0.8760 - val_loss: 2.7436 - val_accuracy: 0.5050\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5641 - accuracy: 0.8783 - val_loss: 3.4879 - val_accuracy: 0.5115\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8589 - accuracy: 0.8807 - val_loss: 3.0720 - val_accuracy: 0.5080\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4833 - accuracy: 0.8869 - val_loss: 3.9386 - val_accuracy: 0.5090\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.6055 - accuracy: 0.8796 - val_loss: 3.4951 - val_accuracy: 0.4960\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5541 - accuracy: 0.8855 - val_loss: 4.6794 - val_accuracy: 0.5085\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7102 - accuracy: 0.8820 - val_loss: 3.5396 - val_accuracy: 0.5110\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.6418 - accuracy: 0.8688 - val_loss: 3.7120 - val_accuracy: 0.4320\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7328 - accuracy: 0.8673 - val_loss: 4.2582 - val_accuracy: 0.4835\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.9715 - accuracy: 0.8756 - val_loss: 3.6765 - val_accuracy: 0.5095\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.6229 - accuracy: 0.8613 - val_loss: 4.4983 - val_accuracy: 0.4770\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6724 - accuracy: 0.8628 - val_loss: 3.8794 - val_accuracy: 0.4870\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.8103 - accuracy: 0.8541 - val_loss: 4.0596 - val_accuracy: 0.4845\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7594 - accuracy: 0.8569 - val_loss: 3.9871 - val_accuracy: 0.4745\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7602 - accuracy: 0.8432 - val_loss: 4.1900 - val_accuracy: 0.5090\n",
      "SUMMARY OF net_1\n",
      "Training Loss: 0.7601510882377625\n",
      "Training Accuracy: 0.8432251811027527\n",
      "Validation Loss: 4.190030574798584\n",
      "Validation Accuracy: 0.5090000033378601\n",
      "Classification Error Rate: 0.4909999966621399\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_2\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c8c13e5c0>, <__main__.Block object at 0x7d4c8c14da00>, <__main__.Block object at 0x7d4c8c49d840>, <__main__.Block object at 0x7d4c8c2fae40>, <__main__.Block object at 0x7d4c8c20f180>, <__main__.Block object at 0x7d4c8c289600>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_26\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_26/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_26/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,256], [3,3,256,512].\n",
      "\n",
      "Call arguments received by layer \"conv2d_26\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 256), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_2\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 6s 9ms/step - loss: 2.9237 - accuracy: 0.0983 - val_loss: 2.6443 - val_accuracy: 0.1350\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.4572 - accuracy: 0.2410 - val_loss: 2.5850 - val_accuracy: 0.2250\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.1105 - accuracy: 0.3598 - val_loss: 1.9375 - val_accuracy: 0.4085\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.8739 - accuracy: 0.4317 - val_loss: 1.8740 - val_accuracy: 0.4485\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.6658 - accuracy: 0.4975 - val_loss: 1.7600 - val_accuracy: 0.5020\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4716 - accuracy: 0.5598 - val_loss: 1.5766 - val_accuracy: 0.5505\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3017 - accuracy: 0.6111 - val_loss: 1.6068 - val_accuracy: 0.5385\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1048 - accuracy: 0.6617 - val_loss: 1.5816 - val_accuracy: 0.5570\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9412 - accuracy: 0.7049 - val_loss: 1.6025 - val_accuracy: 0.5640\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8108 - accuracy: 0.7501 - val_loss: 1.6942 - val_accuracy: 0.5930\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.6928 - accuracy: 0.7958 - val_loss: 1.7719 - val_accuracy: 0.5830\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5788 - accuracy: 0.8322 - val_loss: 2.0938 - val_accuracy: 0.5400\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5125 - accuracy: 0.8529 - val_loss: 1.9607 - val_accuracy: 0.5740\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4623 - accuracy: 0.8695 - val_loss: 2.5650 - val_accuracy: 0.5795\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4852 - accuracy: 0.8828 - val_loss: 2.4154 - val_accuracy: 0.5375\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5203 - accuracy: 0.8918 - val_loss: 2.5232 - val_accuracy: 0.5465\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4393 - accuracy: 0.8927 - val_loss: 2.5507 - val_accuracy: 0.5205\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4563 - accuracy: 0.8905 - val_loss: 3.6018 - val_accuracy: 0.5800\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4256 - accuracy: 0.9054 - val_loss: 2.2417 - val_accuracy: 0.5630\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4508 - accuracy: 0.8960 - val_loss: 3.2569 - val_accuracy: 0.5600\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4553 - accuracy: 0.8944 - val_loss: 3.4264 - val_accuracy: 0.5825\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4825 - accuracy: 0.8914 - val_loss: 2.6663 - val_accuracy: 0.5765\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5005 - accuracy: 0.8935 - val_loss: 2.4993 - val_accuracy: 0.5785\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5093 - accuracy: 0.8927 - val_loss: 3.8847 - val_accuracy: 0.5730\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5835 - accuracy: 0.9022 - val_loss: 3.3219 - val_accuracy: 0.5415\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5459 - accuracy: 0.8977 - val_loss: 4.3663 - val_accuracy: 0.5275\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.6844 - accuracy: 0.8857 - val_loss: 4.0726 - val_accuracy: 0.5315\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6424 - accuracy: 0.8837 - val_loss: 4.6320 - val_accuracy: 0.5455\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.7970 - accuracy: 0.8828 - val_loss: 5.6376 - val_accuracy: 0.5355\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.7111 - accuracy: 0.8833 - val_loss: 4.4239 - val_accuracy: 0.5480\n",
      "SUMMARY OF net_2\n",
      "Training Loss: 0.7110956907272339\n",
      "Training Accuracy: 0.8832794427871704\n",
      "Validation Loss: 4.42389440536499\n",
      "Validation Accuracy: 0.5479999780654907\n",
      "Classification Error Rate: 0.4520000219345093\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_3\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c5297c1c0>, <__main__.Block object at 0x7d4c4bfda500>, <__main__.Block object at 0x7d4c39b707c0>, <__main__.Block object at 0x7d4c39b05940>, <__main__.Block object at 0x7d4c52940940>, <__main__.Block object at 0x7d4c8c333340>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_3\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 09:42:21.435708: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_3/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 7s 13ms/step - loss: 3.1992 - accuracy: 0.0680 - val_loss: 2.9896 - val_accuracy: 0.0615\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 3.1567 - accuracy: 0.2247 - val_loss: 2.6941 - val_accuracy: 0.2375\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.1980 - accuracy: 0.3603 - val_loss: 2.0654 - val_accuracy: 0.3805\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9407 - accuracy: 0.4437 - val_loss: 2.2851 - val_accuracy: 0.4350\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.0677 - accuracy: 0.5192 - val_loss: 1.8277 - val_accuracy: 0.4910\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.2858 - accuracy: 0.5722 - val_loss: 2.3954 - val_accuracy: 0.4730\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.9523 - accuracy: 0.6272 - val_loss: 2.6485 - val_accuracy: 0.4670\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.5695 - accuracy: 0.6826 - val_loss: 5.4842 - val_accuracy: 0.4415\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.3767 - accuracy: 0.7281 - val_loss: 2.2788 - val_accuracy: 0.5485\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8568 - accuracy: 0.7711 - val_loss: 2.5383 - val_accuracy: 0.5395\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.7297 - accuracy: 0.8015 - val_loss: 1.8798 - val_accuracy: 0.5905\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.9792 - accuracy: 0.8412 - val_loss: 2.3088 - val_accuracy: 0.5035\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.7976 - accuracy: 0.8492 - val_loss: 7.0227 - val_accuracy: 0.5375\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 3.0965 - accuracy: 0.8697 - val_loss: 1.9947 - val_accuracy: 0.6075\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.6738 - accuracy: 0.8846 - val_loss: 6.7546 - val_accuracy: 0.6100\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 3.1645 - accuracy: 0.8837 - val_loss: 10.6598 - val_accuracy: 0.6180\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 32.6258 - accuracy: 0.8894 - val_loss: 4.2280 - val_accuracy: 0.6105\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 6.7167 - accuracy: 0.9049 - val_loss: 7.3341 - val_accuracy: 0.5485\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 5.0718 - accuracy: 0.9002 - val_loss: 14.5807 - val_accuracy: 0.4865\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 4.0676 - accuracy: 0.9021 - val_loss: 8.4247 - val_accuracy: 0.5900\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 9.3330 - accuracy: 0.9084 - val_loss: 9.0474 - val_accuracy: 0.6190\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 7.9718 - accuracy: 0.9014 - val_loss: 4.3514 - val_accuracy: 0.5435\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 11.6739 - accuracy: 0.8969 - val_loss: 8.7212 - val_accuracy: 0.5825\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 13.9804 - accuracy: 0.8925 - val_loss: 4.6824 - val_accuracy: 0.6180\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 11.0184 - accuracy: 0.9034 - val_loss: 23.7257 - val_accuracy: 0.5960\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 12.9068 - accuracy: 0.8928 - val_loss: 3.2917 - val_accuracy: 0.5415\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 34.1429 - accuracy: 0.8932 - val_loss: 10.7641 - val_accuracy: 0.6130\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 14.5276 - accuracy: 0.9008 - val_loss: 24.6024 - val_accuracy: 0.6115\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 49.2529 - accuracy: 0.8873 - val_loss: 17.5234 - val_accuracy: 0.4805\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 15.6085 - accuracy: 0.8807 - val_loss: 2.7881 - val_accuracy: 0.4780\n",
      "SUMMARY OF net_3\n",
      "Training Loss: 15.608489990234375\n",
      "Training Accuracy: 0.8806717395782471\n",
      "Validation Loss: 2.7881381511688232\n",
      "Validation Accuracy: 0.4779999852180481\n",
      "Classification Error Rate: 0.5220000147819519\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_4\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.5  to  0.4\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c281dd840>, <__main__.Block object at 0x7d4c28162500>, <__main__.Block object at 0x7d4c28175a00>, <__main__.Block object at 0x7d4c281d8c00>, <__main__.Block object at 0x7d4c281a0100>, <__main__.Block object at 0x7d4c28289a00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_44\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_44/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_44/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,512].\n",
      "\n",
      "Call arguments received by layer \"conv2d_44\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_4\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 09:43:58.655592: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_4/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 9ms/step - loss: 3.0261 - accuracy: 0.0898 - val_loss: 2.9005 - val_accuracy: 0.1310\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.4937 - accuracy: 0.2564 - val_loss: 2.9660 - val_accuracy: 0.2730\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.1407 - accuracy: 0.3554 - val_loss: 2.2730 - val_accuracy: 0.3390\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.9314 - accuracy: 0.4279 - val_loss: 1.9663 - val_accuracy: 0.4035\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.8174 - accuracy: 0.4767 - val_loss: 2.0665 - val_accuracy: 0.3960\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.7263 - accuracy: 0.5229 - val_loss: 2.0057 - val_accuracy: 0.4445\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.7503 - accuracy: 0.5578 - val_loss: 2.4383 - val_accuracy: 0.3845\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.4882 - accuracy: 0.5911 - val_loss: 1.9674 - val_accuracy: 0.4535\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.4266 - accuracy: 0.6147 - val_loss: 1.6809 - val_accuracy: 0.5195\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.3138 - accuracy: 0.6443 - val_loss: 2.3252 - val_accuracy: 0.4035\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4534 - accuracy: 0.6609 - val_loss: 2.0446 - val_accuracy: 0.4840\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2709 - accuracy: 0.6774 - val_loss: 1.9510 - val_accuracy: 0.4905\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1368 - accuracy: 0.6958 - val_loss: 1.8455 - val_accuracy: 0.5440\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0816 - accuracy: 0.7069 - val_loss: 1.9620 - val_accuracy: 0.5015\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1047 - accuracy: 0.7119 - val_loss: 1.8894 - val_accuracy: 0.5250\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1740 - accuracy: 0.7169 - val_loss: 1.8261 - val_accuracy: 0.4815\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.0701 - accuracy: 0.7241 - val_loss: 1.8359 - val_accuracy: 0.5675\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1985 - accuracy: 0.7225 - val_loss: 1.8713 - val_accuracy: 0.5010\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.0911 - accuracy: 0.7323 - val_loss: 1.8147 - val_accuracy: 0.5480\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1181 - accuracy: 0.7256 - val_loss: 2.3726 - val_accuracy: 0.3915\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.0870 - accuracy: 0.7264 - val_loss: 1.9139 - val_accuracy: 0.5715\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2322 - accuracy: 0.7181 - val_loss: 2.3734 - val_accuracy: 0.4295\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.0706 - accuracy: 0.7198 - val_loss: 1.9383 - val_accuracy: 0.5295\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1762 - accuracy: 0.7092 - val_loss: 2.3314 - val_accuracy: 0.5570\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2445 - accuracy: 0.7135 - val_loss: 1.9510 - val_accuracy: 0.4935\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1839 - accuracy: 0.7118 - val_loss: 2.4686 - val_accuracy: 0.5025\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.7373 - accuracy: 0.7018 - val_loss: 2.4336 - val_accuracy: 0.4105\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2895 - accuracy: 0.6806 - val_loss: 2.3105 - val_accuracy: 0.5170\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.7819 - accuracy: 0.6990 - val_loss: 2.5734 - val_accuracy: 0.5140\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.4212 - accuracy: 0.6998 - val_loss: 2.1554 - val_accuracy: 0.4505\n",
      "SUMMARY OF net_4\n",
      "Training Loss: 1.4211721420288086\n",
      "Training Accuracy: 0.6998018026351929\n",
      "Validation Loss: 2.1554460525512695\n",
      "Validation Accuracy: 0.4505000114440918\n",
      "Classification Error Rate: 0.5494999885559082\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_5\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c183a11c0>, <__main__.Block object at 0x7d4c1839a500>, <__main__.Block object at 0x7d4c18466ac0>, <__main__.Block object at 0x7d4c184cb0c0>, <__main__.Block object at 0x7d4c18353340>, <__main__.Block object at 0x7d4c182039c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_5\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 6s 9ms/step - loss: 3.2201 - accuracy: 0.0864 - val_loss: 2.7096 - val_accuracy: 0.1605\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.4538 - accuracy: 0.2474 - val_loss: 2.2219 - val_accuracy: 0.3185\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.0734 - accuracy: 0.3679 - val_loss: 2.0624 - val_accuracy: 0.3710\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.8370 - accuracy: 0.4468 - val_loss: 1.9492 - val_accuracy: 0.4320\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.6179 - accuracy: 0.5127 - val_loss: 2.0614 - val_accuracy: 0.3965\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.4475 - accuracy: 0.5667 - val_loss: 1.7612 - val_accuracy: 0.4875\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2754 - accuracy: 0.6139 - val_loss: 1.6242 - val_accuracy: 0.5320\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.0923 - accuracy: 0.6674 - val_loss: 1.6912 - val_accuracy: 0.5040\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.9592 - accuracy: 0.7146 - val_loss: 2.0682 - val_accuracy: 0.4790\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8265 - accuracy: 0.7474 - val_loss: 1.8307 - val_accuracy: 0.5305\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7382 - accuracy: 0.7820 - val_loss: 1.8706 - val_accuracy: 0.5075\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6727 - accuracy: 0.8055 - val_loss: 2.2026 - val_accuracy: 0.4970\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 0.6157 - accuracy: 0.8210 - val_loss: 2.0200 - val_accuracy: 0.5325\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5736 - accuracy: 0.8430 - val_loss: 2.2275 - val_accuracy: 0.5390\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5750 - accuracy: 0.8441 - val_loss: 2.0607 - val_accuracy: 0.5310\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5862 - accuracy: 0.8530 - val_loss: 3.1081 - val_accuracy: 0.5410\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6070 - accuracy: 0.8467 - val_loss: 2.3582 - val_accuracy: 0.4875\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6233 - accuracy: 0.8548 - val_loss: 2.6743 - val_accuracy: 0.5095\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6638 - accuracy: 0.8613 - val_loss: 3.2323 - val_accuracy: 0.4095\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7303 - accuracy: 0.8649 - val_loss: 2.5467 - val_accuracy: 0.4430\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7931 - accuracy: 0.8506 - val_loss: 2.8909 - val_accuracy: 0.4700\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6754 - accuracy: 0.8604 - val_loss: 3.9363 - val_accuracy: 0.4515\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6735 - accuracy: 0.8634 - val_loss: 2.3400 - val_accuracy: 0.4745\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6127 - accuracy: 0.8717 - val_loss: 3.4770 - val_accuracy: 0.4835\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6441 - accuracy: 0.8681 - val_loss: 6.3237 - val_accuracy: 0.3270\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.8467 - accuracy: 0.8617 - val_loss: 3.6286 - val_accuracy: 0.4025\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6870 - accuracy: 0.8692 - val_loss: 5.8870 - val_accuracy: 0.4120\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6985 - accuracy: 0.8611 - val_loss: 2.3350 - val_accuracy: 0.4080\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8524 - accuracy: 0.8519 - val_loss: 5.2493 - val_accuracy: 0.4970\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7345 - accuracy: 0.8648 - val_loss: 3.7518 - val_accuracy: 0.3750\n",
      "SUMMARY OF net_5\n",
      "Training Loss: 0.7344725728034973\n",
      "Training Accuracy: 0.8648169636726379\n",
      "Validation Loss: 3.7517917156219482\n",
      "Validation Accuracy: 0.375\n",
      "Classification Error Rate: 0.625\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_6\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c18254e80>, <__main__.Block object at 0x7d4c10f7c800>, <__main__.Block object at 0x7d4c105a0a00>, <__main__.Block object at 0x7d4c105f0940>, <__main__.Block object at 0x7d4c105580c0>, <__main__.Block object at 0x7d4c1043b9c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_64\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_64/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_64/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,512].\n",
      "\n",
      "Call arguments received by layer \"conv2d_64\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 6s 10ms/step - loss: 2.9042 - accuracy: 0.1239 - val_loss: 3.0111 - val_accuracy: 0.1285\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.5381 - accuracy: 0.2983 - val_loss: 2.5115 - val_accuracy: 0.3070\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.3948 - accuracy: 0.4168 - val_loss: 2.0744 - val_accuracy: 0.3875\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.0371 - accuracy: 0.4785 - val_loss: 3.6435 - val_accuracy: 0.2925\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.8138 - accuracy: 0.5348 - val_loss: 2.3469 - val_accuracy: 0.3715\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.8635 - accuracy: 0.5915 - val_loss: 1.8953 - val_accuracy: 0.5130\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.9624 - accuracy: 0.6430 - val_loss: 1.9554 - val_accuracy: 0.5025\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.9576 - accuracy: 0.6978 - val_loss: 3.3109 - val_accuracy: 0.3005\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 5.2417 - accuracy: 0.7398 - val_loss: 2.4155 - val_accuracy: 0.5050\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.5364 - accuracy: 0.7770 - val_loss: 2.6675 - val_accuracy: 0.4980\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.3445 - accuracy: 0.8097 - val_loss: 3.6118 - val_accuracy: 0.4730\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.8009 - accuracy: 0.8296 - val_loss: 2.0250 - val_accuracy: 0.5375\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.0475 - accuracy: 0.8553 - val_loss: 3.9227 - val_accuracy: 0.5065\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.5309 - accuracy: 0.8725 - val_loss: 2.5771 - val_accuracy: 0.5260\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.3810 - accuracy: 0.8765 - val_loss: 3.3158 - val_accuracy: 0.5495\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.1468 - accuracy: 0.8853 - val_loss: 2.6223 - val_accuracy: 0.5345\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.5378 - accuracy: 0.8863 - val_loss: 3.1085 - val_accuracy: 0.5105\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.4651 - accuracy: 0.8909 - val_loss: 3.4568 - val_accuracy: 0.5315\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.7247 - accuracy: 0.8983 - val_loss: 5.8249 - val_accuracy: 0.5350\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 6.2266 - accuracy: 0.9024 - val_loss: 6.1658 - val_accuracy: 0.5080\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 5.7078 - accuracy: 0.8985 - val_loss: 5.0316 - val_accuracy: 0.4765\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.5729 - accuracy: 0.8912 - val_loss: 5.5596 - val_accuracy: 0.4685\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 6.3086 - accuracy: 0.8922 - val_loss: 3.3574 - val_accuracy: 0.4870\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 10.2823 - accuracy: 0.8917 - val_loss: 6.4998 - val_accuracy: 0.4945\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 9.5569 - accuracy: 0.8899 - val_loss: 6.0097 - val_accuracy: 0.4470\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 8.3828 - accuracy: 0.8798 - val_loss: 5.7252 - val_accuracy: 0.5320\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 6.7211 - accuracy: 0.9079 - val_loss: 4.6091 - val_accuracy: 0.4560\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 4.5876 - accuracy: 0.8993 - val_loss: 9.1746 - val_accuracy: 0.4715\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 6.3262 - accuracy: 0.8949 - val_loss: 3.1092 - val_accuracy: 0.4905\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 5.5703 - accuracy: 0.8877 - val_loss: 5.4242 - val_accuracy: 0.4825\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 5.570282936096191\n",
      "Training Accuracy: 0.8876603841781616\n",
      "Validation Loss: 5.424215793609619\n",
      "Validation Accuracy: 0.48249998688697815\n",
      "Classification Error Rate: 0.5175000131130219\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_7\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Removing a Conv2D layer at 1\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf86c04c0>, <__main__.Block object at 0x7d4bf8632500>, <__main__.Block object at 0x7d4bf86ce940>, <__main__.Block object at 0x7d4bf873dac0>, <__main__.Block object at 0x7d4bf87eb880>, <__main__.Block object at 0x7d4bf87b0440>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 6s 12ms/step - loss: 3.4166 - accuracy: 0.0848 - val_loss: 3.2393 - val_accuracy: 0.1470\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.4778 - accuracy: 0.2620 - val_loss: 2.7295 - val_accuracy: 0.2540\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.1683 - accuracy: 0.3850 - val_loss: 3.0808 - val_accuracy: 0.3350\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8421 - accuracy: 0.4701 - val_loss: 2.7755 - val_accuracy: 0.3550\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.6425 - accuracy: 0.5344 - val_loss: 2.3940 - val_accuracy: 0.4575\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.4236 - accuracy: 0.5950 - val_loss: 2.5311 - val_accuracy: 0.4540\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.2912 - accuracy: 0.6560 - val_loss: 2.1957 - val_accuracy: 0.4545\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.0525 - accuracy: 0.7050 - val_loss: 1.9520 - val_accuracy: 0.5145\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.8685 - accuracy: 0.7584 - val_loss: 2.0370 - val_accuracy: 0.5225\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.7918 - accuracy: 0.7943 - val_loss: 3.0922 - val_accuracy: 0.4795\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.8048 - accuracy: 0.8135 - val_loss: 3.2871 - val_accuracy: 0.4830\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.6232 - accuracy: 0.8276 - val_loss: 2.8986 - val_accuracy: 0.5430\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.2303 - accuracy: 0.8350 - val_loss: 4.3748 - val_accuracy: 0.4220\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.6876 - accuracy: 0.8352 - val_loss: 3.3614 - val_accuracy: 0.4815\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.8928 - accuracy: 0.8239 - val_loss: 4.9528 - val_accuracy: 0.5095\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.9957 - accuracy: 0.8210 - val_loss: 3.3123 - val_accuracy: 0.4570\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.8371 - accuracy: 0.8066 - val_loss: 3.6295 - val_accuracy: 0.5320\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.7783 - accuracy: 0.8217 - val_loss: 3.4214 - val_accuracy: 0.5190\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.8829 - accuracy: 0.8035 - val_loss: 5.2759 - val_accuracy: 0.5335\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.9545 - accuracy: 0.8047 - val_loss: 3.6828 - val_accuracy: 0.5235\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.5022 - accuracy: 0.7837 - val_loss: 3.6013 - val_accuracy: 0.4035\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.9976 - accuracy: 0.7834 - val_loss: 3.2230 - val_accuracy: 0.4980\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.1020 - accuracy: 0.7600 - val_loss: 4.5239 - val_accuracy: 0.5320\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.0578 - accuracy: 0.7394 - val_loss: 4.9085 - val_accuracy: 0.4180\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.2263 - accuracy: 0.7418 - val_loss: 4.7594 - val_accuracy: 0.4945\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.3547 - accuracy: 0.6542 - val_loss: 4.6055 - val_accuracy: 0.4350\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.6882 - accuracy: 0.6193 - val_loss: 3.2410 - val_accuracy: 0.4780\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.2865 - accuracy: 0.4957 - val_loss: 2.6439 - val_accuracy: 0.2890\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.2538 - accuracy: 0.4307 - val_loss: 3.1117 - val_accuracy: 0.3030\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.7682 - accuracy: 0.2380 - val_loss: 2.8562 - val_accuracy: 0.1125\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 2.7681684494018555\n",
      "Training Accuracy: 0.23803067207336426\n",
      "Validation Loss: 2.856228828430176\n",
      "Validation Accuracy: 0.11249999701976776\n",
      "Classification Error Rate: 0.8875000029802322\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_8\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c10bca180>, <__main__.Block object at 0x7d4c10cea500>, <__main__.Block object at 0x7d4c10a56940>, <__main__.Block object at 0x7d4c10b5b880>, <__main__.Block object at 0x7d4c10cd30c0>, <__main__.Block object at 0x7d4c10c037c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_83\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_83/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_83/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,512], [3,3,512,512].\n",
      "\n",
      "Call arguments received by layer \"conv2d_83\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 512), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 6s 10ms/step - loss: 2.9710 - accuracy: 0.1123 - val_loss: 2.6807 - val_accuracy: 0.1845\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.4377 - accuracy: 0.2859 - val_loss: 2.7303 - val_accuracy: 0.2530\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.1804 - accuracy: 0.3787 - val_loss: 1.8506 - val_accuracy: 0.4355\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.9323 - accuracy: 0.4544 - val_loss: 2.6944 - val_accuracy: 0.3830\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.0248 - accuracy: 0.5075 - val_loss: 2.1866 - val_accuracy: 0.4485\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.9455 - accuracy: 0.5579 - val_loss: 2.2341 - val_accuracy: 0.4830\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.4587 - accuracy: 0.6049 - val_loss: 2.5797 - val_accuracy: 0.3755\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.4450 - accuracy: 0.6422 - val_loss: 1.9735 - val_accuracy: 0.4810\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1546 - accuracy: 0.6833 - val_loss: 2.3700 - val_accuracy: 0.4780\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.5330 - accuracy: 0.7241 - val_loss: 2.1103 - val_accuracy: 0.4545\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.5191 - accuracy: 0.7573 - val_loss: 2.7074 - val_accuracy: 0.5200\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.5646 - accuracy: 0.7882 - val_loss: 6.0693 - val_accuracy: 0.3570\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 13.6411 - accuracy: 0.8082 - val_loss: 2.1733 - val_accuracy: 0.5020\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.5244 - accuracy: 0.8342 - val_loss: 2.2340 - val_accuracy: 0.5190\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.7782 - accuracy: 0.8332 - val_loss: 3.4078 - val_accuracy: 0.5235\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4714 - accuracy: 0.8447 - val_loss: 3.2068 - val_accuracy: 0.5165\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.2555 - accuracy: 0.8504 - val_loss: 2.9995 - val_accuracy: 0.4925\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.9038 - accuracy: 0.8480 - val_loss: 3.7678 - val_accuracy: 0.5425\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.6427 - accuracy: 0.8522 - val_loss: 4.2121 - val_accuracy: 0.4605\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.2917 - accuracy: 0.8527 - val_loss: 5.2740 - val_accuracy: 0.4600\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0591 - accuracy: 0.8353 - val_loss: 2.7469 - val_accuracy: 0.5185\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1413 - accuracy: 0.8437 - val_loss: 3.4345 - val_accuracy: 0.5265\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.9102 - accuracy: 0.8477 - val_loss: 6.3204 - val_accuracy: 0.4765\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.5534 - accuracy: 0.8396 - val_loss: 4.5552 - val_accuracy: 0.5180\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 6.5636 - accuracy: 0.8219 - val_loss: 4.1271 - val_accuracy: 0.4955\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.4816 - accuracy: 0.8241 - val_loss: 3.5225 - val_accuracy: 0.4760\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.6065 - accuracy: 0.8179 - val_loss: 2.3939 - val_accuracy: 0.4530\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 5.9921 - accuracy: 0.8073 - val_loss: 4.4889 - val_accuracy: 0.4460\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.1718 - accuracy: 0.8080 - val_loss: 4.2157 - val_accuracy: 0.4890\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 8.3153 - accuracy: 0.7971 - val_loss: 3.5388 - val_accuracy: 0.4140\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 8.315250396728516\n",
      "Training Accuracy: 0.7971211075782776\n",
      "Validation Loss: 3.5387661457061768\n",
      "Validation Accuracy: 0.414000004529953\n",
      "Classification Error Rate: 0.585999995470047\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_9\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c8c113680>, <__main__.Block object at 0x7d4bf8385a00>, <__main__.Block object at 0x7d4c1079eac0>, <__main__.Block object at 0x7d4bf8410c00>, <__main__.Block object at 0x7d4bf820be40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 6s 13ms/step - loss: 5.8684 - accuracy: 0.0876 - val_loss: 2.8450 - val_accuracy: 0.1360\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.5609 - accuracy: 0.2416 - val_loss: 2.2596 - val_accuracy: 0.3345\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.1026 - accuracy: 0.3685 - val_loss: 1.9886 - val_accuracy: 0.4250\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8170 - accuracy: 0.4552 - val_loss: 1.9994 - val_accuracy: 0.4300\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.6248 - accuracy: 0.5072 - val_loss: 1.7749 - val_accuracy: 0.4935\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.4588 - accuracy: 0.5559 - val_loss: 1.8112 - val_accuracy: 0.4765\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.3004 - accuracy: 0.6072 - val_loss: 1.8180 - val_accuracy: 0.5150\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.1875 - accuracy: 0.6413 - val_loss: 1.6427 - val_accuracy: 0.5435\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.1365 - accuracy: 0.6595 - val_loss: 1.8739 - val_accuracy: 0.4940\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.0904 - accuracy: 0.6843 - val_loss: 2.5977 - val_accuracy: 0.4880\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.1010 - accuracy: 0.6836 - val_loss: 5.0630 - val_accuracy: 0.4910\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.1370 - accuracy: 0.6861 - val_loss: 3.6400 - val_accuracy: 0.4950\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.2320 - accuracy: 0.6615 - val_loss: 2.7501 - val_accuracy: 0.5115\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.2783 - accuracy: 0.6533 - val_loss: 2.7666 - val_accuracy: 0.4280\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.3306 - accuracy: 0.6399 - val_loss: 4.0301 - val_accuracy: 0.5050\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.4154 - accuracy: 0.6175 - val_loss: 2.4956 - val_accuracy: 0.4015\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.5171 - accuracy: 0.5952 - val_loss: 2.2528 - val_accuracy: 0.4085\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6640 - accuracy: 0.5634 - val_loss: 2.5043 - val_accuracy: 0.4260\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.7321 - accuracy: 0.5337 - val_loss: 2.2661 - val_accuracy: 0.4355\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.8683 - accuracy: 0.4961 - val_loss: 2.2200 - val_accuracy: 0.4205\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8827 - accuracy: 0.4911 - val_loss: 2.5464 - val_accuracy: 0.3440\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8848 - accuracy: 0.4909 - val_loss: 2.2543 - val_accuracy: 0.4470\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.8181 - accuracy: 0.4997 - val_loss: 2.4481 - val_accuracy: 0.4665\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9942 - accuracy: 0.4609 - val_loss: 2.2686 - val_accuracy: 0.3840\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.0131 - accuracy: 0.4401 - val_loss: 3.6907 - val_accuracy: 0.4635\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.1192 - accuracy: 0.4287 - val_loss: 2.3810 - val_accuracy: 0.3175\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9439 - accuracy: 0.4498 - val_loss: 3.2394 - val_accuracy: 0.3555\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.0896 - accuracy: 0.4268 - val_loss: 4.5154 - val_accuracy: 0.3700\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.0736 - accuracy: 0.4204 - val_loss: 2.6847 - val_accuracy: 0.3840\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.0318 - accuracy: 0.4310 - val_loss: 2.7300 - val_accuracy: 0.4205\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 2.0318331718444824\n",
      "Training Accuracy: 0.43100032210350037\n",
      "Validation Loss: 2.7300145626068115\n",
      "Validation Accuracy: 0.4205000102519989\n",
      "Classification Error Rate: 0.5794999897480011\n",
      "\n",
      "-------------------------------------\n",
      "Initial Population:\n",
      "net_4 :  2.1554460525512695\n",
      "net_9 :  2.7300145626068115\n",
      "net_3 :  2.7881381511688232\n",
      "net_7 :  2.856228828430176\n",
      "net_8 :  3.5387661457061768\n",
      "net_5 :  3.7517917156219482\n",
      "net_1 :  4.190030574798584\n",
      "net_2 :  4.42389440536499\n",
      "net_6 :  5.424215793609619\n",
      "parent_0 :  8.12821102142334\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 1\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_4 and net_9 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  512\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf9eccb40>, <__main__.Block object at 0x7d4bf93110c0>, <__main__.Block object at 0x7d4bf94a4f00>, <__main__.Block object at 0x7d4bf9ecccc0>, <__main__.Block object at 0x7d4bf9ecca80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 6s 12ms/step - loss: 4.9096 - accuracy: 0.1080 - val_loss: 2.6408 - val_accuracy: 0.2075\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.5254 - accuracy: 0.2444 - val_loss: 2.2118 - val_accuracy: 0.3420\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.1472 - accuracy: 0.3576 - val_loss: 2.0183 - val_accuracy: 0.3920\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.9177 - accuracy: 0.4287 - val_loss: 1.8167 - val_accuracy: 0.4485\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.7779 - accuracy: 0.4668 - val_loss: 1.7856 - val_accuracy: 0.4775\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6940 - accuracy: 0.4883 - val_loss: 1.7928 - val_accuracy: 0.4880\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6275 - accuracy: 0.5117 - val_loss: 1.9990 - val_accuracy: 0.4315\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6200 - accuracy: 0.5238 - val_loss: 1.7970 - val_accuracy: 0.5075\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.5893 - accuracy: 0.5303 - val_loss: 2.2717 - val_accuracy: 0.4285\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.5606 - accuracy: 0.5455 - val_loss: 2.3627 - val_accuracy: 0.4675\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.5694 - accuracy: 0.5485 - val_loss: 2.2109 - val_accuracy: 0.4835\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6068 - accuracy: 0.5408 - val_loss: 2.2205 - val_accuracy: 0.4865\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6664 - accuracy: 0.5308 - val_loss: 2.6267 - val_accuracy: 0.4510\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6572 - accuracy: 0.5336 - val_loss: 2.2934 - val_accuracy: 0.3940\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.7232 - accuracy: 0.5223 - val_loss: 2.3213 - val_accuracy: 0.3725\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.7064 - accuracy: 0.5210 - val_loss: 2.2468 - val_accuracy: 0.4020\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.8443 - accuracy: 0.4864 - val_loss: 3.0580 - val_accuracy: 0.4650\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.8105 - accuracy: 0.4878 - val_loss: 2.7594 - val_accuracy: 0.3545\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.9016 - accuracy: 0.4794 - val_loss: 2.8390 - val_accuracy: 0.3685\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.0398 - accuracy: 0.4385 - val_loss: 2.2713 - val_accuracy: 0.3930\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.0555 - accuracy: 0.4477 - val_loss: 3.2549 - val_accuracy: 0.3865\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.0901 - accuracy: 0.4246 - val_loss: 3.0328 - val_accuracy: 0.4320\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.1005 - accuracy: 0.4093 - val_loss: 2.3962 - val_accuracy: 0.3975\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.1783 - accuracy: 0.3889 - val_loss: 2.2310 - val_accuracy: 0.3925\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.1150 - accuracy: 0.4136 - val_loss: 2.8698 - val_accuracy: 0.3955\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.1575 - accuracy: 0.4028 - val_loss: 2.1602 - val_accuracy: 0.4105\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.0725 - accuracy: 0.4122 - val_loss: 2.5908 - val_accuracy: 0.4220\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.2302 - accuracy: 0.3902 - val_loss: 2.4258 - val_accuracy: 0.2985\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.1564 - accuracy: 0.4054 - val_loss: 4.8013 - val_accuracy: 0.4055\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.1306 - accuracy: 0.3950 - val_loss: 2.3568 - val_accuracy: 0.3460\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 2.1305840015411377\n",
      "Training Accuracy: 0.39501407742500305\n",
      "Validation Loss: 2.3568124771118164\n",
      "Validation Accuracy: 0.34599998593330383\n",
      "Classification Error Rate: 0.6540000140666962\n",
      "----->Evolution: Child net_10 with fitness 2.3568124771118164 replaces parent parent_0 with fitness 8.12821102142334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_4 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf90f2840>, <__main__.Block object at 0x7d4bf812ab80>, <__main__.Block object at 0x7d47dc247c40>, <__main__.Block object at 0x7d47dc214f40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 4s 6ms/step - loss: 2.4584 - accuracy: 0.2673 - val_loss: 3.5003 - val_accuracy: 0.1845\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.8407 - accuracy: 0.4582 - val_loss: 3.8928 - val_accuracy: 0.2535\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.4977 - accuracy: 0.5569 - val_loss: 2.2244 - val_accuracy: 0.4295\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.2388 - accuracy: 0.6315 - val_loss: 2.4509 - val_accuracy: 0.4695\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.0187 - accuracy: 0.7123 - val_loss: 2.4752 - val_accuracy: 0.4715\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.7897 - accuracy: 0.7703 - val_loss: 2.9359 - val_accuracy: 0.4770\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.5954 - accuracy: 0.8229 - val_loss: 2.5634 - val_accuracy: 0.5475\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.5346 - accuracy: 0.8610 - val_loss: 2.4990 - val_accuracy: 0.5395\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.3720 - accuracy: 0.8950 - val_loss: 4.0012 - val_accuracy: 0.5055\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.3505 - accuracy: 0.9178 - val_loss: 3.5900 - val_accuracy: 0.5415\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3297 - accuracy: 0.9236 - val_loss: 3.8192 - val_accuracy: 0.5575\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.3064 - accuracy: 0.9346 - val_loss: 4.5982 - val_accuracy: 0.5595\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.2719 - accuracy: 0.9404 - val_loss: 4.2757 - val_accuracy: 0.5760\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.3173 - accuracy: 0.9432 - val_loss: 5.1469 - val_accuracy: 0.5505\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.2863 - accuracy: 0.9497 - val_loss: 5.5689 - val_accuracy: 0.5680\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.3303 - accuracy: 0.9489 - val_loss: 5.7137 - val_accuracy: 0.5825\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.2428 - accuracy: 0.9546 - val_loss: 5.7353 - val_accuracy: 0.5370\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.2827 - accuracy: 0.9542 - val_loss: 6.5621 - val_accuracy: 0.5815\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.2917 - accuracy: 0.9556 - val_loss: 7.4668 - val_accuracy: 0.5240\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.3535 - accuracy: 0.9609 - val_loss: 6.7263 - val_accuracy: 0.5485\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.2994 - accuracy: 0.9607 - val_loss: 7.6616 - val_accuracy: 0.5590\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.3386 - accuracy: 0.9597 - val_loss: 5.7314 - val_accuracy: 0.5870\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.3254 - accuracy: 0.9581 - val_loss: 5.3568 - val_accuracy: 0.5960\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.4146 - accuracy: 0.9646 - val_loss: 8.0640 - val_accuracy: 0.5665\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.2888 - accuracy: 0.9603 - val_loss: 8.1503 - val_accuracy: 0.5640\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.3521 - accuracy: 0.9615 - val_loss: 7.2342 - val_accuracy: 0.6055\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.3173 - accuracy: 0.9674 - val_loss: 7.6224 - val_accuracy: 0.5480\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.3490 - accuracy: 0.9638 - val_loss: 9.3896 - val_accuracy: 0.5690\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.2898 - accuracy: 0.9643 - val_loss: 6.8795 - val_accuracy: 0.5850\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.2824 - accuracy: 0.9654 - val_loss: 9.1139 - val_accuracy: 0.5870\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 0.2823708951473236\n",
      "Training Accuracy: 0.9653697609901428\n",
      "Validation Loss: 9.113865852355957\n",
      "Validation Accuracy: 0.5870000123977661\n",
      "Classification Error Rate: 0.4129999876022339\n",
      "----->Evolution: Child net_11 with fitness 9.113865852355957 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_4 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.35000000000000003\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47dc268440>, <__main__.Block object at 0x7d4bf9c3a9c0>, <__main__.Block object at 0x7d4bf9a34f00>, <__main__.Block object at 0x7d4bf9adb880>, <__main__.Block object at 0x7d4bf9af5c40>, <__main__.Block object at 0x7d4bf811d600>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_110. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 09:54:49.381883: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_12/dropout_2/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 9ms/step - loss: 2.9513 - accuracy: 0.0959 - val_loss: 2.6957 - val_accuracy: 0.1510\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.4446 - accuracy: 0.2531 - val_loss: 3.6478 - val_accuracy: 0.1865\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.1194 - accuracy: 0.3637 - val_loss: 3.1481 - val_accuracy: 0.2745\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.9260 - accuracy: 0.4295 - val_loss: 2.3162 - val_accuracy: 0.3475\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.7187 - accuracy: 0.4851 - val_loss: 3.4916 - val_accuracy: 0.3150\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.5890 - accuracy: 0.5228 - val_loss: 2.0682 - val_accuracy: 0.4200\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.4620 - accuracy: 0.5565 - val_loss: 1.5982 - val_accuracy: 0.5285\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3594 - accuracy: 0.5975 - val_loss: 2.1001 - val_accuracy: 0.4180\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3234 - accuracy: 0.6214 - val_loss: 2.3643 - val_accuracy: 0.4340\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1811 - accuracy: 0.6570 - val_loss: 2.6483 - val_accuracy: 0.3975\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1566 - accuracy: 0.6709 - val_loss: 2.0870 - val_accuracy: 0.4705\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1826 - accuracy: 0.6909 - val_loss: 2.4505 - val_accuracy: 0.4005\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1816 - accuracy: 0.7140 - val_loss: 2.6390 - val_accuracy: 0.4725\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.9947 - accuracy: 0.7215 - val_loss: 1.8475 - val_accuracy: 0.5615\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2554 - accuracy: 0.7365 - val_loss: 2.5587 - val_accuracy: 0.5055\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0942 - accuracy: 0.7442 - val_loss: 2.1022 - val_accuracy: 0.5520\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1255 - accuracy: 0.7596 - val_loss: 2.2506 - val_accuracy: 0.5040\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0141 - accuracy: 0.7641 - val_loss: 2.5602 - val_accuracy: 0.5075\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8379 - accuracy: 0.7747 - val_loss: 1.8055 - val_accuracy: 0.5830\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8289 - accuracy: 0.7812 - val_loss: 3.8268 - val_accuracy: 0.5060\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8794 - accuracy: 0.7815 - val_loss: 2.2861 - val_accuracy: 0.5190\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8007 - accuracy: 0.7861 - val_loss: 1.9572 - val_accuracy: 0.5500\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.7389 - accuracy: 0.7952 - val_loss: 2.0593 - val_accuracy: 0.5280\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.7561 - accuracy: 0.7937 - val_loss: 1.6895 - val_accuracy: 0.6040\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.6942 - accuracy: 0.8126 - val_loss: 1.9899 - val_accuracy: 0.5775\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.6976 - accuracy: 0.8159 - val_loss: 1.7627 - val_accuracy: 0.5685\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7589 - accuracy: 0.8103 - val_loss: 1.8175 - val_accuracy: 0.5645\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6667 - accuracy: 0.8181 - val_loss: 2.0364 - val_accuracy: 0.6100\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.6884 - accuracy: 0.8249 - val_loss: 1.9174 - val_accuracy: 0.6200\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6716 - accuracy: 0.8253 - val_loss: 2.2790 - val_accuracy: 0.6040\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 0.671618640422821\n",
      "Training Accuracy: 0.8252842426300049\n",
      "Validation Loss: 2.2789652347564697\n",
      "Validation Accuracy: 0.6039999723434448\n",
      "Classification Error Rate: 0.3960000276565552\n",
      "----->Evolution: Child net_12 with fitness 2.2789652347564697 replaces parent net_6 with fitness 5.424215793609619\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_4 and net_6 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c105e2780>, <__main__.Block object at 0x7d4c10508c80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 3s 5ms/step - loss: 2.9621 - accuracy: 0.2428 - val_loss: 2.1366 - val_accuracy: 0.3860\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.7983 - accuracy: 0.4702 - val_loss: 1.7187 - val_accuracy: 0.4995\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.3571 - accuracy: 0.5932 - val_loss: 1.6331 - val_accuracy: 0.5505\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.0277 - accuracy: 0.6871 - val_loss: 1.8297 - val_accuracy: 0.5515\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.7546 - accuracy: 0.7699 - val_loss: 2.0514 - val_accuracy: 0.5215\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5337 - accuracy: 0.8397 - val_loss: 2.0322 - val_accuracy: 0.5625\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.3786 - accuracy: 0.8810 - val_loss: 2.4525 - val_accuracy: 0.5720\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2754 - accuracy: 0.9166 - val_loss: 2.8956 - val_accuracy: 0.5465\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2139 - accuracy: 0.9352 - val_loss: 3.0471 - val_accuracy: 0.5755\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1911 - accuracy: 0.9426 - val_loss: 3.8639 - val_accuracy: 0.5460\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1528 - accuracy: 0.9544 - val_loss: 4.1608 - val_accuracy: 0.5250\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1372 - accuracy: 0.9602 - val_loss: 4.1153 - val_accuracy: 0.5690\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1348 - accuracy: 0.9598 - val_loss: 4.7589 - val_accuracy: 0.5575\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1218 - accuracy: 0.9646 - val_loss: 5.0957 - val_accuracy: 0.5530\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1122 - accuracy: 0.9662 - val_loss: 5.2397 - val_accuracy: 0.5365\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0996 - accuracy: 0.9713 - val_loss: 6.2300 - val_accuracy: 0.5465\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0975 - accuracy: 0.9724 - val_loss: 5.9310 - val_accuracy: 0.5610\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0914 - accuracy: 0.9747 - val_loss: 6.1366 - val_accuracy: 0.5400\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0979 - accuracy: 0.9755 - val_loss: 6.5732 - val_accuracy: 0.5690\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0943 - accuracy: 0.9762 - val_loss: 5.9759 - val_accuracy: 0.5790\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0918 - accuracy: 0.9769 - val_loss: 7.1852 - val_accuracy: 0.5565\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0886 - accuracy: 0.9801 - val_loss: 7.0731 - val_accuracy: 0.5540\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0867 - accuracy: 0.9792 - val_loss: 7.3788 - val_accuracy: 0.5580\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0814 - accuracy: 0.9796 - val_loss: 7.7949 - val_accuracy: 0.5620\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0829 - accuracy: 0.9800 - val_loss: 8.3016 - val_accuracy: 0.5540\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0821 - accuracy: 0.9827 - val_loss: 7.8588 - val_accuracy: 0.5625\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0957 - accuracy: 0.9779 - val_loss: 7.9257 - val_accuracy: 0.5600\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0923 - accuracy: 0.9801 - val_loss: 8.4441 - val_accuracy: 0.5665\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0995 - accuracy: 0.9795 - val_loss: 9.3324 - val_accuracy: 0.5580\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0926 - accuracy: 0.9797 - val_loss: 10.1925 - val_accuracy: 0.5400\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 0.09263157099485397\n",
      "Training Accuracy: 0.9796599745750427\n",
      "Validation Loss: 10.192495346069336\n",
      "Validation Accuracy: 0.5400000214576721\n",
      "Classification Error Rate: 0.4599999785423279\n",
      "----->Evolution: Child net_13 with fitness 10.192495346069336 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 2\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_4 and net_6 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.35000000000000003  to  0.4\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4ca5fc8440>, <__main__.Block object at 0x7d4bf96690c0>, <__main__.Block object at 0x7d4bf986b880>, <__main__.Block object at 0x7d4ca018b0c0>, <__main__.Block object at 0x7d4bf8580940>, <__main__.Block object at 0x7d4bf91af240>, <__main__.Block object at 0x7d4bf9c8b9c0>, <__main__.Block object at 0x7d4c1031d600>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_121. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_21\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_21/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_21\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.5  to  0.6\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c10230e00>, <__main__.Block object at 0x7d4c10232080>, <__main__.Block object at 0x7d4c10231080>, <__main__.Block object at 0x7d4c102339c0>, <__main__.Block object at 0x7d4c10233900>, <__main__.Block object at 0x7d4c10233e00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_127. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_23\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_23/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_23\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.35000000000000003  to  0.30000000000000004\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.35000000000000003\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c10217dc0>, <__main__.Block object at 0x7d4c10217a80>, <__main__.Block object at 0x7d4c102173c0>, <__main__.Block object at 0x7d4c10217c80>, <__main__.Block object at 0x7d47dc070840>, <__main__.Block object at 0x7d4bf925c980>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_134\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_134/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_134/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_134\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_136. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_26\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_26/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_26\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c1020a380>, <__main__.Block object at 0x7d4c10209000>, <__main__.Block object at 0x7d4c1020a640>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 09:56:43.705528: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_17/dropout_7/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 3s 5ms/step - loss: 2.2334 - accuracy: 0.3364 - val_loss: 3.3373 - val_accuracy: 0.2755\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.6253 - accuracy: 0.5055 - val_loss: 4.2452 - val_accuracy: 0.2985\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.3666 - accuracy: 0.5845 - val_loss: 2.6748 - val_accuracy: 0.4535\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.1577 - accuracy: 0.6428 - val_loss: 4.9698 - val_accuracy: 0.3480\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.9891 - accuracy: 0.6944 - val_loss: 3.6221 - val_accuracy: 0.4340\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.8181 - accuracy: 0.7426 - val_loss: 5.4677 - val_accuracy: 0.4010\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.6823 - accuracy: 0.7866 - val_loss: 4.5500 - val_accuracy: 0.4500\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5505 - accuracy: 0.8199 - val_loss: 6.4021 - val_accuracy: 0.4095\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4718 - accuracy: 0.8466 - val_loss: 7.0596 - val_accuracy: 0.4190\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3873 - accuracy: 0.8733 - val_loss: 6.3947 - val_accuracy: 0.4465\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3410 - accuracy: 0.8886 - val_loss: 7.4711 - val_accuracy: 0.4530\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3069 - accuracy: 0.9053 - val_loss: 7.3515 - val_accuracy: 0.4675\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2904 - accuracy: 0.9105 - val_loss: 7.5541 - val_accuracy: 0.4680\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2527 - accuracy: 0.9193 - val_loss: 8.5426 - val_accuracy: 0.4670\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2495 - accuracy: 0.9263 - val_loss: 8.5530 - val_accuracy: 0.4805\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2306 - accuracy: 0.9293 - val_loss: 10.7404 - val_accuracy: 0.4450\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2257 - accuracy: 0.9356 - val_loss: 10.9224 - val_accuracy: 0.4505\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2158 - accuracy: 0.9384 - val_loss: 9.9786 - val_accuracy: 0.4800\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1930 - accuracy: 0.9451 - val_loss: 11.5125 - val_accuracy: 0.4785\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2109 - accuracy: 0.9449 - val_loss: 12.9944 - val_accuracy: 0.4425\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2235 - accuracy: 0.9411 - val_loss: 11.3863 - val_accuracy: 0.4880\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1937 - accuracy: 0.9473 - val_loss: 15.1169 - val_accuracy: 0.4310\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.1804 - accuracy: 0.9526 - val_loss: 11.9905 - val_accuracy: 0.4815\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1939 - accuracy: 0.9502 - val_loss: 14.4462 - val_accuracy: 0.4725\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1865 - accuracy: 0.9553 - val_loss: 12.2632 - val_accuracy: 0.4990\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1779 - accuracy: 0.9571 - val_loss: 16.1162 - val_accuracy: 0.4655\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9525 - val_loss: 16.7151 - val_accuracy: 0.4510\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1785 - accuracy: 0.9563 - val_loss: 14.7856 - val_accuracy: 0.4780\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2002 - accuracy: 0.9555 - val_loss: 19.2297 - val_accuracy: 0.4360\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1761 - accuracy: 0.9607 - val_loss: 17.0654 - val_accuracy: 0.4675\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.1760820746421814\n",
      "Training Accuracy: 0.9606758952140808\n",
      "Validation Loss: 17.065404891967773\n",
      "Validation Accuracy: 0.4675000011920929\n",
      "Classification Error Rate: 0.5324999988079071\n",
      "----->Evolution: Child net_10 with fitness 17.065404891967773 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_4 and net_6 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c10305600>, <__main__.Block object at 0x7d4c104ea700>, <__main__.Block object at 0x7d4bf9164f00>, <__main__.Block object at 0x7d4bf93f5a00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 6s 12ms/step - loss: 3.0458 - accuracy: 0.1834 - val_loss: 3.3456 - val_accuracy: 0.1890\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.0094 - accuracy: 0.4135 - val_loss: 2.4173 - val_accuracy: 0.3360\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.5804 - accuracy: 0.5343 - val_loss: 1.9169 - val_accuracy: 0.4575\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.2214 - accuracy: 0.6359 - val_loss: 1.4862 - val_accuracy: 0.5855\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.8927 - accuracy: 0.7322 - val_loss: 1.6887 - val_accuracy: 0.5795\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.6460 - accuracy: 0.8166 - val_loss: 2.1917 - val_accuracy: 0.5735\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.4150 - accuracy: 0.8812 - val_loss: 2.7350 - val_accuracy: 0.5670\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.3255 - accuracy: 0.9108 - val_loss: 2.8998 - val_accuracy: 0.5760\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.3315 - accuracy: 0.9272 - val_loss: 4.6925 - val_accuracy: 0.5240\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.3042 - accuracy: 0.9289 - val_loss: 7.2673 - val_accuracy: 0.5340\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.3593 - accuracy: 0.9325 - val_loss: 4.3163 - val_accuracy: 0.5695\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.3404 - accuracy: 0.9374 - val_loss: 5.8655 - val_accuracy: 0.5740\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.2896 - accuracy: 0.9462 - val_loss: 5.3576 - val_accuracy: 0.5880\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.3467 - accuracy: 0.9412 - val_loss: 6.3490 - val_accuracy: 0.5920\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.5292 - accuracy: 0.9451 - val_loss: 7.5171 - val_accuracy: 0.5220\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.3746 - accuracy: 0.9460 - val_loss: 9.3007 - val_accuracy: 0.5340\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.3800 - accuracy: 0.9468 - val_loss: 9.6884 - val_accuracy: 0.5885\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.4666 - accuracy: 0.9454 - val_loss: 7.6277 - val_accuracy: 0.5755\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.5251 - accuracy: 0.9484 - val_loss: 11.9309 - val_accuracy: 0.5435\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.5786 - accuracy: 0.9499 - val_loss: 10.1681 - val_accuracy: 0.5455\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.4277 - accuracy: 0.9482 - val_loss: 15.4878 - val_accuracy: 0.5655\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.4256 - accuracy: 0.9520 - val_loss: 10.4786 - val_accuracy: 0.5695\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.4705 - accuracy: 0.9514 - val_loss: 13.9834 - val_accuracy: 0.5810\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.5596 - accuracy: 0.9551 - val_loss: 13.8351 - val_accuracy: 0.5280\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.8740 - accuracy: 0.9546 - val_loss: 16.7434 - val_accuracy: 0.5755\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.6153 - accuracy: 0.9519 - val_loss: 17.3853 - val_accuracy: 0.5690\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.7857 - accuracy: 0.9562 - val_loss: 25.9547 - val_accuracy: 0.5165\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.6709 - accuracy: 0.9564 - val_loss: 21.5176 - val_accuracy: 0.5760\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.6970 - accuracy: 0.9520 - val_loss: 24.0947 - val_accuracy: 0.5635\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.8580 - accuracy: 0.9549 - val_loss: 30.2528 - val_accuracy: 0.5830\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 0.8579543232917786\n",
      "Training Accuracy: 0.9549390077590942\n",
      "Validation Loss: 30.2528018951416\n",
      "Validation Accuracy: 0.5830000042915344\n",
      "Classification Error Rate: 0.4169999957084656\n",
      "----->Evolution: Child net_11 with fitness 30.2528018951416 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_4 and net_6 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.35000000000000003  to  0.45000000000000007\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf989d600>, <__main__.Block object at 0x7d47dbd72500>, <__main__.Block object at 0x7d47dbd890c0>, <__main__.Block object at 0x7d4bf924d5c0>, <__main__.Block object at 0x7d47dbcee940>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_152. Consider increasing the input size. Received input shape [None, 1, 1, 512] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 09:59:04.897161: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_19/dropout_8/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 6s 9ms/step - loss: 3.6401 - accuracy: 0.0663 - val_loss: 3.0891 - val_accuracy: 0.0580\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.3128 - accuracy: 0.1599 - val_loss: 2.6356 - val_accuracy: 0.1985\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.4657 - accuracy: 0.2661 - val_loss: 2.4729 - val_accuracy: 0.2595\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 5.5179 - accuracy: 0.3155 - val_loss: 2.4835 - val_accuracy: 0.2810\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 5.2175 - accuracy: 0.3382 - val_loss: 2.2265 - val_accuracy: 0.3440\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 6.3300 - accuracy: 0.3621 - val_loss: 3.2637 - val_accuracy: 0.1095\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 13.4706 - accuracy: 0.3555 - val_loss: 4.6627 - val_accuracy: 0.1010\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 14.3955 - accuracy: 0.3577 - val_loss: 2.9487 - val_accuracy: 0.2940\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 19.7662 - accuracy: 0.3898 - val_loss: 3.8592 - val_accuracy: 0.2360\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 15.8807 - accuracy: 0.3874 - val_loss: 2.7863 - val_accuracy: 0.2910\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 26.3501 - accuracy: 0.3958 - val_loss: 2.6048 - val_accuracy: 0.3655\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 24.6894 - accuracy: 0.3913 - val_loss: 3.7627 - val_accuracy: 0.2450\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 27.1603 - accuracy: 0.3922 - val_loss: 4.7714 - val_accuracy: 0.1800\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 18.0750 - accuracy: 0.3872 - val_loss: 4.2371 - val_accuracy: 0.2115\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 30.7210 - accuracy: 0.3821 - val_loss: 4.8353 - val_accuracy: 0.3030\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 19.8159 - accuracy: 0.3766 - val_loss: 16.8362 - val_accuracy: 0.1340\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 30.9476 - accuracy: 0.3657 - val_loss: 10.0259 - val_accuracy: 0.2355\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 34.4350 - accuracy: 0.3641 - val_loss: 7.8729 - val_accuracy: 0.1785\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 20.3402 - accuracy: 0.3627 - val_loss: 7.3274 - val_accuracy: 0.3665\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 77.4922 - accuracy: 0.3649 - val_loss: 4.2685 - val_accuracy: 0.1835\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 22.1280 - accuracy: 0.3444 - val_loss: 3.9448 - val_accuracy: 0.2685\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 14.1026 - accuracy: 0.3537 - val_loss: 8.4760 - val_accuracy: 0.1185\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 20.1224 - accuracy: 0.3026 - val_loss: 9.7574 - val_accuracy: 0.1420\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 18.4253 - accuracy: 0.3375 - val_loss: 4.6491 - val_accuracy: 0.2245\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 33.2220 - accuracy: 0.3361 - val_loss: 13.7133 - val_accuracy: 0.2415\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 18.5284 - accuracy: 0.3375 - val_loss: 13.3512 - val_accuracy: 0.1400\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 15.9970 - accuracy: 0.2924 - val_loss: 16.3525 - val_accuracy: 0.2765\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 8.4447 - accuracy: 0.3282 - val_loss: 13.2491 - val_accuracy: 0.1910\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 7.3910 - accuracy: 0.3282 - val_loss: 9.7460 - val_accuracy: 0.1065\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 8.8617 - accuracy: 0.3043 - val_loss: 49.3178 - val_accuracy: 0.3010\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 8.861713409423828\n",
      "Training Accuracy: 0.30426618456840515\n",
      "Validation Loss: 49.31779479980469\n",
      "Validation Accuracy: 0.3009999990463257\n",
      "Classification Error Rate: 0.6990000009536743\n",
      "----->Evolution: Child net_12 with fitness 49.31779479980469 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_4 and net_6 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.35000000000000003  to  0.30000000000000004\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e8810440>, <__main__.Block object at 0x7d47dbc12700>, <__main__.Block object at 0x7d47e9aa3880>, <__main__.Block object at 0x7d47e8860940>, <__main__.Block object at 0x7d47e881b7c0>, <__main__.Block object at 0x7d47e8906640>, <__main__.Block object at 0x7d47e888f240>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_161\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_161/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_161/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_161\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:00:14.937094: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_20/dropout_9/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 6s 10ms/step - loss: 3.0822 - accuracy: 0.0731 - val_loss: 3.5048 - val_accuracy: 0.0605\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.8099 - accuracy: 0.1909 - val_loss: 2.4362 - val_accuracy: 0.2375\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 4.8389 - accuracy: 0.2920 - val_loss: 2.4832 - val_accuracy: 0.2780\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 3.3097 - accuracy: 0.3449 - val_loss: 2.4557 - val_accuracy: 0.2530\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 4.5095 - accuracy: 0.3885 - val_loss: 3.6955 - val_accuracy: 0.2560\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 6.5818 - accuracy: 0.4086 - val_loss: 2.4852 - val_accuracy: 0.2770\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 5.9574 - accuracy: 0.4327 - val_loss: 2.3421 - val_accuracy: 0.3320\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 25.0522 - accuracy: 0.4554 - val_loss: 2.9889 - val_accuracy: 0.1700\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 23.9800 - accuracy: 0.4703 - val_loss: 2.0112 - val_accuracy: 0.4270\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 69.5566 - accuracy: 0.5030 - val_loss: 2.0434 - val_accuracy: 0.4120\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 21.2298 - accuracy: 0.5147 - val_loss: 2.1851 - val_accuracy: 0.3985\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 13.2750 - accuracy: 0.5249 - val_loss: 2.1186 - val_accuracy: 0.3965\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 46.7283 - accuracy: 0.5397 - val_loss: 3.8256 - val_accuracy: 0.2255\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 18.9072 - accuracy: 0.5433 - val_loss: 2.0775 - val_accuracy: 0.3980\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 44.0628 - accuracy: 0.5671 - val_loss: 2.0859 - val_accuracy: 0.4205\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 34.2241 - accuracy: 0.5746 - val_loss: 2.0097 - val_accuracy: 0.4260\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 22.0804 - accuracy: 0.5857 - val_loss: 2.0133 - val_accuracy: 0.4210\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 49.2765 - accuracy: 0.5927 - val_loss: 2.0716 - val_accuracy: 0.4480\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 31.8338 - accuracy: 0.6051 - val_loss: 2.7347 - val_accuracy: 0.3280\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 83.7034 - accuracy: 0.6179 - val_loss: 2.5674 - val_accuracy: 0.4230\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 58.0428 - accuracy: 0.6187 - val_loss: 2.1139 - val_accuracy: 0.4125\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 48.0865 - accuracy: 0.6345 - val_loss: 2.3334 - val_accuracy: 0.3710\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 71.7399 - accuracy: 0.6223 - val_loss: 2.1280 - val_accuracy: 0.4670\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 53.1021 - accuracy: 0.6347 - val_loss: 2.3119 - val_accuracy: 0.3945\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 33.6919 - accuracy: 0.6350 - val_loss: 2.3246 - val_accuracy: 0.4265\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 55.1115 - accuracy: 0.6455 - val_loss: 2.5171 - val_accuracy: 0.4265\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 25.3114 - accuracy: 0.6418 - val_loss: 2.3514 - val_accuracy: 0.3785\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 21.5338 - accuracy: 0.6394 - val_loss: 2.1425 - val_accuracy: 0.4140\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 82.2056 - accuracy: 0.6509 - val_loss: 2.1583 - val_accuracy: 0.4335\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 26.7599 - accuracy: 0.6627 - val_loss: 2.6559 - val_accuracy: 0.4595\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 26.759891510009766\n",
      "Training Accuracy: 0.6626681685447693\n",
      "Validation Loss: 2.6559247970581055\n",
      "Validation Accuracy: 0.4595000147819519\n",
      "Classification Error Rate: 0.5404999852180481\n",
      "----->Evolution: Child net_13 with fitness 2.6559247970581055 replaces parent net_2 with fitness 4.42389440536499\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 3\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Proportionate selection\n",
      "Selected net_9 and net_7 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e7b0f300>, <__main__.Block object at 0x7d47dbb0da00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 3s 6ms/step - loss: 5.3751 - accuracy: 0.1409 - val_loss: 8.2883 - val_accuracy: 0.1450\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.5829 - accuracy: 0.2330 - val_loss: 2.3787 - val_accuracy: 0.2670\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.2015 - accuracy: 0.3298 - val_loss: 2.1203 - val_accuracy: 0.3785\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.8856 - accuracy: 0.4307 - val_loss: 2.0347 - val_accuracy: 0.4450\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.6775 - accuracy: 0.4948 - val_loss: 2.0289 - val_accuracy: 0.4425\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.4799 - accuracy: 0.5513 - val_loss: 1.9443 - val_accuracy: 0.4685\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.3481 - accuracy: 0.5937 - val_loss: 2.0053 - val_accuracy: 0.4850\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.2236 - accuracy: 0.6323 - val_loss: 2.1220 - val_accuracy: 0.5090\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.1213 - accuracy: 0.6664 - val_loss: 2.0289 - val_accuracy: 0.5030\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.0081 - accuracy: 0.6946 - val_loss: 3.5456 - val_accuracy: 0.4910\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8895 - accuracy: 0.7296 - val_loss: 2.5774 - val_accuracy: 0.5285\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8285 - accuracy: 0.7502 - val_loss: 2.4582 - val_accuracy: 0.4970\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7556 - accuracy: 0.7739 - val_loss: 2.8122 - val_accuracy: 0.5485\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7148 - accuracy: 0.7871 - val_loss: 3.2859 - val_accuracy: 0.5075\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.6594 - accuracy: 0.8054 - val_loss: 2.8574 - val_accuracy: 0.5005\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5966 - accuracy: 0.8194 - val_loss: 4.2811 - val_accuracy: 0.5275\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5824 - accuracy: 0.8333 - val_loss: 3.3866 - val_accuracy: 0.5265\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5309 - accuracy: 0.8434 - val_loss: 3.6791 - val_accuracy: 0.4800\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4993 - accuracy: 0.8564 - val_loss: 4.0930 - val_accuracy: 0.5090\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4682 - accuracy: 0.8663 - val_loss: 4.2079 - val_accuracy: 0.5275\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4635 - accuracy: 0.8689 - val_loss: 4.1466 - val_accuracy: 0.5380\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4321 - accuracy: 0.8784 - val_loss: 4.5310 - val_accuracy: 0.5340\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3849 - accuracy: 0.8878 - val_loss: 4.5790 - val_accuracy: 0.5355\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3748 - accuracy: 0.8924 - val_loss: 4.8541 - val_accuracy: 0.5415\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3679 - accuracy: 0.8999 - val_loss: 5.4311 - val_accuracy: 0.5260\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3553 - accuracy: 0.9026 - val_loss: 7.1703 - val_accuracy: 0.5195\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3585 - accuracy: 0.9016 - val_loss: 6.5066 - val_accuracy: 0.5285\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3726 - accuracy: 0.9035 - val_loss: 6.4935 - val_accuracy: 0.5430\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3174 - accuracy: 0.9161 - val_loss: 6.9179 - val_accuracy: 0.5545\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3223 - accuracy: 0.9167 - val_loss: 6.0003 - val_accuracy: 0.5110\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.32233232259750366\n",
      "Training Accuracy: 0.9166579842567444\n",
      "Validation Loss: 6.000296115875244\n",
      "Validation Accuracy: 0.5109999775886536\n",
      "Classification Error Rate: 0.48900002241134644\n",
      "----->Evolution: Child net_10 with fitness 6.000296115875244 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Proportionate selection\n",
      "Selected net_4 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.5\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47dbae5600>, <__main__.Block object at 0x7d47e90fa500>, <__main__.Block object at 0x7d47e8f6da00>, <__main__.Block object at 0x7d47e8e7f480>, <__main__.Block object at 0x7d47e8ec3200>, <__main__.Block object at 0x7d47e8e2eac0>, <__main__.Block object at 0x7d47e8ecdc40>, <__main__.Block object at 0x7d47e9066700>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_176. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:02:30.875844: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_22/dropout_10/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 11s 23ms/step - loss: 3.3949 - accuracy: 0.0484 - val_loss: 2.9959 - val_accuracy: 0.0515\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 6s 20ms/step - loss: 3.0107 - accuracy: 0.0480 - val_loss: 2.9957 - val_accuracy: 0.0340\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 3.0004 - accuracy: 0.0536 - val_loss: 2.9964 - val_accuracy: 0.0510\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 3.0128 - accuracy: 0.0486 - val_loss: 2.9965 - val_accuracy: 0.0510\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 2.9961 - accuracy: 0.0489 - val_loss: 2.9966 - val_accuracy: 0.0510\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 6s 20ms/step - loss: 3.0053 - accuracy: 0.0479 - val_loss: 2.9967 - val_accuracy: 0.0455\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 6s 20ms/step - loss: 2.9959 - accuracy: 0.0499 - val_loss: 2.9967 - val_accuracy: 0.0455\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 2.9960 - accuracy: 0.0470 - val_loss: 2.9969 - val_accuracy: 0.0440\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 2.9959 - accuracy: 0.0500 - val_loss: 2.9969 - val_accuracy: 0.0440\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 2.9959 - accuracy: 0.0480 - val_loss: 2.9969 - val_accuracy: 0.0440\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 6s 20ms/step - loss: 2.9959 - accuracy: 0.0470 - val_loss: 2.9969 - val_accuracy: 0.0440\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 6s 20ms/step - loss: 2.9960 - accuracy: 0.0459 - val_loss: 2.9969 - val_accuracy: 0.0440\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 3.2652 - accuracy: 0.0499 - val_loss: 2.9968 - val_accuracy: 0.0455\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 2.9964 - accuracy: 0.0475 - val_loss: 2.9970 - val_accuracy: 0.0510\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 3.0001 - accuracy: 0.0489 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 2.9959 - accuracy: 0.0475 - val_loss: 2.9971 - val_accuracy: 0.0440\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 6s 20ms/step - loss: 2.9961 - accuracy: 0.0492 - val_loss: 2.9971 - val_accuracy: 0.0440\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 2.9963 - accuracy: 0.0503 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 2.9959 - accuracy: 0.0457 - val_loss: 2.9970 - val_accuracy: 0.0455\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 2.9959 - accuracy: 0.0495 - val_loss: 2.9970 - val_accuracy: 0.0455\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 2.9959 - accuracy: 0.0465 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 2.9960 - accuracy: 0.0455 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 6s 20ms/step - loss: 2.9959 - accuracy: 0.0462 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 2.9960 - accuracy: 0.0493 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 2.9959 - accuracy: 0.0498 - val_loss: 2.9971 - val_accuracy: 0.0440\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 2.9959 - accuracy: 0.0482 - val_loss: 2.9969 - val_accuracy: 0.0440\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 2.9960 - accuracy: 0.0476 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 6s 20ms/step - loss: 2.9960 - accuracy: 0.0485 - val_loss: 2.9969 - val_accuracy: 0.0440\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 2.9960 - accuracy: 0.0502 - val_loss: 2.9969 - val_accuracy: 0.0510\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 6s 19ms/step - loss: 2.9959 - accuracy: 0.0484 - val_loss: 2.9968 - val_accuracy: 0.0510\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 2.995945692062378\n",
      "Training Accuracy: 0.04839887470006943\n",
      "Validation Loss: 2.9968483448028564\n",
      "Validation Accuracy: 0.050999999046325684\n",
      "Classification Error Rate: 0.9490000009536743\n",
      "----->Evolution: Child net_11 with fitness 2.9968483448028564 replaces parent net_1 with fitness 4.190030574798584\n",
      "\n",
      "Creating Child 2\n",
      "----->Proportionate selection\n",
      "Selected net_4 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.45\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4ca0191b40>, <__main__.Block object at 0x7d47c86fda00>, <__main__.Block object at 0x7d4c8ff91300>, <__main__.Block object at 0x7d4ca00deec0>, <__main__.Block object at 0x7d47e8a62d00>, <__main__.Block object at 0x7d47d81c9ac0>, <__main__.Block object at 0x7d47d811a000>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_186. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:05:31.999517: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_23/dropout_11/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 6s 12ms/step - loss: 3.2171 - accuracy: 0.0537 - val_loss: 2.9960 - val_accuracy: 0.0510\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.9267 - accuracy: 0.0968 - val_loss: 2.7385 - val_accuracy: 0.1535\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.6087 - accuracy: 0.2145 - val_loss: 2.3847 - val_accuracy: 0.2810\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.3639 - accuracy: 0.2849 - val_loss: 2.4845 - val_accuracy: 0.2710\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.2176 - accuracy: 0.3262 - val_loss: 2.5037 - val_accuracy: 0.2695\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.1174 - accuracy: 0.3563 - val_loss: 2.1571 - val_accuracy: 0.3390\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.0366 - accuracy: 0.3895 - val_loss: 1.9518 - val_accuracy: 0.4375\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9850 - accuracy: 0.4019 - val_loss: 1.9903 - val_accuracy: 0.4145\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9464 - accuracy: 0.4154 - val_loss: 2.1219 - val_accuracy: 0.4140\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9239 - accuracy: 0.4242 - val_loss: 1.9727 - val_accuracy: 0.4420\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9163 - accuracy: 0.4251 - val_loss: 1.8776 - val_accuracy: 0.4540\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9007 - accuracy: 0.4277 - val_loss: 1.9525 - val_accuracy: 0.4525\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8640 - accuracy: 0.4423 - val_loss: 1.9141 - val_accuracy: 0.4355\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8508 - accuracy: 0.4484 - val_loss: 1.9601 - val_accuracy: 0.4315\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8612 - accuracy: 0.4469 - val_loss: 2.0656 - val_accuracy: 0.4320\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8651 - accuracy: 0.4484 - val_loss: 2.0392 - val_accuracy: 0.4290\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9008 - accuracy: 0.4398 - val_loss: 2.0951 - val_accuracy: 0.4015\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9003 - accuracy: 0.4460 - val_loss: 2.0268 - val_accuracy: 0.3975\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8731 - accuracy: 0.4473 - val_loss: 2.1315 - val_accuracy: 0.4135\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9336 - accuracy: 0.4328 - val_loss: 2.2528 - val_accuracy: 0.4330\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9504 - accuracy: 0.4343 - val_loss: 2.2350 - val_accuracy: 0.4025\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9949 - accuracy: 0.4184 - val_loss: 2.3485 - val_accuracy: 0.3605\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9836 - accuracy: 0.4162 - val_loss: 2.5239 - val_accuracy: 0.3860\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9966 - accuracy: 0.4198 - val_loss: 2.4153 - val_accuracy: 0.4360\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.0166 - accuracy: 0.4174 - val_loss: 3.1609 - val_accuracy: 0.4080\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9832 - accuracy: 0.4277 - val_loss: 3.4092 - val_accuracy: 0.3595\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.0519 - accuracy: 0.4066 - val_loss: 4.5358 - val_accuracy: 0.4270\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.0082 - accuracy: 0.4221 - val_loss: 6.7296 - val_accuracy: 0.4425\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.0505 - accuracy: 0.4116 - val_loss: 5.4618 - val_accuracy: 0.4015\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.1183 - accuracy: 0.3938 - val_loss: 5.9066 - val_accuracy: 0.4315\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 2.118292808532715\n",
      "Training Accuracy: 0.39376237988471985\n",
      "Validation Loss: 5.9065985679626465\n",
      "Validation Accuracy: 0.43149998784065247\n",
      "Classification Error Rate: 0.5685000121593475\n",
      "----->Evolution: Child net_12 with fitness 5.9065985679626465 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Proportionate selection\n",
      "Selected net_3 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating Conv2D layer:\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.35  to  0.39999999999999997\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e974dbc0>, <__main__.Block object at 0x7d47e9318440>, <__main__.Block object at 0x7d47e9654800>, <__main__.Block object at 0x7d47c8708a00>, <__main__.Block object at 0x7d47e957b0c0>, <__main__.Block object at 0x7d47e9670940>, <__main__.Block object at 0x7d47e9415d00>, <__main__.Block object at 0x7d47e96e65c0>, <__main__.Block object at 0x7d47e9405600>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_196\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_196/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_196/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_196\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:07:03.775936: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_24/dropout_12/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 8s 14ms/step - loss: 3.0223 - accuracy: 0.0534 - val_loss: 2.9794 - val_accuracy: 0.0665\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.9269 - accuracy: 0.0953 - val_loss: 2.9216 - val_accuracy: 0.0835\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.7297 - accuracy: 0.1389 - val_loss: 2.7384 - val_accuracy: 0.1480\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 2.6265 - accuracy: 0.1859 - val_loss: 2.8906 - val_accuracy: 0.1515\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.9397 - accuracy: 0.2193 - val_loss: 2.4843 - val_accuracy: 0.2385\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 4.8831 - accuracy: 0.2713 - val_loss: 2.3890 - val_accuracy: 0.2725\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 3.6288 - accuracy: 0.3165 - val_loss: 2.3246 - val_accuracy: 0.2975\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 3.5311 - accuracy: 0.3581 - val_loss: 2.1020 - val_accuracy: 0.3640\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.2999 - accuracy: 0.3877 - val_loss: 2.0723 - val_accuracy: 0.3580\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 3.1679 - accuracy: 0.4226 - val_loss: 2.3079 - val_accuracy: 0.3240\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 4.9213 - accuracy: 0.4459 - val_loss: 2.2082 - val_accuracy: 0.3735\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 7.6209 - accuracy: 0.4690 - val_loss: 2.2480 - val_accuracy: 0.3670\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 4.3838 - accuracy: 0.4957 - val_loss: 2.2268 - val_accuracy: 0.4165\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 8.2967 - accuracy: 0.5206 - val_loss: 2.0519 - val_accuracy: 0.4605\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 6.6531 - accuracy: 0.5391 - val_loss: 1.9742 - val_accuracy: 0.4420\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 6.6563 - accuracy: 0.5530 - val_loss: 2.1584 - val_accuracy: 0.4295\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 6.7539 - accuracy: 0.5745 - val_loss: 1.7822 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 16.7406 - accuracy: 0.5961 - val_loss: 1.9539 - val_accuracy: 0.4590\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 10.3179 - accuracy: 0.6177 - val_loss: 2.4853 - val_accuracy: 0.4375\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 7.8759 - accuracy: 0.6318 - val_loss: 1.9750 - val_accuracy: 0.5130\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 5.9337 - accuracy: 0.6462 - val_loss: 2.3056 - val_accuracy: 0.4845\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 19.2934 - accuracy: 0.6557 - val_loss: 2.7563 - val_accuracy: 0.4980\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 5.6859 - accuracy: 0.6617 - val_loss: 2.2614 - val_accuracy: 0.5130\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 14.8073 - accuracy: 0.6773 - val_loss: 3.3020 - val_accuracy: 0.4885\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 5.5945 - accuracy: 0.6984 - val_loss: 5.0942 - val_accuracy: 0.4820\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 16.7280 - accuracy: 0.7018 - val_loss: 6.0259 - val_accuracy: 0.5305\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 102.8715 - accuracy: 0.7261 - val_loss: 2.1412 - val_accuracy: 0.5485\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 13.4223 - accuracy: 0.7347 - val_loss: 2.1685 - val_accuracy: 0.5050\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 14.9468 - accuracy: 0.7370 - val_loss: 5.2009 - val_accuracy: 0.5065\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 24.9337 - accuracy: 0.7406 - val_loss: 6.4066 - val_accuracy: 0.5000\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 24.93365478515625\n",
      "Training Accuracy: 0.7405862212181091\n",
      "Validation Loss: 6.406614303588867\n",
      "Validation Accuracy: 0.5\n",
      "Classification Error Rate: 0.5\n",
      "----->Evolution: Child net_13 with fitness 6.406614303588867 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 4\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Proportionate selection\n",
      "Selected net_9 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  128.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e845be00>, <__main__.Block object at 0x7d47e81510c0>, <__main__.Block object at 0x7d47e8116940>, <__main__.Block object at 0x7d47e9210880>, <__main__.Block object at 0x7d47e811b880>, <__main__.Block object at 0x7d47e84cb0c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_210\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_210/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_210/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,512], [3,3,512,512].\n",
      "\n",
      "Call arguments received by layer \"conv2d_210\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 512), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 7s 12ms/step - loss: 3.1028 - accuracy: 0.1004 - val_loss: 2.7373 - val_accuracy: 0.1320\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.4978 - accuracy: 0.2566 - val_loss: 5.0745 - val_accuracy: 0.1690\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.2008 - accuracy: 0.3489 - val_loss: 3.7787 - val_accuracy: 0.2320\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.0307 - accuracy: 0.4102 - val_loss: 2.8843 - val_accuracy: 0.2680\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.8089 - accuracy: 0.4702 - val_loss: 2.2214 - val_accuracy: 0.3605\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.6800 - accuracy: 0.5217 - val_loss: 2.1881 - val_accuracy: 0.3965\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.4939 - accuracy: 0.5688 - val_loss: 2.2718 - val_accuracy: 0.4105\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.3454 - accuracy: 0.6306 - val_loss: 2.3337 - val_accuracy: 0.4140\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1320 - accuracy: 0.6827 - val_loss: 3.4140 - val_accuracy: 0.3495\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.9474 - accuracy: 0.7497 - val_loss: 2.5816 - val_accuracy: 0.4390\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.9940 - accuracy: 0.7859 - val_loss: 3.4766 - val_accuracy: 0.4365\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7928 - accuracy: 0.8157 - val_loss: 3.4928 - val_accuracy: 0.3585\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.9895 - accuracy: 0.8430 - val_loss: 2.9958 - val_accuracy: 0.4430\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6769 - accuracy: 0.8533 - val_loss: 2.9953 - val_accuracy: 0.4505\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5444 - accuracy: 0.8588 - val_loss: 4.1335 - val_accuracy: 0.4185\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6188 - accuracy: 0.8652 - val_loss: 4.9597 - val_accuracy: 0.4285\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8053 - accuracy: 0.8555 - val_loss: 4.2477 - val_accuracy: 0.4575\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6885 - accuracy: 0.8646 - val_loss: 3.4183 - val_accuracy: 0.4345\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7871 - accuracy: 0.8733 - val_loss: 4.3642 - val_accuracy: 0.4590\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5852 - accuracy: 0.8660 - val_loss: 4.2945 - val_accuracy: 0.4570\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6084 - accuracy: 0.8686 - val_loss: 3.8443 - val_accuracy: 0.4600\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7806 - accuracy: 0.8516 - val_loss: 5.3358 - val_accuracy: 0.4300\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2962 - accuracy: 0.8562 - val_loss: 8.8767 - val_accuracy: 0.3325\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8255 - accuracy: 0.8536 - val_loss: 4.5572 - val_accuracy: 0.4320\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8974 - accuracy: 0.8588 - val_loss: 4.9302 - val_accuracy: 0.4650\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7268 - accuracy: 0.8715 - val_loss: 5.2507 - val_accuracy: 0.4215\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7809 - accuracy: 0.8400 - val_loss: 5.6392 - val_accuracy: 0.3690\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8635 - accuracy: 0.8411 - val_loss: 5.9930 - val_accuracy: 0.4680\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.0225 - accuracy: 0.8303 - val_loss: 5.0518 - val_accuracy: 0.4125\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1944 - accuracy: 0.8453 - val_loss: 6.1263 - val_accuracy: 0.4140\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 1.1944197416305542\n",
      "Training Accuracy: 0.8453113436698914\n",
      "Validation Loss: 6.126265048980713\n",
      "Validation Accuracy: 0.414000004529953\n",
      "Classification Error Rate: 0.585999995470047\n",
      "----->Evolution: Child net_10 with fitness 6.126265048980713 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Proportionate selection\n",
      "Selected net_5 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.30000000000000004  to  0.20000000000000004\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e813d600>, <__main__.Block object at 0x7d47e86b2500>, <__main__.Block object at 0x7d47dbda10c0>, <__main__.Block object at 0x7d4c103ce940>, <__main__.Block object at 0x7d47e8850880>, <__main__.Block object at 0x7d47e81687c0>, <__main__.Block object at 0x7d4c10b4b7c0>, <__main__.Block object at 0x7d4ca5f2d600>, <__main__.Block object at 0x7d4bf9779040>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_218. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_223. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_64\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_64/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_64\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2)]\n",
      "Removing a Conv2D layer at 1\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf9647140>, <__main__.Block object at 0x7d4bf9646600>, <__main__.Block object at 0x7d4bf96461c0>, <__main__.Block object at 0x7d4bf9647380>, <__main__.Block object at 0x7d4bf9646680>, <__main__.Block object at 0x7d4bf9644280>, <__main__.Block object at 0x7d4c39bcdfc0>, <__main__.Block object at 0x7d4c1828a000>, <__main__.Block object at 0x7d4bf9e37840>, <__main__.Block object at 0x7d4bf9e356c0>, <__main__.Block object at 0x7d4bf9e37d00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_66\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_66/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,64].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_66\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 64), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2)]\n",
      "Inserting a Pooling layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  1024  to  2048\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf963d240>, <__main__.Block object at 0x7d4bf963c780>, <__main__.Block object at 0x7d4bf963d100>, <__main__.Block object at 0x7d4bf9955400>, <__main__.Block object at 0x7d4bf9956040>, <__main__.Block object at 0x7d4bf99578c0>, <__main__.Block object at 0x7d4bf9a5cc40>, <__main__.Block object at 0x7d4bf95da840>, <__main__.Block object at 0x7d4bf9a89380>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_243\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_243/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_243/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,256], [3,3,256,256].\n",
      "\n",
      "Call arguments received by layer \"conv2d_243\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 256), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_248. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_55\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_55/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_55\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf85152c0>, <__main__.Block object at 0x7d4bf9a659c0>, <__main__.Block object at 0x7d4bf9a65480>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 4s 7ms/step - loss: 2.4609 - accuracy: 0.2623 - val_loss: 2.2605 - val_accuracy: 0.3455\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.8084 - accuracy: 0.4603 - val_loss: 2.2969 - val_accuracy: 0.3730\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.4979 - accuracy: 0.5558 - val_loss: 1.9962 - val_accuracy: 0.4555\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.2939 - accuracy: 0.6231 - val_loss: 2.5578 - val_accuracy: 0.3570\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.1138 - accuracy: 0.6748 - val_loss: 1.8047 - val_accuracy: 0.5385\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.9413 - accuracy: 0.7283 - val_loss: 2.3771 - val_accuracy: 0.4745\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7960 - accuracy: 0.7698 - val_loss: 2.0339 - val_accuracy: 0.5250\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.6764 - accuracy: 0.8106 - val_loss: 2.1725 - val_accuracy: 0.5110\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5685 - accuracy: 0.8474 - val_loss: 2.1316 - val_accuracy: 0.5615\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4654 - accuracy: 0.8771 - val_loss: 2.6871 - val_accuracy: 0.5350\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5333 - accuracy: 0.8976 - val_loss: 2.7757 - val_accuracy: 0.5505\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4789 - accuracy: 0.9100 - val_loss: 2.8888 - val_accuracy: 0.5630\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4203 - accuracy: 0.9238 - val_loss: 3.6052 - val_accuracy: 0.5635\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3659 - accuracy: 0.9320 - val_loss: 3.3216 - val_accuracy: 0.5700\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3149 - accuracy: 0.9389 - val_loss: 3.7024 - val_accuracy: 0.5470\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4021 - accuracy: 0.9384 - val_loss: 4.4952 - val_accuracy: 0.5595\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4425 - accuracy: 0.9419 - val_loss: 4.2834 - val_accuracy: 0.5500\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5549 - accuracy: 0.9501 - val_loss: 4.9462 - val_accuracy: 0.5400\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3913 - accuracy: 0.9495 - val_loss: 4.9861 - val_accuracy: 0.5540\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4676 - accuracy: 0.9497 - val_loss: 5.8862 - val_accuracy: 0.5085\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4121 - accuracy: 0.9559 - val_loss: 4.9737 - val_accuracy: 0.5685\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4350 - accuracy: 0.9531 - val_loss: 5.6602 - val_accuracy: 0.5215\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3621 - accuracy: 0.9530 - val_loss: 5.9253 - val_accuracy: 0.5700\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4473 - accuracy: 0.9583 - val_loss: 5.8598 - val_accuracy: 0.5610\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.3195 - accuracy: 0.9584 - val_loss: 6.8078 - val_accuracy: 0.5180\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.4415 - accuracy: 0.9577 - val_loss: 6.0119 - val_accuracy: 0.5515\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7770 - accuracy: 0.9608 - val_loss: 7.8661 - val_accuracy: 0.5655\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.4929 - accuracy: 0.9622 - val_loss: 7.9866 - val_accuracy: 0.5465\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.6771 - accuracy: 0.9594 - val_loss: 6.6611 - val_accuracy: 0.5760\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5606 - accuracy: 0.9614 - val_loss: 7.1624 - val_accuracy: 0.5635\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 0.5605718493461609\n",
      "Training Accuracy: 0.9614060521125793\n",
      "Validation Loss: 7.162378311157227\n",
      "Validation Accuracy: 0.5634999871253967\n",
      "Classification Error Rate: 0.43650001287460327\n",
      "----->Evolution: Child net_11 with fitness 7.162378311157227 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Proportionate selection\n",
      "Selected net_4 and net_8 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf8232d80>, <__main__.Block object at 0x7d47e847a500>, <__main__.Block object at 0x7d47e993cf00>, <__main__.Block object at 0x7d47dbd98940>, <__main__.Block object at 0x7d47e8ecdc40>, <__main__.Block object at 0x7d47e9ae6700>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_260. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_261. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:11:34.347392: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_30/dropout_17/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 8ms/step - loss: 2.6495 - accuracy: 0.2179 - val_loss: 2.4301 - val_accuracy: 0.2540\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.1863 - accuracy: 0.4050 - val_loss: 2.2223 - val_accuracy: 0.3220\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.8459 - accuracy: 0.4949 - val_loss: 1.9709 - val_accuracy: 0.4590\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.7246 - accuracy: 0.5621 - val_loss: 1.8620 - val_accuracy: 0.4590\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.0305 - accuracy: 0.6127 - val_loss: 2.1767 - val_accuracy: 0.3720\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.4851 - accuracy: 0.6642 - val_loss: 2.0364 - val_accuracy: 0.5030\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.1114 - accuracy: 0.7091 - val_loss: 1.6213 - val_accuracy: 0.5675\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.4335 - accuracy: 0.7496 - val_loss: 1.7074 - val_accuracy: 0.5510\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.3410 - accuracy: 0.7792 - val_loss: 2.0061 - val_accuracy: 0.5590\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.5842 - accuracy: 0.8043 - val_loss: 2.2280 - val_accuracy: 0.5720\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.6008 - accuracy: 0.8231 - val_loss: 2.3789 - val_accuracy: 0.5430\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.6904 - accuracy: 0.8469 - val_loss: 1.9573 - val_accuracy: 0.5930\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.8480 - accuracy: 0.8609 - val_loss: 2.3607 - val_accuracy: 0.5745\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.1529 - accuracy: 0.8630 - val_loss: 2.8833 - val_accuracy: 0.5640\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 5.1477 - accuracy: 0.8699 - val_loss: 2.0474 - val_accuracy: 0.5940\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.0946 - accuracy: 0.8776 - val_loss: 2.7073 - val_accuracy: 0.5680\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.7954 - accuracy: 0.8814 - val_loss: 2.8519 - val_accuracy: 0.5850\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 5.0695 - accuracy: 0.8857 - val_loss: 2.4891 - val_accuracy: 0.5675\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.6835 - accuracy: 0.8951 - val_loss: 3.8710 - val_accuracy: 0.5665\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 5.9303 - accuracy: 0.8882 - val_loss: 2.8972 - val_accuracy: 0.5615\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.6663 - accuracy: 0.8928 - val_loss: 2.9695 - val_accuracy: 0.5650\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.1301 - accuracy: 0.8938 - val_loss: 4.3497 - val_accuracy: 0.5485\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.3173 - accuracy: 0.8983 - val_loss: 3.4158 - val_accuracy: 0.5690\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.4180 - accuracy: 0.8916 - val_loss: 2.7129 - val_accuracy: 0.5785\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.4985 - accuracy: 0.8941 - val_loss: 3.1728 - val_accuracy: 0.5035\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.2410 - accuracy: 0.8839 - val_loss: 2.7688 - val_accuracy: 0.5735\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.5750 - accuracy: 0.8895 - val_loss: 4.8978 - val_accuracy: 0.5860\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.0536 - accuracy: 0.8969 - val_loss: 3.7361 - val_accuracy: 0.5875\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.7458 - accuracy: 0.9020 - val_loss: 3.7945 - val_accuracy: 0.5740\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.6844 - accuracy: 0.8942 - val_loss: 2.6060 - val_accuracy: 0.5585\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 1.6844086647033691\n",
      "Training Accuracy: 0.8942317962646484\n",
      "Validation Loss: 2.6059792041778564\n",
      "Validation Accuracy: 0.5584999918937683\n",
      "Classification Error Rate: 0.4415000081062317\n",
      "----->Evolution: Child net_12 with fitness 2.6059792041778564 replaces parent net_5 with fitness 3.7517917156219482\n",
      "\n",
      "Creating Child 3\n",
      "----->Proportionate selection\n",
      "Selected net_4 and net_8 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c8c57b640>, <__main__.Block object at 0x7d4c185be180>, <__main__.Block object at 0x7d4c182cad40>, <__main__.Block object at 0x7d47dbb86940>, <__main__.Block object at 0x7d4c18298600>, <__main__.Block object at 0x7d4c18243440>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_269. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_62\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_62/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_62\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.30000000000000004\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e9a79680>, <__main__.Block object at 0x7d47e9a79940>, <__main__.Block object at 0x7d47e9a798c0>, <__main__.Block object at 0x7d47e9a7a000>, <__main__.Block object at 0x7d47e9a7a280>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_278\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_278/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_278/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,512], [3,3,512,512].\n",
      "\n",
      "Call arguments received by layer \"conv2d_278\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 512), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Input 0 of layer \"average_pooling2d_64\" is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 20)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2)]\n",
      "Removing a Conv2D layer at 1\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c8c64ce40>, <__main__.Block object at 0x7d4c8c5b9480>, <__main__.Block object at 0x7d4c63981980>, <__main__.Block object at 0x7d4c639ea9c0>, <__main__.Block object at 0x7d47dbbd5000>, <__main__.Block object at 0x7d47e840be00>, <__main__.Block object at 0x7d4bf99f7a80>, <__main__.Block object at 0x7d4c63947140>, <__main__.Block object at 0x7d47dbfce080>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_286. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_288. Consider increasing the input size. Received input shape [None, 1, 1, 512] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_289. Consider increasing the input size. Received input shape [None, 1, 1, 512] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_293. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_68\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_68/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_68\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 2)]\n",
      "Inserting a Pooling layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.30000000000000004\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e9a87b40>, <__main__.Block object at 0x7d47e9a87e00>, <__main__.Block object at 0x7d47e9a84c00>, <__main__.Block object at 0x7d47e9a848c0>, <__main__.Block object at 0x7d47e9a85c80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:12:58.404058: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_34/dropout_21/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 6s 10ms/step - loss: 3.1197 - accuracy: 0.0762 - val_loss: 2.8857 - val_accuracy: 0.1250\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.8670 - accuracy: 0.1643 - val_loss: 3.4273 - val_accuracy: 0.1740\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.6942 - accuracy: 0.2649 - val_loss: 2.8887 - val_accuracy: 0.2130\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 3.0415 - accuracy: 0.3010 - val_loss: 2.8111 - val_accuracy: 0.2125\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.8951 - accuracy: 0.3265 - val_loss: 2.4762 - val_accuracy: 0.2765\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.7211 - accuracy: 0.3474 - val_loss: 3.1643 - val_accuracy: 0.2550\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.5437 - accuracy: 0.3579 - val_loss: 4.0699 - val_accuracy: 0.1595\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.7684 - accuracy: 0.3642 - val_loss: 3.1046 - val_accuracy: 0.2345\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.1160 - accuracy: 0.3733 - val_loss: 2.2565 - val_accuracy: 0.3885\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.1697 - accuracy: 0.3853 - val_loss: 3.4935 - val_accuracy: 0.2460\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.1656 - accuracy: 0.3703 - val_loss: 2.4262 - val_accuracy: 0.3410\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.7044 - accuracy: 0.3764 - val_loss: 3.0391 - val_accuracy: 0.2125\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.1469 - accuracy: 0.3713 - val_loss: 2.8302 - val_accuracy: 0.3460\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.1457 - accuracy: 0.3787 - val_loss: 2.7174 - val_accuracy: 0.3835\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.4045 - accuracy: 0.3816 - val_loss: 3.3370 - val_accuracy: 0.1855\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 3.4266 - accuracy: 0.3852 - val_loss: 3.5822 - val_accuracy: 0.2980\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 2.6422 - accuracy: 0.3714 - val_loss: 3.1998 - val_accuracy: 0.2170\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 5.1714 - accuracy: 0.3727 - val_loss: 7.5184 - val_accuracy: 0.1485\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 2.1857 - accuracy: 0.3672 - val_loss: 2.5630 - val_accuracy: 0.4110\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.1989 - accuracy: 0.3691 - val_loss: 2.5814 - val_accuracy: 0.3075\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 4.2828 - accuracy: 0.3409 - val_loss: 3.4905 - val_accuracy: 0.2730\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 6.0876 - accuracy: 0.3544 - val_loss: 4.6787 - val_accuracy: 0.2895\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.7321 - accuracy: 0.3554 - val_loss: 4.4854 - val_accuracy: 0.1275\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.2698 - accuracy: 0.3521 - val_loss: 3.2761 - val_accuracy: 0.2940\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.2535 - accuracy: 0.3479 - val_loss: 2.6442 - val_accuracy: 0.3610\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.1868 - accuracy: 0.3661 - val_loss: 3.0638 - val_accuracy: 0.3600\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.1709 - accuracy: 0.3684 - val_loss: 3.0667 - val_accuracy: 0.3425\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.5758 - accuracy: 0.3660 - val_loss: 4.1624 - val_accuracy: 0.2265\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 3.5721 - accuracy: 0.3425 - val_loss: 5.8675 - val_accuracy: 0.2275\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 5.0466 - accuracy: 0.3339 - val_loss: 5.7359 - val_accuracy: 0.2345\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 5.046573638916016\n",
      "Training Accuracy: 0.3338896334171295\n",
      "Validation Loss: 5.73585844039917\n",
      "Validation Accuracy: 0.2345000058412552\n",
      "Classification Error Rate: 0.7654999941587448\n",
      "----->Evolution: Child net_13 with fitness 5.73585844039917 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 5\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Tournament selection\n",
      "Selected net_6 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e8bb6fc0>, <__main__.Block object at 0x7d4c8c0ca500>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 3s 5ms/step - loss: 3.3388 - accuracy: 0.2205 - val_loss: 2.1592 - val_accuracy: 0.3580\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.9901 - accuracy: 0.4002 - val_loss: 1.7992 - val_accuracy: 0.4625\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.6880 - accuracy: 0.4951 - val_loss: 1.7676 - val_accuracy: 0.4885\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.4369 - accuracy: 0.5657 - val_loss: 2.0502 - val_accuracy: 0.4865\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.2208 - accuracy: 0.6266 - val_loss: 1.7517 - val_accuracy: 0.5285\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.0054 - accuracy: 0.6894 - val_loss: 2.4151 - val_accuracy: 0.4455\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.7899 - accuracy: 0.7550 - val_loss: 2.1200 - val_accuracy: 0.5095\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.6180 - accuracy: 0.8118 - val_loss: 2.4139 - val_accuracy: 0.5175\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.4750 - accuracy: 0.8491 - val_loss: 2.6304 - val_accuracy: 0.5260\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.3557 - accuracy: 0.8845 - val_loss: 2.9700 - val_accuracy: 0.5300\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.2914 - accuracy: 0.9059 - val_loss: 3.3370 - val_accuracy: 0.5140\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.2196 - accuracy: 0.9288 - val_loss: 4.3520 - val_accuracy: 0.4925\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1901 - accuracy: 0.9430 - val_loss: 4.0571 - val_accuracy: 0.5295\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1652 - accuracy: 0.9503 - val_loss: 4.3822 - val_accuracy: 0.5025\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1482 - accuracy: 0.9542 - val_loss: 4.8258 - val_accuracy: 0.5265\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1529 - accuracy: 0.9512 - val_loss: 5.9467 - val_accuracy: 0.5160\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1321 - accuracy: 0.9636 - val_loss: 5.5477 - val_accuracy: 0.5235\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1321 - accuracy: 0.9614 - val_loss: 5.0064 - val_accuracy: 0.4980\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1086 - accuracy: 0.9694 - val_loss: 7.2379 - val_accuracy: 0.4930\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1159 - accuracy: 0.9688 - val_loss: 6.5040 - val_accuracy: 0.5225\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1012 - accuracy: 0.9721 - val_loss: 6.3934 - val_accuracy: 0.5045\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1131 - accuracy: 0.9696 - val_loss: 6.8114 - val_accuracy: 0.5305\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1187 - accuracy: 0.9712 - val_loss: 6.9597 - val_accuracy: 0.5125\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1182 - accuracy: 0.9717 - val_loss: 7.9811 - val_accuracy: 0.5305\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1136 - accuracy: 0.9734 - val_loss: 8.0246 - val_accuracy: 0.5225\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1181 - accuracy: 0.9731 - val_loss: 8.0319 - val_accuracy: 0.5305\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0994 - accuracy: 0.9762 - val_loss: 8.3665 - val_accuracy: 0.5205\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1039 - accuracy: 0.9777 - val_loss: 8.8314 - val_accuracy: 0.5175\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1078 - accuracy: 0.9752 - val_loss: 8.6198 - val_accuracy: 0.4900\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0928 - accuracy: 0.9786 - val_loss: 8.9976 - val_accuracy: 0.5180\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.0927918329834938\n",
      "Training Accuracy: 0.9786168932914734\n",
      "Validation Loss: 8.997607231140137\n",
      "Validation Accuracy: 0.5180000066757202\n",
      "Classification Error Rate: 0.4819999933242798\n",
      "----->Evolution: Child net_10 with fitness 8.997607231140137 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Tournament selection\n",
      "Selected net_8 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e9856900>, <__main__.Block object at 0x7d47e91390c0>, <__main__.Block object at 0x7d47e86d8c00>, <__main__.Block object at 0x7d47e92e0880>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 5s 9ms/step - loss: 2.9402 - accuracy: 0.1776 - val_loss: 2.7805 - val_accuracy: 0.2315\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.0779 - accuracy: 0.3799 - val_loss: 1.8263 - val_accuracy: 0.4570\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.7035 - accuracy: 0.4931 - val_loss: 1.6968 - val_accuracy: 0.4890\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.3816 - accuracy: 0.5817 - val_loss: 1.5893 - val_accuracy: 0.5505\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1122 - accuracy: 0.6678 - val_loss: 1.6534 - val_accuracy: 0.5830\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8571 - accuracy: 0.7415 - val_loss: 1.6754 - val_accuracy: 0.6030\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6354 - accuracy: 0.8074 - val_loss: 2.0719 - val_accuracy: 0.5705\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5083 - accuracy: 0.8525 - val_loss: 2.2551 - val_accuracy: 0.6060\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4172 - accuracy: 0.8817 - val_loss: 2.5867 - val_accuracy: 0.5905\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4173 - accuracy: 0.8879 - val_loss: 2.4334 - val_accuracy: 0.6140\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3764 - accuracy: 0.9057 - val_loss: 4.2011 - val_accuracy: 0.5970\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3631 - accuracy: 0.9118 - val_loss: 3.8605 - val_accuracy: 0.6150\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3814 - accuracy: 0.9107 - val_loss: 3.2688 - val_accuracy: 0.5840\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3978 - accuracy: 0.9146 - val_loss: 8.0321 - val_accuracy: 0.5475\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4067 - accuracy: 0.9181 - val_loss: 4.6433 - val_accuracy: 0.5980\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4523 - accuracy: 0.9124 - val_loss: 4.7873 - val_accuracy: 0.5825\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4269 - accuracy: 0.9199 - val_loss: 5.3965 - val_accuracy: 0.5840\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.3974 - accuracy: 0.9254 - val_loss: 5.7961 - val_accuracy: 0.5895\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5001 - accuracy: 0.9125 - val_loss: 9.0407 - val_accuracy: 0.5935\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4802 - accuracy: 0.9201 - val_loss: 7.1507 - val_accuracy: 0.5835\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6276 - accuracy: 0.9079 - val_loss: 4.9294 - val_accuracy: 0.4640\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5386 - accuracy: 0.9170 - val_loss: 7.8488 - val_accuracy: 0.6160\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5976 - accuracy: 0.9173 - val_loss: 14.8579 - val_accuracy: 0.6125\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6346 - accuracy: 0.9233 - val_loss: 7.4659 - val_accuracy: 0.6035\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6441 - accuracy: 0.9142 - val_loss: 9.2936 - val_accuracy: 0.6275\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6702 - accuracy: 0.9133 - val_loss: 10.5555 - val_accuracy: 0.6305\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6988 - accuracy: 0.9127 - val_loss: 11.6143 - val_accuracy: 0.5715\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7466 - accuracy: 0.9138 - val_loss: 5.4241 - val_accuracy: 0.5215\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7387 - accuracy: 0.9107 - val_loss: 8.0381 - val_accuracy: 0.5955\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7319 - accuracy: 0.9078 - val_loss: 13.2768 - val_accuracy: 0.6135\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 0.7318915724754333\n",
      "Training Accuracy: 0.907791793346405\n",
      "Validation Loss: 13.276798248291016\n",
      "Validation Accuracy: 0.6134999990463257\n",
      "Classification Error Rate: 0.3865000009536743\n",
      "----->Evolution: Child net_11 with fitness 13.276798248291016 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Tournament selection\n",
      "Selected parent_0 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  256.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47c85bbd80>, <__main__.Block object at 0x7d47c8405a00>, <__main__.Block object at 0x7d47c8675940>, <__main__.Block object at 0x7d47c8503800>, <__main__.Block object at 0x7d47c86ad840>, <__main__.Block object at 0x7d47c86e39c0>, <__main__.Block object at 0x7d47c850f1c0>, <__main__.Block object at 0x7d47e7de1600>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_314\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_314/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_314/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,32], [3,3,32,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_314\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 32), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_318. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_319. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_91\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_91/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,64].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_91\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 64), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  1024  to  2048\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47c8417f80>, <__main__.Block object at 0x7d47c8416cc0>, <__main__.Block object at 0x7d47c8417d40>, <__main__.Block object at 0x7d47c8414c00>, <__main__.Block object at 0x7d47c8417780>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 5s 8ms/step - loss: 3.1738 - accuracy: 0.1141 - val_loss: 2.6431 - val_accuracy: 0.2065\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.4271 - accuracy: 0.2716 - val_loss: 2.2565 - val_accuracy: 0.3230\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.0924 - accuracy: 0.3658 - val_loss: 2.0610 - val_accuracy: 0.3855\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.8756 - accuracy: 0.4307 - val_loss: 1.9177 - val_accuracy: 0.4340\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.6900 - accuracy: 0.4860 - val_loss: 1.7970 - val_accuracy: 0.4740\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4978 - accuracy: 0.5365 - val_loss: 1.7345 - val_accuracy: 0.5100\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3020 - accuracy: 0.5911 - val_loss: 1.9807 - val_accuracy: 0.4980\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0906 - accuracy: 0.6569 - val_loss: 2.1461 - val_accuracy: 0.4850\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8888 - accuracy: 0.7183 - val_loss: 2.0241 - val_accuracy: 0.5020\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.7152 - accuracy: 0.7751 - val_loss: 2.5931 - val_accuracy: 0.5210\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.6197 - accuracy: 0.8094 - val_loss: 2.9477 - val_accuracy: 0.5215\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5197 - accuracy: 0.8476 - val_loss: 3.0576 - val_accuracy: 0.5025\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4920 - accuracy: 0.8597 - val_loss: 2.9567 - val_accuracy: 0.4900\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4813 - accuracy: 0.8673 - val_loss: 4.0503 - val_accuracy: 0.5285\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4831 - accuracy: 0.8707 - val_loss: 4.1637 - val_accuracy: 0.4730\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4824 - accuracy: 0.8757 - val_loss: 4.1225 - val_accuracy: 0.5190\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4589 - accuracy: 0.8851 - val_loss: 3.6594 - val_accuracy: 0.5205\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4622 - accuracy: 0.8846 - val_loss: 4.4317 - val_accuracy: 0.4815\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4602 - accuracy: 0.8896 - val_loss: 4.3402 - val_accuracy: 0.5125\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4714 - accuracy: 0.8832 - val_loss: 4.9883 - val_accuracy: 0.5395\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4392 - accuracy: 0.8967 - val_loss: 5.4550 - val_accuracy: 0.5105\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4567 - accuracy: 0.8914 - val_loss: 6.0247 - val_accuracy: 0.4985\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4761 - accuracy: 0.8960 - val_loss: 6.1148 - val_accuracy: 0.4800\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4895 - accuracy: 0.8906 - val_loss: 5.4172 - val_accuracy: 0.4895\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4927 - accuracy: 0.8938 - val_loss: 4.9135 - val_accuracy: 0.5095\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5507 - accuracy: 0.8825 - val_loss: 4.5053 - val_accuracy: 0.4995\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5548 - accuracy: 0.8828 - val_loss: 5.1129 - val_accuracy: 0.4990\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5700 - accuracy: 0.8883 - val_loss: 5.5464 - val_accuracy: 0.4750\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5449 - accuracy: 0.8925 - val_loss: 7.9856 - val_accuracy: 0.5205\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5947 - accuracy: 0.8882 - val_loss: 6.4155 - val_accuracy: 0.4730\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 0.5946987271308899\n",
      "Training Accuracy: 0.8881819248199463\n",
      "Validation Loss: 6.415524482727051\n",
      "Validation Accuracy: 0.4729999899864197\n",
      "Classification Error Rate: 0.5270000100135803\n",
      "----->Evolution: Child net_12 with fitness 6.415524482727051 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Tournament selection\n",
      "Selected parent_0 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e17f6ac0>, <__main__.Block object at 0x7d47e16f5a00>, <__main__.Block object at 0x7d47e16f4f00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 6s 12ms/step - loss: 7.8339 - accuracy: 0.1304 - val_loss: 30.7180 - val_accuracy: 0.0500\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 10.5957 - accuracy: 0.3328 - val_loss: 14.8033 - val_accuracy: 0.1000\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 14.6565 - accuracy: 0.4770 - val_loss: 9.3263 - val_accuracy: 0.1355\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 18.8218 - accuracy: 0.5660 - val_loss: 9.4569 - val_accuracy: 0.2595\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 16.2947 - accuracy: 0.6757 - val_loss: 4.7712 - val_accuracy: 0.4380\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 17.5207 - accuracy: 0.7595 - val_loss: 6.4773 - val_accuracy: 0.4365\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 24.1237 - accuracy: 0.8347 - val_loss: 13.6695 - val_accuracy: 0.4150\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 22.6499 - accuracy: 0.8761 - val_loss: 9.1409 - val_accuracy: 0.4850\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 24.2766 - accuracy: 0.8978 - val_loss: 9.8993 - val_accuracy: 0.4715\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 38.2333 - accuracy: 0.9100 - val_loss: 15.1673 - val_accuracy: 0.4670\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 44.3808 - accuracy: 0.9251 - val_loss: 17.5621 - val_accuracy: 0.4790\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 29.4773 - accuracy: 0.9338 - val_loss: 16.5389 - val_accuracy: 0.4855\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 30.7676 - accuracy: 0.9368 - val_loss: 19.8383 - val_accuracy: 0.4610\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 32.7835 - accuracy: 0.9377 - val_loss: 24.5658 - val_accuracy: 0.4795\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 60.6159 - accuracy: 0.9412 - val_loss: 21.9447 - val_accuracy: 0.4715\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 38.8265 - accuracy: 0.9389 - val_loss: 20.9704 - val_accuracy: 0.4935\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 50.1000 - accuracy: 0.9483 - val_loss: 19.6152 - val_accuracy: 0.5105\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 57.8769 - accuracy: 0.9454 - val_loss: 25.2458 - val_accuracy: 0.5220\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 42.7086 - accuracy: 0.9514 - val_loss: 24.4332 - val_accuracy: 0.5280\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 67.1407 - accuracy: 0.9530 - val_loss: 25.2314 - val_accuracy: 0.4920\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 63.7324 - accuracy: 0.9494 - val_loss: 38.4118 - val_accuracy: 0.5090\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 58.4958 - accuracy: 0.9555 - val_loss: 38.9774 - val_accuracy: 0.4955\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 65.8782 - accuracy: 0.9618 - val_loss: 39.9687 - val_accuracy: 0.5195\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 89.2908 - accuracy: 0.9590 - val_loss: 42.9875 - val_accuracy: 0.5120\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 180.5888 - accuracy: 0.9589 - val_loss: 44.1181 - val_accuracy: 0.5270\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 114.6380 - accuracy: 0.9595 - val_loss: 55.2196 - val_accuracy: 0.5010\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 157.4025 - accuracy: 0.9579 - val_loss: 51.2543 - val_accuracy: 0.5350\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 61.2151 - accuracy: 0.9689 - val_loss: 64.5154 - val_accuracy: 0.4975\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 88.5003 - accuracy: 0.9628 - val_loss: 67.2661 - val_accuracy: 0.4750\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 142.8562 - accuracy: 0.9616 - val_loss: 60.9070 - val_accuracy: 0.5325\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 142.85623168945312\n",
      "Training Accuracy: 0.9616146683692932\n",
      "Validation Loss: 60.90700149536133\n",
      "Validation Accuracy: 0.5325000286102295\n",
      "Classification Error Rate: 0.4674999713897705\n",
      "----->Evolution: Child net_13 with fitness 60.90700149536133 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 6\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Tournament selection\n",
      "Selected net_4 and net_6 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e7838880>, <__main__.Block object at 0x7d47e78d2500>, <__main__.Block object at 0x7d47e79707c0>, <__main__.Block object at 0x7d47e7816ac0>, <__main__.Block object at 0x7d47e79bdc40>, <__main__.Block object at 0x7d47e781f240>, <__main__.Block object at 0x7d47e78ed740>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_339\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_339/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_339/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,512].\n",
      "\n",
      "Call arguments received by layer \"conv2d_339\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_341\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_341/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_341/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,512], [3,3,512,512].\n",
      "\n",
      "Call arguments received by layer \"conv2d_341\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 512), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_342\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_342/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_342/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,512], [3,3,512,512].\n",
      "\n",
      "Call arguments received by layer \"conv2d_342\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 512), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:19:16.810530: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_40/dropout_22/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 9ms/step - loss: 2.9391 - accuracy: 0.1127 - val_loss: 2.4830 - val_accuracy: 0.2605\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.3621 - accuracy: 0.2801 - val_loss: 2.6273 - val_accuracy: 0.2250\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.0716 - accuracy: 0.3712 - val_loss: 2.0774 - val_accuracy: 0.3755\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.8973 - accuracy: 0.4344 - val_loss: 3.0762 - val_accuracy: 0.2700\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.7567 - accuracy: 0.4714 - val_loss: 1.9593 - val_accuracy: 0.4255\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.6270 - accuracy: 0.5157 - val_loss: 1.9726 - val_accuracy: 0.4195\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.5161 - accuracy: 0.5456 - val_loss: 2.7433 - val_accuracy: 0.3875\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4156 - accuracy: 0.5758 - val_loss: 1.7080 - val_accuracy: 0.4995\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3509 - accuracy: 0.5964 - val_loss: 1.8998 - val_accuracy: 0.4310\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2676 - accuracy: 0.6181 - val_loss: 1.9957 - val_accuracy: 0.4430\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2319 - accuracy: 0.6284 - val_loss: 1.6544 - val_accuracy: 0.5250\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1548 - accuracy: 0.6482 - val_loss: 1.9545 - val_accuracy: 0.4875\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1419 - accuracy: 0.6608 - val_loss: 1.7342 - val_accuracy: 0.5090\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1203 - accuracy: 0.6681 - val_loss: 2.1060 - val_accuracy: 0.4650\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1018 - accuracy: 0.6788 - val_loss: 1.9240 - val_accuracy: 0.4570\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1377 - accuracy: 0.6865 - val_loss: 2.7015 - val_accuracy: 0.4120\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1188 - accuracy: 0.6831 - val_loss: 2.0828 - val_accuracy: 0.4345\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1036 - accuracy: 0.6853 - val_loss: 2.1929 - val_accuracy: 0.5090\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0924 - accuracy: 0.6939 - val_loss: 1.9317 - val_accuracy: 0.5005\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1364 - accuracy: 0.6960 - val_loss: 2.1616 - val_accuracy: 0.5160\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1093 - accuracy: 0.6901 - val_loss: 2.3019 - val_accuracy: 0.4885\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1092 - accuracy: 0.6993 - val_loss: 2.2791 - val_accuracy: 0.4740\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1474 - accuracy: 0.6923 - val_loss: 2.7574 - val_accuracy: 0.4130\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1238 - accuracy: 0.7012 - val_loss: 2.1851 - val_accuracy: 0.5050\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1422 - accuracy: 0.6861 - val_loss: 2.6337 - val_accuracy: 0.4940\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1500 - accuracy: 0.6986 - val_loss: 2.2687 - val_accuracy: 0.4585\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1310 - accuracy: 0.7001 - val_loss: 2.5744 - val_accuracy: 0.4410\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1659 - accuracy: 0.7014 - val_loss: 3.8014 - val_accuracy: 0.3920\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1581 - accuracy: 0.7060 - val_loss: 3.0942 - val_accuracy: 0.4795\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0867 - accuracy: 0.7086 - val_loss: 3.0998 - val_accuracy: 0.5170\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 1.0866966247558594\n",
      "Training Accuracy: 0.7085636854171753\n",
      "Validation Loss: 3.0998058319091797\n",
      "Validation Accuracy: 0.5170000195503235\n",
      "Classification Error Rate: 0.4829999804496765\n",
      "----->Evolution: Child net_10 with fitness 3.0998058319091797 replaces parent net_8 with fitness 3.5387661457061768\n",
      "\n",
      "Creating Child 1\n",
      "----->Tournament selection\n",
      "Selected net_4 and net_6 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c10b6dd40>, <__main__.Block object at 0x7d47e731da00>, <__main__.Block object at 0x7d47e75d4300>, <__main__.Block object at 0x7d4c10bb0d80>, <__main__.Block object at 0x7d4c10bb2e40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_347\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_347/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_347/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,64], [3,3,64,64].\n",
      "\n",
      "Call arguments received by layer \"conv2d_347\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 64), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_348. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 4s 8ms/step - loss: 2.5778 - accuracy: 0.2120 - val_loss: 3.3998 - val_accuracy: 0.2635\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.9578 - accuracy: 0.4019 - val_loss: 3.5695 - val_accuracy: 0.2595\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.6553 - accuracy: 0.4935 - val_loss: 2.0531 - val_accuracy: 0.4375\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.4430 - accuracy: 0.5567 - val_loss: 1.6076 - val_accuracy: 0.5175\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.2972 - accuracy: 0.6050 - val_loss: 1.8013 - val_accuracy: 0.4900\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.1722 - accuracy: 0.6418 - val_loss: 2.2826 - val_accuracy: 0.4635\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.0673 - accuracy: 0.6708 - val_loss: 2.4676 - val_accuracy: 0.4350\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.9837 - accuracy: 0.7031 - val_loss: 2.6883 - val_accuracy: 0.5065\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.9225 - accuracy: 0.7198 - val_loss: 3.8352 - val_accuracy: 0.4520\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8673 - accuracy: 0.7423 - val_loss: 4.1865 - val_accuracy: 0.4255\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8076 - accuracy: 0.7564 - val_loss: 2.0712 - val_accuracy: 0.5595\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8171 - accuracy: 0.7644 - val_loss: 2.9834 - val_accuracy: 0.5040\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7345 - accuracy: 0.7859 - val_loss: 2.3431 - val_accuracy: 0.5550\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7414 - accuracy: 0.7876 - val_loss: 6.3053 - val_accuracy: 0.4000\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7687 - accuracy: 0.7914 - val_loss: 6.5762 - val_accuracy: 0.4100\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7374 - accuracy: 0.8061 - val_loss: 7.1222 - val_accuracy: 0.3855\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7166 - accuracy: 0.8071 - val_loss: 3.6544 - val_accuracy: 0.4985\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7197 - accuracy: 0.8046 - val_loss: 3.7358 - val_accuracy: 0.5060\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7570 - accuracy: 0.8089 - val_loss: 5.2204 - val_accuracy: 0.5175\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.6996 - accuracy: 0.8228 - val_loss: 4.4945 - val_accuracy: 0.5070\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.6946 - accuracy: 0.8167 - val_loss: 5.8583 - val_accuracy: 0.5395\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7569 - accuracy: 0.8190 - val_loss: 10.0121 - val_accuracy: 0.4585\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7216 - accuracy: 0.8226 - val_loss: 5.4563 - val_accuracy: 0.5175\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7463 - accuracy: 0.8328 - val_loss: 4.7989 - val_accuracy: 0.4790\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.6574 - accuracy: 0.8415 - val_loss: 9.6504 - val_accuracy: 0.5285\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.6992 - accuracy: 0.8402 - val_loss: 3.8975 - val_accuracy: 0.5390\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.6907 - accuracy: 0.8337 - val_loss: 3.8142 - val_accuracy: 0.5230\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.6910 - accuracy: 0.8325 - val_loss: 4.3763 - val_accuracy: 0.5885\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7074 - accuracy: 0.8379 - val_loss: 6.9931 - val_accuracy: 0.5110\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7156 - accuracy: 0.8425 - val_loss: 8.9512 - val_accuracy: 0.5125\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 0.7156403660774231\n",
      "Training Accuracy: 0.8424950242042542\n",
      "Validation Loss: 8.951248168945312\n",
      "Validation Accuracy: 0.512499988079071\n",
      "Classification Error Rate: 0.48750001192092896\n",
      "----->Evolution: Child net_11 with fitness 8.951248168945312 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Tournament selection\n",
      "Selected net_9 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e77521c0>, <__main__.Block object at 0x7d47e1e9da00>, <__main__.Block object at 0x7d47e1f96940>, <__main__.Block object at 0x7d47e22bc800>, <__main__.Block object at 0x7d47e1ffeac0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:21:24.577435: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_42/dropout_23/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 9ms/step - loss: 2.7918 - accuracy: 0.1622 - val_loss: 5.0951 - val_accuracy: 0.1410\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.2645 - accuracy: 0.3298 - val_loss: 2.3556 - val_accuracy: 0.3060\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.9181 - accuracy: 0.4344 - val_loss: 2.3788 - val_accuracy: 0.3865\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.6799 - accuracy: 0.5079 - val_loss: 1.9503 - val_accuracy: 0.4690\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.5146 - accuracy: 0.5833 - val_loss: 2.4201 - val_accuracy: 0.4450\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2459 - accuracy: 0.6408 - val_loss: 2.2188 - val_accuracy: 0.4880\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.0659 - accuracy: 0.6912 - val_loss: 1.9628 - val_accuracy: 0.4985\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8781 - accuracy: 0.7479 - val_loss: 1.9621 - val_accuracy: 0.5660\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7319 - accuracy: 0.7899 - val_loss: 2.0209 - val_accuracy: 0.5710\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.6088 - accuracy: 0.8259 - val_loss: 2.4021 - val_accuracy: 0.6310\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.7483 - accuracy: 0.8557 - val_loss: 2.4799 - val_accuracy: 0.5820\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6638 - accuracy: 0.8802 - val_loss: 2.9525 - val_accuracy: 0.5675\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5449 - accuracy: 0.8935 - val_loss: 3.2974 - val_accuracy: 0.5970\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4948 - accuracy: 0.9059 - val_loss: 2.7767 - val_accuracy: 0.5570\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4671 - accuracy: 0.9104 - val_loss: 2.6106 - val_accuracy: 0.5850\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4645 - accuracy: 0.9186 - val_loss: 3.3057 - val_accuracy: 0.5810\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3953 - accuracy: 0.9294 - val_loss: 4.3466 - val_accuracy: 0.5660\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3959 - accuracy: 0.9252 - val_loss: 3.1243 - val_accuracy: 0.6150\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3535 - accuracy: 0.9307 - val_loss: 4.4900 - val_accuracy: 0.5735\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8625 - accuracy: 0.9325 - val_loss: 4.1719 - val_accuracy: 0.6180\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3927 - accuracy: 0.9332 - val_loss: 3.2632 - val_accuracy: 0.5755\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4440 - accuracy: 0.9315 - val_loss: 4.6659 - val_accuracy: 0.5790\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4794 - accuracy: 0.9385 - val_loss: 3.9382 - val_accuracy: 0.5270\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3897 - accuracy: 0.9362 - val_loss: 3.7335 - val_accuracy: 0.5550\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5164 - accuracy: 0.9298 - val_loss: 4.8099 - val_accuracy: 0.6020\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5924 - accuracy: 0.9350 - val_loss: 4.4607 - val_accuracy: 0.5770\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4393 - accuracy: 0.9363 - val_loss: 5.3967 - val_accuracy: 0.6315\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7731 - accuracy: 0.9326 - val_loss: 3.6668 - val_accuracy: 0.6010\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4267 - accuracy: 0.9376 - val_loss: 6.3915 - val_accuracy: 0.5830\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5754 - accuracy: 0.9335 - val_loss: 5.1622 - val_accuracy: 0.5645\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 0.5754218697547913\n",
      "Training Accuracy: 0.9334515333175659\n",
      "Validation Loss: 5.162158489227295\n",
      "Validation Accuracy: 0.5644999742507935\n",
      "Classification Error Rate: 0.43550002574920654\n",
      "----->Evolution: Child net_12 with fitness 5.162158489227295 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Tournament selection\n",
      "Selected net_5 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e1687600>, <__main__.Block object at 0x7d47e15c6940>, <__main__.Block object at 0x7d47e1bd8c00>, <__main__.Block object at 0x7d47e1592500>, <__main__.Block object at 0x7d47e167b880>, <__main__.Block object at 0x7d47e163b7c0>, <__main__.Block object at 0x7d47e165e5c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_365. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:22:49.009282: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_43/dropout_24/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 8s 12ms/step - loss: 2.8810 - accuracy: 0.1224 - val_loss: 2.7508 - val_accuracy: 0.1245\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.4806 - accuracy: 0.2507 - val_loss: 3.8624 - val_accuracy: 0.2140\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.3572 - accuracy: 0.3430 - val_loss: 2.3150 - val_accuracy: 0.3735\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.6124 - accuracy: 0.3953 - val_loss: 2.1887 - val_accuracy: 0.3635\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.9703 - accuracy: 0.4288 - val_loss: 2.6030 - val_accuracy: 0.4355\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.5218 - accuracy: 0.4656 - val_loss: 2.1685 - val_accuracy: 0.4150\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.5038 - accuracy: 0.4971 - val_loss: 2.4345 - val_accuracy: 0.3950\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.7956 - accuracy: 0.5220 - val_loss: 2.0458 - val_accuracy: 0.4275\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.9948 - accuracy: 0.5493 - val_loss: 1.8199 - val_accuracy: 0.4925\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.9191 - accuracy: 0.5680 - val_loss: 2.6813 - val_accuracy: 0.4335\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.0639 - accuracy: 0.5900 - val_loss: 3.7946 - val_accuracy: 0.4430\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 3.7930 - accuracy: 0.6027 - val_loss: 1.9253 - val_accuracy: 0.4820\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.4846 - accuracy: 0.6158 - val_loss: 2.2066 - val_accuracy: 0.4700\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.2021 - accuracy: 0.6288 - val_loss: 2.1120 - val_accuracy: 0.4820\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.3579 - accuracy: 0.6413 - val_loss: 2.0485 - val_accuracy: 0.4370\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.9470 - accuracy: 0.6497 - val_loss: 1.8947 - val_accuracy: 0.4740\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.3770 - accuracy: 0.6626 - val_loss: 1.9667 - val_accuracy: 0.4950\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.1419 - accuracy: 0.6674 - val_loss: 2.1314 - val_accuracy: 0.4610\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.8436 - accuracy: 0.6815 - val_loss: 2.3541 - val_accuracy: 0.5210\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.4374 - accuracy: 0.6855 - val_loss: 2.2640 - val_accuracy: 0.4960\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.8927 - accuracy: 0.6863 - val_loss: 3.0613 - val_accuracy: 0.5190\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 6.1887 - accuracy: 0.6983 - val_loss: 2.0102 - val_accuracy: 0.5090\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 17.7878 - accuracy: 0.6909 - val_loss: 2.1450 - val_accuracy: 0.4775\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 8.6355 - accuracy: 0.6954 - val_loss: 2.1635 - val_accuracy: 0.4865\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 3.2578 - accuracy: 0.7072 - val_loss: 2.9185 - val_accuracy: 0.4965\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 9.1761 - accuracy: 0.7091 - val_loss: 3.7719 - val_accuracy: 0.4905\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 8.1165 - accuracy: 0.7178 - val_loss: 4.9747 - val_accuracy: 0.4570\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 5.0626 - accuracy: 0.7146 - val_loss: 6.0491 - val_accuracy: 0.4960\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 14.9753 - accuracy: 0.7199 - val_loss: 4.1736 - val_accuracy: 0.4390\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 10.3348 - accuracy: 0.7068 - val_loss: 4.5578 - val_accuracy: 0.5020\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 10.3347749710083\n",
      "Training Accuracy: 0.7067904472351074\n",
      "Validation Loss: 4.557821273803711\n",
      "Validation Accuracy: 0.5019999742507935\n",
      "Classification Error Rate: 0.49800002574920654\n",
      "----->Evolution: Child net_13 with fitness 4.557821273803711 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 7\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_4 and net_6 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.35000000000000003  to  0.30000000000000004\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  256.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e8b1a740>, <__main__.Block object at 0x7d47c87ca500>, <__main__.Block object at 0x7d47e81587c0>, <__main__.Block object at 0x7d47e21300c0>, <__main__.Block object at 0x7d47e7a3e5c0>, <__main__.Block object at 0x7d4c8c6fe640>, <__main__.Block object at 0x7d47e1a17240>, <__main__.Block object at 0x7d47e7d92e40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_107\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_107/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_107\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2)]\n",
      "Inserting a Pooling layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.35000000000000003  to  0.4\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf963e9c0>, <__main__.Block object at 0x7d4bf963e540>, <__main__.Block object at 0x7d4bf963f900>, <__main__.Block object at 0x7d4bf963ef00>, <__main__.Block object at 0x7d4bf963c700>, <__main__.Block object at 0x7d4bf963e500>, <__main__.Block object at 0x7d4bf963ed40>, <__main__.Block object at 0x7d4bf963e980>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_386\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_386/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_386/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_386\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_387\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_387/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_387/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_387\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:24:29.083263: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_45/dropout_26/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 7s 11ms/step - loss: 3.0164 - accuracy: 0.0520 - val_loss: 2.9900 - val_accuracy: 0.0485\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.9655 - accuracy: 0.0813 - val_loss: 2.7280 - val_accuracy: 0.1195\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.6563 - accuracy: 0.1565 - val_loss: 2.5855 - val_accuracy: 0.1890\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.4516 - accuracy: 0.2299 - val_loss: 2.5501 - val_accuracy: 0.2140\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.2553 - accuracy: 0.3002 - val_loss: 2.2104 - val_accuracy: 0.3070\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.0708 - accuracy: 0.3673 - val_loss: 2.1076 - val_accuracy: 0.3660\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.9513 - accuracy: 0.4046 - val_loss: 1.8357 - val_accuracy: 0.4400\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.8525 - accuracy: 0.4445 - val_loss: 1.8809 - val_accuracy: 0.4420\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.7657 - accuracy: 0.4748 - val_loss: 2.3839 - val_accuracy: 0.3380\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.6601 - accuracy: 0.5065 - val_loss: 1.9654 - val_accuracy: 0.4245\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.5764 - accuracy: 0.5347 - val_loss: 1.6999 - val_accuracy: 0.5075\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.4694 - accuracy: 0.5655 - val_loss: 2.2475 - val_accuracy: 0.4560\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.3990 - accuracy: 0.5853 - val_loss: 1.6693 - val_accuracy: 0.5225\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.3186 - accuracy: 0.6130 - val_loss: 1.7635 - val_accuracy: 0.5195\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.2760 - accuracy: 0.6279 - val_loss: 1.7172 - val_accuracy: 0.5490\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.2041 - accuracy: 0.6502 - val_loss: 1.4215 - val_accuracy: 0.5970\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.1588 - accuracy: 0.6688 - val_loss: 1.5621 - val_accuracy: 0.5855\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.1356 - accuracy: 0.6782 - val_loss: 1.5423 - val_accuracy: 0.5855\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.1055 - accuracy: 0.6965 - val_loss: 1.7678 - val_accuracy: 0.5480\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0611 - accuracy: 0.7037 - val_loss: 1.4881 - val_accuracy: 0.5835\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0294 - accuracy: 0.7214 - val_loss: 1.8577 - val_accuracy: 0.5815\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.9999 - accuracy: 0.7224 - val_loss: 1.5105 - val_accuracy: 0.5980\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.9958 - accuracy: 0.7278 - val_loss: 1.5811 - val_accuracy: 0.5930\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0026 - accuracy: 0.7302 - val_loss: 1.6092 - val_accuracy: 0.6115\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.9907 - accuracy: 0.7383 - val_loss: 1.8961 - val_accuracy: 0.5985\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0574 - accuracy: 0.7392 - val_loss: 1.7643 - val_accuracy: 0.5855\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.9807 - accuracy: 0.7431 - val_loss: 1.4803 - val_accuracy: 0.6270\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0210 - accuracy: 0.7408 - val_loss: 1.9574 - val_accuracy: 0.5810\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0760 - accuracy: 0.7366 - val_loss: 1.6272 - val_accuracy: 0.5965\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0377 - accuracy: 0.7467 - val_loss: 1.6142 - val_accuracy: 0.6275\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 1.0376697778701782\n",
      "Training Accuracy: 0.7467404007911682\n",
      "Validation Loss: 1.6141917705535889\n",
      "Validation Accuracy: 0.6274999976158142\n",
      "Classification Error Rate: 0.3725000023841858\n",
      "----->Evolution: Child net_10 with fitness 1.6141917705535889 replaces parent net_8 with fitness 3.0998058319091797\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.35000000000000003\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e77250c0>, <__main__.Block object at 0x7d47e75cb340>, <__main__.Block object at 0x7d47e22202c0>, <__main__.Block object at 0x7d47e74e2040>, <__main__.Block object at 0x7d47e74b9780>, <__main__.Block object at 0x7d47e77f0ac0>, <__main__.Block object at 0x7d47e7445e40>, <__main__.Block object at 0x7d47e7355e00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_399\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_399/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_399/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,256].\n",
      "\n",
      "Call arguments received by layer \"conv2d_399\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_401. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_402. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:25:54.979538: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_46/dropout_28/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 6s 9ms/step - loss: 3.0379 - accuracy: 0.0806 - val_loss: 2.8158 - val_accuracy: 0.1020\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.7456 - accuracy: 0.1893 - val_loss: 2.7686 - val_accuracy: 0.1480\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.0275 - accuracy: 0.3106 - val_loss: 3.3340 - val_accuracy: 0.1815\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 5.7882 - accuracy: 0.3936 - val_loss: 2.1955 - val_accuracy: 0.3470\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 5.0286 - accuracy: 0.4482 - val_loss: 2.3342 - val_accuracy: 0.3120\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 5.0800 - accuracy: 0.5006 - val_loss: 1.7953 - val_accuracy: 0.4665\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 5.1711 - accuracy: 0.5398 - val_loss: 2.4030 - val_accuracy: 0.3170\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 5.8261 - accuracy: 0.5745 - val_loss: 1.7591 - val_accuracy: 0.4910\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 21.1590 - accuracy: 0.6115 - val_loss: 2.2263 - val_accuracy: 0.3505\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 13.4519 - accuracy: 0.6362 - val_loss: 1.7565 - val_accuracy: 0.4900\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 13.5445 - accuracy: 0.6662 - val_loss: 1.7463 - val_accuracy: 0.5315\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 7.4431 - accuracy: 0.6941 - val_loss: 1.9035 - val_accuracy: 0.4765\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 27.6964 - accuracy: 0.7059 - val_loss: 2.0978 - val_accuracy: 0.5235\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 11.0860 - accuracy: 0.7156 - val_loss: 1.9076 - val_accuracy: 0.5120\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 8.0326 - accuracy: 0.7306 - val_loss: 1.9472 - val_accuracy: 0.5525\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 14.4203 - accuracy: 0.7448 - val_loss: 1.7157 - val_accuracy: 0.5595\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 11.9241 - accuracy: 0.7572 - val_loss: 1.9707 - val_accuracy: 0.5930\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 59.6374 - accuracy: 0.7687 - val_loss: 2.0689 - val_accuracy: 0.4970\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 39.2302 - accuracy: 0.7585 - val_loss: 2.0743 - val_accuracy: 0.5690\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 39.0378 - accuracy: 0.7642 - val_loss: 2.2037 - val_accuracy: 0.5725\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 128.5811 - accuracy: 0.7726 - val_loss: 2.3228 - val_accuracy: 0.5270\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 171.3748 - accuracy: 0.7779 - val_loss: 2.3379 - val_accuracy: 0.5685\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 101.8380 - accuracy: 0.7798 - val_loss: 2.7245 - val_accuracy: 0.5110\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 109.2391 - accuracy: 0.7748 - val_loss: 3.2602 - val_accuracy: 0.4380\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 65.1551 - accuracy: 0.7576 - val_loss: 1.9361 - val_accuracy: 0.5640\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1643.0287 - accuracy: 0.7813 - val_loss: 3.9518 - val_accuracy: 0.5325\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 132.3466 - accuracy: 0.7486 - val_loss: 2.3959 - val_accuracy: 0.5800\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 90.8233 - accuracy: 0.7689 - val_loss: 3.6792 - val_accuracy: 0.4930\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 43.7068 - accuracy: 0.7617 - val_loss: 2.9923 - val_accuracy: 0.6020\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 61.5801 - accuracy: 0.7505 - val_loss: 3.6538 - val_accuracy: 0.5540\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 61.58006286621094\n",
      "Training Accuracy: 0.750495433807373\n",
      "Validation Loss: 3.6538467407226562\n",
      "Validation Accuracy: 0.5540000200271606\n",
      "Classification Error Rate: 0.44599997997283936\n",
      "----->Evolution: Child net_11 with fitness 3.6538467407226562 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.45\n",
      "Mutating Conv2D layer:\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c10abfdc0>, <__main__.Block object at 0x7d4c18192500>, <__main__.Block object at 0x7d47e8610440>, <__main__.Block object at 0x7d4c10f0b0c0>, <__main__.Block object at 0x7d47e846b7c0>, <__main__.Block object at 0x7d4c185c9040>, <__main__.Block object at 0x7d47e848b800>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_116\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_116/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,64].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_116\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 64), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.30000000000000004\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.35000000000000003\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e19f65c0>, <__main__.Block object at 0x7d47e19f6100>, <__main__.Block object at 0x7d47e19f74c0>, <__main__.Block object at 0x7d47e19f7600>, <__main__.Block object at 0x7d47e19f7980>, <__main__.Block object at 0x7d47e19f7c40>, <__main__.Block object at 0x7d47e19f7f40>, <__main__.Block object at 0x7d47e19f5680>, <__main__.Block object at 0x7d47e819c280>, <__main__.Block object at 0x7d47e819c340>, <__main__.Block object at 0x7d47e819c3c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_421. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_422. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_119\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_119/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_119\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2)]\n",
      "Inserting a Pooling layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.35000000000000003\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.5\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e81a7dc0>, <__main__.Block object at 0x7d47e81a5680>, <__main__.Block object at 0x7d47e81a5f80>, <__main__.Block object at 0x7d47e81a5300>, <__main__.Block object at 0x7d47e81a6a00>, <__main__.Block object at 0x7d47e81a6f40>, <__main__.Block object at 0x7d47e81a6ac0>, <__main__.Block object at 0x7d47e81a7600>, <__main__.Block object at 0x7d47dbcc0740>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_434. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_435. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_106\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_106/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_106\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2)]\n",
      "Inserting a Pooling layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.45\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.5\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e1a675c0>, <__main__.Block object at 0x7d47e1a01800>, <__main__.Block object at 0x7d47e962e000>, <__main__.Block object at 0x7d47e1752200>, <__main__.Block object at 0x7d4c8c6abb00>, <__main__.Block object at 0x7d47e84b1240>, <__main__.Block object at 0x7d47e84b3b80>, <__main__.Block object at 0x7d47e84b1980>, <__main__.Block object at 0x7d47e84b07c0>, <__main__.Block object at 0x7d47e1a62b40>, <__main__.Block object at 0x7d4c639c3400>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_110\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_110/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,64].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_110\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 64), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.25  to  0.15\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.5\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.45\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e81dd2c0>, <__main__.Block object at 0x7d47e81dcc00>, <__main__.Block object at 0x7d47e81de5c0>, <__main__.Block object at 0x7d47e81de6c0>, <__main__.Block object at 0x7d47e81de900>, <__main__.Block object at 0x7d47e81debc0>, <__main__.Block object at 0x7d47e81deec0>, <__main__.Block object at 0x7d47e81b59c0>, <__main__.Block object at 0x7d47e81df1c0>, <__main__.Block object at 0x7d47e81df280>, <__main__.Block object at 0x7d47e81df300>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_456\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_456/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_456/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_456\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_457\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_457/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_457/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,256].\n",
      "\n",
      "Call arguments received by layer \"conv2d_457\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_113\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_113/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_113\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.45\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.35000000000000003\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e1a1d100>, <__main__.Block object at 0x7d47e1a1df40>, <__main__.Block object at 0x7d47e81d3b00>, <__main__.Block object at 0x7d47e81d1180>, <__main__.Block object at 0x7d47e81d2a00>, <__main__.Block object at 0x7d47e81d1740>, <__main__.Block object at 0x7d47e81d04c0>, <__main__.Block object at 0x7d47e81d2680>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_468. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_129\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_129/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_129\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.5\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e1c0b700>, <__main__.Block object at 0x7d47e1c0bc40>, <__main__.Block object at 0x7d47e1c089c0>, <__main__.Block object at 0x7d47e1c09a80>, <__main__.Block object at 0x7d47dbc5d540>, <__main__.Block object at 0x7d4c10989380>, <__main__.Block object at 0x7d47e1a22000>, <__main__.Block object at 0x7d47e8191a40>, <__main__.Block object at 0x7d47e81eec00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_132\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_132/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_132\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2)]\n",
      "Removing a Conv2D layer at 1\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.30000000000000004\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e819e340>, <__main__.Block object at 0x7d47e817b000>, <__main__.Block object at 0x7d47e1c0b3c0>, <__main__.Block object at 0x7d47e1c0b040>, <__main__.Block object at 0x7d47e1c0ad00>, <__main__.Block object at 0x7d47e1c0a8c0>, <__main__.Block object at 0x7d47e1c0b200>, <__main__.Block object at 0x7d47e1c09e00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_487. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_491. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:27:09.268436: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_54/dropout_42/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 6s 9ms/step - loss: 2.9583 - accuracy: 0.0745 - val_loss: 2.9524 - val_accuracy: 0.0655\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.6745 - accuracy: 0.1760 - val_loss: 2.4880 - val_accuracy: 0.2110\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.4622 - accuracy: 0.2652 - val_loss: 2.7108 - val_accuracy: 0.2160\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.2842 - accuracy: 0.3302 - val_loss: 2.5993 - val_accuracy: 0.2080\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.3040 - accuracy: 0.3807 - val_loss: 2.1498 - val_accuracy: 0.3410\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.1570 - accuracy: 0.4214 - val_loss: 1.8966 - val_accuracy: 0.4245\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.0213 - accuracy: 0.4464 - val_loss: 2.3334 - val_accuracy: 0.3995\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.0524 - accuracy: 0.4827 - val_loss: 2.5467 - val_accuracy: 0.4040\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.3112 - accuracy: 0.5113 - val_loss: 1.7877 - val_accuracy: 0.4725\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.7688 - accuracy: 0.5401 - val_loss: 1.8008 - val_accuracy: 0.4685\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 1.9202 - accuracy: 0.5584 - val_loss: 1.8452 - val_accuracy: 0.5155\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 2.3466 - accuracy: 0.5787 - val_loss: 1.9443 - val_accuracy: 0.4665\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 1.6207 - accuracy: 0.5865 - val_loss: 1.8550 - val_accuracy: 0.5100\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 1.9465 - accuracy: 0.6150 - val_loss: 2.0918 - val_accuracy: 0.4410\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.6050 - accuracy: 0.6269 - val_loss: 1.6268 - val_accuracy: 0.5285\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.5870 - accuracy: 0.6355 - val_loss: 1.5787 - val_accuracy: 0.5555\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.8275 - accuracy: 0.6538 - val_loss: 1.6220 - val_accuracy: 0.5645\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 2.7797 - accuracy: 0.6597 - val_loss: 2.1570 - val_accuracy: 0.5210\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.3888 - accuracy: 0.6721 - val_loss: 1.7201 - val_accuracy: 0.5380\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.2011 - accuracy: 0.6776 - val_loss: 1.8219 - val_accuracy: 0.5190\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 3.9777 - accuracy: 0.6755 - val_loss: 2.1697 - val_accuracy: 0.5405\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 3.5844 - accuracy: 0.6881 - val_loss: 3.1231 - val_accuracy: 0.5330\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 5.6453 - accuracy: 0.6950 - val_loss: 1.9213 - val_accuracy: 0.5465\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 5.2910 - accuracy: 0.6930 - val_loss: 2.2729 - val_accuracy: 0.5085\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 4.6157 - accuracy: 0.6982 - val_loss: 1.9180 - val_accuracy: 0.5495\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 4.1853 - accuracy: 0.7085 - val_loss: 1.8779 - val_accuracy: 0.5595\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 9.4604 - accuracy: 0.7159 - val_loss: 1.6688 - val_accuracy: 0.5680\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 4.1605 - accuracy: 0.7145 - val_loss: 1.9325 - val_accuracy: 0.5085\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 9.4777 - accuracy: 0.7044 - val_loss: 2.2936 - val_accuracy: 0.5320\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 5.2368 - accuracy: 0.7086 - val_loss: 2.9759 - val_accuracy: 0.5145\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 5.236814975738525\n",
      "Training Accuracy: 0.7085636854171753\n",
      "Validation Loss: 2.975867748260498\n",
      "Validation Accuracy: 0.5145000219345093\n",
      "Classification Error Rate: 0.4854999780654907\n",
      "----->Evolution: Child net_12 with fitness 2.975867748260498 replaces parent net_1 with fitness 2.9968483448028564\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47d8237d00>, <__main__.Block object at 0x7d47d8046040>, <__main__.Block object at 0x7d47d81f9040>, <__main__.Block object at 0x7d47dbb98ac0>, <__main__.Block object at 0x7d47d8076280>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:28:29.035521: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_55/dropout_44/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 8ms/step - loss: 2.8067 - accuracy: 0.1304 - val_loss: 2.7452 - val_accuracy: 0.1690\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.4703 - accuracy: 0.2780 - val_loss: 2.5792 - val_accuracy: 0.2505\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.4372 - accuracy: 0.3606 - val_loss: 2.5846 - val_accuracy: 0.2250\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.4346 - accuracy: 0.4120 - val_loss: 2.2474 - val_accuracy: 0.3670\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.6493 - accuracy: 0.4562 - val_loss: 2.0516 - val_accuracy: 0.4160\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.5834 - accuracy: 0.4863 - val_loss: 2.2392 - val_accuracy: 0.4145\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.2849 - accuracy: 0.5140 - val_loss: 2.0034 - val_accuracy: 0.4190\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.0268 - accuracy: 0.5327 - val_loss: 2.2976 - val_accuracy: 0.4435\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.4858 - accuracy: 0.5600 - val_loss: 2.1742 - val_accuracy: 0.4405\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.0740 - accuracy: 0.5724 - val_loss: 2.4227 - val_accuracy: 0.3965\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.4464 - accuracy: 0.5936 - val_loss: 2.3039 - val_accuracy: 0.4210\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.3186 - accuracy: 0.6130 - val_loss: 2.2111 - val_accuracy: 0.4825\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.6868 - accuracy: 0.6278 - val_loss: 2.0637 - val_accuracy: 0.4800\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.6660 - accuracy: 0.6400 - val_loss: 1.9590 - val_accuracy: 0.4880\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.7449 - accuracy: 0.6516 - val_loss: 2.1310 - val_accuracy: 0.4810\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.0039 - accuracy: 0.6537 - val_loss: 2.5125 - val_accuracy: 0.4590\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.8795 - accuracy: 0.6624 - val_loss: 2.7364 - val_accuracy: 0.4445\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.0129 - accuracy: 0.6729 - val_loss: 3.6210 - val_accuracy: 0.4420\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.2552 - accuracy: 0.6734 - val_loss: 2.4014 - val_accuracy: 0.4885\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.5704 - accuracy: 0.6767 - val_loss: 2.5188 - val_accuracy: 0.4720\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.4333 - accuracy: 0.6824 - val_loss: 2.5365 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.2590 - accuracy: 0.6798 - val_loss: 2.2332 - val_accuracy: 0.4805\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 7.9136 - accuracy: 0.6783 - val_loss: 5.6860 - val_accuracy: 0.4055\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.7817 - accuracy: 0.6705 - val_loss: 2.3724 - val_accuracy: 0.4805\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 9.0047 - accuracy: 0.6781 - val_loss: 3.6361 - val_accuracy: 0.4090\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 9.0383 - accuracy: 0.6549 - val_loss: 2.8598 - val_accuracy: 0.3960\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.0055 - accuracy: 0.6414 - val_loss: 3.5992 - val_accuracy: 0.4250\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 9.2748 - accuracy: 0.6361 - val_loss: 3.3477 - val_accuracy: 0.4025\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 8.4036 - accuracy: 0.6483 - val_loss: 3.3877 - val_accuracy: 0.3655\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 6.3736 - accuracy: 0.6364 - val_loss: 3.4445 - val_accuracy: 0.4685\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 6.373561859130859\n",
      "Training Accuracy: 0.6363825798034668\n",
      "Validation Loss: 3.444495439529419\n",
      "Validation Accuracy: 0.4684999883174896\n",
      "Classification Error Rate: 0.5315000116825104\n",
      "----->Evolution: Child net_13 with fitness 3.444495439529419 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 8\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.5\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47c9fd6940>, <__main__.Block object at 0x7d47c9fea500>, <__main__.Block object at 0x7d47c9fd10c0>, <__main__.Block object at 0x7d47c8356ac0>, <__main__.Block object at 0x7d47e80b1040>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:29:33.480043: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_56/dropout_45/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 4s 7ms/step - loss: 2.9229 - accuracy: 0.1158 - val_loss: 2.5990 - val_accuracy: 0.2345\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.4023 - accuracy: 0.2770 - val_loss: 2.1237 - val_accuracy: 0.3605\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.1149 - accuracy: 0.3663 - val_loss: 2.1600 - val_accuracy: 0.3735\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.9102 - accuracy: 0.4280 - val_loss: 1.8474 - val_accuracy: 0.4560\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.7465 - accuracy: 0.4688 - val_loss: 1.6389 - val_accuracy: 0.5045\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.6010 - accuracy: 0.5115 - val_loss: 1.5027 - val_accuracy: 0.5540\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4944 - accuracy: 0.5522 - val_loss: 1.6236 - val_accuracy: 0.5335\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.3812 - accuracy: 0.5829 - val_loss: 1.4128 - val_accuracy: 0.5955\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.2999 - accuracy: 0.6064 - val_loss: 1.4100 - val_accuracy: 0.5840\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.2049 - accuracy: 0.6270 - val_loss: 1.4125 - val_accuracy: 0.5905\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.1564 - accuracy: 0.6473 - val_loss: 1.3678 - val_accuracy: 0.6115\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.0975 - accuracy: 0.6704 - val_loss: 1.4787 - val_accuracy: 0.5880\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.0291 - accuracy: 0.6870 - val_loss: 1.3739 - val_accuracy: 0.6300\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.9965 - accuracy: 0.6989 - val_loss: 1.6080 - val_accuracy: 0.5850\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.9516 - accuracy: 0.7129 - val_loss: 1.3296 - val_accuracy: 0.6350\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8999 - accuracy: 0.7261 - val_loss: 1.6077 - val_accuracy: 0.6160\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.9171 - accuracy: 0.7230 - val_loss: 1.4224 - val_accuracy: 0.6245\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8902 - accuracy: 0.7310 - val_loss: 1.4157 - val_accuracy: 0.6195\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8657 - accuracy: 0.7410 - val_loss: 1.5945 - val_accuracy: 0.6370\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8808 - accuracy: 0.7449 - val_loss: 1.6869 - val_accuracy: 0.6190\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8513 - accuracy: 0.7574 - val_loss: 1.6835 - val_accuracy: 0.6265\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8451 - accuracy: 0.7566 - val_loss: 1.5299 - val_accuracy: 0.6580\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8892 - accuracy: 0.7515 - val_loss: 1.8576 - val_accuracy: 0.6405\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8473 - accuracy: 0.7602 - val_loss: 1.6485 - val_accuracy: 0.6315\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8804 - accuracy: 0.7546 - val_loss: 1.6611 - val_accuracy: 0.6220\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8657 - accuracy: 0.7636 - val_loss: 1.9792 - val_accuracy: 0.6570\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9140 - accuracy: 0.7510 - val_loss: 1.6908 - val_accuracy: 0.6080\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8918 - accuracy: 0.7603 - val_loss: 1.9567 - val_accuracy: 0.6305\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.9598 - accuracy: 0.7449 - val_loss: 1.5374 - val_accuracy: 0.6405\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.9945 - accuracy: 0.7433 - val_loss: 1.7258 - val_accuracy: 0.5705\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.9945191740989685\n",
      "Training Accuracy: 0.7432982325553894\n",
      "Validation Loss: 1.7257758378982544\n",
      "Validation Accuracy: 0.5705000162124634\n",
      "Classification Error Rate: 0.4294999837875366\n",
      "----->Evolution: Child net_10 with fitness 1.7257758378982544 replaces parent net_1 with fitness 2.975867748260498\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e22e1d40>, <__main__.Block object at 0x7d47e7eee3c0>, <__main__.Block object at 0x7d47c843b140>, <__main__.Block object at 0x7d4c18166180>, <__main__.Block object at 0x7d47e28c9040>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_512\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_512/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_512/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,64], [3,3,64,256].\n",
      "\n",
      "Call arguments received by layer \"conv2d_512\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 64), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:30:33.590748: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_57/dropout_46/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 4s 7ms/step - loss: 2.6435 - accuracy: 0.2029 - val_loss: 3.7116 - val_accuracy: 0.1110\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.1030 - accuracy: 0.3655 - val_loss: 2.1706 - val_accuracy: 0.3700\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.7981 - accuracy: 0.4628 - val_loss: 1.8504 - val_accuracy: 0.4330\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.5843 - accuracy: 0.5271 - val_loss: 1.7966 - val_accuracy: 0.5055\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.4729 - accuracy: 0.5662 - val_loss: 1.5909 - val_accuracy: 0.5410\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.3973 - accuracy: 0.6122 - val_loss: 1.5546 - val_accuracy: 0.5570\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.2605 - accuracy: 0.6397 - val_loss: 1.8173 - val_accuracy: 0.5210\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.3152 - accuracy: 0.6601 - val_loss: 1.6766 - val_accuracy: 0.6010\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.1609 - accuracy: 0.6915 - val_loss: 1.6512 - val_accuracy: 0.5870\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.1637 - accuracy: 0.7111 - val_loss: 1.5455 - val_accuracy: 0.5680\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.0205 - accuracy: 0.7269 - val_loss: 1.8183 - val_accuracy: 0.5575\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.0482 - accuracy: 0.7388 - val_loss: 1.6335 - val_accuracy: 0.6040\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8941 - accuracy: 0.7595 - val_loss: 1.9869 - val_accuracy: 0.5490\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1697 - accuracy: 0.7638 - val_loss: 1.7251 - val_accuracy: 0.6305\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.0638 - accuracy: 0.7738 - val_loss: 1.5461 - val_accuracy: 0.6820\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.1007 - accuracy: 0.7820 - val_loss: 1.5686 - val_accuracy: 0.5980\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8391 - accuracy: 0.7904 - val_loss: 2.0810 - val_accuracy: 0.6205\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.9312 - accuracy: 0.7988 - val_loss: 1.6557 - val_accuracy: 0.6230\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.1147 - accuracy: 0.7999 - val_loss: 1.6735 - val_accuracy: 0.6085\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.1067 - accuracy: 0.8007 - val_loss: 2.1000 - val_accuracy: 0.5970\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7158 - accuracy: 0.8248 - val_loss: 1.6722 - val_accuracy: 0.6260\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.0215 - accuracy: 0.8073 - val_loss: 2.5894 - val_accuracy: 0.5635\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8664 - accuracy: 0.8122 - val_loss: 1.8332 - val_accuracy: 0.5810\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.0862 - accuracy: 0.7943 - val_loss: 2.2977 - val_accuracy: 0.5885\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.3452 - accuracy: 0.8170 - val_loss: 2.1948 - val_accuracy: 0.5865\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.1511 - accuracy: 0.8158 - val_loss: 1.7893 - val_accuracy: 0.6455\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.9140 - accuracy: 0.8157 - val_loss: 1.9233 - val_accuracy: 0.5800\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.9548 - accuracy: 0.8106 - val_loss: 1.8258 - val_accuracy: 0.6315\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.6716 - accuracy: 0.8128 - val_loss: 2.3414 - val_accuracy: 0.6000\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.3330 - accuracy: 0.8113 - val_loss: 2.0368 - val_accuracy: 0.6055\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 1.333046793937683\n",
      "Training Accuracy: 0.8113069534301758\n",
      "Validation Loss: 2.036752700805664\n",
      "Validation Accuracy: 0.6054999828338623\n",
      "Classification Error Rate: 0.3945000171661377\n",
      "----->Evolution: Child net_11 with fitness 2.036752700805664 replaces parent net_7 with fitness 2.856228828430176\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.5\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c101dfd00>, <__main__.Block object at 0x7d4bf8e64300>, <__main__.Block object at 0x7d4bf8fc1ac0>, <__main__.Block object at 0x7d4bf851bd80>, <__main__.Block object at 0x7d4bf8745740>, <__main__.Block object at 0x7d4bf8d15900>, <__main__.Block object at 0x7d4bf8df2900>, <__main__.Block object at 0x7d4bf87a6d80>, <__main__.Block object at 0x7d4bf8fe9b80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_521. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_522. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_523. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_524. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_128\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_128/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_128\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.45\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf8dadec0>, <__main__.Block object at 0x7d4bf8fa3b40>, <__main__.Block object at 0x7d4bf8c357c0>, <__main__.Block object at 0x7d4bf8c374c0>, <__main__.Block object at 0x7d4bf8c37880>, <__main__.Block object at 0x7d4bf8c37f40>, <__main__.Block object at 0x7d4bf8c37980>, <__main__.Block object at 0x7d4bf8c35980>, <__main__.Block object at 0x7d4bf8c37900>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_533. Consider increasing the input size. Received input shape [None, 1, 1, 512] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_130\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_130/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_130\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Inserting a Pooling layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf8c54e00>, <__main__.Block object at 0x7d4bf8c3d1c0>, <__main__.Block object at 0x7d4bf8c55140>, <__main__.Block object at 0x7d4bf8c54e40>, <__main__.Block object at 0x7d4bf8c553c0>, <__main__.Block object at 0x7d4bf8c55400>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_542\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_542/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_542/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,512], [3,3,512,512].\n",
      "\n",
      "Call arguments received by layer \"conv2d_542\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 512), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_135\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_135/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_135\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf8c49bc0>, <__main__.Block object at 0x7d4bf8c4aa00>, <__main__.Block object at 0x7d4bf8c42fc0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 3s 6ms/step - loss: 2.4475 - accuracy: 0.2930 - val_loss: 1.9948 - val_accuracy: 0.4175\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.7280 - accuracy: 0.4854 - val_loss: 1.5562 - val_accuracy: 0.5365\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.3878 - accuracy: 0.5846 - val_loss: 1.4591 - val_accuracy: 0.5685\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.1242 - accuracy: 0.6601 - val_loss: 1.4892 - val_accuracy: 0.6015\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.9094 - accuracy: 0.7213 - val_loss: 1.5799 - val_accuracy: 0.6010\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.7253 - accuracy: 0.7738 - val_loss: 1.7651 - val_accuracy: 0.5870\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5499 - accuracy: 0.8305 - val_loss: 2.0350 - val_accuracy: 0.5850\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4312 - accuracy: 0.8610 - val_loss: 2.0669 - val_accuracy: 0.5840\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.3503 - accuracy: 0.8943 - val_loss: 2.7149 - val_accuracy: 0.5890\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2725 - accuracy: 0.9147 - val_loss: 2.6192 - val_accuracy: 0.5970\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2371 - accuracy: 0.9258 - val_loss: 2.9301 - val_accuracy: 0.5935\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.9316 - val_loss: 3.9016 - val_accuracy: 0.5520\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1826 - accuracy: 0.9417 - val_loss: 3.3301 - val_accuracy: 0.5865\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1770 - accuracy: 0.9437 - val_loss: 3.7287 - val_accuracy: 0.5860\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1805 - accuracy: 0.9470 - val_loss: 4.1801 - val_accuracy: 0.5755\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1657 - accuracy: 0.9520 - val_loss: 4.2525 - val_accuracy: 0.5830\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1551 - accuracy: 0.9559 - val_loss: 4.7764 - val_accuracy: 0.5950\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1562 - accuracy: 0.9564 - val_loss: 5.1738 - val_accuracy: 0.5730\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1398 - accuracy: 0.9612 - val_loss: 5.3920 - val_accuracy: 0.5835\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1518 - accuracy: 0.9565 - val_loss: 5.1429 - val_accuracy: 0.5955\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1608 - accuracy: 0.9607 - val_loss: 5.8968 - val_accuracy: 0.5795\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1461 - accuracy: 0.9639 - val_loss: 6.4311 - val_accuracy: 0.5810\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1525 - accuracy: 0.9650 - val_loss: 7.0769 - val_accuracy: 0.5655\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1412 - accuracy: 0.9653 - val_loss: 7.0744 - val_accuracy: 0.5735\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1538 - accuracy: 0.9659 - val_loss: 7.2028 - val_accuracy: 0.5890\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1330 - accuracy: 0.9710 - val_loss: 7.2948 - val_accuracy: 0.5975\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1602 - accuracy: 0.9659 - val_loss: 7.0160 - val_accuracy: 0.5715\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1459 - accuracy: 0.9700 - val_loss: 8.1445 - val_accuracy: 0.5910\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1391 - accuracy: 0.9703 - val_loss: 10.5399 - val_accuracy: 0.5470\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1621 - accuracy: 0.9690 - val_loss: 8.6522 - val_accuracy: 0.5765\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 0.16213025152683258\n",
      "Training Accuracy: 0.9690205454826355\n",
      "Validation Loss: 8.652170181274414\n",
      "Validation Accuracy: 0.5764999985694885\n",
      "Classification Error Rate: 0.4235000014305115\n",
      "----->Evolution: Child net_12 with fitness 8.652170181274414 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.45\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.5  to  0.45\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf8a66940>, <__main__.Block object at 0x7d4bf8bfa500>, <__main__.Block object at 0x7d4bf8a8f600>, <__main__.Block object at 0x7d4bf8b8b880>, <__main__.Block object at 0x7d4bf8cb5600>, <__main__.Block object at 0x7d4bf8c50c00>, <__main__.Block object at 0x7d4bf8b4b0c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_555. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:32:11.223313: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_62/dropout_52/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 9ms/step - loss: 2.9969 - accuracy: 0.0672 - val_loss: 3.7647 - val_accuracy: 0.1155\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.6201 - accuracy: 0.2071 - val_loss: 2.3137 - val_accuracy: 0.2980\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.4190 - accuracy: 0.3059 - val_loss: 2.6595 - val_accuracy: 0.2110\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.2353 - accuracy: 0.3653 - val_loss: 2.2073 - val_accuracy: 0.3190\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.0971 - accuracy: 0.4152 - val_loss: 2.1817 - val_accuracy: 0.3750\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.1549 - accuracy: 0.4536 - val_loss: 2.5169 - val_accuracy: 0.3875\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.1891 - accuracy: 0.4716 - val_loss: 3.4144 - val_accuracy: 0.2720\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.9265 - accuracy: 0.5036 - val_loss: 4.3197 - val_accuracy: 0.2845\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.0133 - accuracy: 0.5223 - val_loss: 2.1958 - val_accuracy: 0.4725\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.4501 - accuracy: 0.5518 - val_loss: 3.2044 - val_accuracy: 0.4295\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.1090 - accuracy: 0.5701 - val_loss: 2.9681 - val_accuracy: 0.3470\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.6565 - accuracy: 0.5707 - val_loss: 3.7402 - val_accuracy: 0.3545\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 4.2052 - accuracy: 0.5931 - val_loss: 2.4511 - val_accuracy: 0.4120\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 4.7117 - accuracy: 0.6033 - val_loss: 2.7547 - val_accuracy: 0.4230\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 5.0737 - accuracy: 0.6177 - val_loss: 2.2097 - val_accuracy: 0.4335\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 5.4783 - accuracy: 0.6320 - val_loss: 2.8046 - val_accuracy: 0.4195\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 5.1378 - accuracy: 0.6296 - val_loss: 3.5660 - val_accuracy: 0.4105\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 9.6664 - accuracy: 0.6352 - val_loss: 2.0694 - val_accuracy: 0.4940\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.6404 - accuracy: 0.6478 - val_loss: 2.0608 - val_accuracy: 0.5225\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 6.1947 - accuracy: 0.6405 - val_loss: 3.6806 - val_accuracy: 0.4175\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 7.9419 - accuracy: 0.6480 - val_loss: 2.0564 - val_accuracy: 0.5190\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 10.3977 - accuracy: 0.6608 - val_loss: 2.4053 - val_accuracy: 0.4730\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 8.2064 - accuracy: 0.6451 - val_loss: 3.3908 - val_accuracy: 0.4135\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 12.8431 - accuracy: 0.6478 - val_loss: 2.4932 - val_accuracy: 0.5015\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 5.7128 - accuracy: 0.6493 - val_loss: 2.4750 - val_accuracy: 0.4795\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 18.9815 - accuracy: 0.6489 - val_loss: 3.3574 - val_accuracy: 0.4355\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 11.3034 - accuracy: 0.6298 - val_loss: 2.7004 - val_accuracy: 0.4470\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 7.6363 - accuracy: 0.6418 - val_loss: 2.1871 - val_accuracy: 0.5190\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 36.8510 - accuracy: 0.6543 - val_loss: 2.2121 - val_accuracy: 0.4770\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 20.8006 - accuracy: 0.6435 - val_loss: 4.1313 - val_accuracy: 0.3885\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 20.800575256347656\n",
      "Training Accuracy: 0.6434755325317383\n",
      "Validation Loss: 4.131277084350586\n",
      "Validation Accuracy: 0.38850000500679016\n",
      "Classification Error Rate: 0.6114999949932098\n",
      "----->Evolution: Child net_13 with fitness 4.131277084350586 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 9\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.30000000000000004\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e2372040>, <__main__.Block object at 0x7d47e2582500>, <__main__.Block object at 0x7d47e2353880>, <__main__.Block object at 0x7d47e246b800>, <__main__.Block object at 0x7d47e2460940>, <__main__.Block object at 0x7d47e2308880>, <__main__.Block object at 0x7d47e269b9c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_563\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_563/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_563/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_563\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_564\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_564/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_564/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_564\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:33:27.050602: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_63/dropout_54/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 7s 10ms/step - loss: 2.8577 - accuracy: 0.0941 - val_loss: 3.0184 - val_accuracy: 0.0670\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.7052 - accuracy: 0.1510 - val_loss: 2.5850 - val_accuracy: 0.1705\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 3.5939 - accuracy: 0.2334 - val_loss: 2.3683 - val_accuracy: 0.2205\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 3.0589 - accuracy: 0.2922 - val_loss: 2.3133 - val_accuracy: 0.2755\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 4.9760 - accuracy: 0.3411 - val_loss: 2.3518 - val_accuracy: 0.2810\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.2062 - accuracy: 0.3859 - val_loss: 2.0960 - val_accuracy: 0.3385\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.4216 - accuracy: 0.4230 - val_loss: 2.2213 - val_accuracy: 0.3560\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.2196 - accuracy: 0.4486 - val_loss: 2.0103 - val_accuracy: 0.3845\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.2063 - accuracy: 0.4868 - val_loss: 2.0682 - val_accuracy: 0.4060\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.9695 - accuracy: 0.5170 - val_loss: 1.8587 - val_accuracy: 0.4495\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.6093 - accuracy: 0.5467 - val_loss: 1.6876 - val_accuracy: 0.4845\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.4539 - accuracy: 0.5688 - val_loss: 1.5934 - val_accuracy: 0.5595\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.1573 - accuracy: 0.5999 - val_loss: 1.6766 - val_accuracy: 0.5165\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.7264 - accuracy: 0.6344 - val_loss: 1.5712 - val_accuracy: 0.5485\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.4794 - accuracy: 0.6515 - val_loss: 1.5288 - val_accuracy: 0.5525\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.3664 - accuracy: 0.6752 - val_loss: 1.5591 - val_accuracy: 0.5765\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.3738 - accuracy: 0.6979 - val_loss: 1.5351 - val_accuracy: 0.5785\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.1208 - accuracy: 0.7256 - val_loss: 1.5979 - val_accuracy: 0.5610\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.9485 - accuracy: 0.7414 - val_loss: 1.5848 - val_accuracy: 0.5830\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.9204 - accuracy: 0.7618 - val_loss: 1.5836 - val_accuracy: 0.5805\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.7247 - accuracy: 0.7811 - val_loss: 1.5338 - val_accuracy: 0.6205\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.7332 - accuracy: 0.7902 - val_loss: 1.4569 - val_accuracy: 0.6085\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.7434 - accuracy: 0.8137 - val_loss: 1.7574 - val_accuracy: 0.6000\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.5877 - accuracy: 0.8208 - val_loss: 1.5723 - val_accuracy: 0.6160\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.5899 - accuracy: 0.8325 - val_loss: 1.4081 - val_accuracy: 0.6400\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.5319 - accuracy: 0.8402 - val_loss: 1.7766 - val_accuracy: 0.6135\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.5060 - accuracy: 0.8479 - val_loss: 1.6807 - val_accuracy: 0.6280\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.5045 - accuracy: 0.8627 - val_loss: 1.6776 - val_accuracy: 0.6240\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0453 - accuracy: 0.8672 - val_loss: 2.1826 - val_accuracy: 0.5980\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.7835 - accuracy: 0.8796 - val_loss: 1.7619 - val_accuracy: 0.6210\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.7835411429405212\n",
      "Training Accuracy: 0.8796286582946777\n",
      "Validation Loss: 1.7618521451950073\n",
      "Validation Accuracy: 0.6209999918937683\n",
      "Classification Error Rate: 0.3790000081062317\n",
      "----->Evolution: Child net_10 with fitness 1.7618521451950073 replaces parent net_3 with fitness 2.7881381511688232\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c63903300>, <__main__.Block object at 0x7d4c8c41da00>, <__main__.Block object at 0x7d4c39b93880>, <__main__.Block object at 0x7d4c39b43d00>, <__main__.Block object at 0x7d4c39b96ec0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 4s 6ms/step - loss: 2.5871 - accuracy: 0.2283 - val_loss: 2.4167 - val_accuracy: 0.2900\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.0031 - accuracy: 0.4095 - val_loss: 1.9157 - val_accuracy: 0.4460\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.6721 - accuracy: 0.5115 - val_loss: 2.2286 - val_accuracy: 0.4140\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.4932 - accuracy: 0.5764 - val_loss: 3.3654 - val_accuracy: 0.3200\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.2755 - accuracy: 0.6420 - val_loss: 1.8647 - val_accuracy: 0.5265\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.3358 - accuracy: 0.6899 - val_loss: 3.3887 - val_accuracy: 0.4425\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.0118 - accuracy: 0.7414 - val_loss: 1.9453 - val_accuracy: 0.5385\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.8878 - accuracy: 0.7834 - val_loss: 1.9537 - val_accuracy: 0.5505\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8710 - accuracy: 0.8134 - val_loss: 2.5927 - val_accuracy: 0.5585\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9820 - accuracy: 0.8490 - val_loss: 2.8607 - val_accuracy: 0.5540\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8541 - accuracy: 0.8661 - val_loss: 2.8368 - val_accuracy: 0.5920\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.0533 - accuracy: 0.8827 - val_loss: 3.9608 - val_accuracy: 0.5395\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.0972 - accuracy: 0.8950 - val_loss: 3.3550 - val_accuracy: 0.5855\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.2159 - accuracy: 0.9025 - val_loss: 3.7279 - val_accuracy: 0.5370\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.6159 - accuracy: 0.9103 - val_loss: 3.4455 - val_accuracy: 0.5865\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.8950 - accuracy: 0.9173 - val_loss: 3.6046 - val_accuracy: 0.5625\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.5780 - accuracy: 0.9244 - val_loss: 4.7412 - val_accuracy: 0.6000\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.2786 - accuracy: 0.9254 - val_loss: 4.5601 - val_accuracy: 0.6085\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.3559 - accuracy: 0.9321 - val_loss: 4.9008 - val_accuracy: 0.5915\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.1763 - accuracy: 0.9336 - val_loss: 5.8991 - val_accuracy: 0.5470\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.3319 - accuracy: 0.9274 - val_loss: 5.5032 - val_accuracy: 0.5610\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.3555 - accuracy: 0.9363 - val_loss: 6.4689 - val_accuracy: 0.5870\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.9401 - accuracy: 0.9327 - val_loss: 6.4500 - val_accuracy: 0.5915\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.0096 - accuracy: 0.9350 - val_loss: 5.6164 - val_accuracy: 0.6080\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.8857 - accuracy: 0.9351 - val_loss: 6.1076 - val_accuracy: 0.5575\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.2663 - accuracy: 0.9413 - val_loss: 5.8383 - val_accuracy: 0.5705\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.3311 - accuracy: 0.9452 - val_loss: 7.4657 - val_accuracy: 0.6045\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.2564 - accuracy: 0.9398 - val_loss: 5.9416 - val_accuracy: 0.6110\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.6779 - accuracy: 0.9460 - val_loss: 6.0675 - val_accuracy: 0.5800\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.2396 - accuracy: 0.9444 - val_loss: 5.1517 - val_accuracy: 0.5920\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 2.2395994663238525\n",
      "Training Accuracy: 0.944403886795044\n",
      "Validation Loss: 5.151651382446289\n",
      "Validation Accuracy: 0.5920000076293945\n",
      "Classification Error Rate: 0.40799999237060547\n",
      "----->Evolution: Child net_11 with fitness 5.151651382446289 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.5  to  0.45\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.35000000000000003\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.35000000000000003\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  256.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47c96c6940>, <__main__.Block object at 0x7d47e1c990c0>, <__main__.Block object at 0x7d4c1099da00>, <__main__.Block object at 0x7d47c96b4300>, <__main__.Block object at 0x7d4bf88039c0>, <__main__.Block object at 0x7d47c84855c0>, <__main__.Block object at 0x7d4bf8c5e640>, <__main__.Block object at 0x7d4bf8836ac0>, <__main__.Block object at 0x7d47e2720100>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_584. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_148\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_148/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_148\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.5  to  0.45\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c8c408c00>, <__main__.Block object at 0x7d4c6394b280>, <__main__.Block object at 0x7d4c6394b940>, <__main__.Block object at 0x7d4c6394b3c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:35:43.042303: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_66/dropout_58/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 4s 8ms/step - loss: 3.1251 - accuracy: 0.1066 - val_loss: 2.7716 - val_accuracy: 0.1930\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.7962 - accuracy: 0.2183 - val_loss: 2.7238 - val_accuracy: 0.2590\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.6076 - accuracy: 0.2944 - val_loss: 2.6329 - val_accuracy: 0.2215\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.6723 - accuracy: 0.3224 - val_loss: 2.8553 - val_accuracy: 0.2885\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.7919 - accuracy: 0.3387 - val_loss: 3.1342 - val_accuracy: 0.2110\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.8745 - accuracy: 0.3555 - val_loss: 3.7330 - val_accuracy: 0.2070\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9601 - accuracy: 0.3629 - val_loss: 2.2589 - val_accuracy: 0.3270\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 3.1119 - accuracy: 0.3682 - val_loss: 2.8583 - val_accuracy: 0.2075\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 3.4129 - accuracy: 0.3829 - val_loss: 2.4564 - val_accuracy: 0.3300\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 3.5684 - accuracy: 0.3865 - val_loss: 2.2307 - val_accuracy: 0.3435\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 3.0921 - accuracy: 0.3946 - val_loss: 2.3619 - val_accuracy: 0.2845\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9357 - accuracy: 0.3977 - val_loss: 2.3307 - val_accuracy: 0.3405\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 3.1981 - accuracy: 0.4006 - val_loss: 2.1066 - val_accuracy: 0.3630\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 3.4506 - accuracy: 0.3997 - val_loss: 2.7168 - val_accuracy: 0.2745\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.2155 - accuracy: 0.4027 - val_loss: 2.2609 - val_accuracy: 0.3440\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 4.0004 - accuracy: 0.4008 - val_loss: 4.1062 - val_accuracy: 0.1795\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.1664 - accuracy: 0.4061 - val_loss: 2.9952 - val_accuracy: 0.2130\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.8366 - accuracy: 0.3996 - val_loss: 2.1143 - val_accuracy: 0.3565\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.7196 - accuracy: 0.4117 - val_loss: 2.2661 - val_accuracy: 0.3130\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.0761 - accuracy: 0.4067 - val_loss: 5.9954 - val_accuracy: 0.0735\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 3.3943 - accuracy: 0.4010 - val_loss: 2.2686 - val_accuracy: 0.3335\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.9241 - accuracy: 0.4005 - val_loss: 2.4267 - val_accuracy: 0.3080\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 4.0132 - accuracy: 0.4013 - val_loss: 2.2189 - val_accuracy: 0.3335\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.9324 - accuracy: 0.3972 - val_loss: 2.6839 - val_accuracy: 0.2025\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.4533 - accuracy: 0.4009 - val_loss: 2.2259 - val_accuracy: 0.3345\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.3030 - accuracy: 0.4006 - val_loss: 2.5781 - val_accuracy: 0.2900\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.3735 - accuracy: 0.4054 - val_loss: 2.1129 - val_accuracy: 0.3465\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.2392 - accuracy: 0.3943 - val_loss: 2.8336 - val_accuracy: 0.2470\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 5.1069 - accuracy: 0.3854 - val_loss: 2.5324 - val_accuracy: 0.2485\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.7091 - accuracy: 0.3815 - val_loss: 9.5830 - val_accuracy: 0.2125\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 4.709128379821777\n",
      "Training Accuracy: 0.3814540505409241\n",
      "Validation Loss: 9.583037376403809\n",
      "Validation Accuracy: 0.21250000596046448\n",
      "Classification Error Rate: 0.7874999940395355\n",
      "----->Evolution: Child net_12 with fitness 9.583037376403809 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.5  to  0.4\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c8c446940>, <__main__.Block object at 0x7d4c108aa9c0>, <__main__.Block object at 0x7d47e12c4f00>, <__main__.Block object at 0x7d47e2166b00>, <__main__.Block object at 0x7d47e801d980>, <__main__.Block object at 0x7d47e2a38c00>, <__main__.Block object at 0x7d47e139b0c0>, <__main__.Block object at 0x7d47e80937c0>, <__main__.Block object at 0x7d47e804dc40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_601. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_153\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_153/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_153\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e177b200>, <__main__.Block object at 0x7d47e177a840>, <__main__.Block object at 0x7d47e1779a80>, <__main__.Block object at 0x7d47e1778f40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 4s 7ms/step - loss: 2.6145 - accuracy: 0.2488 - val_loss: 2.7847 - val_accuracy: 0.2280\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.9952 - accuracy: 0.4681 - val_loss: 1.9545 - val_accuracy: 0.4655\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.5850 - accuracy: 0.5885 - val_loss: 1.9886 - val_accuracy: 0.4760\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.4400 - accuracy: 0.6793 - val_loss: 1.8200 - val_accuracy: 0.4760\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.1042 - accuracy: 0.7689 - val_loss: 1.9904 - val_accuracy: 0.5085\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.9772 - accuracy: 0.8519 - val_loss: 2.1967 - val_accuracy: 0.5530\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.4147 - accuracy: 0.9038 - val_loss: 3.7280 - val_accuracy: 0.4670\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.0162 - accuracy: 0.9229 - val_loss: 3.2907 - val_accuracy: 0.5450\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.6883 - accuracy: 0.9412 - val_loss: 3.5075 - val_accuracy: 0.5040\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.4129 - accuracy: 0.9482 - val_loss: 4.7446 - val_accuracy: 0.5530\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.8519 - accuracy: 0.9571 - val_loss: 4.5897 - val_accuracy: 0.4715\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.3991 - accuracy: 0.9557 - val_loss: 3.7555 - val_accuracy: 0.5580\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.3802 - accuracy: 0.9617 - val_loss: 5.4473 - val_accuracy: 0.5420\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.4456 - accuracy: 0.9631 - val_loss: 4.7077 - val_accuracy: 0.5385\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.8170 - accuracy: 0.9633 - val_loss: 3.6991 - val_accuracy: 0.5550\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.6325 - accuracy: 0.9683 - val_loss: 5.8112 - val_accuracy: 0.5235\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 3.1007 - accuracy: 0.9716 - val_loss: 6.6560 - val_accuracy: 0.5405\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.1591 - accuracy: 0.9707 - val_loss: 4.9848 - val_accuracy: 0.5355\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 3.4046 - accuracy: 0.9686 - val_loss: 5.7753 - val_accuracy: 0.5680\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.5097 - accuracy: 0.9747 - val_loss: 4.7870 - val_accuracy: 0.5410\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 4.6690 - accuracy: 0.9725 - val_loss: 8.5680 - val_accuracy: 0.5335\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.7103 - accuracy: 0.9741 - val_loss: 5.4549 - val_accuracy: 0.5695\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.0707 - accuracy: 0.9768 - val_loss: 5.7165 - val_accuracy: 0.5540\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 3.6009 - accuracy: 0.9766 - val_loss: 8.6893 - val_accuracy: 0.5415\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 3.1080 - accuracy: 0.9743 - val_loss: 6.7588 - val_accuracy: 0.5480\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 6.6003 - accuracy: 0.9748 - val_loss: 7.7679 - val_accuracy: 0.5780\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 3.0786 - accuracy: 0.9779 - val_loss: 7.3033 - val_accuracy: 0.6010\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.8635 - accuracy: 0.9743 - val_loss: 7.0487 - val_accuracy: 0.5910\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 3.0743 - accuracy: 0.9773 - val_loss: 7.4829 - val_accuracy: 0.5625\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 4.8159 - accuracy: 0.9766 - val_loss: 8.6894 - val_accuracy: 0.5855\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 4.815872669219971\n",
      "Training Accuracy: 0.9766350388526917\n",
      "Validation Loss: 8.689375877380371\n",
      "Validation Accuracy: 0.5855000019073486\n",
      "Classification Error Rate: 0.41449999809265137\n",
      "----->Evolution: Child net_13 with fitness 8.689375877380371 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 10\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Tournament selection\n",
      "Selected net_9 and net_8 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e1788b00>, <__main__.Block object at 0x7d4bf884a500>, <__main__.Block object at 0x7d47e1445a00>, <__main__.Block object at 0x7d47e14deac0>, <__main__.Block object at 0x7d47e148b0c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 6s 12ms/step - loss: 7.3992 - accuracy: 0.0634 - val_loss: 3.4619 - val_accuracy: 0.0540\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.9700 - accuracy: 0.1286 - val_loss: 6.9301 - val_accuracy: 0.1235\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.3997 - accuracy: 0.2926 - val_loss: 2.4964 - val_accuracy: 0.2895\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.0279 - accuracy: 0.4060 - val_loss: 2.4380 - val_accuracy: 0.3635\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.7821 - accuracy: 0.4839 - val_loss: 2.7378 - val_accuracy: 0.3950\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.5884 - accuracy: 0.5510 - val_loss: 2.3722 - val_accuracy: 0.4115\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.4817 - accuracy: 0.6060 - val_loss: 2.1203 - val_accuracy: 0.4750\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.1799 - accuracy: 0.6660 - val_loss: 2.4834 - val_accuracy: 0.4650\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.9270 - accuracy: 0.7280 - val_loss: 2.2707 - val_accuracy: 0.4940\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.0178 - accuracy: 0.7606 - val_loss: 3.2306 - val_accuracy: 0.4280\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.7524 - accuracy: 0.7858 - val_loss: 3.1546 - val_accuracy: 0.4350\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.7868 - accuracy: 0.7874 - val_loss: 3.0961 - val_accuracy: 0.4480\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.9118 - accuracy: 0.7706 - val_loss: 4.0445 - val_accuracy: 0.4705\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.9969 - accuracy: 0.7603 - val_loss: 2.7804 - val_accuracy: 0.3850\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.0731 - accuracy: 0.7407 - val_loss: 4.2564 - val_accuracy: 0.3510\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.3222 - accuracy: 0.7087 - val_loss: 3.8312 - val_accuracy: 0.2535\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6156 - accuracy: 0.6376 - val_loss: 8.2055 - val_accuracy: 0.2935\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6788 - accuracy: 0.6391 - val_loss: 5.2173 - val_accuracy: 0.3640\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6678 - accuracy: 0.5916 - val_loss: 2.7973 - val_accuracy: 0.3740\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6628 - accuracy: 0.5792 - val_loss: 4.1715 - val_accuracy: 0.3690\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.7061 - accuracy: 0.5704 - val_loss: 4.3658 - val_accuracy: 0.3565\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.7489 - accuracy: 0.5487 - val_loss: 4.0743 - val_accuracy: 0.1945\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.0645 - accuracy: 0.4597 - val_loss: 3.4723 - val_accuracy: 0.2480\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.2403 - accuracy: 0.4165 - val_loss: 3.5957 - val_accuracy: 0.2455\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.3477 - accuracy: 0.3663 - val_loss: 2.6966 - val_accuracy: 0.2800\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.2881 - accuracy: 0.3627 - val_loss: 2.8067 - val_accuracy: 0.2235\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.3777 - accuracy: 0.3388 - val_loss: 3.1293 - val_accuracy: 0.3050\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.3104 - accuracy: 0.3463 - val_loss: 4.3977 - val_accuracy: 0.2810\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.3606 - accuracy: 0.3388 - val_loss: 2.7990 - val_accuracy: 0.2495\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 2.4160 - accuracy: 0.3296 - val_loss: 3.0075 - val_accuracy: 0.1300\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 2.416003465652466\n",
      "Training Accuracy: 0.3296130299568176\n",
      "Validation Loss: 3.007535934448242\n",
      "Validation Accuracy: 0.12999999523162842\n",
      "Classification Error Rate: 0.8700000047683716\n",
      "----->Evolution: Child net_10 with fitness 3.007535934448242 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Tournament selection\n",
      "Selected net_8 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.30000000000000004\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47defdf600>, <__main__.Block object at 0x7d47def790c0>, <__main__.Block object at 0x7d47def03880>, <__main__.Block object at 0x7d47deffb7c0>, <__main__.Block object at 0x7d47defb5980>, <__main__.Block object at 0x7d47def92500>, <__main__.Block object at 0x7d47df1b39c0>, <__main__.Block object at 0x7d47df0a5dc0>, <__main__.Block object at 0x7d47def955c0>, <__main__.Block object at 0x7d47df1c7280>, <__main__.Block object at 0x7d47df14d4c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_625. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_626. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_158\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_158/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_158\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Removing a Pooling/Dropout layer at 1\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47dedf8ac0>, <__main__.Block object at 0x7d47dedfac40>, <__main__.Block object at 0x7d47dedfb3c0>, <__main__.Block object at 0x7d47dedf8bc0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 4s 8ms/step - loss: 2.5402 - accuracy: 0.2455 - val_loss: 2.1213 - val_accuracy: 0.3435\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.8538 - accuracy: 0.4401 - val_loss: 1.6393 - val_accuracy: 0.5005\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4906 - accuracy: 0.5437 - val_loss: 1.6090 - val_accuracy: 0.5115\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1659 - accuracy: 0.6459 - val_loss: 1.5482 - val_accuracy: 0.5545\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8539 - accuracy: 0.7332 - val_loss: 1.4583 - val_accuracy: 0.6050\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5593 - accuracy: 0.8217 - val_loss: 1.7055 - val_accuracy: 0.6185\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.3748 - accuracy: 0.8916 - val_loss: 2.0448 - val_accuracy: 0.5735\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.2780 - accuracy: 0.9202 - val_loss: 2.7295 - val_accuracy: 0.5640\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.2370 - accuracy: 0.9356 - val_loss: 2.6654 - val_accuracy: 0.5525\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.2328 - accuracy: 0.9424 - val_loss: 2.3508 - val_accuracy: 0.5995\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1923 - accuracy: 0.9530 - val_loss: 2.8861 - val_accuracy: 0.5700\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1825 - accuracy: 0.9521 - val_loss: 2.8354 - val_accuracy: 0.5440\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1766 - accuracy: 0.9591 - val_loss: 2.9569 - val_accuracy: 0.6105\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1796 - accuracy: 0.9593 - val_loss: 3.0136 - val_accuracy: 0.5695\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1748 - accuracy: 0.9617 - val_loss: 2.5206 - val_accuracy: 0.6015\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1671 - accuracy: 0.9661 - val_loss: 3.3434 - val_accuracy: 0.5700\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1694 - accuracy: 0.9672 - val_loss: 3.9955 - val_accuracy: 0.6090\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1463 - accuracy: 0.9683 - val_loss: 3.5232 - val_accuracy: 0.5940\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1519 - accuracy: 0.9711 - val_loss: 3.9723 - val_accuracy: 0.5565\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1469 - accuracy: 0.9714 - val_loss: 3.7165 - val_accuracy: 0.6035\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.1433 - accuracy: 0.9705 - val_loss: 3.7261 - val_accuracy: 0.5925\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1290 - accuracy: 0.9736 - val_loss: 4.2700 - val_accuracy: 0.6020\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.1332 - accuracy: 0.9709 - val_loss: 3.7013 - val_accuracy: 0.5985\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1803 - accuracy: 0.9728 - val_loss: 3.3388 - val_accuracy: 0.6230\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1454 - accuracy: 0.9743 - val_loss: 3.8883 - val_accuracy: 0.6280\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1723 - accuracy: 0.9730 - val_loss: 4.3811 - val_accuracy: 0.5860\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1427 - accuracy: 0.9756 - val_loss: 4.0481 - val_accuracy: 0.6005\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1076 - accuracy: 0.9790 - val_loss: 5.3530 - val_accuracy: 0.6050\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1908 - accuracy: 0.9756 - val_loss: 4.6035 - val_accuracy: 0.6035\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.1333 - accuracy: 0.9763 - val_loss: 4.4342 - val_accuracy: 0.6030\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 0.13330407440662384\n",
      "Training Accuracy: 0.9763221144676208\n",
      "Validation Loss: 4.4341511726379395\n",
      "Validation Accuracy: 0.6029999852180481\n",
      "Classification Error Rate: 0.3970000147819519\n",
      "----->Evolution: Child net_11 with fitness 4.4341511726379395 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Tournament selection\n",
      "Selected net_9 and net_8 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.30000000000000004\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  256.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47dee1f140>, <__main__.Block object at 0x7d47debb90c0>, <__main__.Block object at 0x7d47deb15a00>, <__main__.Block object at 0x7d47deb8b9c0>, <__main__.Block object at 0x7d47deede640>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:41:04.538358: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_72/dropout_62/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 8ms/step - loss: 3.0111 - accuracy: 0.1171 - val_loss: 2.4613 - val_accuracy: 0.2745\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.3827 - accuracy: 0.3153 - val_loss: 3.1488 - val_accuracy: 0.2040\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.0392 - accuracy: 0.4121 - val_loss: 11.5923 - val_accuracy: 0.1085\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.9099 - accuracy: 0.4697 - val_loss: 2.0534 - val_accuracy: 0.4340\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.9640 - accuracy: 0.5374 - val_loss: 3.0816 - val_accuracy: 0.4025\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.5069 - accuracy: 0.5773 - val_loss: 2.3162 - val_accuracy: 0.5465\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3483 - accuracy: 0.6161 - val_loss: 3.4133 - val_accuracy: 0.4490\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4456 - accuracy: 0.6462 - val_loss: 2.2318 - val_accuracy: 0.5405\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3519 - accuracy: 0.6794 - val_loss: 2.7809 - val_accuracy: 0.4625\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4108 - accuracy: 0.7045 - val_loss: 2.7275 - val_accuracy: 0.5990\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3050 - accuracy: 0.7157 - val_loss: 3.5898 - val_accuracy: 0.5230\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.8051 - accuracy: 0.7381 - val_loss: 2.3267 - val_accuracy: 0.5765\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4487 - accuracy: 0.7424 - val_loss: 3.3227 - val_accuracy: 0.5610\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3906 - accuracy: 0.7492 - val_loss: 5.9831 - val_accuracy: 0.5160\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0850 - accuracy: 0.7553 - val_loss: 3.7741 - val_accuracy: 0.4410\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1769 - accuracy: 0.7418 - val_loss: 3.0505 - val_accuracy: 0.5255\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0287 - accuracy: 0.7475 - val_loss: 2.3131 - val_accuracy: 0.5660\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2230 - accuracy: 0.7433 - val_loss: 3.8930 - val_accuracy: 0.5725\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.5035 - accuracy: 0.7525 - val_loss: 3.0580 - val_accuracy: 0.5945\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.6445 - accuracy: 0.7503 - val_loss: 9.9162 - val_accuracy: 0.5425\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2072 - accuracy: 0.7491 - val_loss: 3.6219 - val_accuracy: 0.5455\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2653 - accuracy: 0.7442 - val_loss: 3.2416 - val_accuracy: 0.4690\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2335 - accuracy: 0.7369 - val_loss: 15.9374 - val_accuracy: 0.3720\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4842 - accuracy: 0.7352 - val_loss: 2.8810 - val_accuracy: 0.5750\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2804 - accuracy: 0.7376 - val_loss: 4.9684 - val_accuracy: 0.5540\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3130 - accuracy: 0.7400 - val_loss: 2.4156 - val_accuracy: 0.4635\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0910 - accuracy: 0.7379 - val_loss: 2.3432 - val_accuracy: 0.4875\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2499 - accuracy: 0.7191 - val_loss: 2.2676 - val_accuracy: 0.5230\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2667 - accuracy: 0.7209 - val_loss: 2.4387 - val_accuracy: 0.5710\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1496 - accuracy: 0.7380 - val_loss: 2.6787 - val_accuracy: 0.5660\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 1.149649977684021\n",
      "Training Accuracy: 0.7379785180091858\n",
      "Validation Loss: 2.678723096847534\n",
      "Validation Accuracy: 0.5659999847412109\n",
      "Classification Error Rate: 0.43400001525878906\n",
      "----->Evolution: Child net_12 with fitness 2.678723096847534 replaces parent net_9 with fitness 2.7300145626068115\n",
      "\n",
      "Creating Child 3\n",
      "----->Tournament selection\n",
      "Selected net_5 and net_9 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256.0  to  512.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf8362940>, <__main__.Block object at 0x7d47e0fdda00>, <__main__.Block object at 0x7d4bf82220c0>, <__main__.Block object at 0x7d4c10a8ff00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:42:12.572451: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_73/dropout_63/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 9ms/step - loss: 3.3684 - accuracy: 0.0537 - val_loss: 3.1431 - val_accuracy: 0.0715\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.7597 - accuracy: 0.2375 - val_loss: 2.7274 - val_accuracy: 0.2540\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.3648 - accuracy: 0.4146 - val_loss: 2.7528 - val_accuracy: 0.4245\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.3295 - accuracy: 0.5252 - val_loss: 2.8166 - val_accuracy: 0.3645\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.1516 - accuracy: 0.6004 - val_loss: 1.7419 - val_accuracy: 0.5330\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.5463 - accuracy: 0.6689 - val_loss: 2.0481 - val_accuracy: 0.5480\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.7928 - accuracy: 0.7157 - val_loss: 3.5345 - val_accuracy: 0.5180\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.1896 - accuracy: 0.7695 - val_loss: 2.4193 - val_accuracy: 0.5720\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.0605 - accuracy: 0.8137 - val_loss: 2.7272 - val_accuracy: 0.5750\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.2573 - accuracy: 0.8481 - val_loss: 3.5290 - val_accuracy: 0.5780\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.6167 - accuracy: 0.8743 - val_loss: 2.4755 - val_accuracy: 0.5880\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.6428 - accuracy: 0.8937 - val_loss: 5.7756 - val_accuracy: 0.6120\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 4.5763 - accuracy: 0.8929 - val_loss: 4.7402 - val_accuracy: 0.5690\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.1890 - accuracy: 0.9041 - val_loss: 4.0711 - val_accuracy: 0.5510\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.3308 - accuracy: 0.9170 - val_loss: 3.5064 - val_accuracy: 0.5995\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 5.5500 - accuracy: 0.9211 - val_loss: 7.8291 - val_accuracy: 0.5840\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.1774 - accuracy: 0.9236 - val_loss: 8.0311 - val_accuracy: 0.6200\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 4.9218 - accuracy: 0.9268 - val_loss: 5.7086 - val_accuracy: 0.6015\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 5.1390 - accuracy: 0.9309 - val_loss: 6.0722 - val_accuracy: 0.5955\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 9.4813 - accuracy: 0.9303 - val_loss: 12.5089 - val_accuracy: 0.5850\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 7.6167 - accuracy: 0.9331 - val_loss: 8.9723 - val_accuracy: 0.6080\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 4.0019 - accuracy: 0.9363 - val_loss: 12.7495 - val_accuracy: 0.5585\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 8.8109 - accuracy: 0.9319 - val_loss: 8.8279 - val_accuracy: 0.6210\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 10.0895 - accuracy: 0.9394 - val_loss: 5.8262 - val_accuracy: 0.5980\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 4.4021 - accuracy: 0.9342 - val_loss: 11.8101 - val_accuracy: 0.5260\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 16.1458 - accuracy: 0.9332 - val_loss: 5.0980 - val_accuracy: 0.6070\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 8.7228 - accuracy: 0.9360 - val_loss: 12.2864 - val_accuracy: 0.5805\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 6.9934 - accuracy: 0.9356 - val_loss: 14.9869 - val_accuracy: 0.5695\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 5.8651 - accuracy: 0.9413 - val_loss: 9.6818 - val_accuracy: 0.5820\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 10.7545 - accuracy: 0.9420 - val_loss: 13.4994 - val_accuracy: 0.6060\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 10.754484176635742\n",
      "Training Accuracy: 0.9420047998428345\n",
      "Validation Loss: 13.499368667602539\n",
      "Validation Accuracy: 0.6060000061988831\n",
      "Classification Error Rate: 0.39399999380111694\n",
      "----->Evolution: Child net_13 with fitness 13.499368667602539 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 11\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Proportionate selection\n",
      "Selected net_4 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.5\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  128.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47df240880>, <__main__.Block object at 0x7d47df1fa500>, <__main__.Block object at 0x7d47df2a10c0>, <__main__.Block object at 0x7d47c9500c00>, <__main__.Block object at 0x7d47df228940>, <__main__.Block object at 0x7d47e0ce8440>, <__main__.Block object at 0x7d47df20b400>, <__main__.Block object at 0x7d47df24d5c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_652\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_652/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_652/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,32].\n",
      "\n",
      "Call arguments received by layer \"conv2d_652\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_653. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_654. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_172\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_172/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_172\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47df2c5640>, <__main__.Block object at 0x7d47df3026c0>, <__main__.Block object at 0x7d47df2b7a80>, <__main__.Block object at 0x7d47df332b80>, <__main__.Block object at 0x7d47df330540>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Input 0 of layer \"max_pooling2d_174\" is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 20)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47c9505640>, <__main__.Block object at 0x7d47df2e4040>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 3s 6ms/step - loss: 3.3979 - accuracy: 0.2577 - val_loss: 2.1330 - val_accuracy: 0.3780\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.8217 - accuracy: 0.4578 - val_loss: 1.8679 - val_accuracy: 0.4600\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.4567 - accuracy: 0.5574 - val_loss: 1.8034 - val_accuracy: 0.5035\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.1611 - accuracy: 0.6438 - val_loss: 1.8473 - val_accuracy: 0.5130\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.8905 - accuracy: 0.7248 - val_loss: 1.8402 - val_accuracy: 0.5235\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.6634 - accuracy: 0.7941 - val_loss: 2.0232 - val_accuracy: 0.5375\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.4734 - accuracy: 0.8526 - val_loss: 2.4328 - val_accuracy: 0.5350\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.3473 - accuracy: 0.8931 - val_loss: 2.6018 - val_accuracy: 0.5375\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.2508 - accuracy: 0.9204 - val_loss: 2.8408 - val_accuracy: 0.5470\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.1946 - accuracy: 0.9380 - val_loss: 3.1320 - val_accuracy: 0.5205\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.1520 - accuracy: 0.9499 - val_loss: 3.6952 - val_accuracy: 0.5290\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1430 - accuracy: 0.9543 - val_loss: 3.8313 - val_accuracy: 0.5500\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.1336 - accuracy: 0.9593 - val_loss: 4.6765 - val_accuracy: 0.5380\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.1180 - accuracy: 0.9631 - val_loss: 4.8950 - val_accuracy: 0.5095\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.1216 - accuracy: 0.9614 - val_loss: 5.2316 - val_accuracy: 0.5395\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1110 - accuracy: 0.9664 - val_loss: 5.1706 - val_accuracy: 0.5295\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.1089 - accuracy: 0.9701 - val_loss: 5.6027 - val_accuracy: 0.5445\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0963 - accuracy: 0.9719 - val_loss: 5.3542 - val_accuracy: 0.5520\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.1016 - accuracy: 0.9732 - val_loss: 5.7641 - val_accuracy: 0.5425\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0861 - accuracy: 0.9778 - val_loss: 6.0871 - val_accuracy: 0.5440\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0943 - accuracy: 0.9754 - val_loss: 6.9347 - val_accuracy: 0.5385\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.1055 - accuracy: 0.9730 - val_loss: 6.3170 - val_accuracy: 0.5440\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0727 - accuracy: 0.9801 - val_loss: 6.2627 - val_accuracy: 0.5400\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0907 - accuracy: 0.9786 - val_loss: 6.7875 - val_accuracy: 0.5375\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0967 - accuracy: 0.9747 - val_loss: 7.6640 - val_accuracy: 0.5290\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0956 - accuracy: 0.9760 - val_loss: 8.1501 - val_accuracy: 0.5445\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0950 - accuracy: 0.9761 - val_loss: 8.1586 - val_accuracy: 0.5460\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.1006 - accuracy: 0.9771 - val_loss: 7.4832 - val_accuracy: 0.5565\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0716 - accuracy: 0.9810 - val_loss: 8.3849 - val_accuracy: 0.5455\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.1006 - accuracy: 0.9781 - val_loss: 8.0030 - val_accuracy: 0.5450\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.10056156665086746\n",
      "Training Accuracy: 0.9780953526496887\n",
      "Validation Loss: 8.003047943115234\n",
      "Validation Accuracy: 0.5450000166893005\n",
      "Classification Error Rate: 0.45499998331069946\n",
      "----->Evolution: Child net_10 with fitness 8.003047943115234 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Proportionate selection\n",
      "Selected net_8 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.30000000000000004\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.30000000000000004\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47c9228880>, <__main__.Block object at 0x7d47c935da00>, <__main__.Block object at 0x7d47c9354f00>, <__main__.Block object at 0x7d47c9355c40>, <__main__.Block object at 0x7d47c94c1040>, <__main__.Block object at 0x7d47c94a0940>, <__main__.Block object at 0x7d47c92ff240>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_177\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_177/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_177\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2)]\n",
      "Removing a Conv2D layer at 0\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47c959f880>, <__main__.Block object at 0x7d47c923f3c0>, <__main__.Block object at 0x7d47c93f7f40>, <__main__.Block object at 0x7d47c9277a80>, <__main__.Block object at 0x7d47c93754c0>, <__main__.Block object at 0x7d47e0afd4c0>, <__main__.Block object at 0x7d47c9216900>, <__main__.Block object at 0x7d47c92fd840>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_682. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_683. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_685. Consider increasing the input size. Received input shape [None, 1, 1, 512] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_181\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_181/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_181\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.35  to  0.3\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  512\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e0afd5c0>, <__main__.Block object at 0x7d47e0aff200>, <__main__.Block object at 0x7d47e0b14580>, <__main__.Block object at 0x7d47e0b14400>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:44:24.585935: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_79/dropout_71/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 7s 16ms/step - loss: 5.5089 - accuracy: 0.1212 - val_loss: 2.7005 - val_accuracy: 0.2135\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 2.4238 - accuracy: 0.2812 - val_loss: 2.2317 - val_accuracy: 0.3615\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 2.0579 - accuracy: 0.3907 - val_loss: 2.0950 - val_accuracy: 0.3740\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.8245 - accuracy: 0.4574 - val_loss: 1.8746 - val_accuracy: 0.4535\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.6845 - accuracy: 0.5018 - val_loss: 2.2573 - val_accuracy: 0.3445\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.5865 - accuracy: 0.5340 - val_loss: 3.0615 - val_accuracy: 0.2775\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.5627 - accuracy: 0.5503 - val_loss: 2.7331 - val_accuracy: 0.2675\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.4801 - accuracy: 0.5676 - val_loss: 2.2803 - val_accuracy: 0.3780\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.4902 - accuracy: 0.5795 - val_loss: 2.2946 - val_accuracy: 0.3465\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.4729 - accuracy: 0.5881 - val_loss: 2.1267 - val_accuracy: 0.4015\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.4566 - accuracy: 0.5971 - val_loss: 2.2696 - val_accuracy: 0.3645\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.5529 - accuracy: 0.5697 - val_loss: 1.8701 - val_accuracy: 0.4645\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.5415 - accuracy: 0.5813 - val_loss: 2.2836 - val_accuracy: 0.3775\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.5713 - accuracy: 0.5688 - val_loss: 2.2396 - val_accuracy: 0.3695\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.6661 - accuracy: 0.5406 - val_loss: 2.5235 - val_accuracy: 0.3820\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.6496 - accuracy: 0.5477 - val_loss: 2.4167 - val_accuracy: 0.2885\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.7527 - accuracy: 0.5284 - val_loss: 2.3950 - val_accuracy: 0.3505\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.7774 - accuracy: 0.5240 - val_loss: 2.3480 - val_accuracy: 0.2945\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.8599 - accuracy: 0.5074 - val_loss: 3.2088 - val_accuracy: 0.2175\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.8797 - accuracy: 0.4935 - val_loss: 2.3044 - val_accuracy: 0.3305\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 2.0597 - accuracy: 0.4567 - val_loss: 2.4215 - val_accuracy: 0.2840\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.9931 - accuracy: 0.4683 - val_loss: 2.4552 - val_accuracy: 0.2470\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 1.9416 - accuracy: 0.4700 - val_loss: 2.3907 - val_accuracy: 0.2870\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 2.1342 - accuracy: 0.4320 - val_loss: 2.5355 - val_accuracy: 0.2605\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 2.1094 - accuracy: 0.4303 - val_loss: 2.2995 - val_accuracy: 0.2955\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 2.0424 - accuracy: 0.4415 - val_loss: 2.6700 - val_accuracy: 0.1800\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 2.1229 - accuracy: 0.4317 - val_loss: 2.3089 - val_accuracy: 0.3075\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 2.2520 - accuracy: 0.3835 - val_loss: 2.1838 - val_accuracy: 0.3565\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 2.2597 - accuracy: 0.3897 - val_loss: 2.5178 - val_accuracy: 0.2755\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 2.3459 - accuracy: 0.3498 - val_loss: 2.3679 - val_accuracy: 0.2795\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 2.345888614654541\n",
      "Training Accuracy: 0.34984874725341797\n",
      "Validation Loss: 2.367948055267334\n",
      "Validation Accuracy: 0.27950000762939453\n",
      "Classification Error Rate: 0.7204999923706055\n",
      "----->Evolution: Child net_11 with fitness 2.367948055267334 replaces parent net_9 with fitness 2.678723096847534\n",
      "\n",
      "Creating Child 2\n",
      "----->Proportionate selection\n",
      "Selected net_6 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.35000000000000003  to  0.25\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47df8747c0>, <__main__.Block object at 0x7d47e101d0c0>, <__main__.Block object at 0x7d47e10c5ec0>, <__main__.Block object at 0x7d47e0ff2d40>, <__main__.Block object at 0x7d47e0e81b00>, <__main__.Block object at 0x7d47e0f3ae40>, <__main__.Block object at 0x7d47e0f821c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_698\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_698/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_698/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_698\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_699. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:46:34.262090: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_80/dropout_73/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 8ms/step - loss: 2.8353 - accuracy: 0.1133 - val_loss: 2.7656 - val_accuracy: 0.1960\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.3465 - accuracy: 0.2666 - val_loss: 2.2232 - val_accuracy: 0.3125\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.0186 - accuracy: 0.3719 - val_loss: 2.2182 - val_accuracy: 0.3645\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.7745 - accuracy: 0.4551 - val_loss: 2.3581 - val_accuracy: 0.3545\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.5745 - accuracy: 0.5177 - val_loss: 1.9381 - val_accuracy: 0.4495\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3942 - accuracy: 0.5738 - val_loss: 1.7017 - val_accuracy: 0.5215\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2207 - accuracy: 0.6238 - val_loss: 1.4304 - val_accuracy: 0.5815\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0779 - accuracy: 0.6712 - val_loss: 1.5346 - val_accuracy: 0.5900\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9391 - accuracy: 0.7096 - val_loss: 1.6884 - val_accuracy: 0.5585\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8121 - accuracy: 0.7535 - val_loss: 2.0059 - val_accuracy: 0.5395\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.6926 - accuracy: 0.7867 - val_loss: 1.7289 - val_accuracy: 0.6005\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.6266 - accuracy: 0.8149 - val_loss: 3.1515 - val_accuracy: 0.4590\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5356 - accuracy: 0.8361 - val_loss: 2.2430 - val_accuracy: 0.5980\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4662 - accuracy: 0.8634 - val_loss: 1.6347 - val_accuracy: 0.6325\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4245 - accuracy: 0.8798 - val_loss: 2.6455 - val_accuracy: 0.5860\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3739 - accuracy: 0.8882 - val_loss: 2.3950 - val_accuracy: 0.6360\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3809 - accuracy: 0.8951 - val_loss: 2.6301 - val_accuracy: 0.5630\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.3413 - accuracy: 0.9073 - val_loss: 2.2358 - val_accuracy: 0.6240\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3033 - accuracy: 0.9177 - val_loss: 2.5376 - val_accuracy: 0.6210\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3031 - accuracy: 0.9198 - val_loss: 3.9855 - val_accuracy: 0.5820\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3250 - accuracy: 0.9244 - val_loss: 2.7297 - val_accuracy: 0.5870\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.2832 - accuracy: 0.9268 - val_loss: 3.3079 - val_accuracy: 0.6125\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.2436 - accuracy: 0.9350 - val_loss: 2.9741 - val_accuracy: 0.6235\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.3105 - accuracy: 0.9360 - val_loss: 3.8368 - val_accuracy: 0.5580\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.2864 - accuracy: 0.9382 - val_loss: 3.5713 - val_accuracy: 0.6150\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.3420 - accuracy: 0.9398 - val_loss: 3.9011 - val_accuracy: 0.6105\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3655 - accuracy: 0.9429 - val_loss: 3.9484 - val_accuracy: 0.5815\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.3108 - accuracy: 0.9416 - val_loss: 4.2547 - val_accuracy: 0.5970\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.2781 - accuracy: 0.9475 - val_loss: 3.6807 - val_accuracy: 0.5760\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5011 - accuracy: 0.9496 - val_loss: 4.6320 - val_accuracy: 0.5950\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 0.5011041760444641\n",
      "Training Accuracy: 0.9496192932128906\n",
      "Validation Loss: 4.6320085525512695\n",
      "Validation Accuracy: 0.5950000286102295\n",
      "Classification Error Rate: 0.4049999713897705\n",
      "----->Evolution: Child net_12 with fitness 4.6320085525512695 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Proportionate selection\n",
      "Selected net_7 and net_8 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.45\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  256.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47def2f200>, <__main__.Block object at 0x7d4c8c612500>, <__main__.Block object at 0x7d4c10120880>, <__main__.Block object at 0x7d47e1a76ac0>, <__main__.Block object at 0x7d47c96b5980>, <__main__.Block object at 0x7d4c108db0c0>, <__main__.Block object at 0x7d47e0a18100>, <__main__.Block object at 0x7d47e22a5c40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_184\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_184/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_184\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2)]\n",
      "Inserting a Pooling layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.5\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.5\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e228dfc0>, <__main__.Block object at 0x7d4c10d9b800>, <__main__.Block object at 0x7d47deea5bc0>, <__main__.Block object at 0x7d4bf8e7ef80>, <__main__.Block object at 0x7d4c10104e80>, <__main__.Block object at 0x7d4bf8be6180>, <__main__.Block object at 0x7d47dbb7a2c0>, <__main__.Block object at 0x7d4bf8f57200>, <__main__.Block object at 0x7d4c8c674880>, <__main__.Block object at 0x7d4bf89e5c00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_193\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_193/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_193\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2)]\n",
      "Removing a Conv2D layer at 0\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.35000000000000003\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf92d3400>, <__main__.Block object at 0x7d4bf9888cc0>, <__main__.Block object at 0x7d4bf988bfc0>, <__main__.Block object at 0x7d47e84363c0>, <__main__.Block object at 0x7d47dbc56080>, <__main__.Block object at 0x7d4bf9da14c0>, <__main__.Block object at 0x7d4bf9a659c0>, <__main__.Block object at 0x7d4bf9af7480>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_725. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:47:45.774214: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_83/dropout_75/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 6s 9ms/step - loss: 3.0114 - accuracy: 0.0577 - val_loss: 2.9089 - val_accuracy: 0.1020\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.7901 - accuracy: 0.1467 - val_loss: 2.6567 - val_accuracy: 0.1830\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.5793 - accuracy: 0.2180 - val_loss: 2.4940 - val_accuracy: 0.2530\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.4211 - accuracy: 0.2904 - val_loss: 2.2606 - val_accuracy: 0.2995\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.4405 - accuracy: 0.3368 - val_loss: 2.6073 - val_accuracy: 0.2470\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.2078 - accuracy: 0.3662 - val_loss: 2.0689 - val_accuracy: 0.3795\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.3693 - accuracy: 0.4018 - val_loss: 2.3798 - val_accuracy: 0.2970\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.0040 - accuracy: 0.4264 - val_loss: 1.9883 - val_accuracy: 0.4035\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.0241 - accuracy: 0.4560 - val_loss: 2.0271 - val_accuracy: 0.4120\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.6275 - accuracy: 0.4808 - val_loss: 2.2038 - val_accuracy: 0.3655\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.4457 - accuracy: 0.4972 - val_loss: 2.3087 - val_accuracy: 0.3835\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 4.2960 - accuracy: 0.5164 - val_loss: 1.9290 - val_accuracy: 0.4555\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 6.3191 - accuracy: 0.5246 - val_loss: 1.8712 - val_accuracy: 0.4560\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.3079 - accuracy: 0.5431 - val_loss: 1.9477 - val_accuracy: 0.4260\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 4.4660 - accuracy: 0.5504 - val_loss: 1.7521 - val_accuracy: 0.4995\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.7825 - accuracy: 0.5703 - val_loss: 1.9981 - val_accuracy: 0.4210\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.2933 - accuracy: 0.5776 - val_loss: 1.9062 - val_accuracy: 0.4760\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 5.3331 - accuracy: 0.5771 - val_loss: 1.8542 - val_accuracy: 0.4800\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 8.6465 - accuracy: 0.5887 - val_loss: 2.0183 - val_accuracy: 0.4805\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 4.3775 - accuracy: 0.5916 - val_loss: 2.0456 - val_accuracy: 0.4820\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 7.8584 - accuracy: 0.5997 - val_loss: 1.7995 - val_accuracy: 0.5135\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.9475 - accuracy: 0.6176 - val_loss: 1.8858 - val_accuracy: 0.5130\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.0229 - accuracy: 0.6145 - val_loss: 2.0322 - val_accuracy: 0.4850\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 9.8335 - accuracy: 0.6083 - val_loss: 2.1995 - val_accuracy: 0.3590\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 6.9713 - accuracy: 0.6034 - val_loss: 1.9135 - val_accuracy: 0.4575\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 17.5568 - accuracy: 0.5984 - val_loss: 2.0774 - val_accuracy: 0.4695\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 8.5676 - accuracy: 0.6042 - val_loss: 1.9371 - val_accuracy: 0.4730\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 7.5555 - accuracy: 0.6020 - val_loss: 2.1144 - val_accuracy: 0.5025\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 7.8383 - accuracy: 0.6005 - val_loss: 2.3432 - val_accuracy: 0.4595\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 19.2867 - accuracy: 0.6034 - val_loss: 2.3705 - val_accuracy: 0.4415\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 19.28668212890625\n",
      "Training Accuracy: 0.6034212708473206\n",
      "Validation Loss: 2.3705034255981445\n",
      "Validation Accuracy: 0.4415000081062317\n",
      "Classification Error Rate: 0.5584999918937683\n",
      "----->Evolution: Child net_13 with fitness 2.3705034255981445 replaces parent net_2 with fitness 2.6559247970581055\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 12\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Proportionate selection\n",
      "Selected net_6 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.5\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e8a48b00>, <__main__.Block object at 0x7d47e0d5da00>, <__main__.Block object at 0x7d47e7ba29c0>, <__main__.Block object at 0x7d47e7b24d80>, <__main__.Block object at 0x7d47dbb12980>, <__main__.Block object at 0x7d47e7cb3980>, <__main__.Block object at 0x7d47e8655240>, <__main__.Block object at 0x7d47dbae64c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_733\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_733/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_733/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,512].\n",
      "\n",
      "Call arguments received by layer \"conv2d_733\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_735. Consider increasing the input size. Received input shape [None, 1, 1, 512] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_736. Consider increasing the input size. Received input shape [None, 1, 1, 512] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_191\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_191/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_191\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.25  to  0.2\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.30000000000000004\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.35000000000000003  to  0.45000000000000007\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47dbc30280>, <__main__.Block object at 0x7d47c954df80>, <__main__.Block object at 0x7d47e14b96c0>, <__main__.Block object at 0x7d47e14bb940>, <__main__.Block object at 0x7d47e14b9f40>, <__main__.Block object at 0x7d47dbc88900>, <__main__.Block object at 0x7d47dbcc1540>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_745. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_200\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_200/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_200\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 2)]\n",
      "Creating a new block with two Convolutional layers and a Pooling layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47c85fdd80>, <__main__.Block object at 0x7d47e131e140>, <__main__.Block object at 0x7d47e2a1ba80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 3s 6ms/step - loss: 2.5283 - accuracy: 0.2699 - val_loss: 2.1735 - val_accuracy: 0.3775\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.7907 - accuracy: 0.4958 - val_loss: 1.9509 - val_accuracy: 0.4445\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.2779 - accuracy: 0.6359 - val_loss: 2.0499 - val_accuracy: 0.4525\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.8775 - accuracy: 0.7710 - val_loss: 2.2281 - val_accuracy: 0.4970\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.6300 - accuracy: 0.8925 - val_loss: 3.4084 - val_accuracy: 0.4710\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.4813 - accuracy: 0.9389 - val_loss: 4.0326 - val_accuracy: 0.5165\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.4771 - accuracy: 0.9558 - val_loss: 5.2188 - val_accuracy: 0.4825\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.5261 - accuracy: 0.9650 - val_loss: 5.7995 - val_accuracy: 0.4785\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.5533 - accuracy: 0.9684 - val_loss: 5.9187 - val_accuracy: 0.4895\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.6859 - accuracy: 0.9754 - val_loss: 6.9306 - val_accuracy: 0.4815\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5852 - accuracy: 0.9743 - val_loss: 9.3943 - val_accuracy: 0.4390\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.9047 - accuracy: 0.9755 - val_loss: 7.2620 - val_accuracy: 0.4650\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.6705 - accuracy: 0.9785 - val_loss: 8.6460 - val_accuracy: 0.4210\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5139 - accuracy: 0.9771 - val_loss: 9.1345 - val_accuracy: 0.4715\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.4869 - accuracy: 0.9790 - val_loss: 9.0159 - val_accuracy: 0.4970\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.3517 - accuracy: 0.9798 - val_loss: 11.3682 - val_accuracy: 0.4520\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.4477 - accuracy: 0.9789 - val_loss: 9.6648 - val_accuracy: 0.4860\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.9839 - val_loss: 12.0717 - val_accuracy: 0.4740\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.4006 - accuracy: 0.9823 - val_loss: 12.2735 - val_accuracy: 0.4910\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.9830 - val_loss: 14.4231 - val_accuracy: 0.4785\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5023 - accuracy: 0.9816 - val_loss: 10.7072 - val_accuracy: 0.4925\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.3206 - accuracy: 0.9868 - val_loss: 12.4215 - val_accuracy: 0.4780\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.7663 - accuracy: 0.9830 - val_loss: 13.3834 - val_accuracy: 0.4650\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.6298 - accuracy: 0.9861 - val_loss: 16.8323 - val_accuracy: 0.4430\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.8159 - accuracy: 0.9814 - val_loss: 12.4948 - val_accuracy: 0.4845\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.5297 - accuracy: 0.9856 - val_loss: 13.9117 - val_accuracy: 0.4825\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.8778 - accuracy: 0.9829 - val_loss: 14.7045 - val_accuracy: 0.4705\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.7248 - accuracy: 0.9844 - val_loss: 13.5046 - val_accuracy: 0.4835\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.6002 - accuracy: 0.9832 - val_loss: 17.3146 - val_accuracy: 0.4615\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.2137 - accuracy: 0.9842 - val_loss: 13.2392 - val_accuracy: 0.4680\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 1.213668704032898\n",
      "Training Accuracy: 0.9842495322227478\n",
      "Validation Loss: 13.239204406738281\n",
      "Validation Accuracy: 0.46799999475479126\n",
      "Classification Error Rate: 0.5320000052452087\n",
      "----->Evolution: Child net_10 with fitness 13.239204406738281 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Proportionate selection\n",
      "Selected net_6 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e26d9e00>, <__main__.Block object at 0x7d4c10d1da00>, <__main__.Block object at 0x7d4bf828e940>, <__main__.Block object at 0x7d47e22e8880>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 4s 7ms/step - loss: 8.9383 - accuracy: 0.0601 - val_loss: 2.9960 - val_accuracy: 0.0440\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 8.6691 - accuracy: 0.0525 - val_loss: 2.9995 - val_accuracy: 0.0460\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 3.4041 - accuracy: 0.0498 - val_loss: 3.0002 - val_accuracy: 0.0445\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 3.3102 - accuracy: 0.0492 - val_loss: 2.9977 - val_accuracy: 0.0460\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 5.3907 - accuracy: 0.0511 - val_loss: 3.0116 - val_accuracy: 0.0450\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 3.2786 - accuracy: 0.0513 - val_loss: 3.0267 - val_accuracy: 0.0455\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 3.2927 - accuracy: 0.0500 - val_loss: 3.0157 - val_accuracy: 0.0455\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 3.1955 - accuracy: 0.0519 - val_loss: 3.0137 - val_accuracy: 0.0460\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.9962 - accuracy: 0.0513 - val_loss: 3.0196 - val_accuracy: 0.0455\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 3.0437 - accuracy: 0.0486 - val_loss: 3.0378 - val_accuracy: 0.0455\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 3.0280 - accuracy: 0.0480 - val_loss: 3.0194 - val_accuracy: 0.0455\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 3.1191 - accuracy: 0.0469 - val_loss: 3.0125 - val_accuracy: 0.0475\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.9950 - accuracy: 0.0508 - val_loss: 3.0247 - val_accuracy: 0.0455\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 3.0161 - accuracy: 0.0481 - val_loss: 3.0306 - val_accuracy: 0.0455\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.9938 - accuracy: 0.0474 - val_loss: 3.0052 - val_accuracy: 0.0455\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 3.0103 - accuracy: 0.0491 - val_loss: 3.0415 - val_accuracy: 0.0440\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 3.0723 - accuracy: 0.0513 - val_loss: 3.0038 - val_accuracy: 0.0510\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 3.2747 - accuracy: 0.0508 - val_loss: 3.0249 - val_accuracy: 0.0510\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 3.2437 - accuracy: 0.0515 - val_loss: 3.0313 - val_accuracy: 0.0445\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 3.1779 - accuracy: 0.0507 - val_loss: 3.0317 - val_accuracy: 0.0515\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 3.1091 - accuracy: 0.0487 - val_loss: 3.0329 - val_accuracy: 0.0465\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 3.0256 - accuracy: 0.0509 - val_loss: 3.0380 - val_accuracy: 0.0460\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 3.0696 - accuracy: 0.0492 - val_loss: 3.0396 - val_accuracy: 0.0460\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 3.0173 - accuracy: 0.0507 - val_loss: 3.0386 - val_accuracy: 0.0455\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9962 - accuracy: 0.0449 - val_loss: 3.0433 - val_accuracy: 0.0455\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9945 - accuracy: 0.0482 - val_loss: 3.0406 - val_accuracy: 0.0455\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9936 - accuracy: 0.0489 - val_loss: 3.0403 - val_accuracy: 0.0440\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 3.0004 - accuracy: 0.0484 - val_loss: 3.0419 - val_accuracy: 0.0440\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.9933 - accuracy: 0.0523 - val_loss: 3.0445 - val_accuracy: 0.0455\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 2.9979 - accuracy: 0.0501 - val_loss: 3.0475 - val_accuracy: 0.0440\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 2.9979135990142822\n",
      "Training Accuracy: 0.050067801028490067\n",
      "Validation Loss: 3.047482967376709\n",
      "Validation Accuracy: 0.04399999976158142\n",
      "Classification Error Rate: 0.9560000002384186\n",
      "----->Evolution: Child net_11 with fitness 3.047482967376709 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Proportionate selection\n",
      "Selected net_3 and net_7 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e0d4dd00>, <__main__.Block object at 0x7d47dee5a500>, <__main__.Block object at 0x7d47e0d90880>, <__main__.Block object at 0x7d4c2849b0c0>, <__main__.Block object at 0x7d47c95c0940>, <__main__.Block object at 0x7d47dee4d840>, <__main__.Block object at 0x7d4c28315c40>, <__main__.Block object at 0x7d47e0de6700>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_206\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_206/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_206\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.5  to  0.6\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e114c140>, <__main__.Block object at 0x7d47e114d080>, <__main__.Block object at 0x7d47dee744c0>, <__main__.Block object at 0x7d47dee2ed80>, <__main__.Block object at 0x7d47e1175780>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:51:08.324649: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_89/dropout_82/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 10ms/step - loss: 3.4185 - accuracy: 0.0848 - val_loss: 2.7933 - val_accuracy: 0.1165\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 8.6855 - accuracy: 0.1962 - val_loss: 2.4713 - val_accuracy: 0.2250\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 35.2795 - accuracy: 0.3100 - val_loss: 2.6020 - val_accuracy: 0.2530\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 50.0320 - accuracy: 0.3851 - val_loss: 1.9807 - val_accuracy: 0.3915\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 57.1599 - accuracy: 0.4439 - val_loss: 2.1665 - val_accuracy: 0.3605\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 45.4681 - accuracy: 0.4918 - val_loss: 2.3166 - val_accuracy: 0.4005\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 32.3596 - accuracy: 0.5326 - val_loss: 1.9629 - val_accuracy: 0.4215\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 41.3037 - accuracy: 0.5744 - val_loss: 2.3773 - val_accuracy: 0.3995\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 11.2979 - accuracy: 0.6089 - val_loss: 2.3372 - val_accuracy: 0.4330\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 7.6289 - accuracy: 0.6556 - val_loss: 1.7237 - val_accuracy: 0.5185\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 20.0994 - accuracy: 0.6851 - val_loss: 1.9086 - val_accuracy: 0.5235\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 51.4675 - accuracy: 0.7207 - val_loss: 2.1337 - val_accuracy: 0.4755\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 58.4838 - accuracy: 0.7482 - val_loss: 1.9378 - val_accuracy: 0.5140\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 188.4841 - accuracy: 0.7678 - val_loss: 2.2772 - val_accuracy: 0.5520\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 78.1182 - accuracy: 0.7898 - val_loss: 2.3019 - val_accuracy: 0.4820\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 49.1585 - accuracy: 0.7996 - val_loss: 2.1795 - val_accuracy: 0.5575\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 71.4136 - accuracy: 0.8140 - val_loss: 2.0170 - val_accuracy: 0.5535\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 22.5248 - accuracy: 0.8279 - val_loss: 2.9838 - val_accuracy: 0.4775\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 126.5198 - accuracy: 0.8328 - val_loss: 2.3305 - val_accuracy: 0.5505\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 221.8805 - accuracy: 0.8473 - val_loss: 2.8157 - val_accuracy: 0.5425\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 198.0971 - accuracy: 0.8503 - val_loss: 3.0598 - val_accuracy: 0.4480\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 228.9617 - accuracy: 0.8491 - val_loss: 2.7738 - val_accuracy: 0.5345\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 231.4307 - accuracy: 0.8580 - val_loss: 4.4749 - val_accuracy: 0.5155\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 212.3208 - accuracy: 0.8615 - val_loss: 4.9369 - val_accuracy: 0.4635\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 108.1251 - accuracy: 0.8673 - val_loss: 2.4806 - val_accuracy: 0.5360\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 156.7979 - accuracy: 0.8670 - val_loss: 2.8423 - val_accuracy: 0.5450\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 273.0043 - accuracy: 0.8743 - val_loss: 2.5882 - val_accuracy: 0.5570\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 209.7448 - accuracy: 0.8847 - val_loss: 3.2177 - val_accuracy: 0.5170\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 443.8769 - accuracy: 0.8803 - val_loss: 4.2705 - val_accuracy: 0.4735\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 140.6741 - accuracy: 0.8652 - val_loss: 2.9583 - val_accuracy: 0.4935\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 140.6741180419922\n",
      "Training Accuracy: 0.8652341961860657\n",
      "Validation Loss: 2.958258628845215\n",
      "Validation Accuracy: 0.4934999942779541\n",
      "Classification Error Rate: 0.5065000057220459\n",
      "----->Evolution: Child net_12 with fitness 2.958258628845215 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Proportionate selection\n",
      "Selected net_4 and net_7 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c2843d600>, <__main__.Block object at 0x7d47c9e190c0>, <__main__.Block object at 0x7d47df4eb880>, <__main__.Block object at 0x7d47c9eb8c00>, <__main__.Block object at 0x7d47df458940>, <__main__.Block object at 0x7d47c9e28500>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_779. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:52:31.836751: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_90/dropout_83/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 8ms/step - loss: 2.7900 - accuracy: 0.1461 - val_loss: 2.6853 - val_accuracy: 0.1745\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.3202 - accuracy: 0.3014 - val_loss: 2.4400 - val_accuracy: 0.2685\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.0180 - accuracy: 0.3837 - val_loss: 2.0491 - val_accuracy: 0.3640\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.7779 - accuracy: 0.4552 - val_loss: 1.8341 - val_accuracy: 0.4545\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.5735 - accuracy: 0.5329 - val_loss: 1.8799 - val_accuracy: 0.4430\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3758 - accuracy: 0.5859 - val_loss: 1.6795 - val_accuracy: 0.5065\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2368 - accuracy: 0.6324 - val_loss: 1.6372 - val_accuracy: 0.5205\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0773 - accuracy: 0.6773 - val_loss: 1.6820 - val_accuracy: 0.5310\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.9538 - accuracy: 0.7198 - val_loss: 1.6647 - val_accuracy: 0.5465\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8835 - accuracy: 0.7610 - val_loss: 1.4152 - val_accuracy: 0.6025\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.7006 - accuracy: 0.7983 - val_loss: 1.7240 - val_accuracy: 0.5720\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.6296 - accuracy: 0.8153 - val_loss: 1.6928 - val_accuracy: 0.5780\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.6067 - accuracy: 0.8419 - val_loss: 1.7356 - val_accuracy: 0.5965\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.5398 - accuracy: 0.8569 - val_loss: 2.0424 - val_accuracy: 0.5190\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4859 - accuracy: 0.8692 - val_loss: 2.0140 - val_accuracy: 0.5820\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4522 - accuracy: 0.8820 - val_loss: 2.0712 - val_accuracy: 0.5920\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4363 - accuracy: 0.8897 - val_loss: 1.7458 - val_accuracy: 0.6005\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4586 - accuracy: 0.8942 - val_loss: 1.7778 - val_accuracy: 0.5860\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.3735 - accuracy: 0.9037 - val_loss: 2.0121 - val_accuracy: 0.6120\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.3773 - accuracy: 0.9110 - val_loss: 1.7793 - val_accuracy: 0.6110\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.3685 - accuracy: 0.9109 - val_loss: 2.0221 - val_accuracy: 0.6310\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.3775 - accuracy: 0.9198 - val_loss: 2.1040 - val_accuracy: 0.5880\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.3992 - accuracy: 0.9138 - val_loss: 2.1570 - val_accuracy: 0.5575\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.3543 - accuracy: 0.9191 - val_loss: 1.6958 - val_accuracy: 0.5830\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.3925 - accuracy: 0.9180 - val_loss: 2.2666 - val_accuracy: 0.6505\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4511 - accuracy: 0.9253 - val_loss: 2.0383 - val_accuracy: 0.5795\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.3436 - accuracy: 0.9288 - val_loss: 2.0634 - val_accuracy: 0.6035\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4076 - accuracy: 0.9278 - val_loss: 2.2323 - val_accuracy: 0.6145\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.4081 - accuracy: 0.9289 - val_loss: 1.6596 - val_accuracy: 0.5955\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.3269 - accuracy: 0.9313 - val_loss: 1.9358 - val_accuracy: 0.6285\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 0.32686078548431396\n",
      "Training Accuracy: 0.9312610626220703\n",
      "Validation Loss: 1.9358001947402954\n",
      "Validation Accuracy: 0.6284999847412109\n",
      "Classification Error Rate: 0.37150001525878906\n",
      "----->Evolution: Child net_13 with fitness 1.9358001947402954 replaces parent net_5 with fitness 2.6059792041778564\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 13\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.5  to  0.45\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c8c557e80>, <__main__.Block object at 0x7d4c63971340>, <__main__.Block object at 0x7d4c8c083ac0>, <__main__.Block object at 0x7d4c1038f900>, <__main__.Block object at 0x7d47dbbd7b80>, <__main__.Block object at 0x7d47dff41040>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_787. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:53:55.523917: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_91/dropout_84/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 9ms/step - loss: 2.7751 - accuracy: 0.1428 - val_loss: 2.3787 - val_accuracy: 0.2615\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.2834 - accuracy: 0.2944 - val_loss: 1.9182 - val_accuracy: 0.4300\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.0424 - accuracy: 0.3813 - val_loss: 1.8436 - val_accuracy: 0.4580\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.8878 - accuracy: 0.4305 - val_loss: 1.8654 - val_accuracy: 0.4640\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.7132 - accuracy: 0.4910 - val_loss: 1.7630 - val_accuracy: 0.4850\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.5921 - accuracy: 0.5226 - val_loss: 1.6666 - val_accuracy: 0.5255\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4879 - accuracy: 0.5565 - val_loss: 1.5029 - val_accuracy: 0.5610\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4006 - accuracy: 0.5824 - val_loss: 1.5972 - val_accuracy: 0.5555\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3201 - accuracy: 0.6091 - val_loss: 1.7503 - val_accuracy: 0.5425\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2692 - accuracy: 0.6286 - val_loss: 1.5025 - val_accuracy: 0.5915\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2009 - accuracy: 0.6438 - val_loss: 1.5649 - val_accuracy: 0.5710\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1392 - accuracy: 0.6627 - val_loss: 1.5599 - val_accuracy: 0.6095\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1071 - accuracy: 0.6775 - val_loss: 1.4844 - val_accuracy: 0.6290\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0623 - accuracy: 0.6915 - val_loss: 1.9046 - val_accuracy: 0.5970\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0247 - accuracy: 0.7027 - val_loss: 1.7313 - val_accuracy: 0.5855\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9998 - accuracy: 0.7104 - val_loss: 1.7452 - val_accuracy: 0.6325\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9454 - accuracy: 0.7301 - val_loss: 1.8945 - val_accuracy: 0.6040\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9723 - accuracy: 0.7272 - val_loss: 1.8450 - val_accuracy: 0.6220\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9095 - accuracy: 0.7427 - val_loss: 1.6471 - val_accuracy: 0.6640\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9216 - accuracy: 0.7356 - val_loss: 2.1484 - val_accuracy: 0.5955\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8959 - accuracy: 0.7495 - val_loss: 1.7864 - val_accuracy: 0.5965\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8691 - accuracy: 0.7601 - val_loss: 2.1369 - val_accuracy: 0.6225\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8408 - accuracy: 0.7668 - val_loss: 1.8348 - val_accuracy: 0.6450\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8805 - accuracy: 0.7612 - val_loss: 2.2546 - val_accuracy: 0.6225\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8356 - accuracy: 0.7743 - val_loss: 1.7223 - val_accuracy: 0.6360\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8207 - accuracy: 0.7752 - val_loss: 2.0125 - val_accuracy: 0.6230\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8732 - accuracy: 0.7696 - val_loss: 1.9794 - val_accuracy: 0.6280\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8682 - accuracy: 0.7759 - val_loss: 1.7087 - val_accuracy: 0.6220\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8218 - accuracy: 0.7819 - val_loss: 1.8118 - val_accuracy: 0.5990\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8355 - accuracy: 0.7808 - val_loss: 1.9652 - val_accuracy: 0.6375\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.8355088233947754\n",
      "Training Accuracy: 0.780849039554596\n",
      "Validation Loss: 1.9652397632598877\n",
      "Validation Accuracy: 0.637499988079071\n",
      "Classification Error Rate: 0.36250001192092896\n",
      "----->Evolution: Child net_10 with fitness 1.9652397632598877 replaces parent net_2 with fitness 2.3705034255981445\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf9ff2f00>, <__main__.Block object at 0x7d47e0bc79c0>, <__main__.Block object at 0x7d47e0be4680>, <__main__.Block object at 0x7d47e0be6f80>, <__main__.Block object at 0x7d47def99f40>, <__main__.Block object at 0x7d47df228880>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_793\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_793/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_793/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,32], [3,3,32,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_793\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 32), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:54:59.383988: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_92/dropout_85/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 4s 8ms/step - loss: 2.8375 - accuracy: 0.1206 - val_loss: 2.4902 - val_accuracy: 0.2945\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.3768 - accuracy: 0.2677 - val_loss: 2.1765 - val_accuracy: 0.3175\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.0736 - accuracy: 0.3667 - val_loss: 1.7547 - val_accuracy: 0.4655\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.8899 - accuracy: 0.4335 - val_loss: 1.6699 - val_accuracy: 0.4890\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.7139 - accuracy: 0.4789 - val_loss: 1.6206 - val_accuracy: 0.5205\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.5858 - accuracy: 0.5148 - val_loss: 1.5736 - val_accuracy: 0.5345\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.4745 - accuracy: 0.5548 - val_loss: 1.5631 - val_accuracy: 0.5405\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.3776 - accuracy: 0.5838 - val_loss: 1.4196 - val_accuracy: 0.5870\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.2471 - accuracy: 0.6183 - val_loss: 1.4310 - val_accuracy: 0.6070\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.1385 - accuracy: 0.6549 - val_loss: 1.5489 - val_accuracy: 0.5575\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.0312 - accuracy: 0.6855 - val_loss: 1.4246 - val_accuracy: 0.6150\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.9560 - accuracy: 0.7000 - val_loss: 1.5222 - val_accuracy: 0.6095\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8654 - accuracy: 0.7291 - val_loss: 1.8767 - val_accuracy: 0.5970\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7944 - accuracy: 0.7495 - val_loss: 1.6594 - val_accuracy: 0.6390\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.7381 - accuracy: 0.7685 - val_loss: 1.7790 - val_accuracy: 0.6355\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.6980 - accuracy: 0.7868 - val_loss: 1.6227 - val_accuracy: 0.6320\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.6555 - accuracy: 0.7984 - val_loss: 1.6344 - val_accuracy: 0.6190\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.6012 - accuracy: 0.8165 - val_loss: 1.7464 - val_accuracy: 0.6360\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5911 - accuracy: 0.8187 - val_loss: 1.8932 - val_accuracy: 0.6060\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5576 - accuracy: 0.8294 - val_loss: 2.2697 - val_accuracy: 0.6170\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5550 - accuracy: 0.8406 - val_loss: 2.2059 - val_accuracy: 0.6230\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5462 - accuracy: 0.8384 - val_loss: 2.4583 - val_accuracy: 0.6275\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5505 - accuracy: 0.8398 - val_loss: 2.3117 - val_accuracy: 0.6475\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5455 - accuracy: 0.8479 - val_loss: 1.9638 - val_accuracy: 0.6280\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5229 - accuracy: 0.8550 - val_loss: 2.6460 - val_accuracy: 0.6050\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5318 - accuracy: 0.8534 - val_loss: 2.5523 - val_accuracy: 0.6275\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5496 - accuracy: 0.8556 - val_loss: 2.0874 - val_accuracy: 0.6290\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5751 - accuracy: 0.8433 - val_loss: 2.1735 - val_accuracy: 0.6155\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5372 - accuracy: 0.8499 - val_loss: 2.6866 - val_accuracy: 0.6100\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.5812 - accuracy: 0.8439 - val_loss: 2.2656 - val_accuracy: 0.6340\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 0.5811806321144104\n",
      "Training Accuracy: 0.8438510298728943\n",
      "Validation Loss: 2.2656493186950684\n",
      "Validation Accuracy: 0.6340000033378601\n",
      "Classification Error Rate: 0.3659999966621399\n",
      "----->Evolution: Child net_11 with fitness 2.2656493186950684 replaces parent net_9 with fitness 2.367948055267334\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.5\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.5  to  0.45\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47df6fbc40>, <__main__.Block object at 0x7d47e057da00>, <__main__.Block object at 0x7d47df85aac0>, <__main__.Block object at 0x7d47e0abc1c0>, <__main__.Block object at 0x7d47e05a9040>, <__main__.Block object at 0x7d47df8b43c0>, <__main__.Block object at 0x7d47e0ad6fc0>, <__main__.Block object at 0x7d47df8fd040>, <__main__.Block object at 0x7d47e0b165c0>, <__main__.Block object at 0x7d47e0b25080>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_803. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_804. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_219\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_219/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_219\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.35000000000000003\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e0414500>, <__main__.Block object at 0x7d47e0416c40>, <__main__.Block object at 0x7d47e0416880>, <__main__.Block object at 0x7d47e0415e00>, <__main__.Block object at 0x7d47e0416c80>, <__main__.Block object at 0x7d47e0416cc0>, <__main__.Block object at 0x7d47e0418cc0>, <__main__.Block object at 0x7d47e0418480>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_815. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_816. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:55:54.979990: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_94/dropout_88/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 7s 11ms/step - loss: 3.0144 - accuracy: 0.0585 - val_loss: 2.9548 - val_accuracy: 0.0670\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.7929 - accuracy: 0.1220 - val_loss: 2.6194 - val_accuracy: 0.1675\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.6316 - accuracy: 0.1797 - val_loss: 2.8877 - val_accuracy: 0.1185\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.4781 - accuracy: 0.2444 - val_loss: 2.3308 - val_accuracy: 0.2920\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.2929 - accuracy: 0.2922 - val_loss: 2.6660 - val_accuracy: 0.2755\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.2177 - accuracy: 0.3269 - val_loss: 2.7005 - val_accuracy: 0.2855\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.1258 - accuracy: 0.3527 - val_loss: 2.0102 - val_accuracy: 0.3775\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.0719 - accuracy: 0.3820 - val_loss: 1.9336 - val_accuracy: 0.3960\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.0117 - accuracy: 0.4057 - val_loss: 2.1008 - val_accuracy: 0.3790\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9801 - accuracy: 0.4241 - val_loss: 1.9737 - val_accuracy: 0.4240\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.0694 - accuracy: 0.4518 - val_loss: 1.8343 - val_accuracy: 0.4610\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.0766 - accuracy: 0.4640 - val_loss: 2.0567 - val_accuracy: 0.4590\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.1068 - accuracy: 0.4793 - val_loss: 1.8170 - val_accuracy: 0.4735\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.2109 - accuracy: 0.4924 - val_loss: 1.7462 - val_accuracy: 0.4910\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.3847 - accuracy: 0.5018 - val_loss: 1.7255 - val_accuracy: 0.5070\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.9909 - accuracy: 0.5119 - val_loss: 1.7752 - val_accuracy: 0.4760\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.0434 - accuracy: 0.5263 - val_loss: 1.8298 - val_accuracy: 0.4480\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.0283 - accuracy: 0.5403 - val_loss: 2.2273 - val_accuracy: 0.4655\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.9960 - accuracy: 0.5574 - val_loss: 1.8241 - val_accuracy: 0.4795\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.8600 - accuracy: 0.5625 - val_loss: 1.7391 - val_accuracy: 0.5135\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.8715 - accuracy: 0.5689 - val_loss: 1.7293 - val_accuracy: 0.5220\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.9318 - accuracy: 0.5759 - val_loss: 1.8052 - val_accuracy: 0.5125\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.2996 - accuracy: 0.5835 - val_loss: 1.8430 - val_accuracy: 0.4705\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.8242 - accuracy: 0.5815 - val_loss: 2.4067 - val_accuracy: 0.4695\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 3.2043 - accuracy: 0.5826 - val_loss: 2.4807 - val_accuracy: 0.4115\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.2665 - accuracy: 0.5790 - val_loss: 1.7899 - val_accuracy: 0.5135\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 4.0873 - accuracy: 0.5972 - val_loss: 2.5623 - val_accuracy: 0.4925\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.3301 - accuracy: 0.5890 - val_loss: 2.0358 - val_accuracy: 0.4655\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 4.4137 - accuracy: 0.5988 - val_loss: 4.2335 - val_accuracy: 0.4015\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 3.3914 - accuracy: 0.5934 - val_loss: 1.9476 - val_accuracy: 0.4445\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 3.391374111175537\n",
      "Training Accuracy: 0.5934077501296997\n",
      "Validation Loss: 1.9475840330123901\n",
      "Validation Accuracy: 0.44449999928474426\n",
      "Classification Error Rate: 0.5555000007152557\n",
      "----->Evolution: Child net_12 with fitness 1.9475840330123901 replaces parent parent_0 with fitness 2.3568124771118164\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.5\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf909d0c0>, <__main__.Block object at 0x7d4bf9042180>, <__main__.Block object at 0x7d47dc266580>, <__main__.Block object at 0x7d47c9ad9040>, <__main__.Block object at 0x7d4bf9d18200>, <__main__.Block object at 0x7d47dc256580>, <__main__.Block object at 0x7d4bf9115840>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_827\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_827/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_827/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,64].\n",
      "\n",
      "Call arguments received by layer \"conv2d_827\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_828\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_828/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_828/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_828\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_227\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_227/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_227\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2)]\n",
      "Removing a Conv2D layer at 0\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.45\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.5  to  0.6\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47c9ed5780>, <__main__.Block object at 0x7d47c9ed63c0>, <__main__.Block object at 0x7d47c9ed6440>, <__main__.Block object at 0x7d47c9d9f900>, <__main__.Block object at 0x7d47df491740>, <__main__.Block object at 0x7d47e00e99c0>, <__main__.Block object at 0x7d47c9d00f80>, <__main__.Block object at 0x7d47df4c8a00>, <__main__.Block object at 0x7d47e011d000>, <__main__.Block object at 0x7d47e04f5e00>, <__main__.Block object at 0x7d47e08bfc40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_838\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_838/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_838/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,256], [3,3,256,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_838\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 256), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_845. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:57:27.510761: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_96/dropout_92/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 8s 12ms/step - loss: 2.9973 - accuracy: 0.0514 - val_loss: 2.9957 - val_accuracy: 0.0440\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.9969 - accuracy: 0.0507 - val_loss: 2.9969 - val_accuracy: 0.0440\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.9978 - accuracy: 0.0495 - val_loss: 2.9968 - val_accuracy: 0.0455\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.9481 - accuracy: 0.0770 - val_loss: 2.9418 - val_accuracy: 0.0865\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.8258 - accuracy: 0.0968 - val_loss: 2.8396 - val_accuracy: 0.1360\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.7300 - accuracy: 0.1403 - val_loss: 2.8056 - val_accuracy: 0.1465\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.6327 - accuracy: 0.1684 - val_loss: 2.6551 - val_accuracy: 0.1740\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.5315 - accuracy: 0.1900 - val_loss: 2.6301 - val_accuracy: 0.1245\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.4487 - accuracy: 0.2113 - val_loss: 2.5043 - val_accuracy: 0.1730\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.4103 - accuracy: 0.2161 - val_loss: 2.5092 - val_accuracy: 0.1690\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.3582 - accuracy: 0.2319 - val_loss: 2.3808 - val_accuracy: 0.2160\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.2960 - accuracy: 0.2485 - val_loss: 2.2791 - val_accuracy: 0.2405\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.2300 - accuracy: 0.2787 - val_loss: 2.2419 - val_accuracy: 0.2650\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.1491 - accuracy: 0.3073 - val_loss: 2.1346 - val_accuracy: 0.2915\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.0910 - accuracy: 0.3368 - val_loss: 2.3503 - val_accuracy: 0.2485\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.0456 - accuracy: 0.3439 - val_loss: 2.1752 - val_accuracy: 0.2730\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.0212 - accuracy: 0.3711 - val_loss: 2.1686 - val_accuracy: 0.3140\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.9559 - accuracy: 0.3850 - val_loss: 2.1097 - val_accuracy: 0.3375\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.9102 - accuracy: 0.4065 - val_loss: 2.2264 - val_accuracy: 0.3155\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.8812 - accuracy: 0.4106 - val_loss: 1.9444 - val_accuracy: 0.4095\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.8445 - accuracy: 0.4311 - val_loss: 1.9851 - val_accuracy: 0.3925\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.8256 - accuracy: 0.4425 - val_loss: 2.2136 - val_accuracy: 0.3265\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.7992 - accuracy: 0.4554 - val_loss: 2.5883 - val_accuracy: 0.4430\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.7944 - accuracy: 0.4748 - val_loss: 2.3972 - val_accuracy: 0.3315\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.7637 - accuracy: 0.4689 - val_loss: 1.8228 - val_accuracy: 0.4515\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.7472 - accuracy: 0.4790 - val_loss: 2.0243 - val_accuracy: 0.4020\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.7055 - accuracy: 0.4859 - val_loss: 1.9331 - val_accuracy: 0.4330\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6891 - accuracy: 0.4948 - val_loss: 2.2282 - val_accuracy: 0.4100\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6669 - accuracy: 0.4968 - val_loss: 1.7932 - val_accuracy: 0.4620\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6616 - accuracy: 0.5087 - val_loss: 1.9362 - val_accuracy: 0.4160\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 1.661582350730896\n",
      "Training Accuracy: 0.508709728717804\n",
      "Validation Loss: 1.9361917972564697\n",
      "Validation Accuracy: 0.41600000858306885\n",
      "Classification Error Rate: 0.5839999914169312\n",
      "----->Evolution: Child net_13 with fitness 1.9361917972564697 replaces parent net_6 with fitness 2.2789652347564697\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 14\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Proportionate selection\n",
      "Selected net_8 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.45\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf967df80>, <__main__.Block object at 0x7d47dc016680>, <__main__.Block object at 0x7d47dbeffbc0>, <__main__.Block object at 0x7d47dbef8880>, <__main__.Block object at 0x7d47e0bb9040>, <__main__.Block object at 0x7d47dc192d80>, <__main__.Block object at 0x7d47dc070b00>, <__main__.Block object at 0x7d47dbfecf00>, <__main__.Block object at 0x7d47dc1d48c0>, <__main__.Block object at 0x7d47dc09aa00>, <__main__.Block object at 0x7d47dc06db80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_855. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_856. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_215\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_215/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_215\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.35000000000000003\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47dfd128c0>, <__main__.Block object at 0x7d47dfd11440>, <__main__.Block object at 0x7d47dfd12800>, <__main__.Block object at 0x7d47dfd12a80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 10:59:51.632871: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_98/dropout_97/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 4s 6ms/step - loss: 2.5895 - accuracy: 0.2377 - val_loss: 2.6474 - val_accuracy: 0.3055\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.9935 - accuracy: 0.4174 - val_loss: 2.9620 - val_accuracy: 0.3750\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.7203 - accuracy: 0.5023 - val_loss: 2.7214 - val_accuracy: 0.3935\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.5573 - accuracy: 0.5550 - val_loss: 3.3832 - val_accuracy: 0.3805\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.4137 - accuracy: 0.5930 - val_loss: 2.2882 - val_accuracy: 0.5120\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.3035 - accuracy: 0.6288 - val_loss: 3.0251 - val_accuracy: 0.4720\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.2517 - accuracy: 0.6523 - val_loss: 2.4560 - val_accuracy: 0.5165\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.2067 - accuracy: 0.6762 - val_loss: 4.6631 - val_accuracy: 0.4245\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.0675 - accuracy: 0.7004 - val_loss: 2.9078 - val_accuracy: 0.5120\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.0722 - accuracy: 0.7194 - val_loss: 2.9580 - val_accuracy: 0.5325\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.0479 - accuracy: 0.7390 - val_loss: 2.5968 - val_accuracy: 0.5465\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.0442 - accuracy: 0.7510 - val_loss: 2.6589 - val_accuracy: 0.6195\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.9000 - accuracy: 0.7601 - val_loss: 4.1551 - val_accuracy: 0.4635\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.9558 - accuracy: 0.7710 - val_loss: 7.4183 - val_accuracy: 0.4525\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.8668 - accuracy: 0.7830 - val_loss: 3.3024 - val_accuracy: 0.5705\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.0900 - accuracy: 0.7907 - val_loss: 5.1970 - val_accuracy: 0.5275\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.9830 - accuracy: 0.7995 - val_loss: 3.2178 - val_accuracy: 0.5620\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.9447 - accuracy: 0.8085 - val_loss: 3.3516 - val_accuracy: 0.5665\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.0281 - accuracy: 0.8098 - val_loss: 3.4765 - val_accuracy: 0.5935\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.9701 - accuracy: 0.8103 - val_loss: 4.5065 - val_accuracy: 0.4865\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.0871 - accuracy: 0.8177 - val_loss: 4.9250 - val_accuracy: 0.5900\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.1230 - accuracy: 0.8189 - val_loss: 4.0886 - val_accuracy: 0.5135\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.2116 - accuracy: 0.8351 - val_loss: 5.0968 - val_accuracy: 0.5960\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.9290 - accuracy: 0.8321 - val_loss: 6.3402 - val_accuracy: 0.4895\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.1353 - accuracy: 0.8272 - val_loss: 5.0438 - val_accuracy: 0.5575\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.1841 - accuracy: 0.8325 - val_loss: 5.7903 - val_accuracy: 0.5870\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.2159 - accuracy: 0.8391 - val_loss: 4.6676 - val_accuracy: 0.5710\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.4613 - accuracy: 0.8273 - val_loss: 5.1985 - val_accuracy: 0.5465\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.5238 - accuracy: 0.8383 - val_loss: 4.8179 - val_accuracy: 0.5775\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 1.2864 - accuracy: 0.8384 - val_loss: 8.7585 - val_accuracy: 0.4655\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 1.2863843441009521\n",
      "Training Accuracy: 0.8384270071983337\n",
      "Validation Loss: 8.758525848388672\n",
      "Validation Accuracy: 0.46549999713897705\n",
      "Classification Error Rate: 0.534500002861023\n",
      "----->Evolution: Child net_10 with fitness 8.758525848388672 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Proportionate selection\n",
      "Selected net_6 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.45  to  0.35\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.35000000000000003\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.6  to  0.5\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e129d600>, <__main__.Block object at 0x7d4bf82fa500>, <__main__.Block object at 0x7d47e9a23880>, <__main__.Block object at 0x7d4bf9e230c0>, <__main__.Block object at 0x7d4bf9e90940>, <__main__.Block object at 0x7d47e06fd980>, <__main__.Block object at 0x7d47df5ee5c0>, <__main__.Block object at 0x7d47e23c5c40>, <__main__.Block object at 0x7d4c39bc6640>, <__main__.Block object at 0x7d47c9df7240>, <__main__.Block object at 0x7d4bf9e72e40>, <__main__.Block object at 0x7d47e8584280>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_873. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_246\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_246/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,64].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_246\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 64), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.35000000000000003\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.6  to  0.65\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e0b1d100>, <__main__.Block object at 0x7d47e0b1d800>, <__main__.Block object at 0x7d47e0b1da00>, <__main__.Block object at 0x7d47e0b1f900>, <__main__.Block object at 0x7d47e0b1fd80>, <__main__.Block object at 0x7d47e0b1d640>, <__main__.Block object at 0x7d47e0b1cf00>, <__main__.Block object at 0x7d47e0b1f6c0>, <__main__.Block object at 0x7d47e0b1e240>, <__main__.Block object at 0x7d47e0b1f9c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_887\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_887/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_887/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,64], [3,3,64,256].\n",
      "\n",
      "Call arguments received by layer \"conv2d_887\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 64), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_889. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_251\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_251/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_251\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf826e140>, <__main__.Block object at 0x7d4bf826e540>, <__main__.Block object at 0x7d4bf826e180>, <__main__.Block object at 0x7d4bf826e600>, <__main__.Block object at 0x7d4bf826e6c0>, <__main__.Block object at 0x7d4bf826e800>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_899\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_899/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_899/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,64], [3,3,64,256].\n",
      "\n",
      "Call arguments received by layer \"conv2d_899\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 64), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:01:15.427999: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_101/dropout_101/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 6s 11ms/step - loss: 2.9090 - accuracy: 0.1135 - val_loss: 2.7243 - val_accuracy: 0.1695\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 2.6193 - accuracy: 0.2359 - val_loss: 2.7139 - val_accuracy: 0.2350\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.4619 - accuracy: 0.3334 - val_loss: 2.5286 - val_accuracy: 0.3260\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.2545 - accuracy: 0.3977 - val_loss: 2.1763 - val_accuracy: 0.3420\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 1.9838 - accuracy: 0.4479 - val_loss: 1.8655 - val_accuracy: 0.4470\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.3073 - accuracy: 0.4971 - val_loss: 1.7660 - val_accuracy: 0.4775\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.7324 - accuracy: 0.5352 - val_loss: 1.7528 - val_accuracy: 0.4695\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.6561 - accuracy: 0.5721 - val_loss: 1.6403 - val_accuracy: 0.5300\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.8535 - accuracy: 0.6164 - val_loss: 1.4976 - val_accuracy: 0.5715\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.6230 - accuracy: 0.6478 - val_loss: 2.2528 - val_accuracy: 0.4805\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.4263 - accuracy: 0.6692 - val_loss: 1.9707 - val_accuracy: 0.5500\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.5969 - accuracy: 0.6992 - val_loss: 1.6523 - val_accuracy: 0.5530\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 1.6130 - accuracy: 0.7181 - val_loss: 1.7418 - val_accuracy: 0.5690\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.9175 - accuracy: 0.7463 - val_loss: 2.0498 - val_accuracy: 0.5585\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.1993 - accuracy: 0.7657 - val_loss: 1.6743 - val_accuracy: 0.6050\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 4.4203 - accuracy: 0.7797 - val_loss: 1.6301 - val_accuracy: 0.6180\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.6081 - accuracy: 0.8036 - val_loss: 1.8200 - val_accuracy: 0.6095\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 7.6383 - accuracy: 0.8089 - val_loss: 1.7254 - val_accuracy: 0.6360\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.0919 - accuracy: 0.8259 - val_loss: 1.7441 - val_accuracy: 0.6425\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.1202 - accuracy: 0.8327 - val_loss: 2.4237 - val_accuracy: 0.6450\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.3169 - accuracy: 0.8405 - val_loss: 1.7737 - val_accuracy: 0.6270\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 4.6476 - accuracy: 0.8492 - val_loss: 2.1913 - val_accuracy: 0.6570\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 7.3416 - accuracy: 0.8623 - val_loss: 2.2954 - val_accuracy: 0.6500\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 5.7646 - accuracy: 0.8658 - val_loss: 2.8352 - val_accuracy: 0.6265\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 8.0718 - accuracy: 0.8708 - val_loss: 3.6755 - val_accuracy: 0.6355\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 10.3093 - accuracy: 0.8663 - val_loss: 2.7876 - val_accuracy: 0.6060\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 13.5557 - accuracy: 0.8714 - val_loss: 1.7531 - val_accuracy: 0.6035\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 12.2695 - accuracy: 0.8759 - val_loss: 2.6144 - val_accuracy: 0.6040\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 14.8721 - accuracy: 0.8806 - val_loss: 2.2029 - val_accuracy: 0.5925\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 14.3204 - accuracy: 0.8755 - val_loss: 2.0835 - val_accuracy: 0.6425\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 14.32040786743164\n",
      "Training Accuracy: 0.8754563331604004\n",
      "Validation Loss: 2.083534002304077\n",
      "Validation Accuracy: 0.6424999833106995\n",
      "Classification Error Rate: 0.35750001668930054\n",
      "----->Evolution: Child net_11 with fitness 2.083534002304077 replaces parent net_9 with fitness 2.2656493186950684\n",
      "\n",
      "Creating Child 2\n",
      "----->Proportionate selection\n",
      "Selected net_1 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.35000000000000003\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e05fa440>, <__main__.Block object at 0x7d47dc9cda00>, <__main__.Block object at 0x7d47e06c1d80>, <__main__.Block object at 0x7d47e050b480>, <__main__.Block object at 0x7d47e07aaac0>, <__main__.Block object at 0x7d47e064a6c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_907. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_256\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_256/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_256\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2)]\n",
      "Removing a Conv2D layer at 1\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47dc80d3c0>, <__main__.Block object at 0x7d47dc80c100>, <__main__.Block object at 0x7d47dc80f500>, <__main__.Block object at 0x7d47dc80f480>, <__main__.Block object at 0x7d47dc80fb80>, <__main__.Block object at 0x7d47dc80fbc0>, <__main__.Block object at 0x7d47dc80fc80>, <__main__.Block object at 0x7d47dc80fcc0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_914\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_914/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_914/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,256].\n",
      "\n",
      "Call arguments received by layer \"conv2d_914\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_258\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_258/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_258\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47dc7ff580>, <__main__.Block object at 0x7d47dc7ff4c0>, <__main__.Block object at 0x7d47dc7ffa80>, <__main__.Block object at 0x7d47dc7ffc40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 6s 12ms/step - loss: 3.2482 - accuracy: 0.1128 - val_loss: 2.6282 - val_accuracy: 0.2085\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.2805 - accuracy: 0.3282 - val_loss: 2.1372 - val_accuracy: 0.3545\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.9679 - accuracy: 0.4375 - val_loss: 2.0101 - val_accuracy: 0.4335\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6436 - accuracy: 0.5222 - val_loss: 2.7516 - val_accuracy: 0.2920\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.4728 - accuracy: 0.5911 - val_loss: 2.3724 - val_accuracy: 0.4155\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.2604 - accuracy: 0.6559 - val_loss: 1.7886 - val_accuracy: 0.5245\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.9491 - accuracy: 0.7283 - val_loss: 1.7445 - val_accuracy: 0.5365\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.8410 - accuracy: 0.7825 - val_loss: 2.1642 - val_accuracy: 0.5335\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.6974 - accuracy: 0.8298 - val_loss: 2.6629 - val_accuracy: 0.5010\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.4902 - accuracy: 0.8717 - val_loss: 3.4218 - val_accuracy: 0.4155\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.4627 - accuracy: 0.8834 - val_loss: 3.1561 - val_accuracy: 0.5565\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.4846 - accuracy: 0.8970 - val_loss: 3.6078 - val_accuracy: 0.5410\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.4925 - accuracy: 0.8985 - val_loss: 3.5016 - val_accuracy: 0.5120\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.4098 - accuracy: 0.9066 - val_loss: 3.5289 - val_accuracy: 0.5320\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.0315 - accuracy: 0.9150 - val_loss: 4.7125 - val_accuracy: 0.5580\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.4196 - accuracy: 0.9171 - val_loss: 4.9541 - val_accuracy: 0.5575\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.3992 - accuracy: 0.9203 - val_loss: 4.6553 - val_accuracy: 0.5505\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.6705 - accuracy: 0.9272 - val_loss: 4.7661 - val_accuracy: 0.5265\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.4472 - accuracy: 0.9236 - val_loss: 4.7677 - val_accuracy: 0.5600\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.6646 - accuracy: 0.9254 - val_loss: 6.3091 - val_accuracy: 0.5300\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.4948 - accuracy: 0.9268 - val_loss: 6.4300 - val_accuracy: 0.5025\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.5313 - accuracy: 0.9232 - val_loss: 5.4745 - val_accuracy: 0.5455\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.6568 - accuracy: 0.9245 - val_loss: 5.9749 - val_accuracy: 0.5075\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.6982 - accuracy: 0.9278 - val_loss: 7.1870 - val_accuracy: 0.5415\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.5418 - accuracy: 0.9276 - val_loss: 8.6554 - val_accuracy: 0.5600\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.6914 - accuracy: 0.9278 - val_loss: 8.8692 - val_accuracy: 0.5360\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.7211 - accuracy: 0.9285 - val_loss: 7.2172 - val_accuracy: 0.5135\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.5876 - accuracy: 0.9248 - val_loss: 8.2347 - val_accuracy: 0.5545\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.9858 - accuracy: 0.9246 - val_loss: 10.6220 - val_accuracy: 0.5250\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 0.7845 - accuracy: 0.9294 - val_loss: 8.2524 - val_accuracy: 0.5345\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 0.7844759821891785\n",
      "Training Accuracy: 0.9293835163116455\n",
      "Validation Loss: 8.252416610717773\n",
      "Validation Accuracy: 0.534500002861023\n",
      "Classification Error Rate: 0.46549999713897705\n",
      "----->Evolution: Child net_12 with fitness 8.252416610717773 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Proportionate selection\n",
      "Selected parent_0 and net_7 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.35000000000000003\n",
      "Mutating Conv2D layer:\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  1024  to  512.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47dc6281c0>, <__main__.Block object at 0x7d47dc5910c0>, <__main__.Block object at 0x7d47dc3fb200>, <__main__.Block object at 0x7d47dc79b880>, <__main__.Block object at 0x7d47dc70e700>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_926\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_926/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_926/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,256], [3,3,256,256].\n",
      "\n",
      "Call arguments received by layer \"conv2d_926\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 256), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:04:13.787546: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_105/dropout_104/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 10ms/step - loss: 2.6688 - accuracy: 0.1741 - val_loss: 2.3565 - val_accuracy: 0.2865\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.2793 - accuracy: 0.3430 - val_loss: 2.2692 - val_accuracy: 0.3495\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.8277 - accuracy: 0.4517 - val_loss: 1.9374 - val_accuracy: 0.4420\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.5540 - accuracy: 0.5352 - val_loss: 1.4223 - val_accuracy: 0.5795\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.3945 - accuracy: 0.5903 - val_loss: 1.3243 - val_accuracy: 0.6055\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.1894 - accuracy: 0.6466 - val_loss: 1.3139 - val_accuracy: 0.6265\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0760 - accuracy: 0.6882 - val_loss: 1.4089 - val_accuracy: 0.6310\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.9609 - accuracy: 0.7207 - val_loss: 1.4922 - val_accuracy: 0.6360\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.8820 - accuracy: 0.7496 - val_loss: 1.3751 - val_accuracy: 0.6605\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.7934 - accuracy: 0.7720 - val_loss: 1.2562 - val_accuracy: 0.6845\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.7591 - accuracy: 0.7835 - val_loss: 1.3902 - val_accuracy: 0.6725\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.7019 - accuracy: 0.8179 - val_loss: 1.3089 - val_accuracy: 0.6880\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.6315 - accuracy: 0.8246 - val_loss: 1.3280 - val_accuracy: 0.6825\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.5730 - accuracy: 0.8389 - val_loss: 1.4895 - val_accuracy: 0.6915\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.5767 - accuracy: 0.8494 - val_loss: 1.5793 - val_accuracy: 0.6660\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.5175 - accuracy: 0.8658 - val_loss: 1.0879 - val_accuracy: 0.7370\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.5025 - accuracy: 0.8726 - val_loss: 1.2729 - val_accuracy: 0.7105\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.5430 - accuracy: 0.8720 - val_loss: 2.4846 - val_accuracy: 0.6680\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.4950 - accuracy: 0.8794 - val_loss: 1.3373 - val_accuracy: 0.7020\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.5052 - accuracy: 0.8833 - val_loss: 1.6913 - val_accuracy: 0.6810\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.5107 - accuracy: 0.8866 - val_loss: 1.3290 - val_accuracy: 0.7235\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.4785 - accuracy: 0.8900 - val_loss: 1.5413 - val_accuracy: 0.7150\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.4668 - accuracy: 0.8968 - val_loss: 1.6792 - val_accuracy: 0.7100\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.4811 - accuracy: 0.8948 - val_loss: 1.4172 - val_accuracy: 0.7210\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.4604 - accuracy: 0.9022 - val_loss: 1.7349 - val_accuracy: 0.7165\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.4503 - accuracy: 0.9008 - val_loss: 1.7846 - val_accuracy: 0.7350\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.4873 - accuracy: 0.9042 - val_loss: 1.5246 - val_accuracy: 0.7415\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.4384 - accuracy: 0.9095 - val_loss: 2.2460 - val_accuracy: 0.6870\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.4932 - accuracy: 0.9083 - val_loss: 2.8628 - val_accuracy: 0.6860\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.5007 - accuracy: 0.9104 - val_loss: 1.8610 - val_accuracy: 0.7080\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 0.5007392168045044\n",
      "Training Accuracy: 0.9103994965553284\n",
      "Validation Loss: 1.8609609603881836\n",
      "Validation Accuracy: 0.7080000042915344\n",
      "Classification Error Rate: 0.2919999957084656\n",
      "----->Evolution: Child net_13 with fitness 1.8609609603881836 replaces parent net_4 with fitness 2.1554460525512695\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 15\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.5\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4c282a1e80>, <__main__.Block object at 0x7d4c281ec880>, <__main__.Block object at 0x7d4c281e8200>, <__main__.Block object at 0x7d4c18747880>, <__main__.Block object at 0x7d47de6f1040>, <__main__.Block object at 0x7d47de7eca80>, <__main__.Block object at 0x7d47de894f40>, <__main__.Block object at 0x7d47de9a3c00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_938\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_938/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_938/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,256], [3,3,256,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_938\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 256), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_939\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_939/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_939/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,256], [3,3,256,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_939\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 256), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_267\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_267/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_267\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.30000000000000004\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47de738780>, <__main__.Block object at 0x7d47de738180>, <__main__.Block object at 0x7d47de738b40>, <__main__.Block object at 0x7d47de738c00>, <__main__.Block object at 0x7d47de738e00>, <__main__.Block object at 0x7d47de738e40>, <__main__.Block object at 0x7d47de738f00>, <__main__.Block object at 0x7d47de738f40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:05:39.130717: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_107/dropout_107/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 6s 9ms/step - loss: 3.0074 - accuracy: 0.0564 - val_loss: 3.0455 - val_accuracy: 0.0665\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.8513 - accuracy: 0.1105 - val_loss: 2.6069 - val_accuracy: 0.1600\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.5946 - accuracy: 0.1893 - val_loss: 2.7124 - val_accuracy: 0.1505\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.4209 - accuracy: 0.2499 - val_loss: 2.3444 - val_accuracy: 0.2790\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.2758 - accuracy: 0.3010 - val_loss: 2.0616 - val_accuracy: 0.3795\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.1230 - accuracy: 0.3601 - val_loss: 1.9726 - val_accuracy: 0.4065\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.9958 - accuracy: 0.4036 - val_loss: 1.9559 - val_accuracy: 0.4155\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.8764 - accuracy: 0.4390 - val_loss: 1.7931 - val_accuracy: 0.4635\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.7654 - accuracy: 0.4736 - val_loss: 1.8147 - val_accuracy: 0.4765\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.6680 - accuracy: 0.5080 - val_loss: 1.7332 - val_accuracy: 0.5160\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.6091 - accuracy: 0.5324 - val_loss: 1.6952 - val_accuracy: 0.5280\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.5145 - accuracy: 0.5553 - val_loss: 1.6851 - val_accuracy: 0.5435\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.4628 - accuracy: 0.5682 - val_loss: 2.1171 - val_accuracy: 0.4685\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.3995 - accuracy: 0.5978 - val_loss: 1.7110 - val_accuracy: 0.5365\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.3440 - accuracy: 0.6149 - val_loss: 1.6353 - val_accuracy: 0.5710\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2664 - accuracy: 0.6309 - val_loss: 1.8699 - val_accuracy: 0.5600\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2370 - accuracy: 0.6488 - val_loss: 1.8711 - val_accuracy: 0.5835\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 1.1711 - accuracy: 0.6633 - val_loss: 1.5781 - val_accuracy: 0.5900\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 1.1434 - accuracy: 0.6771 - val_loss: 1.8699 - val_accuracy: 0.5700\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 1.1392 - accuracy: 0.6747 - val_loss: 1.6766 - val_accuracy: 0.5850\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0922 - accuracy: 0.6975 - val_loss: 1.9219 - val_accuracy: 0.5745\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 1.0808 - accuracy: 0.6989 - val_loss: 1.9151 - val_accuracy: 0.5760\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 1.0501 - accuracy: 0.7124 - val_loss: 1.8494 - val_accuracy: 0.5535\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.0495 - accuracy: 0.7171 - val_loss: 1.6375 - val_accuracy: 0.5775\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 1.0127 - accuracy: 0.7243 - val_loss: 1.8474 - val_accuracy: 0.6010\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 1.0840 - accuracy: 0.7057 - val_loss: 2.6344 - val_accuracy: 0.5475\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.0504 - accuracy: 0.7177 - val_loss: 2.4450 - val_accuracy: 0.5660\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1015 - accuracy: 0.7116 - val_loss: 2.9313 - val_accuracy: 0.5790\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1319 - accuracy: 0.7072 - val_loss: 2.0889 - val_accuracy: 0.5800\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.1832 - accuracy: 0.6878 - val_loss: 2.3377 - val_accuracy: 0.5695\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 1.183233380317688\n",
      "Training Accuracy: 0.6878064274787903\n",
      "Validation Loss: 2.3376593589782715\n",
      "Validation Accuracy: 0.5695000290870667\n",
      "Classification Error Rate: 0.43049997091293335\n",
      "----->Evolution: Child net_10 with fitness 2.3376593589782715 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.45\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47de6bfdc0>, <__main__.Block object at 0x7d47de472500>, <__main__.Block object at 0x7d47de4a4f00>, <__main__.Block object at 0x7d47de37e940>, <__main__.Block object at 0x7d47de428c00>, <__main__.Block object at 0x7d47de333800>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:07:02.866275: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_108/dropout_110/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 7s 12ms/step - loss: 3.7815 - accuracy: 0.0639 - val_loss: 3.1770 - val_accuracy: 0.0555\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 3.7865 - accuracy: 0.1203 - val_loss: 2.7422 - val_accuracy: 0.1580\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 3.6142 - accuracy: 0.2124 - val_loss: 3.9027 - val_accuracy: 0.1120\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 3.7794 - accuracy: 0.2532 - val_loss: 2.7764 - val_accuracy: 0.1970\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 3.5262 - accuracy: 0.2709 - val_loss: 2.4607 - val_accuracy: 0.2395\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.8423 - accuracy: 0.2832 - val_loss: 2.2538 - val_accuracy: 0.3180\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 13.6756 - accuracy: 0.2955 - val_loss: 2.5378 - val_accuracy: 0.2200\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 4.2024 - accuracy: 0.3159 - val_loss: 2.5803 - val_accuracy: 0.2125\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.8466 - accuracy: 0.2955 - val_loss: 2.7147 - val_accuracy: 0.1525\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 3.8329 - accuracy: 0.3013 - val_loss: 2.5550 - val_accuracy: 0.2700\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 5.1004 - accuracy: 0.2910 - val_loss: 2.4894 - val_accuracy: 0.2600\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 3.4662 - accuracy: 0.2955 - val_loss: 2.9793 - val_accuracy: 0.1330\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 3.1966 - accuracy: 0.2604 - val_loss: 2.7030 - val_accuracy: 0.1470\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.6786 - accuracy: 0.2417 - val_loss: 3.0513 - val_accuracy: 0.1280\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.7656 - accuracy: 0.2036 - val_loss: 2.8998 - val_accuracy: 0.1800\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.5806 - accuracy: 0.2319 - val_loss: 2.5640 - val_accuracy: 0.2165\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.6379 - accuracy: 0.2136 - val_loss: 3.1884 - val_accuracy: 0.1675\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.6860 - accuracy: 0.1997 - val_loss: 2.6745 - val_accuracy: 0.1500\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 5.5594 - accuracy: 0.1851 - val_loss: 3.0066 - val_accuracy: 0.0745\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 18.2184 - accuracy: 0.1701 - val_loss: 3.5486 - val_accuracy: 0.1010\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.9918 - accuracy: 0.1298 - val_loss: 2.7809 - val_accuracy: 0.1240\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.8516 - accuracy: 0.1103 - val_loss: 2.8008 - val_accuracy: 0.0885\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.8437 - accuracy: 0.1030 - val_loss: 2.7695 - val_accuracy: 0.1175\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.8372 - accuracy: 0.1202 - val_loss: 2.9619 - val_accuracy: 0.0570\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.8091 - accuracy: 0.1213 - val_loss: 2.7682 - val_accuracy: 0.1160\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.7901 - accuracy: 0.1243 - val_loss: 2.7300 - val_accuracy: 0.1290\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.8603 - accuracy: 0.1085 - val_loss: 2.8013 - val_accuracy: 0.0845\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.7682 - accuracy: 0.1245 - val_loss: 2.7411 - val_accuracy: 0.1085\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 10.4292 - accuracy: 0.1217 - val_loss: 3.0073 - val_accuracy: 0.0675\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 31.0744 - accuracy: 0.1268 - val_loss: 2.8010 - val_accuracy: 0.1075\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 31.074390411376953\n",
      "Training Accuracy: 0.12683843076229095\n",
      "Validation Loss: 2.8010306358337402\n",
      "Validation Accuracy: 0.10750000178813934\n",
      "Classification Error Rate: 0.8924999982118607\n",
      "----->Evolution: Child net_11 with fitness 2.8010306358337402 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47de3dd600>, <__main__.Block object at 0x7d47dd618c00>, <__main__.Block object at 0x7d47dd7e3e40>, <__main__.Block object at 0x7d47dd69b340>, <__main__.Block object at 0x7d47dd661040>, <__main__.Block object at 0x7d47dd6db9c0>, <__main__.Block object at 0x7d47dd60d840>, <__main__.Block object at 0x7d47de075740>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_971\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_971/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_971/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_971\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_972\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_972/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_972/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_972\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_973. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_278\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_278/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_278\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.30000000000000004\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.15  to  0.04999999999999999\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47de3667c0>, <__main__.Block object at 0x7d47dd58ddc0>, <__main__.Block object at 0x7d47dd58de80>, <__main__.Block object at 0x7d47dd58e100>, <__main__.Block object at 0x7d47dd7a3840>, <__main__.Block object at 0x7d47dd5046c0>, <__main__.Block object at 0x7d47dd559500>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:09:27.711624: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_110/dropout_114/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 8s 12ms/step - loss: 3.0437 - accuracy: 0.0542 - val_loss: 2.9902 - val_accuracy: 0.0905\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.9023 - accuracy: 0.1086 - val_loss: 2.8911 - val_accuracy: 0.1490\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.6482 - accuracy: 0.2185 - val_loss: 2.9047 - val_accuracy: 0.1745\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.6155 - accuracy: 0.2857 - val_loss: 2.4043 - val_accuracy: 0.2945\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.5367 - accuracy: 0.3318 - val_loss: 2.4109 - val_accuracy: 0.2620\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 3.2076 - accuracy: 0.3544 - val_loss: 2.0413 - val_accuracy: 0.3985\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 6.6099 - accuracy: 0.3828 - val_loss: 2.0160 - val_accuracy: 0.3935\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 11.4443 - accuracy: 0.3963 - val_loss: 2.8367 - val_accuracy: 0.2210\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.3507 - accuracy: 0.4103 - val_loss: 2.2012 - val_accuracy: 0.3625\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 4.1604 - accuracy: 0.4178 - val_loss: 3.3684 - val_accuracy: 0.3300\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 5.8805 - accuracy: 0.4299 - val_loss: 1.9977 - val_accuracy: 0.4330\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 3.2318 - accuracy: 0.4466 - val_loss: 2.1383 - val_accuracy: 0.4180\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 4.0362 - accuracy: 0.4414 - val_loss: 2.8156 - val_accuracy: 0.3490\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 4.5344 - accuracy: 0.4547 - val_loss: 1.9615 - val_accuracy: 0.4390\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 3.2631 - accuracy: 0.4606 - val_loss: 1.9052 - val_accuracy: 0.4395\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 5.2397 - accuracy: 0.4643 - val_loss: 1.9739 - val_accuracy: 0.4355\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 4.7716 - accuracy: 0.4720 - val_loss: 1.9658 - val_accuracy: 0.4150\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 10.6219 - accuracy: 0.4659 - val_loss: 2.4755 - val_accuracy: 0.3120\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.5055 - accuracy: 0.4625 - val_loss: 1.9883 - val_accuracy: 0.4275\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 3.3556 - accuracy: 0.4701 - val_loss: 2.0493 - val_accuracy: 0.4555\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 4.8634 - accuracy: 0.4778 - val_loss: 2.9439 - val_accuracy: 0.3930\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 14.5609 - accuracy: 0.4762 - val_loss: 2.1350 - val_accuracy: 0.4105\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.7948 - accuracy: 0.4702 - val_loss: 2.0583 - val_accuracy: 0.4200\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 8.1558 - accuracy: 0.4636 - val_loss: 2.0500 - val_accuracy: 0.4460\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 24.4766 - accuracy: 0.4691 - val_loss: 2.3145 - val_accuracy: 0.3720\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 12.8568 - accuracy: 0.4543 - val_loss: 2.2348 - val_accuracy: 0.3645\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 4.7792 - accuracy: 0.4747 - val_loss: 2.3852 - val_accuracy: 0.3125\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 3.1558 - accuracy: 0.4633 - val_loss: 1.9535 - val_accuracy: 0.4360\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 5.3990 - accuracy: 0.4668 - val_loss: 2.1315 - val_accuracy: 0.3800\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 5.7923 - accuracy: 0.4595 - val_loss: 2.3241 - val_accuracy: 0.4280\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 5.7922587394714355\n",
      "Training Accuracy: 0.45947638154029846\n",
      "Validation Loss: 2.3240835666656494\n",
      "Validation Accuracy: 0.42800000309944153\n",
      "Classification Error Rate: 0.5719999969005585\n",
      "----->Evolution: Child net_12 with fitness 2.3240835666656494 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.5\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e0ad8440>, <__main__.Block object at 0x7d47c9df2500>, <__main__.Block object at 0x7d47e09acf00>, <__main__.Block object at 0x7d47dfc25a00>, <__main__.Block object at 0x7d47e86d8c00>, <__main__.Block object at 0x7d47e11bb340>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:11:03.149172: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_111/dropout_117/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 7s 14ms/step - loss: 3.2167 - accuracy: 0.0671 - val_loss: 2.9586 - val_accuracy: 0.0880\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.9356 - accuracy: 0.1066 - val_loss: 2.8161 - val_accuracy: 0.1080\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.7285 - accuracy: 0.1737 - val_loss: 2.7021 - val_accuracy: 0.1660\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.5797 - accuracy: 0.2457 - val_loss: 2.4822 - val_accuracy: 0.2360\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.4418 - accuracy: 0.2717 - val_loss: 2.5453 - val_accuracy: 0.2690\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.4925 - accuracy: 0.2800 - val_loss: 2.6571 - val_accuracy: 0.1905\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.3787 - accuracy: 0.3029 - val_loss: 7.1698 - val_accuracy: 0.1400\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.3204 - accuracy: 0.3086 - val_loss: 2.7851 - val_accuracy: 0.2165\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.3507 - accuracy: 0.3132 - val_loss: 2.2177 - val_accuracy: 0.3115\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.2614 - accuracy: 0.3244 - val_loss: 2.5595 - val_accuracy: 0.2385\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.2242 - accuracy: 0.3348 - val_loss: 2.2209 - val_accuracy: 0.3335\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 2.2031 - accuracy: 0.3460 - val_loss: 2.2197 - val_accuracy: 0.3275\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.1874 - accuracy: 0.3466 - val_loss: 2.2331 - val_accuracy: 0.3530\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.1972 - accuracy: 0.3493 - val_loss: 2.3322 - val_accuracy: 0.2730\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.2170 - accuracy: 0.3514 - val_loss: 2.3126 - val_accuracy: 0.3045\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.2270 - accuracy: 0.3484 - val_loss: 2.1540 - val_accuracy: 0.3425\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.2118 - accuracy: 0.3534 - val_loss: 2.4401 - val_accuracy: 0.2875\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.1991 - accuracy: 0.3496 - val_loss: 2.8488 - val_accuracy: 0.2190\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.2276 - accuracy: 0.3373 - val_loss: 3.0783 - val_accuracy: 0.2200\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.2472 - accuracy: 0.3494 - val_loss: 2.2638 - val_accuracy: 0.3160\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.2324 - accuracy: 0.3467 - val_loss: 2.3396 - val_accuracy: 0.3075\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.2384 - accuracy: 0.3558 - val_loss: 2.7828 - val_accuracy: 0.2365\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.2034 - accuracy: 0.3675 - val_loss: 2.1836 - val_accuracy: 0.3435\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.1754 - accuracy: 0.3616 - val_loss: 2.3724 - val_accuracy: 0.2950\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.2112 - accuracy: 0.3525 - val_loss: 2.1010 - val_accuracy: 0.3640\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.2131 - accuracy: 0.3656 - val_loss: 2.4698 - val_accuracy: 0.2630\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.4732 - accuracy: 0.3448 - val_loss: 2.4733 - val_accuracy: 0.2575\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.3220 - accuracy: 0.3562 - val_loss: 2.4042 - val_accuracy: 0.2510\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.2794 - accuracy: 0.3395 - val_loss: 2.8857 - val_accuracy: 0.1195\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 2.6183 - accuracy: 0.3076 - val_loss: 2.6217 - val_accuracy: 0.1840\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 2.6182913780212402\n",
      "Training Accuracy: 0.307604044675827\n",
      "Validation Loss: 2.6216745376586914\n",
      "Validation Accuracy: 0.18400000035762787\n",
      "Classification Error Rate: 0.8159999996423721\n",
      "----->Evolution: Child net_13 with fitness 2.6216745376586914 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 16\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Tournament selection\n",
      "Selected net_7 and net_9 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.6  to  0.65\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47dc81ae40>, <__main__.Block object at 0x7d47dc7190c0>, <__main__.Block object at 0x7d47de7300c0>, <__main__.Block object at 0x7d47dfd63340>, <__main__.Block object at 0x7d47e09639c0>, <__main__.Block object at 0x7d47de731040>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1003. Consider increasing the input size. Received input shape [None, 1, 1, 32] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:12:57.379919: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_112/dropout_119/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 9ms/step - loss: 2.9567 - accuracy: 0.0817 - val_loss: 2.7095 - val_accuracy: 0.1090\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.6396 - accuracy: 0.1789 - val_loss: 2.5972 - val_accuracy: 0.1630\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.4174 - accuracy: 0.2461 - val_loss: 2.4720 - val_accuracy: 0.2035\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.2554 - accuracy: 0.2910 - val_loss: 2.3828 - val_accuracy: 0.2675\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.1185 - accuracy: 0.3416 - val_loss: 2.3110 - val_accuracy: 0.2695\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.0210 - accuracy: 0.3774 - val_loss: 1.7838 - val_accuracy: 0.4645\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.9009 - accuracy: 0.4205 - val_loss: 1.8265 - val_accuracy: 0.4330\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.7881 - accuracy: 0.4530 - val_loss: 1.7756 - val_accuracy: 0.4695\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.7127 - accuracy: 0.4779 - val_loss: 1.6311 - val_accuracy: 0.5125\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.6285 - accuracy: 0.5058 - val_loss: 1.9963 - val_accuracy: 0.4215\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.5557 - accuracy: 0.5327 - val_loss: 1.8822 - val_accuracy: 0.5235\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.5472 - accuracy: 0.5503 - val_loss: 2.1333 - val_accuracy: 0.3770\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4224 - accuracy: 0.5651 - val_loss: 1.9350 - val_accuracy: 0.4855\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3866 - accuracy: 0.5906 - val_loss: 1.8283 - val_accuracy: 0.4800\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3142 - accuracy: 0.6072 - val_loss: 1.8891 - val_accuracy: 0.4955\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2210 - accuracy: 0.6215 - val_loss: 1.8682 - val_accuracy: 0.4595\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2042 - accuracy: 0.6499 - val_loss: 1.9941 - val_accuracy: 0.5265\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1585 - accuracy: 0.6631 - val_loss: 1.8788 - val_accuracy: 0.4610\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1901 - accuracy: 0.6694 - val_loss: 1.9383 - val_accuracy: 0.5040\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0859 - accuracy: 0.6781 - val_loss: 2.1660 - val_accuracy: 0.4925\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1187 - accuracy: 0.6888 - val_loss: 1.8715 - val_accuracy: 0.5065\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0578 - accuracy: 0.6980 - val_loss: 1.9138 - val_accuracy: 0.5125\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1605 - accuracy: 0.7162 - val_loss: 3.8725 - val_accuracy: 0.4495\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0664 - accuracy: 0.7130 - val_loss: 2.5471 - val_accuracy: 0.4755\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.9679 - accuracy: 0.7306 - val_loss: 3.7983 - val_accuracy: 0.4265\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0511 - accuracy: 0.7197 - val_loss: 3.1517 - val_accuracy: 0.5340\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9442 - accuracy: 0.7372 - val_loss: 1.9887 - val_accuracy: 0.4995\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4076 - accuracy: 0.7386 - val_loss: 2.2167 - val_accuracy: 0.4720\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9700 - accuracy: 0.7348 - val_loss: 2.0555 - val_accuracy: 0.4525\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.9258 - accuracy: 0.7400 - val_loss: 2.1812 - val_accuracy: 0.5395\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.9258167743682861\n",
      "Training Accuracy: 0.7399603724479675\n",
      "Validation Loss: 2.181243658065796\n",
      "Validation Accuracy: 0.5394999980926514\n",
      "Classification Error Rate: 0.46050000190734863\n",
      "----->Evolution: Child net_10 with fitness 2.181243658065796 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Tournament selection\n",
      "Selected net_4 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.35000000000000003  to  0.4\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47c9b6df80>, <__main__.Block object at 0x7d47de7890c0>, <__main__.Block object at 0x7d4c186dc8c0>, <__main__.Block object at 0x7d4c185ab880>, <__main__.Block object at 0x7d4c1855d980>, <__main__.Block object at 0x7d4c1855b800>, <__main__.Block object at 0x7d47e04837c0>, <__main__.Block object at 0x7d47de096b40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_1014\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1014/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1014/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,64], [3,3,64,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_1014\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 64), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_1015\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1015/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1015/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,64], [3,3,64,512].\n",
      "\n",
      "Call arguments received by layer \"conv2d_1015\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 64), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:14:21.302686: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_113/dropout_120/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 7s 11ms/step - loss: 3.0065 - accuracy: 0.0528 - val_loss: 2.9913 - val_accuracy: 0.0620\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.9648 - accuracy: 0.0888 - val_loss: 2.8069 - val_accuracy: 0.1250\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.7106 - accuracy: 0.1579 - val_loss: 3.2785 - val_accuracy: 0.1160\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.5302 - accuracy: 0.2116 - val_loss: 3.7412 - val_accuracy: 0.1200\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.3948 - accuracy: 0.2670 - val_loss: 3.0884 - val_accuracy: 0.2140\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.2930 - accuracy: 0.2934 - val_loss: 2.3857 - val_accuracy: 0.2635\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.2083 - accuracy: 0.3204 - val_loss: 2.2814 - val_accuracy: 0.3405\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.1101 - accuracy: 0.3532 - val_loss: 2.1325 - val_accuracy: 0.3870\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.0528 - accuracy: 0.3832 - val_loss: 2.0180 - val_accuracy: 0.3910\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9652 - accuracy: 0.4022 - val_loss: 2.1582 - val_accuracy: 0.3855\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9548 - accuracy: 0.4169 - val_loss: 2.2512 - val_accuracy: 0.3380\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9428 - accuracy: 0.4328 - val_loss: 2.2779 - val_accuracy: 0.4230\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.8919 - accuracy: 0.4465 - val_loss: 2.2320 - val_accuracy: 0.4490\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.8572 - accuracy: 0.4568 - val_loss: 1.8053 - val_accuracy: 0.4560\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8905 - accuracy: 0.4679 - val_loss: 2.5581 - val_accuracy: 0.4435\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.8458 - accuracy: 0.4751 - val_loss: 2.2747 - val_accuracy: 0.4355\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8283 - accuracy: 0.4942 - val_loss: 4.8301 - val_accuracy: 0.3730\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.7316 - accuracy: 0.5027 - val_loss: 1.9218 - val_accuracy: 0.4770\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8021 - accuracy: 0.5084 - val_loss: 3.7878 - val_accuracy: 0.4080\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8618 - accuracy: 0.5117 - val_loss: 5.4603 - val_accuracy: 0.3185\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.7743 - accuracy: 0.5110 - val_loss: 3.7389 - val_accuracy: 0.3845\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8600 - accuracy: 0.5198 - val_loss: 2.2531 - val_accuracy: 0.4560\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.8143 - accuracy: 0.5210 - val_loss: 2.3893 - val_accuracy: 0.4430\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.9107 - accuracy: 0.5301 - val_loss: 5.7891 - val_accuracy: 0.3795\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.7374 - accuracy: 0.5385 - val_loss: 5.3250 - val_accuracy: 0.3865\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8889 - accuracy: 0.5391 - val_loss: 3.2195 - val_accuracy: 0.4370\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.6682 - accuracy: 0.5406 - val_loss: 7.1470 - val_accuracy: 0.3340\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.8347 - accuracy: 0.5520 - val_loss: 5.9735 - val_accuracy: 0.4360\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.9209 - accuracy: 0.5375 - val_loss: 6.1959 - val_accuracy: 0.4005\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.6840 - accuracy: 0.5536 - val_loss: 11.3446 - val_accuracy: 0.3110\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 1.6840271949768066\n",
      "Training Accuracy: 0.5535621047019958\n",
      "Validation Loss: 11.344602584838867\n",
      "Validation Accuracy: 0.3109999895095825\n",
      "Classification Error Rate: 0.6890000104904175\n",
      "----->Evolution: Child net_11 with fitness 11.344602584838867 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Tournament selection\n",
      "Selected net_2 and net_9 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.6  to  0.65\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47de1705c0>, <__main__.Block object at 0x7d47dd3bda00>, <__main__.Block object at 0x7d47e036c8c0>, <__main__.Block object at 0x7d47dd3d3880>, <__main__.Block object at 0x7d47de1565c0>, <__main__.Block object at 0x7d47dd3ddc40>, <__main__.Block object at 0x7d47dc39d600>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_1026\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1026/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1026/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,64], [3,3,64,512].\n",
      "\n",
      "Call arguments received by layer \"conv2d_1026\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 64), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_1027\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1027/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1027/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,64], [3,3,64,256].\n",
      "\n",
      "Call arguments received by layer \"conv2d_1027\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 64), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:15:51.493621: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_114/dropout_122/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 6s 10ms/step - loss: 3.0213 - accuracy: 0.0530 - val_loss: 2.9163 - val_accuracy: 0.0885\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.9483 - accuracy: 0.0952 - val_loss: 2.8756 - val_accuracy: 0.0925\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.7487 - accuracy: 0.1443 - val_loss: 2.8107 - val_accuracy: 0.1205\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.5459 - accuracy: 0.2157 - val_loss: 2.3875 - val_accuracy: 0.2715\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.3434 - accuracy: 0.2731 - val_loss: 2.2124 - val_accuracy: 0.3065\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.2951 - accuracy: 0.3222 - val_loss: 2.2332 - val_accuracy: 0.3140\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.0900 - accuracy: 0.3648 - val_loss: 2.7793 - val_accuracy: 0.2630\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.9860 - accuracy: 0.4050 - val_loss: 1.9131 - val_accuracy: 0.4215\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.9293 - accuracy: 0.4324 - val_loss: 2.3877 - val_accuracy: 0.3455\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.7988 - accuracy: 0.4642 - val_loss: 1.8619 - val_accuracy: 0.4480\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.7154 - accuracy: 0.4930 - val_loss: 2.2102 - val_accuracy: 0.4080\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.6588 - accuracy: 0.5204 - val_loss: 1.6940 - val_accuracy: 0.4965\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.5265 - accuracy: 0.5537 - val_loss: 1.6044 - val_accuracy: 0.5335\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.5344 - accuracy: 0.5713 - val_loss: 1.7880 - val_accuracy: 0.4965\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.4209 - accuracy: 0.5869 - val_loss: 1.8878 - val_accuracy: 0.5070\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.3202 - accuracy: 0.6060 - val_loss: 1.8969 - val_accuracy: 0.5150\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2851 - accuracy: 0.6282 - val_loss: 2.0567 - val_accuracy: 0.5100\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 1.2227 - accuracy: 0.6447 - val_loss: 2.2979 - val_accuracy: 0.4345\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1690 - accuracy: 0.6620 - val_loss: 1.6870 - val_accuracy: 0.5500\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1861 - accuracy: 0.6720 - val_loss: 1.7488 - val_accuracy: 0.5850\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2001 - accuracy: 0.6859 - val_loss: 1.9831 - val_accuracy: 0.5910\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.4152 - accuracy: 0.6958 - val_loss: 1.7537 - val_accuracy: 0.5550\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1760 - accuracy: 0.7025 - val_loss: 2.1038 - val_accuracy: 0.5535\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 1.1322 - accuracy: 0.7060 - val_loss: 1.8598 - val_accuracy: 0.5500\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.6013 - accuracy: 0.7141 - val_loss: 1.9223 - val_accuracy: 0.5100\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.4503 - accuracy: 0.7152 - val_loss: 1.9146 - val_accuracy: 0.6115\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.6699 - accuracy: 0.7167 - val_loss: 2.3544 - val_accuracy: 0.5475\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2680 - accuracy: 0.7233 - val_loss: 1.9051 - val_accuracy: 0.5465\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.9232 - accuracy: 0.7205 - val_loss: 4.0038 - val_accuracy: 0.5045\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.7299 - accuracy: 0.7316 - val_loss: 2.1783 - val_accuracy: 0.4830\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 2.7299253940582275\n",
      "Training Accuracy: 0.7316157221794128\n",
      "Validation Loss: 2.1782703399658203\n",
      "Validation Accuracy: 0.4830000102519989\n",
      "Classification Error Rate: 0.5169999897480011\n",
      "----->Evolution: Child net_12 with fitness 2.1782703399658203 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Tournament selection\n",
      "Selected net_4 and net_6 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47dcf687c0>, <__main__.Block object at 0x7d47dd0610c0>, <__main__.Block object at 0x7d47dced6ac0>, <__main__.Block object at 0x7d47dcf10940>, <__main__.Block object at 0x7d47dcfcd980>, <__main__.Block object at 0x7d47dd0ab800>, <__main__.Block object at 0x7d47dcefdc40>, <__main__.Block object at 0x7d47dd05f240>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1035. Consider increasing the input size. Received input shape [None, 1, 1, 512] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1036. Consider increasing the input size. Received input shape [None, 1, 1, 512] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1038. Consider increasing the input size. Received input shape [None, 1, 1, 512] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_255\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_255/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_255\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512.0  to  1024.0\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47dcfbee80>, <__main__.Block object at 0x7d47ddeed340>, <__main__.Block object at 0x7d47ddeed140>, <__main__.Block object at 0x7d47ddeec500>, <__main__.Block object at 0x7d47ddeed440>, <__main__.Block object at 0x7d47ddeed180>, <__main__.Block object at 0x7d47ddeed980>, <__main__.Block object at 0x7d47ddeece00>, <__main__.Block object at 0x7d47ddeec7c0>, <__main__.Block object at 0x7d47ddeed280>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_1046\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1046/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1046/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_1046\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_1047\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1047/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1047/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_1047\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:17:10.795848: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_116/dropout_126/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 7s 10ms/step - loss: 2.9988 - accuracy: 0.0491 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.9889 - accuracy: 0.0586 - val_loss: 2.8834 - val_accuracy: 0.1065\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.7785 - accuracy: 0.1280 - val_loss: 2.8155 - val_accuracy: 0.1265\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.5880 - accuracy: 0.1783 - val_loss: 2.5388 - val_accuracy: 0.1635\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.3878 - accuracy: 0.2328 - val_loss: 2.5350 - val_accuracy: 0.1635\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.2828 - accuracy: 0.2760 - val_loss: 2.2818 - val_accuracy: 0.2875\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 2.1781 - accuracy: 0.3218 - val_loss: 2.0941 - val_accuracy: 0.3520\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.0486 - accuracy: 0.3572 - val_loss: 2.1777 - val_accuracy: 0.3145\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.9420 - accuracy: 0.3891 - val_loss: 2.0570 - val_accuracy: 0.3670\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.8768 - accuracy: 0.4167 - val_loss: 1.9960 - val_accuracy: 0.3955\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.7793 - accuracy: 0.4496 - val_loss: 2.1096 - val_accuracy: 0.4010\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.7084 - accuracy: 0.4763 - val_loss: 1.8029 - val_accuracy: 0.4615\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.6485 - accuracy: 0.5005 - val_loss: 1.8622 - val_accuracy: 0.4735\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.5744 - accuracy: 0.5274 - val_loss: 1.7762 - val_accuracy: 0.4820\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.5206 - accuracy: 0.5375 - val_loss: 1.7137 - val_accuracy: 0.4920\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.4558 - accuracy: 0.5617 - val_loss: 1.5838 - val_accuracy: 0.5405\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.3767 - accuracy: 0.5878 - val_loss: 1.7868 - val_accuracy: 0.5075\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.3286 - accuracy: 0.6027 - val_loss: 1.6166 - val_accuracy: 0.5400\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.3131 - accuracy: 0.6132 - val_loss: 1.5684 - val_accuracy: 0.5520\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.2567 - accuracy: 0.6335 - val_loss: 2.0327 - val_accuracy: 0.5105\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.2049 - accuracy: 0.6462 - val_loss: 1.4879 - val_accuracy: 0.5770\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.1529 - accuracy: 0.6619 - val_loss: 1.5018 - val_accuracy: 0.5870\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.1233 - accuracy: 0.6751 - val_loss: 1.7281 - val_accuracy: 0.5610\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.1472 - accuracy: 0.6831 - val_loss: 1.5009 - val_accuracy: 0.5730\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.1969 - accuracy: 0.6981 - val_loss: 1.5210 - val_accuracy: 0.5835\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0437 - accuracy: 0.7093 - val_loss: 1.6318 - val_accuracy: 0.5720\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0321 - accuracy: 0.7154 - val_loss: 1.5263 - val_accuracy: 0.5970\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0738 - accuracy: 0.7216 - val_loss: 1.9205 - val_accuracy: 0.5805\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.0041 - accuracy: 0.7241 - val_loss: 1.7864 - val_accuracy: 0.5810\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.0196 - accuracy: 0.7327 - val_loss: 1.7713 - val_accuracy: 0.5800\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 1.0195637941360474\n",
      "Training Accuracy: 0.7326588034629822\n",
      "Validation Loss: 1.7713475227355957\n",
      "Validation Accuracy: 0.5799999833106995\n",
      "Classification Error Rate: 0.42000001668930054\n",
      "----->Evolution: Child net_13 with fitness 1.7713475227355957 replaces parent net_9 with fitness 2.083534002304077\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 17\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Tournament selection\n",
      "Selected net_8 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.30000000000000004\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47dc967900>, <__main__.Block object at 0x7d47dc93c4c0>, <__main__.Block object at 0x7d47dc90f5c0>, <__main__.Block object at 0x7d47dc928240>, <__main__.Block object at 0x7d47ddae1040>, <__main__.Block object at 0x7d47dfd60ac0>, <__main__.Block object at 0x7d47dfd72a00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_1062\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1062/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1062/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,512].\n",
      "\n",
      "Call arguments received by layer \"conv2d_1062\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_1063\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1063/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1063/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,512].\n",
      "\n",
      "Call arguments received by layer \"conv2d_1063\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:18:41.691628: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_117/dropout_129/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 9ms/step - loss: 2.9741 - accuracy: 0.0900 - val_loss: 2.7688 - val_accuracy: 0.1400\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.5158 - accuracy: 0.2229 - val_loss: 2.4070 - val_accuracy: 0.2745\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.1707 - accuracy: 0.3394 - val_loss: 2.0214 - val_accuracy: 0.3905\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.9414 - accuracy: 0.4070 - val_loss: 1.8951 - val_accuracy: 0.4260\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.7486 - accuracy: 0.4642 - val_loss: 1.6921 - val_accuracy: 0.4975\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.6140 - accuracy: 0.5137 - val_loss: 1.6986 - val_accuracy: 0.5005\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4752 - accuracy: 0.5464 - val_loss: 1.7037 - val_accuracy: 0.4970\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3600 - accuracy: 0.5843 - val_loss: 1.7324 - val_accuracy: 0.5360\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2537 - accuracy: 0.6185 - val_loss: 1.6708 - val_accuracy: 0.5420\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1647 - accuracy: 0.6416 - val_loss: 1.5510 - val_accuracy: 0.5705\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.0544 - accuracy: 0.6711 - val_loss: 1.5088 - val_accuracy: 0.5900\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9772 - accuracy: 0.6945 - val_loss: 1.7109 - val_accuracy: 0.5745\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9375 - accuracy: 0.7146 - val_loss: 1.7325 - val_accuracy: 0.5800\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8923 - accuracy: 0.7278 - val_loss: 1.8862 - val_accuracy: 0.5695\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8559 - accuracy: 0.7376 - val_loss: 1.7915 - val_accuracy: 0.5645\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8209 - accuracy: 0.7528 - val_loss: 1.7056 - val_accuracy: 0.5915\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.8052 - accuracy: 0.7628 - val_loss: 2.0910 - val_accuracy: 0.5735\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.7871 - accuracy: 0.7739 - val_loss: 2.0160 - val_accuracy: 0.5700\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.7871 - accuracy: 0.7690 - val_loss: 1.9533 - val_accuracy: 0.6035\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7855 - accuracy: 0.7768 - val_loss: 2.2009 - val_accuracy: 0.5965\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.7505 - accuracy: 0.7844 - val_loss: 2.2094 - val_accuracy: 0.5740\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.7362 - accuracy: 0.7858 - val_loss: 1.8907 - val_accuracy: 0.5925\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.7849 - accuracy: 0.7814 - val_loss: 3.2836 - val_accuracy: 0.5545\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.7701 - accuracy: 0.7870 - val_loss: 2.4014 - val_accuracy: 0.5850\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7646 - accuracy: 0.7876 - val_loss: 3.2918 - val_accuracy: 0.5310\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7428 - accuracy: 0.8000 - val_loss: 2.4226 - val_accuracy: 0.5790\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.7704 - accuracy: 0.7910 - val_loss: 1.9724 - val_accuracy: 0.6140\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.7695 - accuracy: 0.7899 - val_loss: 1.9911 - val_accuracy: 0.5910\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7965 - accuracy: 0.7830 - val_loss: 2.1191 - val_accuracy: 0.5705\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8360 - accuracy: 0.7830 - val_loss: 2.3561 - val_accuracy: 0.5990\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.8360360264778137\n",
      "Training Accuracy: 0.7830395102500916\n",
      "Validation Loss: 2.356132984161377\n",
      "Validation Accuracy: 0.5989999771118164\n",
      "Classification Error Rate: 0.4010000228881836\n",
      "----->Evolution: Child net_10 with fitness 2.356132984161377 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Tournament selection\n",
      "Selected net_5 and net_6 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  32.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47dccd0440>, <__main__.Block object at 0x7d47dcdaa500>, <__main__.Block object at 0x7d47dcda0c00>, <__main__.Block object at 0x7d47dcbc5c40>, <__main__.Block object at 0x7d47dd971040>, <__main__.Block object at 0x7d47dce36ac0>, <__main__.Block object at 0x7d47dce839c0>, <__main__.Block object at 0x7d47dd90ae40>, <__main__.Block object at 0x7d47dcd18440>, <__main__.Block object at 0x7d47dccdcbc0>, <__main__.Block object at 0x7d47dcd51600>, <__main__.Block object at 0x7d47dcdbb0c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1072. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1077. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_306\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_306/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_306\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47dcbd7dc0>, <__main__.Block object at 0x7d47dcbf23c0>, <__main__.Block object at 0x7d47dcbf2e00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 3s 7ms/step - loss: 4.1294 - accuracy: 0.0498 - val_loss: 2.9960 - val_accuracy: 0.0455\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0511 - val_loss: 2.9963 - val_accuracy: 0.0455\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0495 - val_loss: 2.9965 - val_accuracy: 0.0455\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0505 - val_loss: 2.9967 - val_accuracy: 0.0440\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0490 - val_loss: 2.9967 - val_accuracy: 0.0440\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0489 - val_loss: 2.9968 - val_accuracy: 0.0440\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0478 - val_loss: 2.9969 - val_accuracy: 0.0440\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0465 - val_loss: 2.9969 - val_accuracy: 0.0440\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0499 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0458 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0484 - val_loss: 2.9971 - val_accuracy: 0.0440\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0470 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0488 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0501 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0459 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0498 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0482 - val_loss: 2.9970 - val_accuracy: 0.0455\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0490 - val_loss: 2.9971 - val_accuracy: 0.0455\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0474 - val_loss: 2.9971 - val_accuracy: 0.0455\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.9960 - accuracy: 0.0490 - val_loss: 2.9971 - val_accuracy: 0.0440\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0492 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0465 - val_loss: 2.9969 - val_accuracy: 0.0440\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0485 - val_loss: 2.9969 - val_accuracy: 0.0455\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0490 - val_loss: 2.9969 - val_accuracy: 0.0440\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0475 - val_loss: 2.9969 - val_accuracy: 0.0440\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0486 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0492 - val_loss: 2.9970 - val_accuracy: 0.0455\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0485 - val_loss: 2.9970 - val_accuracy: 0.0455\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0462 - val_loss: 2.9970 - val_accuracy: 0.0440\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0493 - val_loss: 2.9970 - val_accuracy: 0.0455\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 2.9959423542022705\n",
      "Training Accuracy: 0.04933764412999153\n",
      "Validation Loss: 2.99704909324646\n",
      "Validation Accuracy: 0.045499999076128006\n",
      "Classification Error Rate: 0.954500000923872\n",
      "----->Evolution: Child net_11 with fitness 2.99704909324646 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Tournament selection\n",
      "Selected net_7 and net_8 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47c99c5500>, <__main__.Block object at 0x7d47c9952500>, <__main__.Block object at 0x7d47c99b6ac0>, <__main__.Block object at 0x7d47c97db200>, <__main__.Block object at 0x7d47c98d3880>, <__main__.Block object at 0x7d47c98155c0>, <__main__.Block object at 0x7d47c9990940>, <__main__.Block object at 0x7d47c9973340>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_1086\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1086/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1086/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,256].\n",
      "\n",
      "Call arguments received by layer \"conv2d_1086\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_1088\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1088/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1088/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,64], [3,3,64,64].\n",
      "\n",
      "Call arguments received by layer \"conv2d_1088\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 64), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1090. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_309\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_309/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_309\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.30000000000000004\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47cb703a00>, <__main__.Block object at 0x7d47cb700e00>, <__main__.Block object at 0x7d47cb702200>, <__main__.Block object at 0x7d47c97f5000>, <__main__.Block object at 0x7d47c97f78c0>, <__main__.Block object at 0x7d47c97f5c00>, <__main__.Block object at 0x7d47c97f4480>, <__main__.Block object at 0x7d47cb701d40>, <__main__.Block object at 0x7d47c97f50c0>, <__main__.Block object at 0x7d47c98e8d00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_1101\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1101/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1101/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_1101\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_1102\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1102/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1102/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_1102\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_279\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_279/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,32].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_279\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 32), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Inserting a Pooling layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.35000000000000003\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47cb71bdc0>, <__main__.Block object at 0x7d47c97e9c00>, <__main__.Block object at 0x7d47c97eb680>, <__main__.Block object at 0x7d47c97c5280>, <__main__.Block object at 0x7d47c97c7ec0>, <__main__.Block object at 0x7d47c986ef80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:21:02.147368: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_122/dropout_135/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 6s 8ms/step - loss: 3.0684 - accuracy: 0.0927 - val_loss: 2.7669 - val_accuracy: 0.1460\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.6588 - accuracy: 0.2310 - val_loss: 3.3036 - val_accuracy: 0.1590\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.4045 - accuracy: 0.3115 - val_loss: 3.4437 - val_accuracy: 0.2070\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.3991 - accuracy: 0.3605 - val_loss: 3.3417 - val_accuracy: 0.2250\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.2291 - accuracy: 0.3858 - val_loss: 2.1780 - val_accuracy: 0.3635\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.1910 - accuracy: 0.4179 - val_loss: 2.1290 - val_accuracy: 0.3615\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.1073 - accuracy: 0.4481 - val_loss: 2.2545 - val_accuracy: 0.3800\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.0848 - accuracy: 0.4548 - val_loss: 2.2500 - val_accuracy: 0.3720\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.7474 - accuracy: 0.4869 - val_loss: 2.5370 - val_accuracy: 0.3210\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.2600 - accuracy: 0.4943 - val_loss: 1.9888 - val_accuracy: 0.4280\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.1922 - accuracy: 0.5101 - val_loss: 1.8422 - val_accuracy: 0.4435\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.2317 - accuracy: 0.5151 - val_loss: 1.6313 - val_accuracy: 0.5150\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.3465 - accuracy: 0.5273 - val_loss: 1.7613 - val_accuracy: 0.5075\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.1062 - accuracy: 0.5334 - val_loss: 3.2976 - val_accuracy: 0.3655\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.0468 - accuracy: 0.5419 - val_loss: 1.7637 - val_accuracy: 0.4635\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.8004 - accuracy: 0.5481 - val_loss: 2.2597 - val_accuracy: 0.3265\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.5449 - accuracy: 0.5478 - val_loss: 1.9802 - val_accuracy: 0.4445\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.9814 - accuracy: 0.5637 - val_loss: 2.1152 - val_accuracy: 0.3845\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.1273 - accuracy: 0.5617 - val_loss: 1.9526 - val_accuracy: 0.4040\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.2503 - accuracy: 0.5603 - val_loss: 1.9103 - val_accuracy: 0.5260\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.8149 - accuracy: 0.5491 - val_loss: 3.0174 - val_accuracy: 0.3680\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.9136 - accuracy: 0.5402 - val_loss: 2.0679 - val_accuracy: 0.4130\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.5291 - accuracy: 0.5498 - val_loss: 2.0925 - val_accuracy: 0.3890\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.4924 - accuracy: 0.5283 - val_loss: 1.9721 - val_accuracy: 0.3945\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.2834 - accuracy: 0.5345 - val_loss: 2.1257 - val_accuracy: 0.3395\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.0440 - accuracy: 0.5205 - val_loss: 2.4839 - val_accuracy: 0.2895\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.6217 - accuracy: 0.5139 - val_loss: 2.5547 - val_accuracy: 0.2345\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.0532 - accuracy: 0.4937 - val_loss: 2.0470 - val_accuracy: 0.3780\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.8797 - accuracy: 0.4813 - val_loss: 2.2757 - val_accuracy: 0.3510\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.0574 - accuracy: 0.4679 - val_loss: 2.2581 - val_accuracy: 0.3050\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 3.0573554039001465\n",
      "Training Accuracy: 0.4679253101348877\n",
      "Validation Loss: 2.2581393718719482\n",
      "Validation Accuracy: 0.3050000071525574\n",
      "Classification Error Rate: 0.6949999928474426\n",
      "----->Evolution: Child net_12 with fitness 2.2581393718719482 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Tournament selection\n",
      "Selected net_3 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512.0  to  256.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47dcd60440>, <__main__.Block object at 0x7d47dcdaa500>, <__main__.Block object at 0x7d47dc3e0880>, <__main__.Block object at 0x7d47dc4db880>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 5s 9ms/step - loss: 3.0500 - accuracy: 0.1597 - val_loss: 2.4941 - val_accuracy: 0.2530\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.0694 - accuracy: 0.3710 - val_loss: 2.0927 - val_accuracy: 0.3835\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 1.6598 - accuracy: 0.4896 - val_loss: 1.6470 - val_accuracy: 0.4935\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.3728 - accuracy: 0.5832 - val_loss: 1.4818 - val_accuracy: 0.5550\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1212 - accuracy: 0.6559 - val_loss: 1.7941 - val_accuracy: 0.5255\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.9027 - accuracy: 0.7218 - val_loss: 1.8631 - val_accuracy: 0.5430\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 0.6757 - accuracy: 0.7858 - val_loss: 2.6803 - val_accuracy: 0.4760\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5370 - accuracy: 0.8377 - val_loss: 1.7393 - val_accuracy: 0.6190\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4086 - accuracy: 0.8745 - val_loss: 2.5690 - val_accuracy: 0.5185\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3559 - accuracy: 0.8959 - val_loss: 2.0081 - val_accuracy: 0.6440\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3205 - accuracy: 0.9097 - val_loss: 3.0600 - val_accuracy: 0.6210\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3207 - accuracy: 0.9129 - val_loss: 2.6973 - val_accuracy: 0.6045\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.2943 - accuracy: 0.9215 - val_loss: 2.5489 - val_accuracy: 0.6540\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3015 - accuracy: 0.9242 - val_loss: 3.5900 - val_accuracy: 0.6255\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.3203 - accuracy: 0.9280 - val_loss: 3.6248 - val_accuracy: 0.6365\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3128 - accuracy: 0.9301 - val_loss: 3.7266 - val_accuracy: 0.6290\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3458 - accuracy: 0.9335 - val_loss: 4.1831 - val_accuracy: 0.6555\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 0.3629 - accuracy: 0.9304 - val_loss: 4.1128 - val_accuracy: 0.6520\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3304 - accuracy: 0.9381 - val_loss: 3.8071 - val_accuracy: 0.6600\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3410 - accuracy: 0.9354 - val_loss: 5.1193 - val_accuracy: 0.6300\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3602 - accuracy: 0.9403 - val_loss: 5.3798 - val_accuracy: 0.6465\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3905 - accuracy: 0.9410 - val_loss: 5.6464 - val_accuracy: 0.6460\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3778 - accuracy: 0.9449 - val_loss: 6.5847 - val_accuracy: 0.6265\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3510 - accuracy: 0.9474 - val_loss: 7.2187 - val_accuracy: 0.6180\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.4175 - accuracy: 0.9423 - val_loss: 6.4126 - val_accuracy: 0.6475\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.3776 - accuracy: 0.9460 - val_loss: 7.3337 - val_accuracy: 0.6280\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.4590 - accuracy: 0.9491 - val_loss: 8.7098 - val_accuracy: 0.6345\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.4476 - accuracy: 0.9457 - val_loss: 6.0415 - val_accuracy: 0.6650\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.3939 - accuracy: 0.9523 - val_loss: 9.8685 - val_accuracy: 0.6255\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.4601 - accuracy: 0.9497 - val_loss: 9.7389 - val_accuracy: 0.6300\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 0.46005159616470337\n",
      "Training Accuracy: 0.9497236013412476\n",
      "Validation Loss: 9.738883972167969\n",
      "Validation Accuracy: 0.6299999952316284\n",
      "Classification Error Rate: 0.3700000047683716\n",
      "----->Evolution: Child net_13 with fitness 9.738883972167969 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 18\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Tournament selection\n",
      "Selected net_3 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47e0350880>, <__main__.Block object at 0x7d4c185beb00>, <__main__.Block object at 0x7d47e0ac00c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 3s 5ms/step - loss: 2.2840 - accuracy: 0.3086 - val_loss: 1.7889 - val_accuracy: 0.4690\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.7208 - accuracy: 0.4748 - val_loss: 1.6252 - val_accuracy: 0.5065\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.4492 - accuracy: 0.5590 - val_loss: 1.4912 - val_accuracy: 0.5510\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.2445 - accuracy: 0.6139 - val_loss: 1.3235 - val_accuracy: 0.6035\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.0732 - accuracy: 0.6673 - val_loss: 1.3037 - val_accuracy: 0.6275\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.9024 - accuracy: 0.7138 - val_loss: 1.2883 - val_accuracy: 0.6265\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.7392 - accuracy: 0.7662 - val_loss: 1.4494 - val_accuracy: 0.6235\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.5924 - accuracy: 0.8115 - val_loss: 1.7648 - val_accuracy: 0.6015\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.4625 - accuracy: 0.8509 - val_loss: 1.7910 - val_accuracy: 0.6200\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.3528 - accuracy: 0.8885 - val_loss: 1.5979 - val_accuracy: 0.6350\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 0.2751 - accuracy: 0.9129 - val_loss: 1.7931 - val_accuracy: 0.6435\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.2198 - accuracy: 0.9282 - val_loss: 1.8804 - val_accuracy: 0.6420\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1829 - accuracy: 0.9437 - val_loss: 2.0375 - val_accuracy: 0.6430\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1471 - accuracy: 0.9562 - val_loss: 2.4179 - val_accuracy: 0.6390\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.1389 - accuracy: 0.9579 - val_loss: 2.2059 - val_accuracy: 0.6455\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1244 - accuracy: 0.9634 - val_loss: 2.7051 - val_accuracy: 0.6310\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1051 - accuracy: 0.9688 - val_loss: 2.6947 - val_accuracy: 0.6325\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.1044 - accuracy: 0.9681 - val_loss: 3.0291 - val_accuracy: 0.6410\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0976 - accuracy: 0.9698 - val_loss: 2.8097 - val_accuracy: 0.6425\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0857 - accuracy: 0.9736 - val_loss: 2.9248 - val_accuracy: 0.6410\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0868 - accuracy: 0.9762 - val_loss: 3.0017 - val_accuracy: 0.6315\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0922 - accuracy: 0.9757 - val_loss: 3.1604 - val_accuracy: 0.6345\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0834 - accuracy: 0.9761 - val_loss: 3.3406 - val_accuracy: 0.6455\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0826 - accuracy: 0.9771 - val_loss: 3.9226 - val_accuracy: 0.6145\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0945 - accuracy: 0.9755 - val_loss: 3.6212 - val_accuracy: 0.6060\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0688 - accuracy: 0.9804 - val_loss: 3.7095 - val_accuracy: 0.6340\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0887 - accuracy: 0.9750 - val_loss: 3.8856 - val_accuracy: 0.6420\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0832 - accuracy: 0.9788 - val_loss: 4.7075 - val_accuracy: 0.5995\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0793 - accuracy: 0.9798 - val_loss: 3.9972 - val_accuracy: 0.6390\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0815 - accuracy: 0.9775 - val_loss: 4.3121 - val_accuracy: 0.6415\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.08154040575027466\n",
      "Training Accuracy: 0.9774695038795471\n",
      "Validation Loss: 4.312089443206787\n",
      "Validation Accuracy: 0.6414999961853027\n",
      "Classification Error Rate: 0.35850000381469727\n",
      "----->Evolution: Child net_10 with fitness 4.312089443206787 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Tournament selection\n",
      "Selected net_8 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  256.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47dde5a980>, <__main__.Block object at 0x7d4c187d29c0>, <__main__.Block object at 0x7d47e0395dc0>, <__main__.Block object at 0x7d47dde1b0c0>, <__main__.Block object at 0x7d4c28380940>, <__main__.Block object at 0x7d47ddfa6640>, <__main__.Block object at 0x7d47ddfe4bc0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_1129\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1129/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1129/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,256], [3,3,256,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_1129\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 256), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_323\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_323/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_323\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47ddf39dc0>, <__main__.Block object at 0x7d47ddf38f80>, <__main__.Block object at 0x7d47ddf3a180>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 4s 7ms/step - loss: 18.9797 - accuracy: 0.0585 - val_loss: 3.0069 - val_accuracy: 0.0445\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 3.1052 - accuracy: 0.0500 - val_loss: 3.0032 - val_accuracy: 0.0455\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0489 - val_loss: 3.0032 - val_accuracy: 0.0455\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.9960 - accuracy: 0.0484 - val_loss: 3.0033 - val_accuracy: 0.0455\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0467 - val_loss: 3.0033 - val_accuracy: 0.0455\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0482 - val_loss: 3.0033 - val_accuracy: 0.0455\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.9959 - accuracy: 0.0477 - val_loss: 3.0033 - val_accuracy: 0.0455\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.9959 - accuracy: 0.0463 - val_loss: 3.0033 - val_accuracy: 0.0455\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.9959 - accuracy: 0.0506 - val_loss: 3.0033 - val_accuracy: 0.0455\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.9959 - accuracy: 0.0478 - val_loss: 3.0033 - val_accuracy: 0.0470\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.9960 - accuracy: 0.0497 - val_loss: 3.0033 - val_accuracy: 0.0455\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.9959 - accuracy: 0.0487 - val_loss: 3.0034 - val_accuracy: 0.0470\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0476 - val_loss: 3.0034 - val_accuracy: 0.0470\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0491 - val_loss: 3.0035 - val_accuracy: 0.0455\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0477 - val_loss: 3.0036 - val_accuracy: 0.0455\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0470 - val_loss: 3.0036 - val_accuracy: 0.0455\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0461 - val_loss: 3.0034 - val_accuracy: 0.0455\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0482 - val_loss: 3.0034 - val_accuracy: 0.0455\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0485 - val_loss: 3.0035 - val_accuracy: 0.0520\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.9959 - accuracy: 0.0469 - val_loss: 3.0034 - val_accuracy: 0.0455\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0483 - val_loss: 3.0035 - val_accuracy: 0.0455\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0499 - val_loss: 3.0035 - val_accuracy: 0.0455\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0478 - val_loss: 3.0035 - val_accuracy: 0.0455\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0493 - val_loss: 3.0034 - val_accuracy: 0.0455\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0488 - val_loss: 3.0035 - val_accuracy: 0.0455\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0492 - val_loss: 3.0035 - val_accuracy: 0.0470\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0473 - val_loss: 3.0035 - val_accuracy: 0.0470\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9960 - accuracy: 0.0475 - val_loss: 3.0036 - val_accuracy: 0.0470\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0476 - val_loss: 3.0036 - val_accuracy: 0.0470\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 2.9959 - accuracy: 0.0481 - val_loss: 3.0035 - val_accuracy: 0.0470\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 2.9959347248077393\n",
      "Training Accuracy: 0.04808595031499863\n",
      "Validation Loss: 3.0035288333892822\n",
      "Validation Accuracy: 0.04699999839067459\n",
      "Classification Error Rate: 0.9530000016093254\n",
      "----->Evolution: Child net_11 with fitness 3.0035288333892822 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Tournament selection\n",
      "Selected net_1 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.5  to  0.6\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47cb6deac0>, <__main__.Block object at 0x7d47dda8a9c0>, <__main__.Block object at 0x7d47cb6af600>, <__main__.Block object at 0x7d47dd42e700>, <__main__.Block object at 0x7d47cb6c6640>, <__main__.Block object at 0x7d47cb62b7c0>, <__main__.Block object at 0x7d47dd423340>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1141. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1145. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:25:14.219996: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_127/dropout_138/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 8ms/step - loss: 2.8537 - accuracy: 0.1098 - val_loss: 2.5753 - val_accuracy: 0.2365\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.4681 - accuracy: 0.2328 - val_loss: 2.7680 - val_accuracy: 0.1570\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.2150 - accuracy: 0.3225 - val_loss: 2.6094 - val_accuracy: 0.2960\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.0142 - accuracy: 0.3918 - val_loss: 1.8228 - val_accuracy: 0.4555\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.8540 - accuracy: 0.4451 - val_loss: 2.2116 - val_accuracy: 0.3490\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.7483 - accuracy: 0.4841 - val_loss: 1.6946 - val_accuracy: 0.4760\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.6622 - accuracy: 0.5132 - val_loss: 1.8226 - val_accuracy: 0.4795\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.5492 - accuracy: 0.5452 - val_loss: 1.5774 - val_accuracy: 0.5515\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.5004 - accuracy: 0.5695 - val_loss: 1.6298 - val_accuracy: 0.5295\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.4036 - accuracy: 0.5936 - val_loss: 1.4946 - val_accuracy: 0.5825\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.3271 - accuracy: 0.6147 - val_loss: 1.3974 - val_accuracy: 0.6035\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2939 - accuracy: 0.6391 - val_loss: 1.4232 - val_accuracy: 0.6125\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2104 - accuracy: 0.6572 - val_loss: 1.4066 - val_accuracy: 0.6165\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1919 - accuracy: 0.6690 - val_loss: 1.6394 - val_accuracy: 0.5890\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1374 - accuracy: 0.6823 - val_loss: 1.2878 - val_accuracy: 0.6475\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.0799 - accuracy: 0.6931 - val_loss: 1.6157 - val_accuracy: 0.6060\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.0391 - accuracy: 0.7108 - val_loss: 1.4817 - val_accuracy: 0.6550\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.0439 - accuracy: 0.7215 - val_loss: 1.3964 - val_accuracy: 0.6460\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0117 - accuracy: 0.7249 - val_loss: 1.4112 - val_accuracy: 0.6360\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9876 - accuracy: 0.7323 - val_loss: 1.2814 - val_accuracy: 0.6555\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9927 - accuracy: 0.7417 - val_loss: 1.5606 - val_accuracy: 0.6485\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9667 - accuracy: 0.7459 - val_loss: 1.4325 - val_accuracy: 0.6525\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9594 - accuracy: 0.7441 - val_loss: 1.5184 - val_accuracy: 0.6030\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9483 - accuracy: 0.7477 - val_loss: 1.5422 - val_accuracy: 0.6710\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9633 - accuracy: 0.7519 - val_loss: 1.5333 - val_accuracy: 0.6480\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9415 - accuracy: 0.7550 - val_loss: 1.5298 - val_accuracy: 0.5945\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9405 - accuracy: 0.7603 - val_loss: 1.5295 - val_accuracy: 0.6580\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9617 - accuracy: 0.7620 - val_loss: 1.6298 - val_accuracy: 0.6400\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9594 - accuracy: 0.7586 - val_loss: 1.6726 - val_accuracy: 0.6755\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9432 - accuracy: 0.7641 - val_loss: 1.4736 - val_accuracy: 0.6450\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 0.9432457685470581\n",
      "Training Accuracy: 0.7640554904937744\n",
      "Validation Loss: 1.4736344814300537\n",
      "Validation Accuracy: 0.6449999809265137\n",
      "Classification Error Rate: 0.35500001907348633\n",
      "----->Evolution: Child net_12 with fitness 1.4736344814300537 replaces parent net_7 with fitness 2.036752700805664\n",
      "\n",
      "Creating Child 3\n",
      "----->Tournament selection\n",
      "Selected net_3 and net_9 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.30000000000000004  to  0.4\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d4bf8d5c880>, <__main__.Block object at 0x7d47e2a1cac0>, <__main__.Block object at 0x7d4bf8da7700>, <__main__.Block object at 0x7d4bf8ed6100>, <__main__.Block object at 0x7d4bf8ea9f40>, <__main__.Block object at 0x7d4bf8e7f900>, <__main__.Block object at 0x7d4bf8eecdc0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_1153\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1153/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1153/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_1153\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_1154\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1154/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1154/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_1154\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_294\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_294/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_294\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47d8e8d540>, <__main__.Block object at 0x7d47d8e8cf40>, <__main__.Block object at 0x7d47d8e8d640>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n",
      "300/300 [==============================] - 3s 6ms/step - loss: 2.2661 - accuracy: 0.3481 - val_loss: 1.7299 - val_accuracy: 0.4810\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 1.4897 - accuracy: 0.5447 - val_loss: 1.6516 - val_accuracy: 0.5080\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 1.0675 - accuracy: 0.6767 - val_loss: 1.4413 - val_accuracy: 0.5940\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.6986 - accuracy: 0.7839 - val_loss: 1.4804 - val_accuracy: 0.6040\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.4199 - accuracy: 0.8726 - val_loss: 1.5548 - val_accuracy: 0.6350\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.2486 - accuracy: 0.9224 - val_loss: 1.7759 - val_accuracy: 0.6210\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1529 - accuracy: 0.9537 - val_loss: 1.9937 - val_accuracy: 0.6175\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.1021 - accuracy: 0.9702 - val_loss: 2.1313 - val_accuracy: 0.6145\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0815 - accuracy: 0.9744 - val_loss: 2.5115 - val_accuracy: 0.6070\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0599 - accuracy: 0.9837 - val_loss: 2.6784 - val_accuracy: 0.6190\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0573 - accuracy: 0.9819 - val_loss: 2.7442 - val_accuracy: 0.6435\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0547 - accuracy: 0.9847 - val_loss: 2.8527 - val_accuracy: 0.6360\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0408 - accuracy: 0.9875 - val_loss: 2.9153 - val_accuracy: 0.6290\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0425 - accuracy: 0.9882 - val_loss: 3.1114 - val_accuracy: 0.6110\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0416 - accuracy: 0.9873 - val_loss: 3.4938 - val_accuracy: 0.5960\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0395 - accuracy: 0.9884 - val_loss: 3.1306 - val_accuracy: 0.6175\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0342 - accuracy: 0.9913 - val_loss: 3.3091 - val_accuracy: 0.6305\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 3.5758 - val_accuracy: 0.6090\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0314 - accuracy: 0.9907 - val_loss: 3.5050 - val_accuracy: 0.6390\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0251 - accuracy: 0.9929 - val_loss: 3.7021 - val_accuracy: 0.6370\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0335 - accuracy: 0.9904 - val_loss: 3.8434 - val_accuracy: 0.6250\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0310 - accuracy: 0.9917 - val_loss: 4.4832 - val_accuracy: 0.6195\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0371 - accuracy: 0.9907 - val_loss: 4.4545 - val_accuracy: 0.6140\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0409 - accuracy: 0.9890 - val_loss: 4.2104 - val_accuracy: 0.6160\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 5ms/step - loss: 0.0302 - accuracy: 0.9917 - val_loss: 5.0862 - val_accuracy: 0.6205\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 1s 5ms/step - loss: 0.0347 - accuracy: 0.9911 - val_loss: 4.9287 - val_accuracy: 0.6215\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0344 - accuracy: 0.9904 - val_loss: 5.0705 - val_accuracy: 0.6080\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0333 - accuracy: 0.9912 - val_loss: 5.2928 - val_accuracy: 0.6090\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0298 - accuracy: 0.9914 - val_loss: 5.5118 - val_accuracy: 0.6090\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 1s 4ms/step - loss: 0.0284 - accuracy: 0.9920 - val_loss: 5.7304 - val_accuracy: 0.6140\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 0.028419893234968185\n",
      "Training Accuracy: 0.9919682741165161\n",
      "Validation Loss: 5.730386734008789\n",
      "Validation Accuracy: 0.6140000224113464\n",
      "Classification Error Rate: 0.38599997758865356\n",
      "----->Evolution: Child net_13 with fitness 5.730386734008789 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 19\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Proportionate selection\n",
      "Selected net_8 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47d84b0440>, <__main__.Block object at 0x7d47d84dda00>, <__main__.Block object at 0x7d47d83c6ac0>, <__main__.Block object at 0x7d47d83864c0>, <__main__.Block object at 0x7d47d838d5c0>, <__main__.Block object at 0x7d47d85db0c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_1165\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1165/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1165/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,256], [3,3,256,64].\n",
      "\n",
      "Call arguments received by layer \"conv2d_1165\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 256), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:27:48.116777: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_130/dropout_141/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 8ms/step - loss: 2.8043 - accuracy: 0.1495 - val_loss: 4.6733 - val_accuracy: 0.0870\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.3328 - accuracy: 0.3209 - val_loss: 2.7379 - val_accuracy: 0.2675\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.0733 - accuracy: 0.4011 - val_loss: 2.4072 - val_accuracy: 0.3700\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.9351 - accuracy: 0.4667 - val_loss: 2.9037 - val_accuracy: 0.3200\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.7419 - accuracy: 0.5026 - val_loss: 1.8425 - val_accuracy: 0.4970\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.5833 - accuracy: 0.5504 - val_loss: 1.8603 - val_accuracy: 0.4695\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.5852 - accuracy: 0.5792 - val_loss: 2.0510 - val_accuracy: 0.4870\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.5803 - accuracy: 0.6188 - val_loss: 2.1807 - val_accuracy: 0.5320\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.3306 - accuracy: 0.6381 - val_loss: 1.9801 - val_accuracy: 0.5110\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1652 - accuracy: 0.6691 - val_loss: 1.6069 - val_accuracy: 0.5810\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2030 - accuracy: 0.6921 - val_loss: 1.9357 - val_accuracy: 0.5220\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0671 - accuracy: 0.7170 - val_loss: 2.1099 - val_accuracy: 0.5695\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2277 - accuracy: 0.7320 - val_loss: 2.0740 - val_accuracy: 0.5255\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2579 - accuracy: 0.7492 - val_loss: 2.3087 - val_accuracy: 0.5525\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3327 - accuracy: 0.7578 - val_loss: 2.2999 - val_accuracy: 0.5965\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9462 - accuracy: 0.7778 - val_loss: 2.8855 - val_accuracy: 0.5545\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9296 - accuracy: 0.7829 - val_loss: 2.4799 - val_accuracy: 0.5900\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0758 - accuracy: 0.7858 - val_loss: 2.5312 - val_accuracy: 0.5225\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9234 - accuracy: 0.7933 - val_loss: 1.8567 - val_accuracy: 0.5975\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2924 - accuracy: 0.7916 - val_loss: 2.4040 - val_accuracy: 0.5510\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9844 - accuracy: 0.7941 - val_loss: 2.4525 - val_accuracy: 0.5820\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4333 - accuracy: 0.7932 - val_loss: 2.5563 - val_accuracy: 0.5955\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.5684 - accuracy: 0.8096 - val_loss: 3.1905 - val_accuracy: 0.5375\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0822 - accuracy: 0.8030 - val_loss: 2.2634 - val_accuracy: 0.5575\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9355 - accuracy: 0.8089 - val_loss: 2.3467 - val_accuracy: 0.5450\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2843 - accuracy: 0.8021 - val_loss: 2.6678 - val_accuracy: 0.5930\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1369 - accuracy: 0.7972 - val_loss: 2.6708 - val_accuracy: 0.5865\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.6033 - accuracy: 0.8037 - val_loss: 2.5526 - val_accuracy: 0.5945\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2461 - accuracy: 0.8113 - val_loss: 2.1986 - val_accuracy: 0.5660\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1040 - accuracy: 0.8047 - val_loss: 2.0884 - val_accuracy: 0.5385\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 1.1040347814559937\n",
      "Training Accuracy: 0.8047356009483337\n",
      "Validation Loss: 2.0883629322052\n",
      "Validation Accuracy: 0.5385000109672546\n",
      "Classification Error Rate: 0.46149998903274536\n",
      "----->Evolution: Child net_10 with fitness 2.0883629322052 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Proportionate selection\n",
      "Selected net_3 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.30000000000000004  to  0.25000000000000006\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47d8385940>, <__main__.Block object at 0x7d47d83129c0>, <__main__.Block object at 0x7d47ca12cf00>, <__main__.Block object at 0x7d47ca10be40>, <__main__.Block object at 0x7d47ca11b800>, <__main__.Block object at 0x7d47ca2db9c0>, <__main__.Block object at 0x7d47ca115c40>, <__main__.Block object at 0x7d47ca1cfd80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1175. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1176. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1177. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:28:58.003360: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_131/dropout_142/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 6s 9ms/step - loss: 2.9293 - accuracy: 0.0876 - val_loss: 3.3058 - val_accuracy: 0.1020\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.5916 - accuracy: 0.2151 - val_loss: 2.5520 - val_accuracy: 0.2095\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.3634 - accuracy: 0.2851 - val_loss: 2.3802 - val_accuracy: 0.2675\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.1741 - accuracy: 0.3387 - val_loss: 2.2417 - val_accuracy: 0.3090\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.1297 - accuracy: 0.4000 - val_loss: 2.0441 - val_accuracy: 0.3685\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.3456 - accuracy: 0.4345 - val_loss: 2.0793 - val_accuracy: 0.4015\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.9619 - accuracy: 0.4657 - val_loss: 2.0097 - val_accuracy: 0.4010\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.9394 - accuracy: 0.4985 - val_loss: 1.8841 - val_accuracy: 0.4605\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.3532 - accuracy: 0.5264 - val_loss: 2.1776 - val_accuracy: 0.4265\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.8524 - accuracy: 0.5515 - val_loss: 2.2295 - val_accuracy: 0.4455\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.4981 - accuracy: 0.5659 - val_loss: 1.8439 - val_accuracy: 0.4700\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.2715 - accuracy: 0.5915 - val_loss: 2.0972 - val_accuracy: 0.4415\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.8155 - accuracy: 0.6130 - val_loss: 1.7487 - val_accuracy: 0.5090\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.0438 - accuracy: 0.6296 - val_loss: 2.0674 - val_accuracy: 0.4595\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.6846 - accuracy: 0.6474 - val_loss: 2.0265 - val_accuracy: 0.5040\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.6774 - accuracy: 0.6573 - val_loss: 1.7888 - val_accuracy: 0.5290\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.3779 - accuracy: 0.6739 - val_loss: 2.0314 - val_accuracy: 0.4995\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.4786 - accuracy: 0.6860 - val_loss: 2.3689 - val_accuracy: 0.4550\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.5710 - accuracy: 0.7022 - val_loss: 1.8998 - val_accuracy: 0.5030\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.3183 - accuracy: 0.7119 - val_loss: 2.3501 - val_accuracy: 0.5230\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 1.3681 - accuracy: 0.7221 - val_loss: 2.0693 - val_accuracy: 0.4970\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.9027 - accuracy: 0.7299 - val_loss: 2.2469 - val_accuracy: 0.5075\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.8699 - accuracy: 0.7431 - val_loss: 1.9949 - val_accuracy: 0.5275\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.4423 - accuracy: 0.7474 - val_loss: 2.0765 - val_accuracy: 0.5180\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8860 - accuracy: 0.7546 - val_loss: 1.7957 - val_accuracy: 0.5560\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.9871 - accuracy: 0.7585 - val_loss: 2.2000 - val_accuracy: 0.5310\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.8843 - accuracy: 0.7680 - val_loss: 1.9921 - val_accuracy: 0.5385\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.0289 - accuracy: 0.7629 - val_loss: 2.4021 - val_accuracy: 0.5010\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8489 - accuracy: 0.7723 - val_loss: 2.1295 - val_accuracy: 0.5870\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8248 - accuracy: 0.7876 - val_loss: 2.1893 - val_accuracy: 0.5725\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 0.8247881531715393\n",
      "Training Accuracy: 0.7876290678977966\n",
      "Validation Loss: 2.1892647743225098\n",
      "Validation Accuracy: 0.5724999904632568\n",
      "Classification Error Rate: 0.42750000953674316\n",
      "----->Evolution: Child net_11 with fitness 2.1892647743225098 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Proportionate selection\n",
      "Selected net_4 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.5\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512.0  to  256.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47d96e1dc0>, <__main__.Block object at 0x7d47d95590c0>, <__main__.Block object at 0x7d47d96630c0>, <__main__.Block object at 0x7d47d96580c0>, <__main__.Block object at 0x7d47d96ee5c0>, <__main__.Block object at 0x7d47d9569040>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:30:17.527140: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_132/dropout_143/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 6s 10ms/step - loss: 2.9658 - accuracy: 0.0775 - val_loss: 2.9909 - val_accuracy: 0.0770\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.5761 - accuracy: 0.1810 - val_loss: 2.7744 - val_accuracy: 0.1615\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.3391 - accuracy: 0.2913 - val_loss: 2.1979 - val_accuracy: 0.3105\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.0247 - accuracy: 0.3815 - val_loss: 2.1550 - val_accuracy: 0.3385\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8085 - accuracy: 0.4632 - val_loss: 1.9466 - val_accuracy: 0.4365\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.6736 - accuracy: 0.5162 - val_loss: 1.7668 - val_accuracy: 0.4625\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.5272 - accuracy: 0.5633 - val_loss: 2.2215 - val_accuracy: 0.3800\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.3721 - accuracy: 0.6085 - val_loss: 1.6553 - val_accuracy: 0.5275\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.2751 - accuracy: 0.6394 - val_loss: 1.7137 - val_accuracy: 0.4940\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.1505 - accuracy: 0.6850 - val_loss: 1.6732 - val_accuracy: 0.5340\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0143 - accuracy: 0.7160 - val_loss: 1.7278 - val_accuracy: 0.5795\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0000 - accuracy: 0.7386 - val_loss: 1.6472 - val_accuracy: 0.5670\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.9091 - accuracy: 0.7692 - val_loss: 1.5843 - val_accuracy: 0.5620\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.7145 - accuracy: 0.7892 - val_loss: 1.4753 - val_accuracy: 0.6025\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.1116 - accuracy: 0.8077 - val_loss: 1.7399 - val_accuracy: 0.5780\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.9397 - accuracy: 0.8161 - val_loss: 1.5359 - val_accuracy: 0.5910\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.8902 - accuracy: 0.8236 - val_loss: 1.5920 - val_accuracy: 0.5915\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.6909 - accuracy: 0.8327 - val_loss: 1.5942 - val_accuracy: 0.6430\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.7894 - accuracy: 0.8496 - val_loss: 1.6137 - val_accuracy: 0.5905\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.0503 - accuracy: 0.8573 - val_loss: 1.8888 - val_accuracy: 0.5905\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.8207 - accuracy: 0.8549 - val_loss: 1.7387 - val_accuracy: 0.5600\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.7653 - accuracy: 0.8665 - val_loss: 2.2297 - val_accuracy: 0.5390\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.8404 - accuracy: 0.8649 - val_loss: 1.7804 - val_accuracy: 0.6060\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 0.7565 - accuracy: 0.8722 - val_loss: 2.2835 - val_accuracy: 0.5390\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.4539 - accuracy: 0.8706 - val_loss: 2.4133 - val_accuracy: 0.5610\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.2765 - accuracy: 0.8789 - val_loss: 2.0039 - val_accuracy: 0.5430\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.5094 - accuracy: 0.8648 - val_loss: 2.6935 - val_accuracy: 0.4075\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.8581 - accuracy: 0.8674 - val_loss: 1.5999 - val_accuracy: 0.6025\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 0.7259 - accuracy: 0.8778 - val_loss: 1.7866 - val_accuracy: 0.5960\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.3856 - accuracy: 0.8561 - val_loss: 2.2436 - val_accuracy: 0.5590\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 1.3856431245803833\n",
      "Training Accuracy: 0.8560550808906555\n",
      "Validation Loss: 2.2436411380767822\n",
      "Validation Accuracy: 0.5590000152587891\n",
      "Classification Error Rate: 0.44099998474121094\n",
      "----->Evolution: Child net_12 with fitness 2.2436411380767822 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Proportionate selection\n",
      "Selected net_9 and net_9 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.35000000000000003\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  1024.0  to  512.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47ca027b00>, <__main__.Block object at 0x7d47d933a500>, <__main__.Block object at 0x7d47d9406940>, <__main__.Block object at 0x7d47d946c800>, <__main__.Block object at 0x7d47d9278880>, <__main__.Block object at 0x7d47d92eb0c0>, <__main__.Block object at 0x7d47d92965c0>, <__main__.Block object at 0x7d47d924e700>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_344\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_344/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_344\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.25  to  0.2\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  1024.0  to  512.0\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47ca07b740>, <__main__.Block object at 0x7d47ca08af80>, <__main__.Block object at 0x7d47ca08a800>, <__main__.Block object at 0x7d47ca089ac0>, <__main__.Block object at 0x7d47ca088f40>, <__main__.Block object at 0x7d47ca08b800>, <__main__.Block object at 0x7d47ca08ba00>, <__main__.Block object at 0x7d47ca08bd40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1207. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_310\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_310/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_310\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2)]\n",
      "Removing a Pooling/Dropout layer at 1\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.45  to  0.55\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.4  to  0.5\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  1024.0  to  2048.0\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47ca07a880>, <__main__.Block object at 0x7d47d94fc200>, <__main__.Block object at 0x7d47d94fd080>, <__main__.Block object at 0x7d47d94fca80>, <__main__.Block object at 0x7d47d94fc880>, <__main__.Block object at 0x7d47d94fcf40>, <__main__.Block object at 0x7d47d92d3940>, <__main__.Block object at 0x7d47d92d3a40>, <__main__.Block object at 0x7d47d92dbcc0>, <__main__.Block object at 0x7d47d93f01c0>, <__main__.Block object at 0x7d47d92fa140>, <__main__.Block object at 0x7d47d9522a00>, <__main__.Block object at 0x7d47ca0651c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1214. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1215. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1219. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1220. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1222. Consider increasing the input size. Received input shape [None, 1, 1, 512] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1225. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:32:41.914003: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_135/dropout_147/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 8s 14ms/step - loss: 2.9973 - accuracy: 0.0585 - val_loss: 2.9786 - val_accuracy: 0.0650\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.8287 - accuracy: 0.1064 - val_loss: 2.9787 - val_accuracy: 0.0810\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.6664 - accuracy: 0.1462 - val_loss: 2.8806 - val_accuracy: 0.0825\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.5390 - accuracy: 0.1817 - val_loss: 2.4219 - val_accuracy: 0.2260\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.4343 - accuracy: 0.2147 - val_loss: 2.7453 - val_accuracy: 0.1415\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.3433 - accuracy: 0.2330 - val_loss: 2.3409 - val_accuracy: 0.2380\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.2881 - accuracy: 0.2686 - val_loss: 2.4065 - val_accuracy: 0.2375\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.1855 - accuracy: 0.2868 - val_loss: 2.2669 - val_accuracy: 0.2765\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.1087 - accuracy: 0.3169 - val_loss: 2.1610 - val_accuracy: 0.2925\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.0600 - accuracy: 0.3389 - val_loss: 2.0815 - val_accuracy: 0.3680\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 2.0119 - accuracy: 0.3627 - val_loss: 2.1079 - val_accuracy: 0.3590\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.9459 - accuracy: 0.3870 - val_loss: 2.1452 - val_accuracy: 0.3325\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.9412 - accuracy: 0.3997 - val_loss: 2.1978 - val_accuracy: 0.3380\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.8856 - accuracy: 0.4186 - val_loss: 2.1866 - val_accuracy: 0.3125\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8545 - accuracy: 0.4299 - val_loss: 1.9243 - val_accuracy: 0.4180\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8376 - accuracy: 0.4355 - val_loss: 2.1061 - val_accuracy: 0.3625\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.8194 - accuracy: 0.4545 - val_loss: 1.9812 - val_accuracy: 0.3885\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 3s 10ms/step - loss: 1.7693 - accuracy: 0.4649 - val_loss: 1.9848 - val_accuracy: 0.3970\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.7457 - accuracy: 0.4692 - val_loss: 1.8401 - val_accuracy: 0.4425\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.7811 - accuracy: 0.4799 - val_loss: 1.8732 - val_accuracy: 0.4370\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.7165 - accuracy: 0.4840 - val_loss: 1.9986 - val_accuracy: 0.4200\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.7166 - accuracy: 0.4894 - val_loss: 1.9646 - val_accuracy: 0.4245\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6894 - accuracy: 0.4929 - val_loss: 1.9654 - val_accuracy: 0.4540\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6525 - accuracy: 0.5107 - val_loss: 1.9958 - val_accuracy: 0.4275\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 3s 12ms/step - loss: 1.6357 - accuracy: 0.5138 - val_loss: 1.8716 - val_accuracy: 0.4435\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 1.6827 - accuracy: 0.5105 - val_loss: 2.0176 - val_accuracy: 0.3965\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6614 - accuracy: 0.5101 - val_loss: 1.7842 - val_accuracy: 0.4645\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.8194 - accuracy: 0.5018 - val_loss: 2.0218 - val_accuracy: 0.4085\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6563 - accuracy: 0.5101 - val_loss: 1.8839 - val_accuracy: 0.4425\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 3s 11ms/step - loss: 1.6765 - accuracy: 0.5046 - val_loss: 2.0563 - val_accuracy: 0.4090\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 1.6764745712280273\n",
      "Training Accuracy: 0.5046417117118835\n",
      "Validation Loss: 2.056321620941162\n",
      "Validation Accuracy: 0.4090000092983246\n",
      "Classification Error Rate: 0.5909999907016754\n",
      "----->Evolution: Child net_13 with fitness 2.056321620941162 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 20\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_7 and net_8 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.35000000000000003  to  0.25\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.6  to  0.5\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47ca40eac0>, <__main__.Block object at 0x7d47d9f02500>, <__main__.Block object at 0x7d47d854da00>, <__main__.Block object at 0x7d47ca1b8c00>, <__main__.Block object at 0x7d47dd4730c0>, <__main__.Block object at 0x7d47df5e1040>, <__main__.Block object at 0x7d47e01d00c0>, <__main__.Block object at 0x7d47dd5d0440>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_1232\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_1232/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_1232/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_1232\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1234. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1235. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:35:05.591126: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_136/dropout_151/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 8ms/step - loss: 3.0359 - accuracy: 0.0760 - val_loss: 2.7689 - val_accuracy: 0.1490\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.8379 - accuracy: 0.1643 - val_loss: 2.5838 - val_accuracy: 0.2200\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.7760 - accuracy: 0.2411 - val_loss: 2.4667 - val_accuracy: 0.2580\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.8282 - accuracy: 0.2902 - val_loss: 2.1464 - val_accuracy: 0.3455\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 3.0889 - accuracy: 0.3298 - val_loss: 2.0860 - val_accuracy: 0.3630\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 4.5899 - accuracy: 0.3591 - val_loss: 1.8671 - val_accuracy: 0.4360\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.4832 - accuracy: 0.3752 - val_loss: 2.0016 - val_accuracy: 0.4065\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 4.0721 - accuracy: 0.4011 - val_loss: 2.1139 - val_accuracy: 0.3705\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 5.2609 - accuracy: 0.4245 - val_loss: 2.4256 - val_accuracy: 0.2790\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 13.0234 - accuracy: 0.4319 - val_loss: 1.9273 - val_accuracy: 0.4330\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 10.7209 - accuracy: 0.4546 - val_loss: 2.2083 - val_accuracy: 0.3630\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 18.3762 - accuracy: 0.4594 - val_loss: 1.9287 - val_accuracy: 0.4230\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 15.0477 - accuracy: 0.4608 - val_loss: 2.1901 - val_accuracy: 0.3940\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 14.7009 - accuracy: 0.4630 - val_loss: 1.8254 - val_accuracy: 0.4645\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 24.5988 - accuracy: 0.4895 - val_loss: 1.9207 - val_accuracy: 0.4150\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 23.9062 - accuracy: 0.4877 - val_loss: 2.0146 - val_accuracy: 0.4510\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 20.0016 - accuracy: 0.4885 - val_loss: 1.8245 - val_accuracy: 0.4710\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 28.5392 - accuracy: 0.4994 - val_loss: 1.8079 - val_accuracy: 0.4540\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 27.3377 - accuracy: 0.5056 - val_loss: 1.8544 - val_accuracy: 0.4765\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 29.8791 - accuracy: 0.5086 - val_loss: 1.9153 - val_accuracy: 0.4535\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 47.8968 - accuracy: 0.5118 - val_loss: 2.0084 - val_accuracy: 0.3945\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 24.3969 - accuracy: 0.4988 - val_loss: 1.9170 - val_accuracy: 0.4220\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 56.7142 - accuracy: 0.5069 - val_loss: 2.0710 - val_accuracy: 0.3735\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 79.2485 - accuracy: 0.5007 - val_loss: 1.9706 - val_accuracy: 0.4155\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 57.6613 - accuracy: 0.4995 - val_loss: 1.9487 - val_accuracy: 0.4450\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 57.7430 - accuracy: 0.5180 - val_loss: 2.2551 - val_accuracy: 0.3840\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 61.7545 - accuracy: 0.5180 - val_loss: 2.1150 - val_accuracy: 0.4040\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 70.3131 - accuracy: 0.5232 - val_loss: 2.1380 - val_accuracy: 0.3420\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 66.2564 - accuracy: 0.5139 - val_loss: 2.0766 - val_accuracy: 0.4460\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 64.8478 - accuracy: 0.5149 - val_loss: 3.5445 - val_accuracy: 0.3775\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 64.84782409667969\n",
      "Training Accuracy: 0.5148638486862183\n",
      "Validation Loss: 3.5445010662078857\n",
      "Validation Accuracy: 0.3774999976158142\n",
      "Classification Error Rate: 0.6225000023841858\n",
      "----->Evolution: Child net_10 with fitness 3.5445010662078857 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_7 and net_8 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.35000000000000003  to  0.45000000000000007\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47c972f180>, <__main__.Block object at 0x7d47dd665dc0>, <__main__.Block object at 0x7d47ca410880>, <__main__.Block object at 0x7d47da179040>, <__main__.Block object at 0x7d4bf82e0c00>, <__main__.Block object at 0x7d47dd270100>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:36:29.075695: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_137/dropout_153/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 9ms/step - loss: 3.0023 - accuracy: 0.0752 - val_loss: 4.4275 - val_accuracy: 0.0640\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.6783 - accuracy: 0.2034 - val_loss: 3.6452 - val_accuracy: 0.2140\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.5494 - accuracy: 0.3223 - val_loss: 2.1443 - val_accuracy: 0.3870\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.2925 - accuracy: 0.3973 - val_loss: 2.9267 - val_accuracy: 0.2885\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.0971 - accuracy: 0.4445 - val_loss: 2.7358 - val_accuracy: 0.3370\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.0818 - accuracy: 0.4850 - val_loss: 2.1666 - val_accuracy: 0.4500\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.8922 - accuracy: 0.5254 - val_loss: 2.2059 - val_accuracy: 0.4770\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.0788 - accuracy: 0.5526 - val_loss: 3.6381 - val_accuracy: 0.3795\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.8919 - accuracy: 0.5812 - val_loss: 3.1975 - val_accuracy: 0.3280\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.6942 - accuracy: 0.6054 - val_loss: 2.4043 - val_accuracy: 0.4795\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.6260 - accuracy: 0.6266 - val_loss: 1.8797 - val_accuracy: 0.5480\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.6128 - accuracy: 0.6475 - val_loss: 2.4627 - val_accuracy: 0.5275\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.5228 - accuracy: 0.6653 - val_loss: 2.6589 - val_accuracy: 0.4625\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.7212 - accuracy: 0.6870 - val_loss: 2.5384 - val_accuracy: 0.5385\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.5871 - accuracy: 0.7048 - val_loss: 2.3615 - val_accuracy: 0.5085\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.4611 - accuracy: 0.7230 - val_loss: 2.3083 - val_accuracy: 0.5985\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4083 - accuracy: 0.7316 - val_loss: 2.3216 - val_accuracy: 0.5900\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.6515 - accuracy: 0.7436 - val_loss: 2.6798 - val_accuracy: 0.5190\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2528 - accuracy: 0.7540 - val_loss: 3.1279 - val_accuracy: 0.5605\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4548 - accuracy: 0.7599 - val_loss: 2.4829 - val_accuracy: 0.5570\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3642 - accuracy: 0.7669 - val_loss: 2.5401 - val_accuracy: 0.5510\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4349 - accuracy: 0.7738 - val_loss: 3.3219 - val_accuracy: 0.5035\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3108 - accuracy: 0.7613 - val_loss: 3.1131 - val_accuracy: 0.5150\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.8194 - accuracy: 0.7669 - val_loss: 3.1442 - val_accuracy: 0.5215\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.8317 - accuracy: 0.7657 - val_loss: 2.3383 - val_accuracy: 0.5665\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.7835 - accuracy: 0.7679 - val_loss: 3.1721 - val_accuracy: 0.4890\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.6004 - accuracy: 0.7678 - val_loss: 2.9031 - val_accuracy: 0.5470\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2923 - accuracy: 0.7564 - val_loss: 4.3719 - val_accuracy: 0.5880\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 6ms/step - loss: 1.6710 - accuracy: 0.7633 - val_loss: 3.8241 - val_accuracy: 0.5695\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.8106 - accuracy: 0.7629 - val_loss: 4.1839 - val_accuracy: 0.3945\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 1.8106244802474976\n",
      "Training Accuracy: 0.7629081010818481\n",
      "Validation Loss: 4.183897495269775\n",
      "Validation Accuracy: 0.3944999873638153\n",
      "Classification Error Rate: 0.6055000126361847\n",
      "----->Evolution: Child net_11 with fitness 4.183897495269775 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_7 and net_8 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47d917d600>, <__main__.Block object at 0x7d47cb7910c0>, <__main__.Block object at 0x7d47d8ec5a00>, <__main__.Block object at 0x7d47ca4e9040>, <__main__.Block object at 0x7d47da1f0940>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:37:32.476472: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_138/dropout_155/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 9ms/step - loss: 2.9981 - accuracy: 0.1369 - val_loss: 2.5232 - val_accuracy: 0.2550\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.5884 - accuracy: 0.2933 - val_loss: 2.9192 - val_accuracy: 0.2495\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.5351 - accuracy: 0.3631 - val_loss: 3.6656 - val_accuracy: 0.3225\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.1670 - accuracy: 0.4150 - val_loss: 2.4404 - val_accuracy: 0.3500\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.9924 - accuracy: 0.4532 - val_loss: 2.1279 - val_accuracy: 0.4110\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 1.9824 - accuracy: 0.4760 - val_loss: 5.1079 - val_accuracy: 0.2915\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.0658 - accuracy: 0.4914 - val_loss: 2.1165 - val_accuracy: 0.4305\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.2893 - accuracy: 0.5201 - val_loss: 2.5299 - val_accuracy: 0.3630\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.8935 - accuracy: 0.5185 - val_loss: 2.2100 - val_accuracy: 0.4110\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 2.2779 - accuracy: 0.5371 - val_loss: 2.6532 - val_accuracy: 0.4130\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.0443 - accuracy: 0.5316 - val_loss: 2.9894 - val_accuracy: 0.4010\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.2180 - accuracy: 0.5312 - val_loss: 2.3324 - val_accuracy: 0.4090\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.9345 - accuracy: 0.5303 - val_loss: 2.3496 - val_accuracy: 0.4260\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.9819 - accuracy: 0.5364 - val_loss: 3.4899 - val_accuracy: 0.3765\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.2178 - accuracy: 0.5408 - val_loss: 2.6781 - val_accuracy: 0.3505\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.2636 - accuracy: 0.5362 - val_loss: 4.7666 - val_accuracy: 0.3020\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.8421 - accuracy: 0.5378 - val_loss: 2.4796 - val_accuracy: 0.3370\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.8494 - accuracy: 0.5353 - val_loss: 2.5134 - val_accuracy: 0.3540\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.8651 - accuracy: 0.4962 - val_loss: 2.9593 - val_accuracy: 0.3375\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.3619 - accuracy: 0.4992 - val_loss: 3.4348 - val_accuracy: 0.3285\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.6408 - accuracy: 0.4991 - val_loss: 3.6076 - val_accuracy: 0.2695\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.1341 - accuracy: 0.4837 - val_loss: 2.5845 - val_accuracy: 0.2985\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 2.0824 - accuracy: 0.4582 - val_loss: 2.8762 - val_accuracy: 0.3440\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.3338 - accuracy: 0.4412 - val_loss: 2.2996 - val_accuracy: 0.3080\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.1175 - accuracy: 0.4336 - val_loss: 2.0953 - val_accuracy: 0.3890\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.7679 - accuracy: 0.3471 - val_loss: 5.7417 - val_accuracy: 0.1790\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.6686 - accuracy: 0.2513 - val_loss: 2.4137 - val_accuracy: 0.2420\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 4.1268 - accuracy: 0.1565 - val_loss: 3.0592 - val_accuracy: 0.0455\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.3515 - accuracy: 0.0584 - val_loss: 3.0374 - val_accuracy: 0.0455\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 3.1581 - accuracy: 0.0506 - val_loss: 3.0216 - val_accuracy: 0.0455\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 3.1581289768218994\n",
      "Training Accuracy: 0.050589337944984436\n",
      "Validation Loss: 3.0215866565704346\n",
      "Validation Accuracy: 0.045499999076128006\n",
      "Classification Error Rate: 0.954500000923872\n",
      "----->Evolution: Child net_12 with fitness 3.0215866565704346 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_7 and net_8 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47d9b6eac0>, <__main__.Block object at 0x7d47da20a700>, <__main__.Block object at 0x7d47d9cb8c00>, <__main__.Block object at 0x7d47d9b05980>, <__main__.Block object at 0x7d47d9a4b0c0>, <__main__.Block object at 0x7d47cb708940>, <__main__.Block object at 0x7d47d9d01b80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1256. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1257. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:38:49.211361: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_139/dropout_156/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 9ms/step - loss: 2.7824 - accuracy: 0.1191 - val_loss: 3.0828 - val_accuracy: 0.0935\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 3s 8ms/step - loss: 2.4038 - accuracy: 0.2517 - val_loss: 2.4234 - val_accuracy: 0.2455\n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 2.1648 - accuracy: 0.3268 - val_loss: 2.1226 - val_accuracy: 0.3320\n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 3s 9ms/step - loss: 1.9974 - accuracy: 0.3907 - val_loss: 2.2140 - val_accuracy: 0.3610\n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.8300 - accuracy: 0.4480 - val_loss: 1.9913 - val_accuracy: 0.4305\n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.7016 - accuracy: 0.4968 - val_loss: 1.6079 - val_accuracy: 0.5105\n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.5773 - accuracy: 0.5254 - val_loss: 1.8205 - val_accuracy: 0.4975\n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.5094 - accuracy: 0.5585 - val_loss: 1.8751 - val_accuracy: 0.4765\n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.3891 - accuracy: 0.5875 - val_loss: 1.5454 - val_accuracy: 0.5645\n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2907 - accuracy: 0.6198 - val_loss: 1.4300 - val_accuracy: 0.5930\n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.2337 - accuracy: 0.6444 - val_loss: 1.5114 - val_accuracy: 0.5765\n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.1426 - accuracy: 0.6738 - val_loss: 1.7178 - val_accuracy: 0.5665\n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 1.0825 - accuracy: 0.6918 - val_loss: 1.5382 - val_accuracy: 0.5790\n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.9989 - accuracy: 0.7181 - val_loss: 1.6018 - val_accuracy: 0.5855\n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.9379 - accuracy: 0.7360 - val_loss: 1.5943 - val_accuracy: 0.6145\n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8950 - accuracy: 0.7527 - val_loss: 1.5568 - val_accuracy: 0.6340\n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8389 - accuracy: 0.7719 - val_loss: 1.6329 - val_accuracy: 0.6185\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.8110 - accuracy: 0.7839 - val_loss: 1.4733 - val_accuracy: 0.6370\n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7534 - accuracy: 0.7983 - val_loss: 1.6090 - val_accuracy: 0.6280\n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7113 - accuracy: 0.8085 - val_loss: 1.8530 - val_accuracy: 0.6395\n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.7036 - accuracy: 0.8184 - val_loss: 1.8876 - val_accuracy: 0.6310\n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6722 - accuracy: 0.8270 - val_loss: 1.6427 - val_accuracy: 0.6625\n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6183 - accuracy: 0.8382 - val_loss: 1.7481 - val_accuracy: 0.6490\n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.6294 - accuracy: 0.8433 - val_loss: 1.8107 - val_accuracy: 0.6555\n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5661 - accuracy: 0.8541 - val_loss: 1.9067 - val_accuracy: 0.6655\n",
      "Epoch 26/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5635 - accuracy: 0.8630 - val_loss: 2.0314 - val_accuracy: 0.6415\n",
      "Epoch 27/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5650 - accuracy: 0.8615 - val_loss: 1.8512 - val_accuracy: 0.6505\n",
      "Epoch 28/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5534 - accuracy: 0.8727 - val_loss: 2.2729 - val_accuracy: 0.6485\n",
      "Epoch 29/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5516 - accuracy: 0.8675 - val_loss: 2.1215 - val_accuracy: 0.6205\n",
      "Epoch 30/30\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 0.5353 - accuracy: 0.8727 - val_loss: 2.0124 - val_accuracy: 0.6430\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 0.5353034734725952\n",
      "Training Accuracy: 0.8727443218231201\n",
      "Validation Loss: 2.0124340057373047\n",
      "Validation Accuracy: 0.6430000066757202\n",
      "Classification Error Rate: 0.3569999933242798\n",
      "----->Evolution: Child net_13 with fitness 2.0124340057373047 is discarded\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "Final Population\n",
      "-------------------------------------\n",
      "\n",
      "net_7 :  1.4736344814300537\n",
      "net_8 :  1.6141917705535889\n",
      "net_1 :  1.7257758378982544\n",
      "net_3 :  1.7618521451950073\n",
      "net_9 :  1.7713475227355957\n",
      "net_4 :  1.8609609603881836\n",
      "net_5 :  1.9358001947402954\n",
      "net_6 :  1.9361917972564697\n",
      "parent_0 :  1.9475840330123901\n",
      "net_2 :  1.9652397632598877\n",
      "\n",
      "-------------------------------------\n",
      "Stats\n",
      "Best individual at generation 1 has fitness 2.1554460525512695 and parameters 1435284\n",
      "Best individual at generation 2 has fitness 1.4736344814300537 and parameters 1017108\n",
      "-------------------------------------\n",
      "\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7d47d91fea80>, <__main__.Block object at 0x7d47d8e5cf00>, <__main__.Block object at 0x7d47d8f80c40>, <__main__.Block object at 0x7d47d8e55980>, <__main__.Block object at 0x7d47d8e5a180>, <__main__.Block object at 0x7d47d903f780>, <__main__.Block object at 0x7d47d922e740>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1264. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_1268. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 11:40:13.416164: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_140/dropout_158/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 9ms/step - loss: 2.7997 - accuracy: 0.1270 - val_loss: 2.7147 - val_accuracy: 0.1443\n",
      "Epoch 2/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.4126 - accuracy: 0.2476 - val_loss: 2.4330 - val_accuracy: 0.2240\n",
      "Epoch 3/20\n",
      "300/300 [==============================] - 2s 8ms/step - loss: 2.2166 - accuracy: 0.3128 - val_loss: 1.9100 - val_accuracy: 0.3984\n",
      "Epoch 4/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 2.0130 - accuracy: 0.3860 - val_loss: 2.3162 - val_accuracy: 0.3500\n",
      "Epoch 5/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.8743 - accuracy: 0.4321 - val_loss: 1.8099 - val_accuracy: 0.4664\n",
      "Epoch 6/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.7351 - accuracy: 0.4814 - val_loss: 1.6725 - val_accuracy: 0.5186\n",
      "Epoch 7/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.6219 - accuracy: 0.5191 - val_loss: 1.5218 - val_accuracy: 0.5532\n",
      "Epoch 8/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.5582 - accuracy: 0.5481 - val_loss: 1.8889 - val_accuracy: 0.4781\n",
      "Epoch 9/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.4692 - accuracy: 0.5704 - val_loss: 1.9152 - val_accuracy: 0.5131\n",
      "Epoch 10/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3895 - accuracy: 0.5952 - val_loss: 1.6030 - val_accuracy: 0.5411\n",
      "Epoch 11/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.3152 - accuracy: 0.6204 - val_loss: 1.3989 - val_accuracy: 0.5895\n",
      "Epoch 12/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2691 - accuracy: 0.6396 - val_loss: 1.4525 - val_accuracy: 0.6028\n",
      "Epoch 13/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.2108 - accuracy: 0.6590 - val_loss: 1.3307 - val_accuracy: 0.6283\n",
      "Epoch 14/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1575 - accuracy: 0.6749 - val_loss: 1.3080 - val_accuracy: 0.6395\n",
      "Epoch 15/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.1065 - accuracy: 0.6931 - val_loss: 1.3386 - val_accuracy: 0.6562\n",
      "Epoch 16/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0825 - accuracy: 0.6992 - val_loss: 1.3929 - val_accuracy: 0.6508\n",
      "Epoch 17/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0534 - accuracy: 0.7114 - val_loss: 1.6748 - val_accuracy: 0.5949\n",
      "Epoch 18/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 1.0189 - accuracy: 0.7254 - val_loss: 1.4353 - val_accuracy: 0.6512\n",
      "Epoch 19/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9712 - accuracy: 0.7355 - val_loss: 1.4600 - val_accuracy: 0.6400\n",
      "Epoch 20/20\n",
      "300/300 [==============================] - 2s 7ms/step - loss: 0.9248 - accuracy: 0.7482 - val_loss: 1.3486 - val_accuracy: 0.6583\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "The Final CNN has been evolved successfully in the individual net_7\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "Summary of initial CNN\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 16, 16, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 2, 2, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 2, 2, 512)         1180160   \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 1, 1, 512)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4771220 (18.20 MB)\n",
      "Trainable params: 4771220 (18.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fitness of initial CNN: 8.12821102142334\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "Summary of evolved individual\n",
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1260 (Conv2D)        (None, 30, 30, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_1261 (Conv2D)        (None, 30, 30, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_322 (MaxPool  (None, 15, 15, 64)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " max_pooling2d_323 (MaxPool  (None, 7, 7, 64)          0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_1262 (Conv2D)        (None, 7, 7, 256)         147712    \n",
      "                                                                 \n",
      " average_pooling2d_365 (Ave  (None, 3, 3, 256)         0         \n",
      " ragePooling2D)                                                  \n",
      "                                                                 \n",
      " conv2d_1263 (Conv2D)        (None, 1, 1, 128)         295040    \n",
      "                                                                 \n",
      " dropout_158 (Dropout)       (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " conv2d_1265 (Conv2D)        (None, 1, 1, 64)          73792     \n",
      "                                                                 \n",
      " average_pooling2d_366 (Ave  (None, 1, 1, 64)          0         \n",
      " ragePooling2D)                                                  \n",
      "                                                                 \n",
      " conv2d_1266 (Conv2D)        (None, 1, 1, 256)         147712    \n",
      "                                                                 \n",
      " conv2d_1267 (Conv2D)        (None, 1, 1, 128)         295040    \n",
      "                                                                 \n",
      " average_pooling2d_367 (Ave  (None, 1, 1, 128)         0         \n",
      " ragePooling2D)                                                  \n",
      "                                                                 \n",
      " dropout_159 (Dropout)       (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " flatten_184 (Flatten)       (None, 128)               0         \n",
      "                                                                 \n",
      " flatten_185 (Flatten)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_184 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 20)                2580      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1017108 (3.88 MB)\n",
      "Trainable params: 1017108 (3.88 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fitness of the evolved individual: 1.3485597372055054\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from random import sample\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)      # suppress messages from Tensorflow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "def initialize_population(population_size, dataset):\n",
    "    print(\"----->Initializing Population\")\n",
    "    daddy = compute_parent(dataset)                                 # load parent from input\n",
    "    population = [daddy]\n",
    "    for it in range(1, population_size):\n",
    "        population.append(daddy.asexual_reproduction(it, dataset))\n",
    "\n",
    "    # sort population on ascending order based on fitness\n",
    "    return sorted(population, key=lambda cnn: cnn.fitness)\n",
    "\n",
    "\n",
    "def selection(k, population, num_population):\n",
    "    if k == 0:                                              # elitism selection\n",
    "        print(\"----->Elitism selection\")\n",
    "        return population[0], population[1]\n",
    "    elif k == 1:                                            # tournament selection\n",
    "        print(\"----->Tournament selection\")\n",
    "        i = randint(0, num_population - 1)\n",
    "        j = i\n",
    "        while j < num_population - 1:\n",
    "            j += 1\n",
    "            if randint(1, 100) <= 50:\n",
    "                return population[i], population[j]\n",
    "        return population[i], population[0]\n",
    "    else:                                                   # proportionate selection\n",
    "        print(\"----->Proportionate selection\")\n",
    "        cum_sum = 0\n",
    "        for i in range(num_population):\n",
    "            cum_sum += population[i].fitness\n",
    "        perc_range = []\n",
    "        for i in range(num_population):\n",
    "            count = 100 - int(100 * population[i].fitness / cum_sum)\n",
    "            for j in range(count):\n",
    "                perc_range.append(i)\n",
    "        i, j = sample(range(1, len(perc_range)), 2)\n",
    "        while i == j:\n",
    "            i, j = sample(range(1, len(perc_range)), 2)\n",
    "        return population[perc_range[i]], population[perc_range[j]]\n",
    "\n",
    "\n",
    "def crossover(parent1, parent2, it):\n",
    "    print(\"----->Crossover\")\n",
    "    child = Network(it)\n",
    "\n",
    "    first, second = None, None\n",
    "    if randint(0, 1):\n",
    "        first = parent1\n",
    "        second = parent2\n",
    "    else:\n",
    "        first = parent2\n",
    "        second = parent1\n",
    "\n",
    "    child.block_list = deepcopy(first.block_list[:randint(1, len(first.block_list) - 1)]) \\\n",
    "                       + deepcopy(second.block_list[randint(1, len(second.block_list) - 1):])\n",
    "\n",
    "    order_indexes(child)                            # order the indexes of the blocks\n",
    "\n",
    "    return child\n",
    "\n",
    "\n",
    "def genetic_algorithm(num_population, num_generation, num_offspring, dataset, early_stopping_generations=3):\n",
    "    print(\"Genetic Algorithm\")\n",
    "\n",
    "    population = initialize_population(num_population, dataset)\n",
    "\n",
    "    print(\"\\n-------------------------------------\")\n",
    "    print(\"Initial Population:\")\n",
    "    for cnn in population:\n",
    "        print(cnn.name, ': ', cnn.fitness)\n",
    "    print(\"--------------------------------------\\n\")\n",
    "\n",
    "    # for printing statistics about fitness and the number of parameters of the best individual\n",
    "    stats = [(population[0].fitness, population[0].model.count_params())]\n",
    "\n",
    "    # Initialize a variable to keep track of consecutive generations with the same best fitness\n",
    "    consecutive_same_fitness = 0\n",
    "\n",
    "    for gen in range(1, num_generation + 1):\n",
    "        '''\n",
    "            k is the selection parameter:\n",
    "                k = 0 -> elitism selection\n",
    "                k = 1 -> tournament selection\n",
    "                k = 2 -> proportionate selection\n",
    "        '''\n",
    "        k = randint(0, 2)\n",
    "\n",
    "        print(\"\\n------------------------------------\")\n",
    "        print(\"Generation -----------------------------------------------------------------------------------\", gen)\n",
    "        print(\"-------------------------------------\")\n",
    "\n",
    "        for c in range(num_offspring):\n",
    "\n",
    "            print(\"\\nCreating Child\", c)\n",
    "\n",
    "            parent1, parent2 = selection(k, population, num_population)                 # selection\n",
    "            print(\"Selected\", parent1.name, \"and\", parent2.name, \"for reproduction\")\n",
    "\n",
    "            child = crossover(parent1, parent2, c + num_population)                     # crossover\n",
    "            print(\"Child has been created\")\n",
    "\n",
    "            print(\"----->Soft Mutation\")\n",
    "            child.layer_mutation(dataset)                                               # mutation\n",
    "            child.parameters_mutation()\n",
    "            print(\"Child has been mutated\")\n",
    "\n",
    "            model = child.build_model()                                                 # evaluation\n",
    "\n",
    "            while model == -1:\n",
    "                child = crossover(parent1, parent2, c + num_population)\n",
    "                child.block_mutation(dataset)\n",
    "                child.layer_mutation(dataset)\n",
    "                child.parameters_mutation()\n",
    "                model = child.build_model()\n",
    "\n",
    "            child.train_and_evaluate(model, dataset)\n",
    "\n",
    "            if child.fitness < population[-1].fitness:                                  # evolve population\n",
    "                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"replaces parent \", end=\"\")\n",
    "                print(population[-1].name, \"with fitness\", population[-1].fitness)\n",
    "                name = population[-1].name\n",
    "\n",
    "                child.save_network(\"child_model_info.pkl\", \"child_model.h5\")\n",
    "                population[-1].load_network(\"child_model_info.pkl\", \"child_model.h5\")\n",
    "\n",
    "                population[-1].name = name\n",
    "                population = sorted(population, key=lambda net: net.fitness)\n",
    "            else:\n",
    "                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"is discarded\")\n",
    "        \n",
    "        if gen >= 3 and all(population[i].fitness == population[i + 1].fitness for i in range(-3, -1)):\n",
    "            consecutive_same_fitness += 1\n",
    "            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n",
    "        if consecutive_same_fitness >= 3:\n",
    "            print(\"Stopping the algorithm as the best fitness has remained the same for the last 3 generations.\")\n",
    "            break\n",
    "    else:\n",
    "        consecutive_same_fitness = 0\n",
    "        \n",
    "       #Check if the best fitness has remained the same for the last early_stopping_generations generations\n",
    "        if all(population[i].fitness == population[i + 1].fitness for i in range(-early_stopping_generations, -1)):\n",
    "            consecutive_same_fitness += 1\n",
    "            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n",
    "            if consecutive_same_fitness == early_stopping_generations:\n",
    "                print(f\"Stopping the algorithm as the best fitness has remained the same for {early_stopping_generations} generations.\")\n",
    "        else:\n",
    "            consecutive_same_fitness = 0\n",
    "        stats.append((population[0].fitness, population[0].model.count_params()))\n",
    "\n",
    "    print(\"\\n\\n-------------------------------------\")\n",
    "    print(\"Final Population\")\n",
    "    print(\"-------------------------------------\\n\")\n",
    "    for cnn in population:\n",
    "        print(cnn.name, ': ', cnn.fitness)\n",
    "\n",
    "    print(\"\\n-------------------------------------\")\n",
    "    print(\"Stats\")\n",
    "    for i in range(len(stats)):\n",
    "        print(\"Best individual at generation\", i + 1, \"has fitness\", stats[i][0], \"and parameters\", stats[i][1])\n",
    "    print(\"-------------------------------------\\n\")\n",
    "\n",
    "    # plot the fitness and the number of parameters of the best individual at each iteration\n",
    "    plot_statistics(stats)\n",
    "\n",
    "    return population[0]\n",
    "\n",
    "import os\n",
    "import cv2  # OpenCV\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def main():    \n",
    "        #with strategy.scope():\n",
    "        #from tensorflow.python.client import device_lib\n",
    "        #print(device_lib.list_local_devices())\n",
    "        #batch_size = 8\n",
    "        #batch_size = batch_size * strategy.num_replicas_in_sync\n",
    "        batch_size = 32                       # the number of training examples in one forward/backward pass\n",
    "        num_classes = 20                       # number of cifar-10 dataset classes\n",
    "        epochs = 30             # number of forward and backward passes of all the training examples\n",
    "        image_size = (32,32) # Adjust this according to your image size\n",
    "        data_dir = '/kaggle/input/cifar-100-20classes'\n",
    "        '''\n",
    "            dataset contains the hyper parameters for loading data and the dataset:\n",
    "                dataset = {\n",
    "                    'batch_size': batch_size,\n",
    "                    'num_classes': num_classes,\n",
    "                    'epochs': epochs,\n",
    "                    'x_train': x_train,\n",
    "                    'x_test': x_test,\n",
    "                    'y_train': y_train,\n",
    "                    'y_test': y_test\n",
    "                }\n",
    "        '''\n",
    "        #dataset = load_dataset(batch_size, num_classes, epochs)\n",
    "        dataset=load_dataset(batch_size, num_classes, epochs, image_size, data_dir)\n",
    "        num_population = 10\n",
    "        num_generation = 20\n",
    "        num_offspring = 4\n",
    "\n",
    "        # plot the best model obtained\n",
    "        optCNN = genetic_algorithm(num_population, num_generation, num_offspring, dataset)\n",
    "\n",
    "        # plot the training and validation loss and accuracy\n",
    "        num_epoch = 20\n",
    "        model = optCNN.build_model()\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        history = model.fit(dataset['x_train'],\n",
    "                            dataset['y_train'],\n",
    "                            batch_size=dataset['batch_size'],\n",
    "                            epochs=num_epoch,\n",
    "                            validation_data=(dataset['x_test'], dataset['y_test']),\n",
    "                            shuffle=True)\n",
    "        optCNN.model = model                                        # model\n",
    "        optCNN.fitness = history.history['val_loss'][-1]            # fitness\n",
    "\n",
    "        print(\"\\n\\n-------------------------------------\")\n",
    "        print(\"The Final CNN has been evolved successfully in the individual\", optCNN.name)\n",
    "        print(\"-------------------------------------\\n\")\n",
    "        daddy = load_network('parent_0')\n",
    "        model = tf.keras.models.load_model('parent_0.h5')\n",
    "        print(\"\\n\\n-------------------------------------\")\n",
    "        print(\"Summary of initial CNN\")\n",
    "        print(model.summary())\n",
    "        print(\"Fitness of initial CNN:\", daddy.fitness)\n",
    "\n",
    "        print(\"\\n\\n-------------------------------------\")\n",
    "        print(\"Summary of evolved individual\")\n",
    "        print(optCNN.model.summary())\n",
    "        print(\"Fitness of the evolved individual:\", optCNN.fitness)\n",
    "        print(\"-------------------------------------\\n\")\n",
    "\n",
    "        plot_training(history)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e000ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:08:29.134232Z",
     "iopub.status.busy": "2024-04-03T04:08:29.133846Z",
     "iopub.status.idle": "2024-04-03T04:08:29.176237Z",
     "shell.execute_reply": "2024-04-03T04:08:29.174886Z",
     "shell.execute_reply.started": "2024-04-03T04:08:29.134195Z"
    },
    "papermill": {
     "duration": 10.121474,
     "end_time": "2024-04-08T11:41:19.098515",
     "exception": false,
     "start_time": "2024-04-08T11:41:08.977041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## To remove a folder\n",
    "# Clear output folder\n",
    "import os\n",
    "\n",
    "def remove_folder_contents(folder):\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                remove_folder_contents(file_path)\n",
    "                os.rmdir(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "folder_path = '/kaggle/working'\n",
    "remove_folder_contents(folder_path)\n",
    "os.rmdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e6e3a",
   "metadata": {
    "papermill": {
     "duration": 9.882021,
     "end_time": "2024-04-08T11:41:38.811941",
     "exception": false,
     "start_time": "2024-04-08T11:41:28.929920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b5e22",
   "metadata": {
    "papermill": {
     "duration": 9.972247,
     "end_time": "2024-04-08T11:41:58.372582",
     "exception": false,
     "start_time": "2024-04-08T11:41:48.400335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8176720,
     "datasetId": 4755549,
     "sourceId": 8061761,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30637,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7472.002865,
   "end_time": "2024-04-08T11:42:11.582961",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-08T09:37:39.580096",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
