{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86773675",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T03:01:04.683531Z",
     "iopub.status.busy": "2024-02-16T03:01:04.683141Z",
     "iopub.status.idle": "2024-02-16T03:01:16.379082Z",
     "shell.execute_reply": "2024-02-16T03:01:16.378104Z"
    },
    "papermill": {
     "duration": 11.704121,
     "end_time": "2024-02-16T03:01:16.381331",
     "exception": false,
     "start_time": "2024-02-16T03:01:04.677210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "### UTILITIES\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def load_dataset(batch_size, num_classes, epochs):\n",
    "    (x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    # Select a random subset of 4500 images for training\n",
    "    random_indices = np.random.choice(len(x_train_full), size=4500, replace=False)\n",
    "    x_train = x_train_full[random_indices]\n",
    "    y_train = y_train_full[random_indices]\n",
    "\n",
    "    # Normalize and one-hot encode the labels\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "    y_train = to_categorical(y_train, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "    # Randomly select 500 images for validation\n",
    "    random_indices = np.random.choice(len(x_test), size=500, replace=False)\n",
    "    x_val = x_test[random_indices]\n",
    "    y_val = y_test[random_indices]\n",
    "\n",
    "    dataset = {\n",
    "        'batch_size': batch_size,\n",
    "        'num_classes': num_classes,\n",
    "        'epochs': epochs,\n",
    "        'x_train': x_train,\n",
    "        'y_train': y_train,\n",
    "        'x_val': x_val,\n",
    "        'y_val': y_val,\n",
    "        'x_test': x_test,  \n",
    "        'y_test': y_test\n",
    "    }\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def save_network(network):\n",
    "    #object_file = open(network.name + '.obj', 'wb')\n",
    "    #pickle.dump(network, object_file)\n",
    "    #tf.keras.models.save_model(network, network.name)\n",
    "\n",
    "    model_path = network.name + '_model.h5'\n",
    "    tf.keras.models.save_model(network.model, model_path)\n",
    "\n",
    "    # Save the rest of the network information\n",
    "    network_info = {\n",
    "        'name': network.name,\n",
    "        'block_list': network.block_list,\n",
    "        'fitness': network.fitness\n",
    "    }\n",
    "    network_info_path = network.name + '_info.pkl'\n",
    "    with open(network_info_path, 'wb') as info_file:\n",
    "        pickle.dump(network_info, info_file)\n",
    "\n",
    "\n",
    "def load_network(name):\n",
    "    model_path = name + '_model.h5'\n",
    "    loaded_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # Load the network information\n",
    "    info_path = name + '_info.pkl'\n",
    "    with open(info_path, 'rb') as info_file:\n",
    "        network_info = pickle.load(info_file)\n",
    "\n",
    "    # Create a new Network instance\n",
    "    loaded_network = Network(0)  # Update with appropriate 'it' value\n",
    "\n",
    "    # Set the attributes of the loaded network\n",
    "    loaded_network.name = network_info['name']\n",
    "    loaded_network.block_list = network_info['block_list']\n",
    "    loaded_network.fitness = network_info['fitness']\n",
    "    loaded_network.model = loaded_model\n",
    "\n",
    "    return loaded_network\n",
    "\n",
    "\n",
    "\n",
    "def order_indexes(self):\n",
    "    i = 0\n",
    "    for block in self.block_list:\n",
    "        block.index = i\n",
    "        i += 1\n",
    "\n",
    "\n",
    "def plot_training(history):                                           # plot diagnostic learning curves\n",
    "    plt.figure(figsize=[8, 6])  # accuracy curves\n",
    "    plt.plot(history.history['accuracy'], 'r', linewidth=3.0)\n",
    "    plt.plot(history.history['val_accuracy'], 'b', linewidth=3.0)  # <-- Change 'val_acc' to 'val_accuracy'\n",
    "    plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n",
    "    plt.xlabel('Epochs ', fontsize=16)\n",
    "    plt.ylabel('Accuracy', fontsize=16)\n",
    "    plt.title('Accuracy Curves', fontsize=16)\n",
    "\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_acc_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def plot_statistics(stats):\n",
    "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# fitness curves\n",
    "    plt.plot([s[0] for s in stats], 'r', linewidth=3.0)\n",
    "    plt.plot([stats[0][0]] * len(stats), 'b', linewidth=3.0)\n",
    "    plt.legend(['BestFitness', 'InitialFitness'], fontsize=18)\n",
    "    plt.xlabel('Generations', fontsize=16)\n",
    "    plt.ylabel('FitnessValue', fontsize=16)\n",
    "    plt.title('Fitness Curve', fontsize=16)\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_fitness_plot.png')\n",
    "\n",
    "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# parameters curves\n",
    "    plt.plot([s[1] for s in stats], 'r', linewidth=3.0)\n",
    "    plt.plot([stats[0][1]] * len(stats), 'b', linewidth=3.0)\n",
    "    plt.legend(['BestParamsNum', 'InitialParamsNum'], fontsize=18)\n",
    "    plt.xlabel('Generations', fontsize=16)\n",
    "    plt.ylabel('ParamsNum', fontsize=16)\n",
    "    plt.title('Parameters Curve', fontsize=16)\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_params_plot.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c6a566a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T03:01:16.391335Z",
     "iopub.status.busy": "2024-02-16T03:01:16.390827Z",
     "iopub.status.idle": "2024-02-16T03:01:16.404599Z",
     "shell.execute_reply": "2024-02-16T03:01:16.403727Z"
    },
    "papermill": {
     "duration": 0.020824,
     "end_time": "2024-02-16T03:01:16.406534",
     "exception": false,
     "start_time": "2024-02-16T03:01:16.385710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INOUT\n",
    "import os\n",
    "def compute_parent(dataset):\n",
    "    if os.path.isfile('parent_0.h5'):\n",
    "        daddy = load_network('parent_0')\n",
    "        model = tf.keras.models.load_model('parent_0.h5')\n",
    "        print(\"Loading parent_0\")\n",
    "        print(\"SUMMARY OF\", daddy.name)\n",
    "        print(model.summary())\n",
    "        print(\"FITNESS:\", daddy.fitness)\n",
    "        return daddy\n",
    "\n",
    "    daddy = Network(0)\n",
    "    \n",
    "    \n",
    "    #INI BLOCK\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=32, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "        Convolutional(filters=32, filter_size=(3, 3), stride_size=(1, 1), padding='valid',\n",
    "                      input_shape=dataset['x_train'].shape[1:])\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(0, 0, layerList1, layerList2))\n",
    "    \n",
    "    \n",
    "    #MID BLOCK\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='valid',\n",
    "                      input_shape=dataset['x_train'].shape[1:])\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(1, 1, layerList1, layerList2))\n",
    "    \n",
    "    \n",
    "    #FINAL BLOCK\n",
    "    \n",
    "    layerList1 = [\n",
    "        FullyConnected(units=128, num_classes=dataset['num_classes'])\n",
    "    ]\n",
    "    layerList2 = []\n",
    "    daddy.block_list.append(Block(2, 2, layerList1, layerList2))\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #MIDDLE BLOCK 1\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(1, 1, layerList1, layerList2))\n",
    "\n",
    "     #MIDDLE BLOCK 2\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:])\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(1, 2, layerList1, layerList2))\n",
    "\n",
    "    \n",
    "    #MIDDLE BLOCK 3\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=256, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "        Convolutional(filters=256, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:])\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(1, 3, layerList1, layerList2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #MIDDLE BLOCK 4\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=512, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "        Convolutional(filters=512, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:])\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(1, 4, layerList1, layerList2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #FULLY CONNECTED LAYER\n",
    "    layerList1 = [\n",
    "        FlattenLayer(),\n",
    "        FullyConnected(units=128, num_classes=dataset['num_classes'])\n",
    "    ]\n",
    "    layerList2 = []\n",
    "    daddy.block_list.append(Block(2, 5, layerList1, layerList2))\"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    model = daddy.build_model()\n",
    "    print(\"Type of model_final:\", type(model))\n",
    "    daddy.train_and_evaluate(model, dataset)\n",
    "    return daddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa20cd4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T03:01:16.415718Z",
     "iopub.status.busy": "2024-02-16T03:01:16.415411Z",
     "iopub.status.idle": "2024-02-16T03:01:16.465187Z",
     "shell.execute_reply": "2024-02-16T03:01:16.464349Z"
    },
    "papermill": {
     "duration": 0.056749,
     "end_time": "2024-02-16T03:01:16.467147",
     "exception": false,
     "start_time": "2024-02-16T03:01:16.410398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NETWORK\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Sequential\n",
    "from random import randint, choice\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class Network:\n",
    "    __slots__ = ('name', 'block_list', 'fitness', 'model')\n",
    "\n",
    "    def __init__(self, it):\n",
    "        self.name = 'parent_' + str(it) if it == 0 else 'net_' + str(it)\n",
    "        self.block_list = []\n",
    "        self.fitness = None\n",
    "        self.model = None\n",
    "\n",
    "    \"\"\"def build_model(self):\n",
    "        model = Sequential()                                # create model\n",
    "        for block in self.block_list:\n",
    "            for layer in block.get_layers():                # build model\n",
    "                try:\n",
    "                    layer.build_layer(model)\n",
    "                except:\n",
    "                    print(\"\\nINDIVIDUAL ABORTED, CREATING A NEW ONE\\n\")\n",
    "                    return -1\n",
    "        return model\"\"\"\n",
    "    def build_model(self):\n",
    "        model = Sequential()              \n",
    "        print(\"The block is:\")\n",
    "        print(self.block_list)                 # create model\n",
    "        for block in self.block_list:\n",
    "            #print(\"Building block type:\", block.type)\n",
    "            #print(\"TOTAL :::\")\n",
    "            #print(block.get_layer_name())\n",
    "            for layer in block.get_layers():                # build model\n",
    "                #print(\"Adding layer:\", layer.name)\n",
    "                try:\n",
    "                    layer.build_layer(model)\n",
    "                    print(\"Layer added successfully.\")\n",
    "                except Exception as e:\n",
    "                    print(\"Error occurred while adding layer:\", e)\n",
    "                    print(\"Returning None.\")\n",
    "                    return -1\n",
    "        print(\"Model successfully built.\")\n",
    "        return model\n",
    "\n",
    "    def train_and_evaluate(self, model, dataset):\n",
    "        print(\"Training\", self.name)\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(dataset['x_train'],\n",
    "                            dataset['y_train'],\n",
    "                            batch_size=dataset['batch_size'],\n",
    "                            epochs=dataset['epochs'],\n",
    "                            validation_data=(dataset['x_val'], dataset['y_val']),\n",
    "                            shuffle=True)\n",
    "\n",
    "        # Extract metrics from the training history\n",
    "        training_loss = history.history['loss'][-1]\n",
    "        training_accuracy = history.history['accuracy'][-1]\n",
    "        validation_loss = history.history['val_loss'][-1]\n",
    "        validation_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "        # Additional metrics (you can customize this based on your needs)\n",
    "        classification_error_rate = 1.0 - validation_accuracy\n",
    "\n",
    "        self.model = model  # Save the model\n",
    "        self.fitness = validation_loss  # Use validation loss as fitness\n",
    "\n",
    "        # Print metrics\n",
    "        print(\"SUMMARY OF\", self.name)\n",
    "        print(\"Training Loss:\", training_loss)\n",
    "        print(\"Training Accuracy:\", training_accuracy)\n",
    "        print(\"Validation Loss:\", validation_loss)\n",
    "        print(\"Validation Accuracy:\", validation_accuracy)\n",
    "        print(\"Classification Error Rate:\", classification_error_rate)\n",
    "\n",
    "        tf.keras.models.save_model(model, self.name + '.h5')         # save model\n",
    "        #model.save(self.name + '.h5')                       # save model\n",
    "        save_network(self)                                  # save topology, model and fitness\n",
    "\n",
    "    def asexual_reproduction(self, it, dataset):\n",
    "\n",
    "        # if the individual already exists, just load it\n",
    "        if os.path.isfile('net_' + str(it) + '.h5'):\n",
    "            print(\"\\n-------------------------------------\")\n",
    "            print(\"Loading individual net_\" + str(it))\n",
    "            print(\"--------------------------------------\\n\")\n",
    "            individual = load_network('net_' + str(it))\n",
    "            model = tf.keras.models.load_model(individual.name + '.h5')\n",
    "            print(\"SUMMARY OF\", individual.name)\n",
    "            print(model.summary())\n",
    "            print(\"FITNESS: \", individual.fitness)\n",
    "            return individual\n",
    "\n",
    "        # otherwise, create the individual by mutating the parent\n",
    "        individual = Network(it)\n",
    "\n",
    "        print(\"\\n-------------------------------------\")\n",
    "        print(\"\\nCreating individual\", individual.name)\n",
    "        print(\"--------------------------------------\\n\")\n",
    "\n",
    "        individual.block_list = deepcopy(self.block_list)           # copy the layer list from parent\n",
    "\n",
    "        print(\"----->Strong Mutation\")\n",
    "        individual.block_mutation(dataset)                          # mutate a block\n",
    "        individual.layer_mutation(dataset)                          # mutate a layer\n",
    "        individual.parameters_mutation()                            # mutate some parameters\n",
    "\n",
    "        model = individual.build_model()\n",
    "        \n",
    "        if model == -1:\n",
    "            return self.asexual_reproduction(it, dataset)\n",
    "\n",
    "        individual.train_and_evaluate(model, dataset)\n",
    "\n",
    "        return individual\n",
    "\n",
    "    def block_mutation(self, dataset):\n",
    "        try:\n",
    "            print(\"Block Mutation\")\n",
    "\n",
    "            print([(block.index, block.type) for block in self.block_list])\n",
    "\n",
    "            # block list containing all the blocks with type = 1\n",
    "            bl = [block.index for block in self.block_list if block.type == 1]\n",
    "\n",
    "            if len(bl) == 0:\n",
    "                print(\"Creating a new block with two Convolutional layers and a Pooling layer\")\n",
    "                self.block_list[1].index = 2\n",
    "                layerList1 = [\n",
    "                    Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                  filter_size=(3, 3),\n",
    "                                  stride_size=(1, 1),\n",
    "                                  padding='same',\n",
    "                                  input_shape=dataset['x_train'].shape[1:]),\n",
    "                    Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                  filter_size=(3, 3),\n",
    "                                  stride_size=(1, 1),\n",
    "                                  padding='same',\n",
    "                                  input_shape=dataset['x_train'].shape[1:])\n",
    "                ]\n",
    "                layerList2 = [\n",
    "                    Pooling(pool_size=(2, 2),\n",
    "                            stride_size=(2, 2),\n",
    "                            padding='same')\n",
    "                ]\n",
    "                b = Block(1, 1, layerList1, layerList2)\n",
    "                self.block_list.insert(1, b)\n",
    "                return\n",
    "\n",
    "            block_idx = randint(1, max(bl))         # pick a random block among all the blocks with type = 1\n",
    "            block_type_idx = randint(0, 1)          # 1 -> Conv2D; 0 -> Pooling or Dropout\n",
    "            mutation_type = randint(0, 1)           # 1 -> remove; 0 -> add\n",
    "\n",
    "            # list of layers of the selected block\n",
    "            layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
    "            length = len(layerList)\n",
    "\n",
    "            if mutation_type:                                       # remove\n",
    "                if length == 1:\n",
    "                    del self.block_list[block_idx]\n",
    "                elif block_type_idx:\n",
    "                    pos = randint(0, length - 1)\n",
    "                    print(\"Removing a Conv2D layer at\", pos)\n",
    "                    del layerList[pos]\n",
    "                else:\n",
    "                    pos = randint(0, length - 1)\n",
    "                    print(\"Removing a Pooling/Dropout layer at\", pos)\n",
    "                    del layerList[pos]\n",
    "            else:                                                   # add\n",
    "                if block_type_idx:\n",
    "                    print(\"Inserting a Convolutional layer\")\n",
    "                    layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                          filter_size=(3, 3),\n",
    "                                          stride_size=(1, 1),\n",
    "                                          padding='same',\n",
    "                                          input_shape=dataset['x_train'].shape[1:])\n",
    "                    layerList.insert(randint(0, length - 1), layer)\n",
    "                else:\n",
    "                    if randint(0, 1):                               # 1 -> Pooling; 0 -> Dropout\n",
    "                        print(\"Inserting a Pooling layer\")\n",
    "                        layer = Pooling(pool_size=(2, 2),\n",
    "                                        stride_size=(2, 2),\n",
    "                                        padding='same')\n",
    "                        layerList.insert(randint(0, length - 1), layer)\n",
    "                    else:\n",
    "                        print(\"Inserting a Dropout layer\")\n",
    "                        rate = choice([0.15, 0.25, 0.35, 0.50])\n",
    "                        layer = Dropout(rate=rate)\n",
    "                        layerList.insert(randint(0, length - 1), layer)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during block mutation: {e}\")\n",
    "            return None\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "    \"\"\"def layer_mutation(self, dataset):\n",
    "        print(\"Layer Mutation\")\n",
    "\n",
    "        # pick a random block among all the blocks with type = 1\n",
    "        bl = [block.index for block in self.block_list if block.type == 1]\n",
    "\n",
    "        if len(bl) == 0:\n",
    "            return\n",
    "\n",
    "        block_idx = randint(1, max(bl))\n",
    "        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n",
    "\n",
    "        # list of layers of the selected block\n",
    "        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
    "\n",
    "        if len(layerList) == 0:\n",
    "            if block_type_idx:\n",
    "                layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                      filter_size=(3, 3),\n",
    "                                      stride_size=(1, 1),\n",
    "                                      padding='same',\n",
    "                                      input_shape=dataset['x_train'].shape[1:])\n",
    "                self.block_list[block_idx].layerList1.append(layer)\n",
    "                return\n",
    "            else:\n",
    "                layer = Pooling(pool_size=(2, 2),\n",
    "                                stride_size=(2, 2),\n",
    "                                padding='same')\n",
    "                self.block_list[block_idx].layerList2.append(layer)\n",
    "\n",
    "        idx = randint(0, len(layerList) - 1)\n",
    "        layer = layerList[idx]\n",
    "\n",
    "        if layer.name == 'Conv2D':\n",
    "            print(\"Splitting Conv2D layer at index\", idx)\n",
    "            layer.filters = int(layer.filters * 0.5)\n",
    "            layerList.insert(idx, deepcopy(layer))\n",
    "        elif layer.name == 'MaxPooling2D' or layer.name == 'AveragePooling2D':\n",
    "            print(\"Changing Pooling layer at index\", idx, \"with Conv2D layer\")\n",
    "            del layerList[idx]\n",
    "            conv_layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                       filter_size=(3, 3),\n",
    "                                       stride_size=(2, 2),\n",
    "                                       padding=layer.padding,\n",
    "                                       input_shape=dataset['x_train'].shape[1:])\n",
    "            layerList.insert(idx, conv_layer)\"\"\"\n",
    "    \n",
    "    def layer_mutation(self, dataset):\n",
    "        print(\"Layer Mutation\")\n",
    "\n",
    "        # Determine the maximum number of layers that can be added or removed\n",
    "        max_layers_to_add = 16 - sum(len(block.layerList1) + len(block.layerList2) for block in self.block_list)\n",
    "        max_layers_to_remove = sum(len(block.layerList1) + len(block.layerList2) - 1 for block in self.block_list)\n",
    "\n",
    "        if max_layers_to_add == 0 and max_layers_to_remove == 0:\n",
    "            return\n",
    "\n",
    "        # Pick a random block among all the blocks with type = 1\n",
    "        bl = [block.index for block in self.block_list if block.type == 1]\n",
    "\n",
    "        if len(bl) == 0:\n",
    "            return\n",
    "\n",
    "        block_idx = randint(1, max(bl))\n",
    "        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n",
    "\n",
    "        # List of layers of the selected block\n",
    "        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
    "\n",
    "        if len(layerList) == 0:\n",
    "            if block_type_idx:\n",
    "                layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                      filter_size=(3, 3),\n",
    "                                      stride_size=(1, 1),\n",
    "                                      padding='same',\n",
    "                                      input_shape=dataset['x_train'].shape[1:])\n",
    "                self.block_list[block_idx].layerList1.append(layer)\n",
    "            else:\n",
    "                layer = Pooling(pool_size=(2, 2),\n",
    "                                stride_size=(2, 2),\n",
    "                                padding='same')\n",
    "                self.block_list[block_idx].layerList2.append(layer)\n",
    "        else:\n",
    "            # Randomly choose whether to add or remove a layer\n",
    "            add_layer = bool(randint(0, 1))\n",
    "\n",
    "            if add_layer and max_layers_to_add > 0:\n",
    "                # Add a layer\n",
    "                layer = self.create_random_layer(dataset)\n",
    "                layerList.insert(randint(0, len(layerList)), layer)\n",
    "            elif not add_layer and max_layers_to_remove > 0:\n",
    "                # Remove a layer\n",
    "                idx = randint(0, len(layerList) - 1)\n",
    "                del layerList[idx]\n",
    "\n",
    "        # Ensure the total number of layers in the block doesn't exceed 16\n",
    "        if len(self.block_list[block_idx].layerList1) + len(self.block_list[block_idx].layerList2) > 16:\n",
    "            # Remove a random layer to maintain the total count of 16 layers\n",
    "            block_layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
    "            del block_layerList[randint(0, len(block_layerList) - 1)]\n",
    "\n",
    "    def create_random_layer(self, dataset):\n",
    "        # Create a random layer (Conv2D or Pooling)\n",
    "        if randint(0, 1):\n",
    "            # Conv2D layer\n",
    "            return Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                 filter_size=(3, 3),\n",
    "                                 stride_size=(1, 1),\n",
    "                                 padding='same',\n",
    "                                 input_shape=dataset['x_train'].shape[1:])\n",
    "        else:\n",
    "            # Pooling layer\n",
    "            return Pooling(pool_size=(2, 2),\n",
    "                           stride_size=(2, 2),\n",
    "                           padding='same')\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    def parameters_mutation(self):\n",
    "        print(\"Parameters Mutation\")\n",
    "        for block in self.block_list:\n",
    "            for layer in block.get_layers():\n",
    "                if randint(0, 1):\n",
    "                    layer.mutate_parameters()\n",
    "\n",
    "    def save_network_info(self, info_filename):\n",
    "        network_info = {\n",
    "            'name': self.name,\n",
    "            'block_list': self.block_list,\n",
    "            'fitness': self.fitness\n",
    "        }\n",
    "\n",
    "        with open(info_filename, 'wb') as info_file:\n",
    "            pickle.dump(network_info, info_file)\n",
    "\n",
    "    def load_network_info(self, info_filename):\n",
    "        with open(info_filename, 'rb') as info_file:\n",
    "            network_info = pickle.load(info_file)\n",
    "\n",
    "        self.name = network_info['name']\n",
    "        self.block_list = network_info['block_list']\n",
    "        self.fitness = network_info['fitness']\n",
    "\n",
    "    def save_model(self, model_filename):\n",
    "        self.model.save(model_filename)\n",
    "\n",
    "    def load_model(self, model_filename):\n",
    "        self.model = tf.keras.models.load_model(model_filename)\n",
    "\n",
    "    def save_network(self, network_info_filename, model_filename):\n",
    "        # Save non-model attributes\n",
    "        self.save_network_info(network_info_filename)\n",
    "\n",
    "        # Save the model separately\n",
    "        self.save_model(model_filename)\n",
    "\n",
    "    def load_network(self, network_info_filename, model_filename):\n",
    "        # Load non-model attributes\n",
    "        self.load_network_info(network_info_filename)\n",
    "\n",
    "        # Load the model separately\n",
    "        self.load_model(model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20dfe2ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T03:01:16.476110Z",
     "iopub.status.busy": "2024-02-16T03:01:16.475838Z",
     "iopub.status.idle": "2024-02-16T03:01:16.506967Z",
     "shell.execute_reply": "2024-02-16T03:01:16.506146Z"
    },
    "papermill": {
     "duration": 0.037891,
     "end_time": "2024-02-16T03:01:16.508828",
     "exception": false,
     "start_time": "2024-02-16T03:01:16.470937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TOPOLOGY\n",
    "\n",
    "import keras.layers\n",
    "from random import randint\n",
    "\n",
    "\n",
    "class Block:\n",
    "\t__slots__ = ('type', 'index', 'layerList1', 'layerList2')\n",
    "\n",
    "\tdef __init__(self, type, index, layerList1, layerList2):\n",
    "\t\tself.type = type\t\t\t\t\t\t\t\t\t\t# 0 -> initial layer; 1 -> mid layers; 2 -> final layer\n",
    "\t\tself.index = index\t\t\t\t\t\t\t\t\t\t# block index among all the blocks\n",
    "\t\tself.layerList1 = layerList1\t\t\t\t\t\t\t# Convolutional layers\n",
    "\t\tself.layerList2 = layerList2\t\t\t\t\t\t\t# Pooling and Dropout layers\n",
    "\n",
    "\tdef get_layers(self):\n",
    "\t\treturn self.layerList1 + self.layerList2\n",
    "\n",
    "\tdef get_size(self):\n",
    "\t\treturn len(self.get_layers())\n",
    "\n",
    "\n",
    "class Convolutional:\n",
    "\t# __slots__ = ('name', 'filters', 'padding', 'filter_size', 'stride_size', 'input_shape')\n",
    "\n",
    "\tdef __init__(self, filters, padding, filter_size, stride_size, input_shape):\n",
    "\t\tself.name = 'Conv2D'\n",
    "\t\tself.filters = filters\n",
    "\t\tself.padding = padding\n",
    "\t\tself.filter_size = filter_size\n",
    "\t\tself.stride_size = stride_size\n",
    "\t\tself.input_shape = input_shape\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\ttry:\n",
    "\t\t\tmodel.add(keras.layers.Conv2D(filters=self.filters,\n",
    "\t\t\t\t\t\t\t\t\t\t\tkernel_size=self.filter_size,\n",
    "\t\t\t\t\t\t\t\t\t\t\tstrides=self.stride_size,\n",
    "\t\t\t\t\t\t\t\t\t\t\tpadding=self.padding,\n",
    "\t\t\t\t\t\t\t\t\t\t\tactivation='relu',\n",
    "\t\t\t\t\t\t\t\t\t\t\tkernel_initializer='he_uniform',\n",
    "\t\t\t\t\t\t\t\t\t\t\tinput_shape=self.input_shape))\n",
    "\t\texcept ValueError as e:\n",
    "\t\t\tprint(\"Error occurred while adding layer:\", e)\n",
    "\t\t\tprint(\"Skipping current architecture.\")\n",
    "\t\t\treturn  # Skip adding this layer\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tmutation = randint(0, 2)  # Adjusted the number of mutations\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tif mutation == 0 and self.filters >= 64:  # Adjusted the filter reduction threshold\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters = int(self.filters / 2)\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 1 and self.filters <= 256:  # Adjusted the filter increase threshold\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters *= 2\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 2:\n",
    "\t\t\tif self.padding == 'valid':\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'same'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'valid'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\t\"\"\"def mutate_parameters(self):\n",
    "\t\tmutation = randint(0, 4)\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tif mutation == 0 and self.filters >= 32:\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters = int(self.filters / 2)\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 1 and self.filters >= 32:\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters = int(self.filters / 2)\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 2 and self.filters <= 512:\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters *= 2\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 3 and self.filters <= 512:\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters *= 2\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 4:\n",
    "\t\t\tif self.padding == 'valid':\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'same'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'valid'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\"\"\"\n",
    "    \n",
    "\n",
    "'''\n",
    "elif mutation is 4:\n",
    "\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n",
    "\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n",
    "\tprint(\"to \", self.stride_size, \" and \", end=\"\")\n",
    "\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n",
    "\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n",
    "\tprint(\"to \", self.stride_size)\n",
    "'''\n",
    "\n",
    "\n",
    "class Pooling:\n",
    "\t__slots__ = ('name', 'pool_size', 'stride_size', 'padding')\n",
    "\n",
    "\tdef __init__(self, pool_size, stride_size, padding):\n",
    "\t\tself.name = 'MaxPooling2D'\n",
    "\t\tself.pool_size = pool_size\n",
    "\t\tself.stride_size = stride_size\n",
    "\t\tself.padding = padding\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\tif self.name == 'MaxPooling2D':\n",
    "\t\t\tmodel.add(keras.layers.MaxPooling2D(self.pool_size, self.stride_size, self.padding))\n",
    "\t\telif self.name == 'AveragePooling2D':\n",
    "\t\t\tmodel.add(keras.layers.AveragePooling2D(self.pool_size, self.stride_size, self.padding))\n",
    "\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tmutation = randint(0, 1)\n",
    "\t\tif mutation == 0:\n",
    "\t\t\tif self.padding == 'valid':\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'same'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'valid'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\telif mutation == 1:\n",
    "\t\t\tif self.name == 'MaxPooling2D':\n",
    "\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n",
    "\t\t\t\tself.name = 'AveragePooling2D'\n",
    "\t\t\t\tprint(\"to \", self.name)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n",
    "\t\t\t\tself.name = 'MaxPooling2D'\n",
    "\t\t\t\tprint(\"to \", self.name)\n",
    "\n",
    "\n",
    "'''\n",
    "if mutation is 0:\n",
    "\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n",
    "\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n",
    "\tprint(\"to \", self.stride_size)\n",
    "'''\n",
    "\n",
    "\n",
    "class FullyConnected:\n",
    "\t__slots__ = ('name', 'units', 'num_classes')\n",
    "\n",
    "\tdef __init__(self, units, num_classes):\n",
    "\t\tself.name = \"FullyConnected\"\n",
    "\t\tself.units = units\n",
    "\t\tself.num_classes = num_classes\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\tmodel.add(keras.layers.Flatten())\n",
    "\t\tmodel.add(keras.layers.Dense(self.units, activation='relu', kernel_initializer='he_uniform'))\n",
    "\t\tmodel.add(keras.layers.Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tmutation = randint(0, 2)\n",
    "\t\tif mutation == 0:\n",
    "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
    "\t\t\tself.units *= 2\n",
    "\t\t\tprint(\"to \", self.units)\n",
    "\t\telif mutation == 1:\n",
    "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
    "\t\t\tself.units *= 2\n",
    "\t\t\tprint(\"to \", self.units)\n",
    "\t\telif mutation == 2:\n",
    "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
    "\t\t\tself.units /= 2\n",
    "\t\t\tprint(\"to \", self.units)\n",
    "\n",
    "\n",
    "'''\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(self.num_classes, activation='softmax'))\n",
    "'''\n",
    "\n",
    "\n",
    "class Dropout:\n",
    "\t__slots__ = ('name', 'rate')\n",
    "\n",
    "\tdef __init__(self, rate):\n",
    "\t\tself.name = \"Dropout\"\n",
    "\t\tself.rate = rate\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\tmodel.add(keras.layers.Dropout(self.rate))\n",
    "\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tmutation = randint(0, 3)\n",
    "\t\tif mutation == 0 and self.rate <= 0.85:\n",
    "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate + 0.10\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\t\telif mutation == 1 and self.rate <= 0.90:\n",
    "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate + 0.05\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\t\telif mutation == 2 and self.rate >= 0.15:\n",
    "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate - 0.10\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\t\telif mutation == 3 and self.rate >= 0.10:\n",
    "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate - 0.05\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\n",
    "class FlattenLayer:\n",
    "    def __init__(self):\n",
    "        self.name = 'Flatten'\n",
    "\n",
    "    def build_layer(self, model):\n",
    "        model.add(keras.layers.Flatten())\n",
    "\n",
    "    def mutate_parameters(self):\n",
    "        # The Flatten layer does not have any parameters to mutate\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a07263e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T03:01:16.517786Z",
     "iopub.status.busy": "2024-02-16T03:01:16.517494Z",
     "iopub.status.idle": "2024-02-16T03:36:56.802068Z",
     "shell.execute_reply": "2024-02-16T03:36:56.801091Z"
    },
    "papermill": {
     "duration": 2140.291845,
     "end_time": "2024-02-16T03:36:56.804407",
     "exception": false,
     "start_time": "2024-02-16T03:01:16.512562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 8s 0us/step\n",
      "Genetic Algorithm\n",
      "----->Initializing Population\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fd17ba0300>, <__main__.Block object at 0x77fd0d300680>, <__main__.Block object at 0x77fd0d3009c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Type of model_final: <class 'keras.src.engine.sequential.Sequential'>\n",
      "Training parent_0\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 5s 7ms/step - loss: 3.2662 - accuracy: 0.1489 - val_loss: 2.4261 - val_accuracy: 0.1360\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 2.3401 - accuracy: 0.1791 - val_loss: 2.1739 - val_accuracy: 0.2140\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 2.1616 - accuracy: 0.2471 - val_loss: 2.3806 - val_accuracy: 0.2180\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.9932 - accuracy: 0.2964 - val_loss: 2.0653 - val_accuracy: 0.3160\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.8043 - accuracy: 0.3484 - val_loss: 1.8858 - val_accuracy: 0.3240\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.7035 - accuracy: 0.3904 - val_loss: 1.8087 - val_accuracy: 0.3740\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.6060 - accuracy: 0.4169 - val_loss: 2.2527 - val_accuracy: 0.3480\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.5379 - accuracy: 0.4451 - val_loss: 1.7970 - val_accuracy: 0.3840\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.4693 - accuracy: 0.4604 - val_loss: 1.6257 - val_accuracy: 0.4280\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.4133 - accuracy: 0.4820 - val_loss: 1.7621 - val_accuracy: 0.4080\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.3369 - accuracy: 0.5191 - val_loss: 1.8899 - val_accuracy: 0.4360\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2887 - accuracy: 0.5309 - val_loss: 1.7614 - val_accuracy: 0.4360\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2574 - accuracy: 0.5544 - val_loss: 1.9397 - val_accuracy: 0.4600\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.1927 - accuracy: 0.5849 - val_loss: 2.2540 - val_accuracy: 0.3600\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.1012 - accuracy: 0.6036 - val_loss: 2.3113 - val_accuracy: 0.3880\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0805 - accuracy: 0.6158 - val_loss: 2.0899 - val_accuracy: 0.4280\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0539 - accuracy: 0.6227 - val_loss: 2.3815 - val_accuracy: 0.3880\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9959 - accuracy: 0.6496 - val_loss: 3.7314 - val_accuracy: 0.4160\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9803 - accuracy: 0.6656 - val_loss: 2.0674 - val_accuracy: 0.4140\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9058 - accuracy: 0.6780 - val_loss: 2.7133 - val_accuracy: 0.4160\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8713 - accuracy: 0.6947 - val_loss: 3.5368 - val_accuracy: 0.4180\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8433 - accuracy: 0.7040 - val_loss: 3.2157 - val_accuracy: 0.4320\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8569 - accuracy: 0.7251 - val_loss: 3.3092 - val_accuracy: 0.4660\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8055 - accuracy: 0.7322 - val_loss: 3.1209 - val_accuracy: 0.4380\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7531 - accuracy: 0.7362 - val_loss: 3.8595 - val_accuracy: 0.3960\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7511 - accuracy: 0.7498 - val_loss: 3.0549 - val_accuracy: 0.4400\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.7116 - accuracy: 0.7564 - val_loss: 3.6934 - val_accuracy: 0.4440\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6878 - accuracy: 0.7684 - val_loss: 4.6368 - val_accuracy: 0.4720\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6699 - accuracy: 0.7842 - val_loss: 2.9619 - val_accuracy: 0.4300\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6267 - accuracy: 0.7927 - val_loss: 4.0942 - val_accuracy: 0.4240\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5917 - accuracy: 0.8042 - val_loss: 4.4824 - val_accuracy: 0.4040\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6613 - accuracy: 0.8031 - val_loss: 3.7686 - val_accuracy: 0.4580\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6125 - accuracy: 0.8213 - val_loss: 5.2580 - val_accuracy: 0.4160\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6202 - accuracy: 0.8082 - val_loss: 6.0449 - val_accuracy: 0.4340\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6619 - accuracy: 0.8122 - val_loss: 6.6038 - val_accuracy: 0.4180\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6458 - accuracy: 0.8091 - val_loss: 7.5994 - val_accuracy: 0.4240\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6212 - accuracy: 0.8162 - val_loss: 4.9218 - val_accuracy: 0.4280\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5860 - accuracy: 0.8307 - val_loss: 5.8233 - val_accuracy: 0.4460\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5775 - accuracy: 0.8378 - val_loss: 6.4602 - val_accuracy: 0.4340\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4931 - accuracy: 0.8584 - val_loss: 6.1726 - val_accuracy: 0.4180\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6009 - accuracy: 0.8347 - val_loss: 7.1819 - val_accuracy: 0.4300\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.5694 - accuracy: 0.8553 - val_loss: 8.9594 - val_accuracy: 0.4580\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.5177 - accuracy: 0.8571 - val_loss: 6.4602 - val_accuracy: 0.4140\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.5767 - accuracy: 0.8542 - val_loss: 8.4083 - val_accuracy: 0.4260\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.4442 - accuracy: 0.8716 - val_loss: 7.6815 - val_accuracy: 0.3880\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4945 - accuracy: 0.8669 - val_loss: 10.4166 - val_accuracy: 0.3680\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4839 - accuracy: 0.8689 - val_loss: 8.8809 - val_accuracy: 0.3980\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5083 - accuracy: 0.8656 - val_loss: 10.3334 - val_accuracy: 0.4320\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4429 - accuracy: 0.8798 - val_loss: 11.6716 - val_accuracy: 0.4520\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4686 - accuracy: 0.8749 - val_loss: 9.1079 - val_accuracy: 0.4200\n",
      "SUMMARY OF parent_0\n",
      "Training Loss: 0.4685550034046173\n",
      "Training Accuracy: 0.8748888969421387\n",
      "Validation Loss: 9.107863426208496\n",
      "Validation Accuracy: 0.41999998688697815\n",
      "Classification Error Rate: 0.5800000131130219\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_1\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fd04542940>, <__main__.Block object at 0x77fd04589f00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26/3200109428.py:81: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model, self.name + '.h5')         # save model\n",
      "/tmp/ipykernel_26/3118480589.py:50: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(network.model, model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_1\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 5ms/step - loss: 2.5076 - accuracy: 0.2796 - val_loss: 1.9332 - val_accuracy: 0.3140\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.6289 - accuracy: 0.4304 - val_loss: 1.6589 - val_accuracy: 0.3880\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2771 - accuracy: 0.5476 - val_loss: 1.7219 - val_accuracy: 0.3940\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9467 - accuracy: 0.6696 - val_loss: 1.8035 - val_accuracy: 0.4600\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6591 - accuracy: 0.7756 - val_loss: 1.6280 - val_accuracy: 0.4860\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4179 - accuracy: 0.8636 - val_loss: 1.8965 - val_accuracy: 0.4220\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2624 - accuracy: 0.9144 - val_loss: 2.1881 - val_accuracy: 0.4580\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1677 - accuracy: 0.9467 - val_loss: 2.3420 - val_accuracy: 0.4580\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1036 - accuracy: 0.9696 - val_loss: 2.7841 - val_accuracy: 0.4580\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0784 - accuracy: 0.9749 - val_loss: 3.1481 - val_accuracy: 0.4640\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0597 - accuracy: 0.9824 - val_loss: 3.5087 - val_accuracy: 0.4520\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0472 - accuracy: 0.9858 - val_loss: 3.3847 - val_accuracy: 0.4480\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0394 - accuracy: 0.9882 - val_loss: 3.2334 - val_accuracy: 0.4640\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0414 - accuracy: 0.9871 - val_loss: 3.6852 - val_accuracy: 0.4700\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 3.7881 - val_accuracy: 0.4580\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0253 - accuracy: 0.9929 - val_loss: 4.3918 - val_accuracy: 0.4620\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0273 - accuracy: 0.9911 - val_loss: 4.0622 - val_accuracy: 0.5040\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9940 - val_loss: 4.4256 - val_accuracy: 0.4660\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0202 - accuracy: 0.9938 - val_loss: 4.7864 - val_accuracy: 0.4720\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0286 - accuracy: 0.9916 - val_loss: 4.4623 - val_accuracy: 0.4980\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0247 - accuracy: 0.9922 - val_loss: 4.5360 - val_accuracy: 0.4800\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9913 - val_loss: 4.6514 - val_accuracy: 0.4640\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 4.9224 - val_accuracy: 0.4700\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 5.2375 - val_accuracy: 0.4620\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0158 - accuracy: 0.9956 - val_loss: 5.0135 - val_accuracy: 0.4840\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9951 - val_loss: 4.8312 - val_accuracy: 0.4720\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 5.2293 - val_accuracy: 0.4900\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0136 - accuracy: 0.9947 - val_loss: 6.1310 - val_accuracy: 0.4560\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0228 - accuracy: 0.9938 - val_loss: 5.4180 - val_accuracy: 0.4800\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0213 - accuracy: 0.9931 - val_loss: 5.5730 - val_accuracy: 0.4900\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0149 - accuracy: 0.9953 - val_loss: 5.7923 - val_accuracy: 0.4800\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 0.9967 - val_loss: 6.0577 - val_accuracy: 0.4840\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0121 - accuracy: 0.9967 - val_loss: 5.7776 - val_accuracy: 0.4880\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 6.2672 - val_accuracy: 0.4900\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 6.5202 - val_accuracy: 0.4680\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 6.9014 - val_accuracy: 0.4740\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 6.8010 - val_accuracy: 0.4720\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0126 - accuracy: 0.9969 - val_loss: 6.9191 - val_accuracy: 0.4560\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 6.3802 - val_accuracy: 0.4860\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 3.3825e-04 - accuracy: 1.0000 - val_loss: 7.0387 - val_accuracy: 0.4720\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 7.5599 - val_accuracy: 0.4840\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 7.7952 - val_accuracy: 0.4860\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 7.2196 - val_accuracy: 0.4600\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0175 - accuracy: 0.9936 - val_loss: 7.9884 - val_accuracy: 0.4460\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 7.9174 - val_accuracy: 0.4380\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 7.9440 - val_accuracy: 0.4540\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0171 - accuracy: 0.9960 - val_loss: 9.0154 - val_accuracy: 0.4520\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 0.9947 - val_loss: 8.6916 - val_accuracy: 0.4280\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 8.2295 - val_accuracy: 0.4500\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 7.2743 - val_accuracy: 0.4460\n",
      "SUMMARY OF net_1\n",
      "Training Loss: 0.004483052529394627\n",
      "Training Accuracy: 0.9993333220481873\n",
      "Validation Loss: 7.2743377685546875\n",
      "Validation Accuracy: 0.44600000977516174\n",
      "Classification Error Rate: 0.5539999902248383\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_2\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 2)]\n",
      "Removing a Conv2D layer at 0\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fd041857c0>, <__main__.Block object at 0x77fd042a5b80>, <__main__.Block object at 0x77fd0420eac0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_2\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 6ms/step - loss: 2.1444 - accuracy: 0.2162 - val_loss: 1.8647 - val_accuracy: 0.3600\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.7517 - accuracy: 0.3687 - val_loss: 1.6935 - val_accuracy: 0.4080\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.5838 - accuracy: 0.4433 - val_loss: 1.6012 - val_accuracy: 0.4280\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.4647 - accuracy: 0.4707 - val_loss: 1.5690 - val_accuracy: 0.4480\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.3734 - accuracy: 0.5051 - val_loss: 1.5153 - val_accuracy: 0.4820\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2828 - accuracy: 0.5469 - val_loss: 1.5898 - val_accuracy: 0.4400\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2029 - accuracy: 0.5778 - val_loss: 1.5625 - val_accuracy: 0.5100\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.1201 - accuracy: 0.6078 - val_loss: 1.5265 - val_accuracy: 0.4960\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0467 - accuracy: 0.6293 - val_loss: 1.5975 - val_accuracy: 0.4920\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9775 - accuracy: 0.6591 - val_loss: 1.4878 - val_accuracy: 0.5260\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8860 - accuracy: 0.6882 - val_loss: 1.5323 - val_accuracy: 0.5360\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8147 - accuracy: 0.7136 - val_loss: 1.6712 - val_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7463 - accuracy: 0.7438 - val_loss: 1.7157 - val_accuracy: 0.5300\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6915 - accuracy: 0.7600 - val_loss: 1.8336 - val_accuracy: 0.5180\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6119 - accuracy: 0.7824 - val_loss: 1.7490 - val_accuracy: 0.5320\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5535 - accuracy: 0.8051 - val_loss: 1.9049 - val_accuracy: 0.5260\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4987 - accuracy: 0.8278 - val_loss: 2.1589 - val_accuracy: 0.5020\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4429 - accuracy: 0.8464 - val_loss: 2.4307 - val_accuracy: 0.4760\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3979 - accuracy: 0.8649 - val_loss: 2.3605 - val_accuracy: 0.4940\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3631 - accuracy: 0.8722 - val_loss: 2.4970 - val_accuracy: 0.5260\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3312 - accuracy: 0.8898 - val_loss: 2.5791 - val_accuracy: 0.4920\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2757 - accuracy: 0.9109 - val_loss: 3.0779 - val_accuracy: 0.4440\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2644 - accuracy: 0.9038 - val_loss: 3.1258 - val_accuracy: 0.5000\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2410 - accuracy: 0.9187 - val_loss: 3.0810 - val_accuracy: 0.4960\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2182 - accuracy: 0.9267 - val_loss: 3.6790 - val_accuracy: 0.4660\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1724 - accuracy: 0.9453 - val_loss: 3.4175 - val_accuracy: 0.4880\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1963 - accuracy: 0.9353 - val_loss: 3.6250 - val_accuracy: 0.4880\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1592 - accuracy: 0.9502 - val_loss: 3.9439 - val_accuracy: 0.4680\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1370 - accuracy: 0.9536 - val_loss: 4.5155 - val_accuracy: 0.5020\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1378 - accuracy: 0.9529 - val_loss: 4.0261 - val_accuracy: 0.5060\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1349 - accuracy: 0.9560 - val_loss: 4.4698 - val_accuracy: 0.4680\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1189 - accuracy: 0.9636 - val_loss: 4.3594 - val_accuracy: 0.4780\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1172 - accuracy: 0.9644 - val_loss: 5.5274 - val_accuracy: 0.4760\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1242 - accuracy: 0.9629 - val_loss: 5.0016 - val_accuracy: 0.4740\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1146 - accuracy: 0.9642 - val_loss: 4.5150 - val_accuracy: 0.5100\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1026 - accuracy: 0.9662 - val_loss: 5.0473 - val_accuracy: 0.5000\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0980 - accuracy: 0.9722 - val_loss: 5.5217 - val_accuracy: 0.4740\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1001 - accuracy: 0.9700 - val_loss: 4.8472 - val_accuracy: 0.4780\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0934 - accuracy: 0.9687 - val_loss: 5.5397 - val_accuracy: 0.4940\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0931 - accuracy: 0.9716 - val_loss: 4.9792 - val_accuracy: 0.4800\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0878 - accuracy: 0.9756 - val_loss: 5.2984 - val_accuracy: 0.5320\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1048 - accuracy: 0.9733 - val_loss: 5.6689 - val_accuracy: 0.4840\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0843 - accuracy: 0.9771 - val_loss: 5.3090 - val_accuracy: 0.5100\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0910 - accuracy: 0.9742 - val_loss: 5.9551 - val_accuracy: 0.5000\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0774 - accuracy: 0.9789 - val_loss: 5.8686 - val_accuracy: 0.5080\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0778 - accuracy: 0.9784 - val_loss: 6.3935 - val_accuracy: 0.5000\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0990 - accuracy: 0.9740 - val_loss: 5.6059 - val_accuracy: 0.4980\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0581 - accuracy: 0.9813 - val_loss: 5.8573 - val_accuracy: 0.4980\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0873 - accuracy: 0.9776 - val_loss: 6.7655 - val_accuracy: 0.5160\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0839 - accuracy: 0.9740 - val_loss: 6.1897 - val_accuracy: 0.5080\n",
      "SUMMARY OF net_2\n",
      "Training Loss: 0.0839470624923706\n",
      "Training Accuracy: 0.9739999771118164\n",
      "Validation Loss: 6.189674377441406\n",
      "Validation Accuracy: 0.5080000162124634\n",
      "Classification Error Rate: 0.4919999837875366\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_3\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fcf028d7c0>, <__main__.Block object at 0x77fcf02adc80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_3\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 5ms/step - loss: 3.1742 - accuracy: 0.1113 - val_loss: 2.2592 - val_accuracy: 0.1620\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 2.2756 - accuracy: 0.1347 - val_loss: 2.2113 - val_accuracy: 0.2000\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 2.1958 - accuracy: 0.1909 - val_loss: 2.2166 - val_accuracy: 0.1720\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 2.0269 - accuracy: 0.2531 - val_loss: 2.0878 - val_accuracy: 0.2840\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.8369 - accuracy: 0.3262 - val_loss: 1.9282 - val_accuracy: 0.3260\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.6918 - accuracy: 0.3871 - val_loss: 1.7742 - val_accuracy: 0.3740\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.5719 - accuracy: 0.4231 - val_loss: 1.9267 - val_accuracy: 0.3500\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.4513 - accuracy: 0.4818 - val_loss: 1.8727 - val_accuracy: 0.3640\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.3369 - accuracy: 0.5162 - val_loss: 1.7896 - val_accuracy: 0.3780\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2206 - accuracy: 0.5569 - val_loss: 1.8765 - val_accuracy: 0.3720\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.1257 - accuracy: 0.6000 - val_loss: 1.8791 - val_accuracy: 0.4240\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0239 - accuracy: 0.6269 - val_loss: 1.7992 - val_accuracy: 0.4280\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9044 - accuracy: 0.6720 - val_loss: 1.9643 - val_accuracy: 0.4080\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8188 - accuracy: 0.7087 - val_loss: 2.0694 - val_accuracy: 0.4280\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7237 - accuracy: 0.7413 - val_loss: 2.1395 - val_accuracy: 0.4300\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6241 - accuracy: 0.7767 - val_loss: 2.2888 - val_accuracy: 0.4540\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5463 - accuracy: 0.8100 - val_loss: 2.5797 - val_accuracy: 0.4240\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4717 - accuracy: 0.8407 - val_loss: 2.6316 - val_accuracy: 0.4120\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4033 - accuracy: 0.8627 - val_loss: 2.9855 - val_accuracy: 0.4340\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3465 - accuracy: 0.8829 - val_loss: 3.0478 - val_accuracy: 0.4140\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2900 - accuracy: 0.9002 - val_loss: 3.0562 - val_accuracy: 0.4260\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2368 - accuracy: 0.9173 - val_loss: 3.3990 - val_accuracy: 0.4220\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2020 - accuracy: 0.9369 - val_loss: 3.5549 - val_accuracy: 0.4380\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1694 - accuracy: 0.9431 - val_loss: 3.8950 - val_accuracy: 0.4340\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1502 - accuracy: 0.9507 - val_loss: 3.8221 - val_accuracy: 0.4300\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1392 - accuracy: 0.9549 - val_loss: 4.3578 - val_accuracy: 0.4020\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1143 - accuracy: 0.9647 - val_loss: 4.4760 - val_accuracy: 0.4280\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1044 - accuracy: 0.9658 - val_loss: 4.6537 - val_accuracy: 0.4160\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0864 - accuracy: 0.9711 - val_loss: 4.7328 - val_accuracy: 0.4180\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0751 - accuracy: 0.9773 - val_loss: 4.9544 - val_accuracy: 0.4300\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0642 - accuracy: 0.9796 - val_loss: 5.2099 - val_accuracy: 0.4140\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0775 - accuracy: 0.9767 - val_loss: 5.7799 - val_accuracy: 0.4280\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0612 - accuracy: 0.9798 - val_loss: 5.6455 - val_accuracy: 0.4240\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0531 - accuracy: 0.9847 - val_loss: 5.6552 - val_accuracy: 0.3940\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0537 - accuracy: 0.9816 - val_loss: 5.9794 - val_accuracy: 0.4260\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0335 - accuracy: 0.9909 - val_loss: 6.5223 - val_accuracy: 0.4260\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0464 - accuracy: 0.9849 - val_loss: 6.4988 - val_accuracy: 0.4260\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0496 - accuracy: 0.9862 - val_loss: 6.4359 - val_accuracy: 0.4040\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0396 - accuracy: 0.9891 - val_loss: 6.6861 - val_accuracy: 0.4060\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0452 - accuracy: 0.9847 - val_loss: 6.7885 - val_accuracy: 0.3920\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0357 - accuracy: 0.9891 - val_loss: 6.8723 - val_accuracy: 0.4060\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0373 - accuracy: 0.9893 - val_loss: 7.2352 - val_accuracy: 0.4280\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0341 - accuracy: 0.9902 - val_loss: 7.7113 - val_accuracy: 0.4020\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0356 - accuracy: 0.9891 - val_loss: 7.3515 - val_accuracy: 0.4040\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0333 - accuracy: 0.9893 - val_loss: 7.6026 - val_accuracy: 0.4040\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0349 - accuracy: 0.9893 - val_loss: 7.5742 - val_accuracy: 0.4040\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0243 - accuracy: 0.9916 - val_loss: 7.8048 - val_accuracy: 0.4060\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 8.7736 - val_accuracy: 0.3940\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9898 - val_loss: 7.6456 - val_accuracy: 0.4060\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0356 - accuracy: 0.9896 - val_loss: 8.2577 - val_accuracy: 0.4080\n",
      "SUMMARY OF net_3\n",
      "Training Loss: 0.03557230159640312\n",
      "Training Accuracy: 0.9895555377006531\n",
      "Validation Loss: 8.257669448852539\n",
      "Validation Accuracy: 0.40799999237060547\n",
      "Classification Error Rate: 0.5920000076293945\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_4\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 2)]\n",
      "Removing a Conv2D layer at 0\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fcdc74d7c0>, <__main__.Block object at 0x77fcdc700540>, <__main__.Block object at 0x77fcdff79f00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_4\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 5ms/step - loss: 2.0578 - accuracy: 0.2969 - val_loss: 1.7249 - val_accuracy: 0.4020\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.6165 - accuracy: 0.4196 - val_loss: 1.5968 - val_accuracy: 0.4440\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.3976 - accuracy: 0.5036 - val_loss: 1.5060 - val_accuracy: 0.4600\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2301 - accuracy: 0.5611 - val_loss: 1.5241 - val_accuracy: 0.4860\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0845 - accuracy: 0.6089 - val_loss: 1.6580 - val_accuracy: 0.4440\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9360 - accuracy: 0.6667 - val_loss: 1.4007 - val_accuracy: 0.5260\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8176 - accuracy: 0.7100 - val_loss: 1.6971 - val_accuracy: 0.4860\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7098 - accuracy: 0.7549 - val_loss: 1.5388 - val_accuracy: 0.5500\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6023 - accuracy: 0.7836 - val_loss: 1.6839 - val_accuracy: 0.5340\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5081 - accuracy: 0.8271 - val_loss: 1.8879 - val_accuracy: 0.5420\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4214 - accuracy: 0.8531 - val_loss: 1.9867 - val_accuracy: 0.5120\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3707 - accuracy: 0.8671 - val_loss: 2.1809 - val_accuracy: 0.5240\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3102 - accuracy: 0.8922 - val_loss: 2.4212 - val_accuracy: 0.5080\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2640 - accuracy: 0.9096 - val_loss: 2.7128 - val_accuracy: 0.5400\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2249 - accuracy: 0.9218 - val_loss: 2.4605 - val_accuracy: 0.5480\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2001 - accuracy: 0.9300 - val_loss: 2.6647 - val_accuracy: 0.5320\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1859 - accuracy: 0.9351 - val_loss: 3.0853 - val_accuracy: 0.5440\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1687 - accuracy: 0.9416 - val_loss: 3.1977 - val_accuracy: 0.5480\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1417 - accuracy: 0.9547 - val_loss: 3.3172 - val_accuracy: 0.5580\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1301 - accuracy: 0.9556 - val_loss: 3.5141 - val_accuracy: 0.5240\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1332 - accuracy: 0.9582 - val_loss: 3.5084 - val_accuracy: 0.5600\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1177 - accuracy: 0.9620 - val_loss: 4.1179 - val_accuracy: 0.5400\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1218 - accuracy: 0.9636 - val_loss: 3.8393 - val_accuracy: 0.5360\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1159 - accuracy: 0.9627 - val_loss: 4.2969 - val_accuracy: 0.5280\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1064 - accuracy: 0.9671 - val_loss: 4.4375 - val_accuracy: 0.5360\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1032 - accuracy: 0.9647 - val_loss: 4.3041 - val_accuracy: 0.5580\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1124 - accuracy: 0.9644 - val_loss: 4.9658 - val_accuracy: 0.5360\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1112 - accuracy: 0.9680 - val_loss: 4.7760 - val_accuracy: 0.5140\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0952 - accuracy: 0.9709 - val_loss: 5.1571 - val_accuracy: 0.5260\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0917 - accuracy: 0.9727 - val_loss: 5.2000 - val_accuracy: 0.5240\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0925 - accuracy: 0.9722 - val_loss: 5.4043 - val_accuracy: 0.5300\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1045 - accuracy: 0.9716 - val_loss: 5.5496 - val_accuracy: 0.5400\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1014 - accuracy: 0.9711 - val_loss: 5.4741 - val_accuracy: 0.5580\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1105 - accuracy: 0.9711 - val_loss: 5.7012 - val_accuracy: 0.5460\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0922 - accuracy: 0.9744 - val_loss: 6.4395 - val_accuracy: 0.5320\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0947 - accuracy: 0.9760 - val_loss: 7.5522 - val_accuracy: 0.5240\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1014 - accuracy: 0.9716 - val_loss: 6.3640 - val_accuracy: 0.5340\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0912 - accuracy: 0.9758 - val_loss: 6.3848 - val_accuracy: 0.5420\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1239 - accuracy: 0.9727 - val_loss: 7.2468 - val_accuracy: 0.5380\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0946 - accuracy: 0.9771 - val_loss: 7.7256 - val_accuracy: 0.5300\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0822 - accuracy: 0.9784 - val_loss: 7.4744 - val_accuracy: 0.5320\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0855 - accuracy: 0.9764 - val_loss: 6.9861 - val_accuracy: 0.5260\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0731 - accuracy: 0.9798 - val_loss: 7.1365 - val_accuracy: 0.5660\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0764 - accuracy: 0.9793 - val_loss: 6.7460 - val_accuracy: 0.5560\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1002 - accuracy: 0.9762 - val_loss: 8.4168 - val_accuracy: 0.5220\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0855 - accuracy: 0.9767 - val_loss: 7.9502 - val_accuracy: 0.5180\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1148 - accuracy: 0.9742 - val_loss: 8.2502 - val_accuracy: 0.5260\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1115 - accuracy: 0.9747 - val_loss: 8.5011 - val_accuracy: 0.5200\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0992 - accuracy: 0.9793 - val_loss: 8.7303 - val_accuracy: 0.5300\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1139 - accuracy: 0.9760 - val_loss: 8.5277 - val_accuracy: 0.5320\n",
      "SUMMARY OF net_4\n",
      "Training Loss: 0.11392831802368164\n",
      "Training Accuracy: 0.9760000109672546\n",
      "Validation Loss: 8.527738571166992\n",
      "Validation Accuracy: 0.5320000052452087\n",
      "Classification Error Rate: 0.46799999475479126\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_5\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 2)]\n",
      "Removing a Conv2D layer at 0\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fcdc4fa940>, <__main__.Block object at 0x77fcdc5fc880>, <__main__.Block object at 0x77fcdffb4440>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_5\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 5ms/step - loss: 2.0357 - accuracy: 0.2584 - val_loss: 1.7967 - val_accuracy: 0.3480\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.6814 - accuracy: 0.4022 - val_loss: 1.7470 - val_accuracy: 0.3840\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.4838 - accuracy: 0.4640 - val_loss: 1.5529 - val_accuracy: 0.4300\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.3283 - accuracy: 0.5289 - val_loss: 1.5692 - val_accuracy: 0.4320\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.1945 - accuracy: 0.5729 - val_loss: 1.4039 - val_accuracy: 0.5240\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0730 - accuracy: 0.6187 - val_loss: 1.3914 - val_accuracy: 0.5340\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9699 - accuracy: 0.6624 - val_loss: 1.5063 - val_accuracy: 0.4700\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8765 - accuracy: 0.7016 - val_loss: 1.3944 - val_accuracy: 0.5440\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7738 - accuracy: 0.7280 - val_loss: 1.4661 - val_accuracy: 0.5280\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6960 - accuracy: 0.7491 - val_loss: 1.4092 - val_accuracy: 0.5760\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6006 - accuracy: 0.7916 - val_loss: 1.9141 - val_accuracy: 0.4780\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5229 - accuracy: 0.8184 - val_loss: 1.6106 - val_accuracy: 0.5640\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4432 - accuracy: 0.8460 - val_loss: 1.7869 - val_accuracy: 0.5360\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3949 - accuracy: 0.8600 - val_loss: 1.8281 - val_accuracy: 0.5340\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3350 - accuracy: 0.8818 - val_loss: 2.0684 - val_accuracy: 0.5140\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2919 - accuracy: 0.8987 - val_loss: 2.1002 - val_accuracy: 0.5500\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2479 - accuracy: 0.9176 - val_loss: 2.1924 - val_accuracy: 0.5480\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2148 - accuracy: 0.9273 - val_loss: 2.3606 - val_accuracy: 0.5300\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1985 - accuracy: 0.9371 - val_loss: 2.4675 - val_accuracy: 0.5540\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1693 - accuracy: 0.9460 - val_loss: 2.7444 - val_accuracy: 0.5400\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1505 - accuracy: 0.9482 - val_loss: 2.8301 - val_accuracy: 0.5320\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1348 - accuracy: 0.9549 - val_loss: 2.9235 - val_accuracy: 0.5360\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1295 - accuracy: 0.9578 - val_loss: 3.1020 - val_accuracy: 0.5460\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1155 - accuracy: 0.9647 - val_loss: 3.1796 - val_accuracy: 0.5620\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1218 - accuracy: 0.9627 - val_loss: 3.5461 - val_accuracy: 0.5080\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0915 - accuracy: 0.9696 - val_loss: 3.5737 - val_accuracy: 0.5720\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1054 - accuracy: 0.9642 - val_loss: 3.4437 - val_accuracy: 0.5620\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0882 - accuracy: 0.9733 - val_loss: 4.0604 - val_accuracy: 0.5320\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0886 - accuracy: 0.9707 - val_loss: 3.9456 - val_accuracy: 0.5300\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0722 - accuracy: 0.9767 - val_loss: 4.0771 - val_accuracy: 0.5120\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0852 - accuracy: 0.9733 - val_loss: 3.9253 - val_accuracy: 0.5440\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0753 - accuracy: 0.9791 - val_loss: 4.2110 - val_accuracy: 0.5080\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0646 - accuracy: 0.9784 - val_loss: 4.1583 - val_accuracy: 0.5320\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0671 - accuracy: 0.9784 - val_loss: 4.9192 - val_accuracy: 0.5280\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0954 - accuracy: 0.9724 - val_loss: 4.6823 - val_accuracy: 0.5280\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0755 - accuracy: 0.9733 - val_loss: 4.5333 - val_accuracy: 0.5460\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0664 - accuracy: 0.9793 - val_loss: 4.5466 - val_accuracy: 0.5440\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0747 - accuracy: 0.9776 - val_loss: 4.8231 - val_accuracy: 0.5120\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0790 - accuracy: 0.9747 - val_loss: 4.5109 - val_accuracy: 0.5580\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0727 - accuracy: 0.9764 - val_loss: 5.1469 - val_accuracy: 0.5060\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0828 - accuracy: 0.9749 - val_loss: 5.2173 - val_accuracy: 0.5400\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0666 - accuracy: 0.9789 - val_loss: 5.5317 - val_accuracy: 0.5300\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0616 - accuracy: 0.9778 - val_loss: 5.4295 - val_accuracy: 0.5320\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0678 - accuracy: 0.9784 - val_loss: 5.6108 - val_accuracy: 0.5360\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0595 - accuracy: 0.9796 - val_loss: 5.3986 - val_accuracy: 0.5440\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0694 - accuracy: 0.9789 - val_loss: 5.8407 - val_accuracy: 0.5220\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0718 - accuracy: 0.9791 - val_loss: 6.0255 - val_accuracy: 0.5400\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0651 - accuracy: 0.9829 - val_loss: 6.4378 - val_accuracy: 0.5240\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0748 - accuracy: 0.9780 - val_loss: 5.8400 - val_accuracy: 0.5440\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0676 - accuracy: 0.9831 - val_loss: 5.8050 - val_accuracy: 0.5580\n",
      "SUMMARY OF net_5\n",
      "Training Loss: 0.06756260991096497\n",
      "Training Accuracy: 0.9831110835075378\n",
      "Validation Loss: 5.805016994476318\n",
      "Validation Accuracy: 0.5580000281333923\n",
      "Classification Error Rate: 0.44199997186660767\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_6\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fcd7f2c4c0>, <__main__.Block object at 0x77fcdc1bef40>, <__main__.Block object at 0x77fcd7f79240>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_6\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 6ms/step - loss: 2.5296 - accuracy: 0.1447 - val_loss: 2.6309 - val_accuracy: 0.1240\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 2.1224 - accuracy: 0.2289 - val_loss: 2.3065 - val_accuracy: 0.2440\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.9559 - accuracy: 0.3007 - val_loss: 1.8640 - val_accuracy: 0.2880\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.8123 - accuracy: 0.3493 - val_loss: 1.9208 - val_accuracy: 0.3240\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.6710 - accuracy: 0.3984 - val_loss: 2.3323 - val_accuracy: 0.2560\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.5689 - accuracy: 0.4344 - val_loss: 1.8072 - val_accuracy: 0.4160\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.4612 - accuracy: 0.4838 - val_loss: 1.7597 - val_accuracy: 0.3840\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.3645 - accuracy: 0.5047 - val_loss: 1.8630 - val_accuracy: 0.4020\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.2537 - accuracy: 0.5516 - val_loss: 1.8888 - val_accuracy: 0.4340\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.1894 - accuracy: 0.5780 - val_loss: 1.8774 - val_accuracy: 0.4200\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.1112 - accuracy: 0.6109 - val_loss: 1.9618 - val_accuracy: 0.4100\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.0187 - accuracy: 0.6429 - val_loss: 2.0622 - val_accuracy: 0.4080\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9507 - accuracy: 0.6627 - val_loss: 2.3122 - val_accuracy: 0.3640\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8795 - accuracy: 0.6849 - val_loss: 2.8536 - val_accuracy: 0.4140\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8361 - accuracy: 0.6978 - val_loss: 2.6413 - val_accuracy: 0.4020\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7515 - accuracy: 0.7338 - val_loss: 2.7606 - val_accuracy: 0.3960\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7337 - accuracy: 0.7478 - val_loss: 2.9361 - val_accuracy: 0.4260\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6337 - accuracy: 0.7729 - val_loss: 3.0971 - val_accuracy: 0.4200\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6277 - accuracy: 0.7818 - val_loss: 3.5761 - val_accuracy: 0.4140\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5938 - accuracy: 0.8000 - val_loss: 3.3512 - val_accuracy: 0.4280\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6301 - accuracy: 0.7987 - val_loss: 4.0269 - val_accuracy: 0.4200\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5432 - accuracy: 0.8178 - val_loss: 4.1597 - val_accuracy: 0.4180\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5647 - accuracy: 0.8149 - val_loss: 4.7447 - val_accuracy: 0.4040\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5257 - accuracy: 0.8291 - val_loss: 4.5273 - val_accuracy: 0.4220\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4518 - accuracy: 0.8500 - val_loss: 4.6433 - val_accuracy: 0.3860\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4453 - accuracy: 0.8602 - val_loss: 5.2775 - val_accuracy: 0.4140\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.4592 - accuracy: 0.8571 - val_loss: 5.9719 - val_accuracy: 0.4160\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4504 - accuracy: 0.8609 - val_loss: 6.7023 - val_accuracy: 0.4100\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4438 - accuracy: 0.8620 - val_loss: 5.5340 - val_accuracy: 0.4380\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4065 - accuracy: 0.8758 - val_loss: 6.6230 - val_accuracy: 0.4360\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4357 - accuracy: 0.8704 - val_loss: 6.5357 - val_accuracy: 0.4240\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3994 - accuracy: 0.8762 - val_loss: 8.0758 - val_accuracy: 0.4200\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4111 - accuracy: 0.8784 - val_loss: 8.2344 - val_accuracy: 0.4140\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4287 - accuracy: 0.8838 - val_loss: 9.2865 - val_accuracy: 0.3840\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3962 - accuracy: 0.8964 - val_loss: 8.0355 - val_accuracy: 0.4340\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4008 - accuracy: 0.8933 - val_loss: 9.3975 - val_accuracy: 0.3700\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3886 - accuracy: 0.8987 - val_loss: 12.6040 - val_accuracy: 0.3760\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4043 - accuracy: 0.9024 - val_loss: 8.4031 - val_accuracy: 0.4460\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3557 - accuracy: 0.9107 - val_loss: 9.0929 - val_accuracy: 0.4140\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3295 - accuracy: 0.9116 - val_loss: 10.3981 - val_accuracy: 0.4140\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4233 - accuracy: 0.9113 - val_loss: 9.4278 - val_accuracy: 0.4260\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3166 - accuracy: 0.9118 - val_loss: 10.0135 - val_accuracy: 0.4660\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3545 - accuracy: 0.9151 - val_loss: 10.9627 - val_accuracy: 0.3840\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3596 - accuracy: 0.9198 - val_loss: 11.4272 - val_accuracy: 0.4180\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3320 - accuracy: 0.9202 - val_loss: 10.8598 - val_accuracy: 0.4320\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3077 - accuracy: 0.9284 - val_loss: 12.9756 - val_accuracy: 0.4160\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3203 - accuracy: 0.9236 - val_loss: 12.5336 - val_accuracy: 0.4060\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3189 - accuracy: 0.9293 - val_loss: 11.0808 - val_accuracy: 0.3860\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3439 - accuracy: 0.9262 - val_loss: 15.2726 - val_accuracy: 0.4120\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3549 - accuracy: 0.9258 - val_loss: 13.4837 - val_accuracy: 0.3980\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 0.35489049553871155\n",
      "Training Accuracy: 0.925777792930603\n",
      "Validation Loss: 13.483695983886719\n",
      "Validation Accuracy: 0.39800000190734863\n",
      "Classification Error Rate: 0.6019999980926514\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_7\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc9cbda940>, <__main__.Block object at 0x77fcd7ff1f00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_7\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 5ms/step - loss: 2.8192 - accuracy: 0.2302 - val_loss: 2.1358 - val_accuracy: 0.2460\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.7923 - accuracy: 0.3711 - val_loss: 1.8132 - val_accuracy: 0.3580\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.5325 - accuracy: 0.4449 - val_loss: 1.8899 - val_accuracy: 0.4080\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.3009 - accuracy: 0.5367 - val_loss: 1.8170 - val_accuracy: 0.4280\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0763 - accuracy: 0.6200 - val_loss: 1.8957 - val_accuracy: 0.4020\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8537 - accuracy: 0.7047 - val_loss: 1.7419 - val_accuracy: 0.4700\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6308 - accuracy: 0.7822 - val_loss: 2.1663 - val_accuracy: 0.4580\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4550 - accuracy: 0.8493 - val_loss: 2.5244 - val_accuracy: 0.3920\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3300 - accuracy: 0.8933 - val_loss: 2.5324 - val_accuracy: 0.4100\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2170 - accuracy: 0.9356 - val_loss: 2.8026 - val_accuracy: 0.4380\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1462 - accuracy: 0.9582 - val_loss: 3.0121 - val_accuracy: 0.4540\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0932 - accuracy: 0.9753 - val_loss: 3.4151 - val_accuracy: 0.4080\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0812 - accuracy: 0.9793 - val_loss: 3.7640 - val_accuracy: 0.4260\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0609 - accuracy: 0.9824 - val_loss: 3.8865 - val_accuracy: 0.4160\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0446 - accuracy: 0.9884 - val_loss: 4.4364 - val_accuracy: 0.4100\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0389 - accuracy: 0.9900 - val_loss: 4.5966 - val_accuracy: 0.4160\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0366 - accuracy: 0.9902 - val_loss: 4.9446 - val_accuracy: 0.4100\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.9920 - val_loss: 5.2033 - val_accuracy: 0.4320\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0311 - accuracy: 0.9909 - val_loss: 5.4833 - val_accuracy: 0.4180\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0328 - accuracy: 0.9893 - val_loss: 5.4576 - val_accuracy: 0.4300\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 5.4516 - val_accuracy: 0.4280\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9904 - val_loss: 5.6213 - val_accuracy: 0.4120\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 5.1400 - val_accuracy: 0.4100\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 6.2940 - val_accuracy: 0.4180\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 5.9306 - val_accuracy: 0.4120\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0239 - accuracy: 0.9922 - val_loss: 6.4900 - val_accuracy: 0.4340\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0254 - accuracy: 0.9929 - val_loss: 6.1204 - val_accuracy: 0.4280\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0188 - accuracy: 0.9960 - val_loss: 5.9239 - val_accuracy: 0.4240\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 6.5137 - val_accuracy: 0.4580\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 6.3887 - val_accuracy: 0.4580\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 7.1965 - val_accuracy: 0.4340\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 6.7110 - val_accuracy: 0.4320\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 6.9719 - val_accuracy: 0.4260\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 6.9172 - val_accuracy: 0.4220\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0202 - accuracy: 0.9944 - val_loss: 7.1986 - val_accuracy: 0.4340\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 7.2194 - val_accuracy: 0.4380\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0291 - accuracy: 0.9929 - val_loss: 7.1146 - val_accuracy: 0.4460\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9956 - val_loss: 8.6656 - val_accuracy: 0.4260\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 7.2666 - val_accuracy: 0.4500\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0114 - accuracy: 0.9971 - val_loss: 7.3222 - val_accuracy: 0.4220\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 7.3599 - val_accuracy: 0.4240\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0209 - accuracy: 0.9949 - val_loss: 8.5969 - val_accuracy: 0.4100\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 7.7640 - val_accuracy: 0.4280\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 8.2754 - val_accuracy: 0.4260\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.9973 - val_loss: 8.3673 - val_accuracy: 0.4240\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 9.0359 - val_accuracy: 0.4080\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0149 - accuracy: 0.9956 - val_loss: 8.3404 - val_accuracy: 0.4140\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9969 - val_loss: 8.8435 - val_accuracy: 0.4280\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9964 - val_loss: 8.6122 - val_accuracy: 0.4220\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0090 - accuracy: 0.9973 - val_loss: 8.8981 - val_accuracy: 0.4120\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 0.009033594280481339\n",
      "Training Accuracy: 0.9973333477973938\n",
      "Validation Loss: 8.898077011108398\n",
      "Validation Accuracy: 0.41200000047683716\n",
      "Classification Error Rate: 0.5879999995231628\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_8\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc71df60c0>, <__main__.Block object at 0x77fc71d2ef40>, <__main__.Block object at 0x77fc71dc1240>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_8\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 6ms/step - loss: 3.2731 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.0960\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3028 - accuracy: 0.0920 - val_loss: 2.3026 - val_accuracy: 0.0960\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.0900 - val_loss: 2.3026 - val_accuracy: 0.0960\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3025 - accuracy: 0.1040 - val_loss: 2.3027 - val_accuracy: 0.1040\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3025 - accuracy: 0.1036 - val_loss: 2.3027 - val_accuracy: 0.1040\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1016 - val_loss: 2.3028 - val_accuracy: 0.1040\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1036 - val_loss: 2.3028 - val_accuracy: 0.1040\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1000 - val_loss: 2.3028 - val_accuracy: 0.1040\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3029 - val_accuracy: 0.1040\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1002 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3029 - val_accuracy: 0.1040\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.0998 - val_loss: 2.3029 - val_accuracy: 0.1040\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.0993 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1036 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.0978 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.0996 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1007 - val_loss: 2.3029 - val_accuracy: 0.1040\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.0993 - val_loss: 2.3029 - val_accuracy: 0.1040\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1000 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1009 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.0976 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1022 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.0978 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1011 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1024 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1038 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1000 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.0969 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1007 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1027 - val_loss: 2.3029 - val_accuracy: 0.1040\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1029 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1027 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1018 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1024 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1018 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1031 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1009 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.0989 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1031 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1024 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1044 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1002 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 2.302379846572876\n",
      "Training Accuracy: 0.10022222250699997\n",
      "Validation Loss: 2.3030927181243896\n",
      "Validation Accuracy: 0.10400000214576721\n",
      "Classification Error Rate: 0.8959999978542328\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_9\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc71a7a940>, <__main__.Block object at 0x77fc71abe0c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_9\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 5ms/step - loss: 2.3422 - accuracy: 0.2847 - val_loss: 1.9051 - val_accuracy: 0.3500\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.5740 - accuracy: 0.4429 - val_loss: 1.8250 - val_accuracy: 0.3540\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2099 - accuracy: 0.5731 - val_loss: 1.6461 - val_accuracy: 0.4380\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8681 - accuracy: 0.6920 - val_loss: 1.8316 - val_accuracy: 0.4300\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5783 - accuracy: 0.8027 - val_loss: 1.7941 - val_accuracy: 0.4720\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3598 - accuracy: 0.8807 - val_loss: 2.0566 - val_accuracy: 0.4560\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2309 - accuracy: 0.9256 - val_loss: 2.5687 - val_accuracy: 0.4400\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1462 - accuracy: 0.9544 - val_loss: 2.4966 - val_accuracy: 0.4800\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1048 - accuracy: 0.9693 - val_loss: 2.6914 - val_accuracy: 0.4680\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0742 - accuracy: 0.9778 - val_loss: 3.1838 - val_accuracy: 0.4300\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0679 - accuracy: 0.9813 - val_loss: 3.1996 - val_accuracy: 0.4500\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0550 - accuracy: 0.9818 - val_loss: 3.4281 - val_accuracy: 0.4640\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0355 - accuracy: 0.9896 - val_loss: 3.5359 - val_accuracy: 0.4760\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9913 - val_loss: 4.1966 - val_accuracy: 0.4320\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9902 - val_loss: 3.8741 - val_accuracy: 0.4740\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0252 - accuracy: 0.9936 - val_loss: 4.8846 - val_accuracy: 0.4460\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0240 - accuracy: 0.9938 - val_loss: 4.2237 - val_accuracy: 0.4440\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 4.8008 - val_accuracy: 0.4300\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0211 - accuracy: 0.9949 - val_loss: 4.4645 - val_accuracy: 0.4640\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 5.0970 - val_accuracy: 0.4220\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9938 - val_loss: 4.3983 - val_accuracy: 0.5020\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0223 - accuracy: 0.9933 - val_loss: 4.6149 - val_accuracy: 0.4620\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 5.1938 - val_accuracy: 0.4520\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 4.4796 - val_accuracy: 0.5060\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0210 - accuracy: 0.9920 - val_loss: 5.3002 - val_accuracy: 0.4620\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0155 - accuracy: 0.9951 - val_loss: 5.3333 - val_accuracy: 0.4640\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0141 - accuracy: 0.9958 - val_loss: 5.2190 - val_accuracy: 0.4280\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 5.3020 - val_accuracy: 0.4800\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0201 - accuracy: 0.9947 - val_loss: 5.1770 - val_accuracy: 0.4580\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 5.0533 - val_accuracy: 0.4760\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0210 - accuracy: 0.9951 - val_loss: 5.2391 - val_accuracy: 0.4760\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 5.3639 - val_accuracy: 0.4640\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0143 - accuracy: 0.9940 - val_loss: 5.6883 - val_accuracy: 0.4840\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 5.6864 - val_accuracy: 0.4880\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0187 - accuracy: 0.9960 - val_loss: 5.4841 - val_accuracy: 0.4740\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 6.3583 - val_accuracy: 0.4720\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 6.4118 - val_accuracy: 0.4800\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 6.1413 - val_accuracy: 0.5020\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 6.4727 - val_accuracy: 0.4660\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 6.7608 - val_accuracy: 0.4960\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9987 - val_loss: 6.2797 - val_accuracy: 0.4840\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.9973 - val_loss: 7.6512 - val_accuracy: 0.4740\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0205 - accuracy: 0.9956 - val_loss: 6.1364 - val_accuracy: 0.4900\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 6.5586 - val_accuracy: 0.4780\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 6.7636 - val_accuracy: 0.4900\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0163 - accuracy: 0.9962 - val_loss: 6.5225 - val_accuracy: 0.4820\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9938 - val_loss: 7.2926 - val_accuracy: 0.4660\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 7.0479 - val_accuracy: 0.4760\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9971 - val_loss: 7.7158 - val_accuracy: 0.4620\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0209 - accuracy: 0.9949 - val_loss: 7.1912 - val_accuracy: 0.4520\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 0.020920705050230026\n",
      "Training Accuracy: 0.9948889017105103\n",
      "Validation Loss: 7.191214561462402\n",
      "Validation Accuracy: 0.4519999921321869\n",
      "Classification Error Rate: 0.5480000078678131\n",
      "\n",
      "-------------------------------------\n",
      "Initial Population:\n",
      "net_8 :  2.3030927181243896\n",
      "net_5 :  5.805016994476318\n",
      "net_2 :  6.189674377441406\n",
      "net_9 :  7.191214561462402\n",
      "net_1 :  7.2743377685546875\n",
      "net_3 :  8.257669448852539\n",
      "net_4 :  8.527738571166992\n",
      "net_7 :  8.898077011108398\n",
      "parent_0 :  9.107863426208496\n",
      "net_6 :  13.483695983886719\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 1\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Proportionate selection\n",
      "Selected net_2 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  128.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fcf04ba940>, <__main__.Block object at 0x77fc70708540>, <__main__.Block object at 0x77fd044fcb80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 6ms/step - loss: 2.0594 - accuracy: 0.2451 - val_loss: 1.9642 - val_accuracy: 0.3000\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.7502 - accuracy: 0.3658 - val_loss: 1.6215 - val_accuracy: 0.4220\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.5863 - accuracy: 0.4351 - val_loss: 1.6129 - val_accuracy: 0.4400\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.4502 - accuracy: 0.4784 - val_loss: 1.5483 - val_accuracy: 0.4580\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.3400 - accuracy: 0.5251 - val_loss: 1.4748 - val_accuracy: 0.4780\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2489 - accuracy: 0.5518 - val_loss: 1.5215 - val_accuracy: 0.4920\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.1526 - accuracy: 0.5876 - val_loss: 1.4182 - val_accuracy: 0.5000\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0557 - accuracy: 0.6204 - val_loss: 1.4596 - val_accuracy: 0.5120\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9703 - accuracy: 0.6560 - val_loss: 1.4610 - val_accuracy: 0.5160\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8663 - accuracy: 0.6967 - val_loss: 1.4554 - val_accuracy: 0.5480\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7885 - accuracy: 0.7171 - val_loss: 1.6321 - val_accuracy: 0.5160\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7071 - accuracy: 0.7484 - val_loss: 1.7207 - val_accuracy: 0.4980\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6202 - accuracy: 0.7862 - val_loss: 1.9147 - val_accuracy: 0.4480\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5345 - accuracy: 0.8173 - val_loss: 1.8643 - val_accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4636 - accuracy: 0.8358 - val_loss: 1.9801 - val_accuracy: 0.5240\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3988 - accuracy: 0.8591 - val_loss: 2.0818 - val_accuracy: 0.4800\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3437 - accuracy: 0.8800 - val_loss: 2.3900 - val_accuracy: 0.4880\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2928 - accuracy: 0.8987 - val_loss: 2.3895 - val_accuracy: 0.4840\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2466 - accuracy: 0.9164 - val_loss: 2.5867 - val_accuracy: 0.5060\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2053 - accuracy: 0.9284 - val_loss: 2.7295 - val_accuracy: 0.5120\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1836 - accuracy: 0.9384 - val_loss: 3.4383 - val_accuracy: 0.4840\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1628 - accuracy: 0.9464 - val_loss: 3.1559 - val_accuracy: 0.5020\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1653 - accuracy: 0.9498 - val_loss: 3.0111 - val_accuracy: 0.5100\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1356 - accuracy: 0.9558 - val_loss: 3.3796 - val_accuracy: 0.5040\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1210 - accuracy: 0.9613 - val_loss: 3.6440 - val_accuracy: 0.4940\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1228 - accuracy: 0.9573 - val_loss: 3.5359 - val_accuracy: 0.5000\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1140 - accuracy: 0.9618 - val_loss: 4.1266 - val_accuracy: 0.4660\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1020 - accuracy: 0.9678 - val_loss: 3.7702 - val_accuracy: 0.5000\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1032 - accuracy: 0.9656 - val_loss: 3.7757 - val_accuracy: 0.4920\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0926 - accuracy: 0.9709 - val_loss: 4.1595 - val_accuracy: 0.4980\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0809 - accuracy: 0.9747 - val_loss: 4.7660 - val_accuracy: 0.4780\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0798 - accuracy: 0.9738 - val_loss: 4.2122 - val_accuracy: 0.4720\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0805 - accuracy: 0.9756 - val_loss: 4.2679 - val_accuracy: 0.5200\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0794 - accuracy: 0.9764 - val_loss: 4.6121 - val_accuracy: 0.4980\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0625 - accuracy: 0.9798 - val_loss: 4.8628 - val_accuracy: 0.4760\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0768 - accuracy: 0.9747 - val_loss: 4.6507 - val_accuracy: 0.4940\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0704 - accuracy: 0.9782 - val_loss: 4.7730 - val_accuracy: 0.5120\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0785 - accuracy: 0.9736 - val_loss: 5.1542 - val_accuracy: 0.5060\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0725 - accuracy: 0.9789 - val_loss: 4.9171 - val_accuracy: 0.5020\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0856 - accuracy: 0.9738 - val_loss: 4.6994 - val_accuracy: 0.5120\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0642 - accuracy: 0.9811 - val_loss: 5.0671 - val_accuracy: 0.5160\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0639 - accuracy: 0.9822 - val_loss: 5.7676 - val_accuracy: 0.4800\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9818 - val_loss: 5.3271 - val_accuracy: 0.4940\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0535 - accuracy: 0.9840 - val_loss: 6.7128 - val_accuracy: 0.4660\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0666 - accuracy: 0.9816 - val_loss: 5.7042 - val_accuracy: 0.5040\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0530 - accuracy: 0.9822 - val_loss: 6.4799 - val_accuracy: 0.4880\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0625 - accuracy: 0.9824 - val_loss: 6.2827 - val_accuracy: 0.4900\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0698 - accuracy: 0.9836 - val_loss: 5.6380 - val_accuracy: 0.4740\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0576 - accuracy: 0.9829 - val_loss: 6.5686 - val_accuracy: 0.4760\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0678 - accuracy: 0.9800 - val_loss: 5.5571 - val_accuracy: 0.4960\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.06776650995016098\n",
      "Training Accuracy: 0.9800000190734863\n",
      "Validation Loss: 5.557051658630371\n",
      "Validation Accuracy: 0.4959999918937683\n",
      "Classification Error Rate: 0.5040000081062317\n",
      "----->Evolution: Child net_10 with fitness 5.557051658630371 replaces parent net_6 with fitness 13.483695983886719\n",
      "\n",
      "Creating Child 1\n",
      "----->Proportionate selection\n",
      "Selected net_9 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc70d74900>, <__main__.Block object at 0x77fc70f8b9c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 5ms/step - loss: 2.3153 - accuracy: 0.2771 - val_loss: 1.8962 - val_accuracy: 0.3240\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.6063 - accuracy: 0.4378 - val_loss: 1.7645 - val_accuracy: 0.3900\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.3013 - accuracy: 0.5378 - val_loss: 1.5885 - val_accuracy: 0.4580\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0287 - accuracy: 0.6398 - val_loss: 1.6549 - val_accuracy: 0.4620\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7477 - accuracy: 0.7476 - val_loss: 1.6835 - val_accuracy: 0.4740\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5205 - accuracy: 0.8300 - val_loss: 1.7974 - val_accuracy: 0.4940\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3474 - accuracy: 0.8836 - val_loss: 2.0522 - val_accuracy: 0.4780\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2212 - accuracy: 0.9324 - val_loss: 2.1792 - val_accuracy: 0.4800\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1448 - accuracy: 0.9553 - val_loss: 2.5382 - val_accuracy: 0.4540\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0908 - accuracy: 0.9776 - val_loss: 2.6446 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0750 - accuracy: 0.9800 - val_loss: 2.9619 - val_accuracy: 0.4820\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0579 - accuracy: 0.9849 - val_loss: 3.2383 - val_accuracy: 0.4660\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0366 - accuracy: 0.9887 - val_loss: 4.4004 - val_accuracy: 0.4260\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0343 - accuracy: 0.9911 - val_loss: 4.0973 - val_accuracy: 0.4520\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0411 - accuracy: 0.9880 - val_loss: 3.8431 - val_accuracy: 0.4640\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 3.8850 - val_accuracy: 0.4760\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0280 - accuracy: 0.9904 - val_loss: 4.3966 - val_accuracy: 0.4540\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0247 - accuracy: 0.9911 - val_loss: 4.1247 - val_accuracy: 0.4940\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 4.1749 - val_accuracy: 0.4900\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0253 - accuracy: 0.9927 - val_loss: 4.4134 - val_accuracy: 0.4640\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0152 - accuracy: 0.9953 - val_loss: 4.6490 - val_accuracy: 0.4820\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0245 - accuracy: 0.9927 - val_loss: 4.6779 - val_accuracy: 0.5060\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0207 - accuracy: 0.9938 - val_loss: 4.7677 - val_accuracy: 0.4820\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9951 - val_loss: 5.3432 - val_accuracy: 0.4660\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 4.9581 - val_accuracy: 0.5060\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0196 - accuracy: 0.9942 - val_loss: 5.4350 - val_accuracy: 0.4740\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0167 - accuracy: 0.9956 - val_loss: 5.4986 - val_accuracy: 0.4860\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 5.6768 - val_accuracy: 0.4720\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 6.0483 - val_accuracy: 0.4880\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 5.8438 - val_accuracy: 0.4620\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 6.1700 - val_accuracy: 0.4560\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 5.6921 - val_accuracy: 0.5160\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 5.9507 - val_accuracy: 0.4620\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 0.9993 - val_loss: 6.5847 - val_accuracy: 0.4840\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 6.7678 - val_accuracy: 0.4800\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.9958 - val_loss: 6.2304 - val_accuracy: 0.4900\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 6.7252 - val_accuracy: 0.5040\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 6.7192 - val_accuracy: 0.4920\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0116 - accuracy: 0.9956 - val_loss: 7.1968 - val_accuracy: 0.4840\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9924 - val_loss: 7.4792 - val_accuracy: 0.4720\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0188 - accuracy: 0.9938 - val_loss: 7.2374 - val_accuracy: 0.4860\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0100 - accuracy: 0.9953 - val_loss: 7.4102 - val_accuracy: 0.4760\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 7.5606 - val_accuracy: 0.4720\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0195 - accuracy: 0.9951 - val_loss: 6.9632 - val_accuracy: 0.4820\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 7.3857 - val_accuracy: 0.4700\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 6.9950 - val_accuracy: 0.4900\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 7.1317 - val_accuracy: 0.4940\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9929 - val_loss: 7.1606 - val_accuracy: 0.4720\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 7.4842 - val_accuracy: 0.4700\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 7.6083 - val_accuracy: 0.4520\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 0.018926072865724564\n",
      "Training Accuracy: 0.9951111078262329\n",
      "Validation Loss: 7.608337879180908\n",
      "Validation Accuracy: 0.4519999921321869\n",
      "Classification Error Rate: 0.5480000078678131\n",
      "----->Evolution: Child net_11 with fitness 7.608337879180908 replaces parent parent_0 with fitness 9.107863426208496\n",
      "\n",
      "Creating Child 2\n",
      "----->Proportionate selection\n",
      "Selected net_7 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc724ad580>, <__main__.Block object at 0x77fc72361040>, <__main__.Block object at 0x77fc72331f00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 6ms/step - loss: 2.4128 - accuracy: 0.1758 - val_loss: 2.2949 - val_accuracy: 0.2280\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 2.0265 - accuracy: 0.2742 - val_loss: 2.1465 - val_accuracy: 0.3020\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.8248 - accuracy: 0.3302 - val_loss: 1.7527 - val_accuracy: 0.3420\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.7217 - accuracy: 0.3682 - val_loss: 1.9958 - val_accuracy: 0.3260\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.6148 - accuracy: 0.4171 - val_loss: 1.7289 - val_accuracy: 0.3780\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.5213 - accuracy: 0.4507 - val_loss: 1.7619 - val_accuracy: 0.4380\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.4365 - accuracy: 0.4611 - val_loss: 1.6514 - val_accuracy: 0.4340\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.3663 - accuracy: 0.5038 - val_loss: 1.8483 - val_accuracy: 0.4420\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.3060 - accuracy: 0.5333 - val_loss: 1.7742 - val_accuracy: 0.4580\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2336 - accuracy: 0.5624 - val_loss: 1.7305 - val_accuracy: 0.4640\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2134 - accuracy: 0.5776 - val_loss: 1.6639 - val_accuracy: 0.4460\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.1490 - accuracy: 0.5991 - val_loss: 1.7946 - val_accuracy: 0.4840\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.1002 - accuracy: 0.6133 - val_loss: 1.9660 - val_accuracy: 0.4260\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.0700 - accuracy: 0.6296 - val_loss: 2.1136 - val_accuracy: 0.4680\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0201 - accuracy: 0.6524 - val_loss: 2.1269 - val_accuracy: 0.4700\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0602 - accuracy: 0.6380 - val_loss: 2.5986 - val_accuracy: 0.4980\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0777 - accuracy: 0.6489 - val_loss: 2.5326 - val_accuracy: 0.4820\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0014 - accuracy: 0.6756 - val_loss: 2.6182 - val_accuracy: 0.4700\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9717 - accuracy: 0.6729 - val_loss: 3.5687 - val_accuracy: 0.4680\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9602 - accuracy: 0.6869 - val_loss: 2.6194 - val_accuracy: 0.4720\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9443 - accuracy: 0.6991 - val_loss: 3.2057 - val_accuracy: 0.4920\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9667 - accuracy: 0.6913 - val_loss: 3.4520 - val_accuracy: 0.4560\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9040 - accuracy: 0.7120 - val_loss: 3.4127 - val_accuracy: 0.4520\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9244 - accuracy: 0.6996 - val_loss: 3.8047 - val_accuracy: 0.4440\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9506 - accuracy: 0.7002 - val_loss: 3.5682 - val_accuracy: 0.4960\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9214 - accuracy: 0.7153 - val_loss: 4.4334 - val_accuracy: 0.4520\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.9457 - accuracy: 0.7160 - val_loss: 4.2160 - val_accuracy: 0.4580\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.8970 - accuracy: 0.7291 - val_loss: 3.9784 - val_accuracy: 0.4460\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.9195 - accuracy: 0.7200 - val_loss: 3.4528 - val_accuracy: 0.4280\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.9024 - accuracy: 0.7362 - val_loss: 4.5147 - val_accuracy: 0.4700\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9481 - accuracy: 0.7198 - val_loss: 4.9828 - val_accuracy: 0.4140\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9490 - accuracy: 0.7276 - val_loss: 4.6663 - val_accuracy: 0.4780\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0100 - accuracy: 0.7158 - val_loss: 4.8688 - val_accuracy: 0.4560\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.9516 - accuracy: 0.7316 - val_loss: 5.0627 - val_accuracy: 0.4340\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.9623 - accuracy: 0.7378 - val_loss: 4.4375 - val_accuracy: 0.4820\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9626 - accuracy: 0.7311 - val_loss: 6.2419 - val_accuracy: 0.4380\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0232 - accuracy: 0.7258 - val_loss: 5.1333 - val_accuracy: 0.4620\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0043 - accuracy: 0.7282 - val_loss: 7.5684 - val_accuracy: 0.4860\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0258 - accuracy: 0.7204 - val_loss: 6.2583 - val_accuracy: 0.3940\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0258 - accuracy: 0.7384 - val_loss: 5.6927 - val_accuracy: 0.4540\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9381 - accuracy: 0.7402 - val_loss: 5.5745 - val_accuracy: 0.4460\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0414 - accuracy: 0.7356 - val_loss: 5.0024 - val_accuracy: 0.4320\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0607 - accuracy: 0.7420 - val_loss: 6.9857 - val_accuracy: 0.4740\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.0273 - accuracy: 0.7313 - val_loss: 6.9565 - val_accuracy: 0.4480\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.9087 - accuracy: 0.7502 - val_loss: 8.3698 - val_accuracy: 0.4420\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.0248 - accuracy: 0.7300 - val_loss: 8.3623 - val_accuracy: 0.4440\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.2936 - accuracy: 0.6716 - val_loss: 5.8437 - val_accuracy: 0.4280\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.1184 - accuracy: 0.7029 - val_loss: 6.8451 - val_accuracy: 0.4260\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.1233 - accuracy: 0.7240 - val_loss: 7.1539 - val_accuracy: 0.4320\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.0456 - accuracy: 0.7247 - val_loss: 10.8016 - val_accuracy: 0.4300\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 1.0455549955368042\n",
      "Training Accuracy: 0.7246666550636292\n",
      "Validation Loss: 10.801634788513184\n",
      "Validation Accuracy: 0.4300000071525574\n",
      "Classification Error Rate: 0.5699999928474426\n",
      "----->Evolution: Child net_12 with fitness 10.801634788513184 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Proportionate selection\n",
      "Selected net_6 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc721d2940>, <__main__.Block object at 0x77fc71f75b80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 5ms/step - loss: 2.4845 - accuracy: 0.1564 - val_loss: 2.0300 - val_accuracy: 0.2520\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.9793 - accuracy: 0.2833 - val_loss: 2.2559 - val_accuracy: 0.2560\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.7417 - accuracy: 0.3784 - val_loss: 1.9407 - val_accuracy: 0.3320\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.5798 - accuracy: 0.4387 - val_loss: 1.7481 - val_accuracy: 0.4000\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.4466 - accuracy: 0.4809 - val_loss: 1.6874 - val_accuracy: 0.4240\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2861 - accuracy: 0.5491 - val_loss: 1.7761 - val_accuracy: 0.3720\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.1513 - accuracy: 0.5827 - val_loss: 1.9326 - val_accuracy: 0.3960\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0141 - accuracy: 0.6351 - val_loss: 2.0110 - val_accuracy: 0.3820\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8725 - accuracy: 0.6869 - val_loss: 1.9202 - val_accuracy: 0.4320\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7440 - accuracy: 0.7382 - val_loss: 2.1021 - val_accuracy: 0.4220\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6127 - accuracy: 0.7884 - val_loss: 2.3557 - val_accuracy: 0.4120\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4748 - accuracy: 0.8376 - val_loss: 2.3147 - val_accuracy: 0.4280\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4042 - accuracy: 0.8600 - val_loss: 2.4353 - val_accuracy: 0.4240\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3126 - accuracy: 0.8927 - val_loss: 2.9465 - val_accuracy: 0.4060\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2625 - accuracy: 0.9162 - val_loss: 3.0393 - val_accuracy: 0.4180\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2162 - accuracy: 0.9287 - val_loss: 3.3901 - val_accuracy: 0.4180\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1741 - accuracy: 0.9451 - val_loss: 3.3780 - val_accuracy: 0.4140\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1392 - accuracy: 0.9536 - val_loss: 3.9945 - val_accuracy: 0.3800\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1108 - accuracy: 0.9658 - val_loss: 4.4857 - val_accuracy: 0.4080\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0993 - accuracy: 0.9711 - val_loss: 4.5579 - val_accuracy: 0.3920\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0815 - accuracy: 0.9762 - val_loss: 4.7837 - val_accuracy: 0.3980\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0730 - accuracy: 0.9760 - val_loss: 5.2836 - val_accuracy: 0.3800\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0659 - accuracy: 0.9809 - val_loss: 4.9937 - val_accuracy: 0.4060\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0538 - accuracy: 0.9822 - val_loss: 5.4432 - val_accuracy: 0.3860\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0524 - accuracy: 0.9813 - val_loss: 5.5139 - val_accuracy: 0.4040\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0490 - accuracy: 0.9829 - val_loss: 5.3080 - val_accuracy: 0.4220\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0496 - accuracy: 0.9840 - val_loss: 6.1449 - val_accuracy: 0.4100\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0428 - accuracy: 0.9844 - val_loss: 5.9593 - val_accuracy: 0.3920\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0404 - accuracy: 0.9889 - val_loss: 6.2118 - val_accuracy: 0.3980\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0340 - accuracy: 0.9904 - val_loss: 6.0886 - val_accuracy: 0.4200\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0457 - accuracy: 0.9840 - val_loss: 6.6696 - val_accuracy: 0.4060\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0423 - accuracy: 0.9880 - val_loss: 6.5146 - val_accuracy: 0.4140\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0353 - accuracy: 0.9887 - val_loss: 6.8465 - val_accuracy: 0.4220\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0322 - accuracy: 0.9889 - val_loss: 7.7181 - val_accuracy: 0.4080\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0341 - accuracy: 0.9891 - val_loss: 7.1796 - val_accuracy: 0.4160\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.0336 - accuracy: 0.9884 - val_loss: 8.1712 - val_accuracy: 0.4200\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0280 - accuracy: 0.9924 - val_loss: 7.8220 - val_accuracy: 0.4020\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0424 - accuracy: 0.9871 - val_loss: 8.3450 - val_accuracy: 0.4140\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0224 - accuracy: 0.9922 - val_loss: 7.8090 - val_accuracy: 0.4020\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0327 - accuracy: 0.9896 - val_loss: 7.9833 - val_accuracy: 0.4060\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0314 - accuracy: 0.9880 - val_loss: 7.7142 - val_accuracy: 0.4180\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 8.9230 - val_accuracy: 0.4440\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0275 - accuracy: 0.9909 - val_loss: 8.7912 - val_accuracy: 0.4260\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0279 - accuracy: 0.9924 - val_loss: 8.2197 - val_accuracy: 0.4140\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0246 - accuracy: 0.9944 - val_loss: 8.4002 - val_accuracy: 0.4100\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0197 - accuracy: 0.9942 - val_loss: 8.6577 - val_accuracy: 0.4200\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0268 - accuracy: 0.9909 - val_loss: 8.3378 - val_accuracy: 0.4440\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 0.9951 - val_loss: 8.5126 - val_accuracy: 0.4320\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0291 - accuracy: 0.9918 - val_loss: 9.1272 - val_accuracy: 0.4460\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0263 - accuracy: 0.9911 - val_loss: 9.2237 - val_accuracy: 0.4020\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 0.02626657858490944\n",
      "Training Accuracy: 0.9911110997200012\n",
      "Validation Loss: 9.223719596862793\n",
      "Validation Accuracy: 0.4020000100135803\n",
      "Classification Error Rate: 0.5979999899864197\n",
      "----->Evolution: Child net_13 with fitness 9.223719596862793 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 2\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Tournament selection\n",
      "Selected parent_0 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc72aa2940>, <__main__.Block object at 0x77fc7295db80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 6ms/step - loss: 2.4224 - accuracy: 0.2118 - val_loss: 2.0268 - val_accuracy: 0.3160\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.8812 - accuracy: 0.3233 - val_loss: 1.8461 - val_accuracy: 0.3660\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.6838 - accuracy: 0.4091 - val_loss: 1.8263 - val_accuracy: 0.3860\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.5441 - accuracy: 0.4544 - val_loss: 1.7914 - val_accuracy: 0.3900\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.3920 - accuracy: 0.5073 - val_loss: 1.7057 - val_accuracy: 0.4400\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2457 - accuracy: 0.5509 - val_loss: 1.6288 - val_accuracy: 0.4400\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0962 - accuracy: 0.6056 - val_loss: 1.8279 - val_accuracy: 0.3960\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9586 - accuracy: 0.6524 - val_loss: 2.0755 - val_accuracy: 0.3980\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8030 - accuracy: 0.7124 - val_loss: 1.9264 - val_accuracy: 0.4320\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6781 - accuracy: 0.7569 - val_loss: 2.0713 - val_accuracy: 0.4180\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5451 - accuracy: 0.8098 - val_loss: 2.3012 - val_accuracy: 0.4280\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4527 - accuracy: 0.8456 - val_loss: 2.6745 - val_accuracy: 0.3720\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3533 - accuracy: 0.8798 - val_loss: 3.0612 - val_accuracy: 0.3840\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2807 - accuracy: 0.9044 - val_loss: 3.0554 - val_accuracy: 0.4040\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2167 - accuracy: 0.9289 - val_loss: 4.2952 - val_accuracy: 0.4260\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1802 - accuracy: 0.9424 - val_loss: 3.7040 - val_accuracy: 0.4080\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1513 - accuracy: 0.9553 - val_loss: 3.9045 - val_accuracy: 0.4040\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1207 - accuracy: 0.9604 - val_loss: 3.9577 - val_accuracy: 0.4020\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0991 - accuracy: 0.9696 - val_loss: 4.7336 - val_accuracy: 0.4080\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0905 - accuracy: 0.9689 - val_loss: 5.2483 - val_accuracy: 0.3780\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0846 - accuracy: 0.9727 - val_loss: 4.7001 - val_accuracy: 0.3880\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0677 - accuracy: 0.9780 - val_loss: 5.3028 - val_accuracy: 0.4000\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0660 - accuracy: 0.9780 - val_loss: 5.4320 - val_accuracy: 0.3940\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0569 - accuracy: 0.9822 - val_loss: 5.7553 - val_accuracy: 0.4120\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0476 - accuracy: 0.9862 - val_loss: 6.0207 - val_accuracy: 0.3960\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0563 - accuracy: 0.9838 - val_loss: 5.7947 - val_accuracy: 0.4140\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0452 - accuracy: 0.9862 - val_loss: 6.1221 - val_accuracy: 0.4060\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0423 - accuracy: 0.9864 - val_loss: 6.3868 - val_accuracy: 0.4020\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0368 - accuracy: 0.9869 - val_loss: 6.2599 - val_accuracy: 0.4020\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0452 - accuracy: 0.9856 - val_loss: 6.9874 - val_accuracy: 0.3900\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0427 - accuracy: 0.9842 - val_loss: 6.7835 - val_accuracy: 0.4020\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0311 - accuracy: 0.9909 - val_loss: 7.1914 - val_accuracy: 0.3980\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0331 - accuracy: 0.9898 - val_loss: 6.9232 - val_accuracy: 0.3980\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0416 - accuracy: 0.9873 - val_loss: 7.6658 - val_accuracy: 0.4120\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0333 - accuracy: 0.9898 - val_loss: 8.5221 - val_accuracy: 0.3580\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0384 - accuracy: 0.9882 - val_loss: 7.9790 - val_accuracy: 0.3920\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9904 - val_loss: 7.8390 - val_accuracy: 0.3700\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0286 - accuracy: 0.9898 - val_loss: 7.9925 - val_accuracy: 0.3800\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0372 - accuracy: 0.9902 - val_loss: 8.1743 - val_accuracy: 0.3820\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0381 - accuracy: 0.9884 - val_loss: 8.6368 - val_accuracy: 0.3880\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0360 - accuracy: 0.9887 - val_loss: 8.7203 - val_accuracy: 0.3780\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0383 - accuracy: 0.9884 - val_loss: 8.0529 - val_accuracy: 0.3960\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9898 - val_loss: 9.2002 - val_accuracy: 0.3820\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0303 - accuracy: 0.9907 - val_loss: 9.6194 - val_accuracy: 0.3900\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 9.3635 - val_accuracy: 0.4040\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 9.3892 - val_accuracy: 0.3860\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0333 - accuracy: 0.9898 - val_loss: 8.8713 - val_accuracy: 0.3900\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0366 - accuracy: 0.9900 - val_loss: 10.5582 - val_accuracy: 0.3840\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0275 - accuracy: 0.9924 - val_loss: 9.3299 - val_accuracy: 0.3840\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0371 - accuracy: 0.9896 - val_loss: 10.0186 - val_accuracy: 0.4140\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.03712816163897514\n",
      "Training Accuracy: 0.9895555377006531\n",
      "Validation Loss: 10.018610000610352\n",
      "Validation Accuracy: 0.414000004529953\n",
      "Classification Error Rate: 0.585999995470047\n",
      "----->Evolution: Child net_10 with fitness 10.018610000610352 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Tournament selection\n",
      "Selected parent_0 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc72722940>, <__main__.Block object at 0x77fc7261db80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 7ms/step - loss: 5.1040 - accuracy: 0.1200 - val_loss: 2.3024 - val_accuracy: 0.1000\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.5612 - accuracy: 0.1100 - val_loss: 2.2868 - val_accuracy: 0.1140\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3419 - accuracy: 0.1198 - val_loss: 2.2842 - val_accuracy: 0.1160\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3565 - accuracy: 0.1298 - val_loss: 2.1797 - val_accuracy: 0.1920\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.0937 - accuracy: 0.2140 - val_loss: 2.2070 - val_accuracy: 0.2240\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.9144 - accuracy: 0.2760 - val_loss: 2.0625 - val_accuracy: 0.2720\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.7447 - accuracy: 0.3616 - val_loss: 1.7733 - val_accuracy: 0.3620\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.5893 - accuracy: 0.4127 - val_loss: 1.9070 - val_accuracy: 0.3560\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.4402 - accuracy: 0.4660 - val_loss: 1.7518 - val_accuracy: 0.4080\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.2915 - accuracy: 0.5304 - val_loss: 1.9309 - val_accuracy: 0.3760\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.1537 - accuracy: 0.5856 - val_loss: 1.9237 - val_accuracy: 0.4180\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.0032 - accuracy: 0.6438 - val_loss: 1.6960 - val_accuracy: 0.4300\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.8660 - accuracy: 0.6860 - val_loss: 2.1733 - val_accuracy: 0.4200\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.7474 - accuracy: 0.7324 - val_loss: 1.9486 - val_accuracy: 0.4400\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6139 - accuracy: 0.7831 - val_loss: 2.1290 - val_accuracy: 0.4340\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.5112 - accuracy: 0.8173 - val_loss: 2.5117 - val_accuracy: 0.4380\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.4240 - accuracy: 0.8484 - val_loss: 2.4678 - val_accuracy: 0.4420\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3434 - accuracy: 0.8844 - val_loss: 2.9898 - val_accuracy: 0.4240\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2921 - accuracy: 0.9020 - val_loss: 3.6538 - val_accuracy: 0.4140\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2572 - accuracy: 0.9096 - val_loss: 3.9884 - val_accuracy: 0.3920\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2230 - accuracy: 0.9289 - val_loss: 3.3332 - val_accuracy: 0.4500\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1807 - accuracy: 0.9404 - val_loss: 4.1203 - val_accuracy: 0.4540\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1639 - accuracy: 0.9447 - val_loss: 4.1676 - val_accuracy: 0.4360\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1485 - accuracy: 0.9509 - val_loss: 4.6484 - val_accuracy: 0.4000\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1183 - accuracy: 0.9604 - val_loss: 4.2661 - val_accuracy: 0.4380\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1141 - accuracy: 0.9589 - val_loss: 4.3629 - val_accuracy: 0.4280\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1082 - accuracy: 0.9667 - val_loss: 4.8942 - val_accuracy: 0.4280\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1031 - accuracy: 0.9696 - val_loss: 5.0842 - val_accuracy: 0.4100\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0911 - accuracy: 0.9709 - val_loss: 5.4593 - val_accuracy: 0.4320\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0814 - accuracy: 0.9731 - val_loss: 5.3074 - val_accuracy: 0.4520\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0705 - accuracy: 0.9796 - val_loss: 6.2232 - val_accuracy: 0.4160\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0743 - accuracy: 0.9742 - val_loss: 5.8117 - val_accuracy: 0.4280\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0624 - accuracy: 0.9816 - val_loss: 6.3248 - val_accuracy: 0.4380\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0757 - accuracy: 0.9782 - val_loss: 6.6871 - val_accuracy: 0.4080\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0777 - accuracy: 0.9771 - val_loss: 6.8319 - val_accuracy: 0.4400\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0591 - accuracy: 0.9811 - val_loss: 7.1169 - val_accuracy: 0.4300\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0476 - accuracy: 0.9838 - val_loss: 6.6143 - val_accuracy: 0.4180\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0685 - accuracy: 0.9816 - val_loss: 7.0312 - val_accuracy: 0.4160\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0599 - accuracy: 0.9820 - val_loss: 7.7229 - val_accuracy: 0.4140\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0524 - accuracy: 0.9856 - val_loss: 6.6639 - val_accuracy: 0.4260\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0661 - accuracy: 0.9831 - val_loss: 7.8888 - val_accuracy: 0.4080\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0554 - accuracy: 0.9833 - val_loss: 8.2940 - val_accuracy: 0.4080\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0428 - accuracy: 0.9864 - val_loss: 8.1462 - val_accuracy: 0.4320\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0403 - accuracy: 0.9876 - val_loss: 9.2983 - val_accuracy: 0.3920\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0487 - accuracy: 0.9873 - val_loss: 8.0972 - val_accuracy: 0.4020\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0700 - accuracy: 0.9842 - val_loss: 8.2808 - val_accuracy: 0.4200\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0379 - accuracy: 0.9893 - val_loss: 9.5227 - val_accuracy: 0.4060\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0427 - accuracy: 0.9873 - val_loss: 9.5660 - val_accuracy: 0.4000\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0592 - accuracy: 0.9851 - val_loss: 8.4918 - val_accuracy: 0.4280\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0384 - accuracy: 0.9898 - val_loss: 9.4028 - val_accuracy: 0.3940\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 0.03841961547732353\n",
      "Training Accuracy: 0.9897778034210205\n",
      "Validation Loss: 9.40279483795166\n",
      "Validation Accuracy: 0.39399999380111694\n",
      "Classification Error Rate: 0.6060000061988831\n",
      "----->Evolution: Child net_11 with fitness 9.40279483795166 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Tournament selection\n",
      "Selected net_1 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc70b3a940>, <__main__.Block object at 0x77fc70bd8540>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 6ms/step - loss: 6.0802 - accuracy: 0.2300 - val_loss: 2.2803 - val_accuracy: 0.2920\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.9359 - accuracy: 0.3442 - val_loss: 1.9283 - val_accuracy: 0.3300\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.6122 - accuracy: 0.4284 - val_loss: 1.7890 - val_accuracy: 0.3880\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.3370 - accuracy: 0.5318 - val_loss: 2.1679 - val_accuracy: 0.3580\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.0624 - accuracy: 0.6238 - val_loss: 1.8007 - val_accuracy: 0.4280\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.8164 - accuracy: 0.7140 - val_loss: 2.0541 - val_accuracy: 0.4480\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6066 - accuracy: 0.7811 - val_loss: 2.2774 - val_accuracy: 0.4240\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.4480 - accuracy: 0.8531 - val_loss: 2.3173 - val_accuracy: 0.4640\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3231 - accuracy: 0.8958 - val_loss: 2.5364 - val_accuracy: 0.4680\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2258 - accuracy: 0.9240 - val_loss: 3.2824 - val_accuracy: 0.4780\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1734 - accuracy: 0.9413 - val_loss: 3.2594 - val_accuracy: 0.4480\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1341 - accuracy: 0.9562 - val_loss: 3.9296 - val_accuracy: 0.4640\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1082 - accuracy: 0.9678 - val_loss: 4.4970 - val_accuracy: 0.4480\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0908 - accuracy: 0.9687 - val_loss: 3.6672 - val_accuracy: 0.4700\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0743 - accuracy: 0.9771 - val_loss: 4.0939 - val_accuracy: 0.4780\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0610 - accuracy: 0.9813 - val_loss: 4.1116 - val_accuracy: 0.4480\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0505 - accuracy: 0.9864 - val_loss: 5.3132 - val_accuracy: 0.4520\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0643 - accuracy: 0.9813 - val_loss: 5.0001 - val_accuracy: 0.4540\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0503 - accuracy: 0.9842 - val_loss: 5.2272 - val_accuracy: 0.4520\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0528 - accuracy: 0.9847 - val_loss: 5.5540 - val_accuracy: 0.4520\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0532 - accuracy: 0.9836 - val_loss: 5.8768 - val_accuracy: 0.4500\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0458 - accuracy: 0.9840 - val_loss: 5.4174 - val_accuracy: 0.4760\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0355 - accuracy: 0.9900 - val_loss: 5.4725 - val_accuracy: 0.4720\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0352 - accuracy: 0.9909 - val_loss: 6.1877 - val_accuracy: 0.4700\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0441 - accuracy: 0.9887 - val_loss: 5.8070 - val_accuracy: 0.4840\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 6.8605 - val_accuracy: 0.4480\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0397 - accuracy: 0.9893 - val_loss: 6.1642 - val_accuracy: 0.4520\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0350 - accuracy: 0.9896 - val_loss: 6.6104 - val_accuracy: 0.4480\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0287 - accuracy: 0.9913 - val_loss: 7.0314 - val_accuracy: 0.4720\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0424 - accuracy: 0.9873 - val_loss: 7.1816 - val_accuracy: 0.4660\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0416 - accuracy: 0.9891 - val_loss: 8.6529 - val_accuracy: 0.4520\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0313 - accuracy: 0.9918 - val_loss: 9.1326 - val_accuracy: 0.4460\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0405 - accuracy: 0.9904 - val_loss: 7.4757 - val_accuracy: 0.4500\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0165 - accuracy: 0.9956 - val_loss: 8.2169 - val_accuracy: 0.4440\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0281 - accuracy: 0.9920 - val_loss: 8.1856 - val_accuracy: 0.4700\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0261 - accuracy: 0.9909 - val_loss: 8.7415 - val_accuracy: 0.4640\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0426 - accuracy: 0.9904 - val_loss: 9.0023 - val_accuracy: 0.4800\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 8.3851 - val_accuracy: 0.4540\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0238 - accuracy: 0.9938 - val_loss: 7.8697 - val_accuracy: 0.4600\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0463 - accuracy: 0.9918 - val_loss: 8.6456 - val_accuracy: 0.4700\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0323 - accuracy: 0.9916 - val_loss: 8.5989 - val_accuracy: 0.4940\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0337 - accuracy: 0.9918 - val_loss: 9.0385 - val_accuracy: 0.4580\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0232 - accuracy: 0.9949 - val_loss: 8.9357 - val_accuracy: 0.4720\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0286 - accuracy: 0.9929 - val_loss: 9.0144 - val_accuracy: 0.4640\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0305 - accuracy: 0.9922 - val_loss: 8.7312 - val_accuracy: 0.4660\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 9.6963 - val_accuracy: 0.4400\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 9.1584 - val_accuracy: 0.4700\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 0.9984 - val_loss: 9.4806 - val_accuracy: 0.4560\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0187 - accuracy: 0.9971 - val_loss: 10.1498 - val_accuracy: 0.4440\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 9.6101 - val_accuracy: 0.4640\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 0.004290296696126461\n",
      "Training Accuracy: 0.9988889098167419\n",
      "Validation Loss: 9.610097885131836\n",
      "Validation Accuracy: 0.46399998664855957\n",
      "Classification Error Rate: 0.5360000133514404\n",
      "----->Evolution: Child net_12 with fitness 9.610097885131836 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Tournament selection\n",
      "Selected net_6 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc705e2940>, <__main__.Block object at 0x77fc705c0540>, <__main__.Block object at 0x77fc7059d7c0>, <__main__.Block object at 0x77fc70401240>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 6ms/step - loss: 2.1510 - accuracy: 0.1989 - val_loss: 2.0843 - val_accuracy: 0.2060\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.8787 - accuracy: 0.3029 - val_loss: 2.1208 - val_accuracy: 0.2900\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.7174 - accuracy: 0.3631 - val_loss: 1.9843 - val_accuracy: 0.2840\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.6016 - accuracy: 0.4149 - val_loss: 1.6654 - val_accuracy: 0.3900\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.5018 - accuracy: 0.4540 - val_loss: 1.6356 - val_accuracy: 0.4160\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.4348 - accuracy: 0.4853 - val_loss: 1.5545 - val_accuracy: 0.4640\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.3608 - accuracy: 0.5136 - val_loss: 1.6992 - val_accuracy: 0.4280\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2990 - accuracy: 0.5344 - val_loss: 1.6800 - val_accuracy: 0.4240\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2525 - accuracy: 0.5516 - val_loss: 1.4919 - val_accuracy: 0.4660\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2108 - accuracy: 0.5647 - val_loss: 1.6734 - val_accuracy: 0.4640\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.1452 - accuracy: 0.5880 - val_loss: 1.9061 - val_accuracy: 0.4140\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.1026 - accuracy: 0.6002 - val_loss: 1.7902 - val_accuracy: 0.4640\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.0558 - accuracy: 0.6196 - val_loss: 1.7143 - val_accuracy: 0.4800\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0136 - accuracy: 0.6462 - val_loss: 1.6358 - val_accuracy: 0.5140\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9590 - accuracy: 0.6664 - val_loss: 2.4376 - val_accuracy: 0.4120\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9180 - accuracy: 0.6747 - val_loss: 2.1926 - val_accuracy: 0.4580\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8872 - accuracy: 0.6904 - val_loss: 2.0846 - val_accuracy: 0.4600\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8281 - accuracy: 0.7080 - val_loss: 1.9207 - val_accuracy: 0.4660\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8011 - accuracy: 0.7184 - val_loss: 2.6377 - val_accuracy: 0.4520\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7550 - accuracy: 0.7422 - val_loss: 2.6471 - val_accuracy: 0.4660\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7171 - accuracy: 0.7478 - val_loss: 2.6375 - val_accuracy: 0.4500\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6896 - accuracy: 0.7624 - val_loss: 2.3578 - val_accuracy: 0.4860\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6476 - accuracy: 0.7751 - val_loss: 3.8947 - val_accuracy: 0.3880\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6389 - accuracy: 0.7904 - val_loss: 2.9518 - val_accuracy: 0.4580\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5742 - accuracy: 0.8036 - val_loss: 2.5389 - val_accuracy: 0.5280\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5766 - accuracy: 0.8007 - val_loss: 3.2628 - val_accuracy: 0.4700\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5117 - accuracy: 0.8200 - val_loss: 3.0322 - val_accuracy: 0.4860\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5017 - accuracy: 0.8420 - val_loss: 3.3106 - val_accuracy: 0.4620\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.5175 - accuracy: 0.8424 - val_loss: 3.6239 - val_accuracy: 0.4420\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4207 - accuracy: 0.8516 - val_loss: 4.0010 - val_accuracy: 0.4480\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4254 - accuracy: 0.8664 - val_loss: 4.7402 - val_accuracy: 0.4220\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4443 - accuracy: 0.8707 - val_loss: 4.4506 - val_accuracy: 0.4520\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3987 - accuracy: 0.8787 - val_loss: 3.8156 - val_accuracy: 0.4740\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3586 - accuracy: 0.8898 - val_loss: 5.5495 - val_accuracy: 0.4220\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3679 - accuracy: 0.8922 - val_loss: 5.6355 - val_accuracy: 0.4400\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3567 - accuracy: 0.9018 - val_loss: 4.8252 - val_accuracy: 0.4480\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3650 - accuracy: 0.9051 - val_loss: 4.1144 - val_accuracy: 0.4820\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3574 - accuracy: 0.9078 - val_loss: 4.6282 - val_accuracy: 0.4680\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2822 - accuracy: 0.9118 - val_loss: 4.5581 - val_accuracy: 0.4960\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3027 - accuracy: 0.9184 - val_loss: 5.1338 - val_accuracy: 0.4760\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2853 - accuracy: 0.9182 - val_loss: 5.0499 - val_accuracy: 0.4620\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2510 - accuracy: 0.9262 - val_loss: 6.1365 - val_accuracy: 0.4440\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3148 - accuracy: 0.9280 - val_loss: 6.6399 - val_accuracy: 0.4260\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2824 - accuracy: 0.9351 - val_loss: 6.1565 - val_accuracy: 0.4220\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3340 - accuracy: 0.9191 - val_loss: 6.6810 - val_accuracy: 0.4940\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3489 - accuracy: 0.9353 - val_loss: 6.5682 - val_accuracy: 0.4900\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2265 - accuracy: 0.9340 - val_loss: 6.3550 - val_accuracy: 0.4780\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3382 - accuracy: 0.9333 - val_loss: 7.2912 - val_accuracy: 0.4720\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3460 - accuracy: 0.9427 - val_loss: 7.9676 - val_accuracy: 0.4300\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2508 - accuracy: 0.9404 - val_loss: 7.4857 - val_accuracy: 0.4920\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 0.25075510144233704\n",
      "Training Accuracy: 0.9404444694519043\n",
      "Validation Loss: 7.485652446746826\n",
      "Validation Accuracy: 0.492000013589859\n",
      "Classification Error Rate: 0.507999986410141\n",
      "----->Evolution: Child net_13 with fitness 7.485652446746826 replaces parent net_7 with fitness 8.898077011108398\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 3\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Tournament selection\n",
      "Selected parent_0 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc70c03840>, <__main__.Block object at 0x77fc7025ac00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 5ms/step - loss: 2.7779 - accuracy: 0.1069 - val_loss: 2.2365 - val_accuracy: 0.1260\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 2.1212 - accuracy: 0.2049 - val_loss: 1.9069 - val_accuracy: 0.2900\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.9006 - accuracy: 0.2942 - val_loss: 1.7820 - val_accuracy: 0.3180\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.7180 - accuracy: 0.3700 - val_loss: 1.8593 - val_accuracy: 0.3600\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.5403 - accuracy: 0.4351 - val_loss: 1.6934 - val_accuracy: 0.4000\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.4314 - accuracy: 0.4811 - val_loss: 1.6651 - val_accuracy: 0.4280\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2739 - accuracy: 0.5324 - val_loss: 1.7550 - val_accuracy: 0.4620\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.1274 - accuracy: 0.5884 - val_loss: 1.7751 - val_accuracy: 0.4220\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9880 - accuracy: 0.6364 - val_loss: 1.8743 - val_accuracy: 0.4300\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8555 - accuracy: 0.6829 - val_loss: 1.9595 - val_accuracy: 0.4780\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7208 - accuracy: 0.7282 - val_loss: 2.3905 - val_accuracy: 0.4000\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6015 - accuracy: 0.7871 - val_loss: 2.0282 - val_accuracy: 0.4580\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4792 - accuracy: 0.8302 - val_loss: 2.2993 - val_accuracy: 0.4120\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3954 - accuracy: 0.8593 - val_loss: 2.5415 - val_accuracy: 0.4340\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3181 - accuracy: 0.8873 - val_loss: 2.5988 - val_accuracy: 0.4420\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2455 - accuracy: 0.9133 - val_loss: 2.8716 - val_accuracy: 0.4600\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2007 - accuracy: 0.9289 - val_loss: 3.0089 - val_accuracy: 0.4600\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1553 - accuracy: 0.9487 - val_loss: 3.2257 - val_accuracy: 0.4420\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1274 - accuracy: 0.9571 - val_loss: 3.6451 - val_accuracy: 0.4260\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1105 - accuracy: 0.9640 - val_loss: 4.1736 - val_accuracy: 0.4120\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0883 - accuracy: 0.9713 - val_loss: 4.0801 - val_accuracy: 0.4140\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0770 - accuracy: 0.9742 - val_loss: 3.9872 - val_accuracy: 0.4500\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0636 - accuracy: 0.9793 - val_loss: 4.8378 - val_accuracy: 0.4100\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0533 - accuracy: 0.9827 - val_loss: 4.4133 - val_accuracy: 0.4460\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9833 - val_loss: 4.5493 - val_accuracy: 0.4360\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0518 - accuracy: 0.9838 - val_loss: 5.1439 - val_accuracy: 0.4480\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0397 - accuracy: 0.9889 - val_loss: 4.6378 - val_accuracy: 0.4580\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0404 - accuracy: 0.9880 - val_loss: 4.9339 - val_accuracy: 0.4640\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0335 - accuracy: 0.9873 - val_loss: 5.0947 - val_accuracy: 0.4400\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0319 - accuracy: 0.9902 - val_loss: 5.5628 - val_accuracy: 0.4360\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0337 - accuracy: 0.9900 - val_loss: 5.1861 - val_accuracy: 0.4540\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9902 - val_loss: 5.8065 - val_accuracy: 0.4400\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0418 - accuracy: 0.9869 - val_loss: 5.8373 - val_accuracy: 0.4420\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 6.4320 - val_accuracy: 0.4280\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9889 - val_loss: 6.4869 - val_accuracy: 0.4320\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0297 - accuracy: 0.9898 - val_loss: 6.3689 - val_accuracy: 0.4080\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9953 - val_loss: 6.7777 - val_accuracy: 0.3980\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0291 - accuracy: 0.9896 - val_loss: 6.4625 - val_accuracy: 0.4500\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9924 - val_loss: 6.6400 - val_accuracy: 0.4180\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0275 - accuracy: 0.9918 - val_loss: 6.2615 - val_accuracy: 0.4280\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 6.4275 - val_accuracy: 0.4300\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 6.5629 - val_accuracy: 0.4340\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 6.7526 - val_accuracy: 0.4340\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 6.9545 - val_accuracy: 0.4400\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0358 - accuracy: 0.9891 - val_loss: 7.0294 - val_accuracy: 0.4160\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0252 - accuracy: 0.9931 - val_loss: 7.3850 - val_accuracy: 0.4280\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9929 - val_loss: 7.3745 - val_accuracy: 0.4440\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0298 - accuracy: 0.9913 - val_loss: 7.4002 - val_accuracy: 0.4440\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9940 - val_loss: 7.8068 - val_accuracy: 0.4280\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9942 - val_loss: 7.0398 - val_accuracy: 0.4500\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.023730777204036713\n",
      "Training Accuracy: 0.9942222237586975\n",
      "Validation Loss: 7.039821147918701\n",
      "Validation Accuracy: 0.44999998807907104\n",
      "Classification Error Rate: 0.550000011920929\n",
      "----->Evolution: Child net_10 with fitness 7.039821147918701 replaces parent net_4 with fitness 8.527738571166992\n",
      "\n",
      "Creating Child 1\n",
      "----->Tournament selection\n",
      "Selected net_8 and net_6 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  256.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83d1b87c0>, <__main__.Block object at 0x77f83d069240>, <__main__.Block object at 0x77f83cf19240>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 7ms/step - loss: 2.2518 - accuracy: 0.2002 - val_loss: 2.8839 - val_accuracy: 0.2420\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.8164 - accuracy: 0.3589 - val_loss: 2.9473 - val_accuracy: 0.2920\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.6377 - accuracy: 0.4369 - val_loss: 2.2537 - val_accuracy: 0.4200\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.4098 - accuracy: 0.4967 - val_loss: 2.0628 - val_accuracy: 0.4660\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.2329 - accuracy: 0.5673 - val_loss: 2.6763 - val_accuracy: 0.4400\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.0994 - accuracy: 0.6304 - val_loss: 2.5393 - val_accuracy: 0.4460\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.8922 - accuracy: 0.6911 - val_loss: 2.5688 - val_accuracy: 0.4420\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.7404 - accuracy: 0.7524 - val_loss: 2.3678 - val_accuracy: 0.4880\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6339 - accuracy: 0.8042 - val_loss: 3.7369 - val_accuracy: 0.4660\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.5152 - accuracy: 0.8513 - val_loss: 2.7644 - val_accuracy: 0.5040\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3671 - accuracy: 0.8809 - val_loss: 3.9251 - val_accuracy: 0.4560\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3840 - accuracy: 0.9000 - val_loss: 5.1290 - val_accuracy: 0.4300\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3489 - accuracy: 0.9140 - val_loss: 5.2106 - val_accuracy: 0.4860\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2922 - accuracy: 0.9291 - val_loss: 4.6858 - val_accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1891 - accuracy: 0.9429 - val_loss: 5.7029 - val_accuracy: 0.4720\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3210 - accuracy: 0.9358 - val_loss: 7.7315 - val_accuracy: 0.4620\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2434 - accuracy: 0.9451 - val_loss: 7.9662 - val_accuracy: 0.4160\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3396 - accuracy: 0.9467 - val_loss: 11.2873 - val_accuracy: 0.3620\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2491 - accuracy: 0.9498 - val_loss: 7.7243 - val_accuracy: 0.5060\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3274 - accuracy: 0.9484 - val_loss: 7.6515 - val_accuracy: 0.4580\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3020 - accuracy: 0.9529 - val_loss: 7.8637 - val_accuracy: 0.4460\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2533 - accuracy: 0.9551 - val_loss: 7.4522 - val_accuracy: 0.4720\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2022 - accuracy: 0.9578 - val_loss: 7.6052 - val_accuracy: 0.5000\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2302 - accuracy: 0.9516 - val_loss: 10.1578 - val_accuracy: 0.3920\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2271 - accuracy: 0.9598 - val_loss: 7.5471 - val_accuracy: 0.4960\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2319 - accuracy: 0.9611 - val_loss: 9.7146 - val_accuracy: 0.4380\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2168 - accuracy: 0.9640 - val_loss: 7.0575 - val_accuracy: 0.4340\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2427 - accuracy: 0.9602 - val_loss: 9.1310 - val_accuracy: 0.5080\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2181 - accuracy: 0.9627 - val_loss: 10.5444 - val_accuracy: 0.4620\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3567 - accuracy: 0.9647 - val_loss: 10.5253 - val_accuracy: 0.4660\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2915 - accuracy: 0.9667 - val_loss: 10.9231 - val_accuracy: 0.4500\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2257 - accuracy: 0.9687 - val_loss: 10.6149 - val_accuracy: 0.4660\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1719 - accuracy: 0.9633 - val_loss: 8.6123 - val_accuracy: 0.4680\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1916 - accuracy: 0.9689 - val_loss: 9.9950 - val_accuracy: 0.5020\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2901 - accuracy: 0.9693 - val_loss: 16.2500 - val_accuracy: 0.4340\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3755 - accuracy: 0.9620 - val_loss: 9.5004 - val_accuracy: 0.4920\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3406 - accuracy: 0.9700 - val_loss: 12.4089 - val_accuracy: 0.4920\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.4303 - accuracy: 0.9656 - val_loss: 11.0535 - val_accuracy: 0.4920\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2472 - accuracy: 0.9673 - val_loss: 14.3995 - val_accuracy: 0.4720\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3402 - accuracy: 0.9696 - val_loss: 12.1767 - val_accuracy: 0.4760\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2365 - accuracy: 0.9722 - val_loss: 10.8161 - val_accuracy: 0.5040\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2924 - accuracy: 0.9651 - val_loss: 14.7859 - val_accuracy: 0.4760\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.4594 - accuracy: 0.9696 - val_loss: 15.1819 - val_accuracy: 0.5060\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2933 - accuracy: 0.9720 - val_loss: 12.2302 - val_accuracy: 0.4700\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3421 - accuracy: 0.9669 - val_loss: 14.5842 - val_accuracy: 0.4700\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3867 - accuracy: 0.9691 - val_loss: 12.4672 - val_accuracy: 0.4880\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.4123 - accuracy: 0.9707 - val_loss: 16.9426 - val_accuracy: 0.4860\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3781 - accuracy: 0.9742 - val_loss: 11.9121 - val_accuracy: 0.5180\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2996 - accuracy: 0.9722 - val_loss: 22.1689 - val_accuracy: 0.4080\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3064 - accuracy: 0.9691 - val_loss: 13.2505 - val_accuracy: 0.4820\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 0.30638033151626587\n",
      "Training Accuracy: 0.9691110849380493\n",
      "Validation Loss: 13.25045108795166\n",
      "Validation Accuracy: 0.4819999933242798\n",
      "Classification Error Rate: 0.5180000066757202\n",
      "----->Evolution: Child net_11 with fitness 13.25045108795166 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Tournament selection\n",
      "Selected net_1 and net_7 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83cc257c0>, <__main__.Block object at 0x77f83ccbef40>, <__main__.Block object at 0x77fc701baa00>, <__main__.Block object at 0x77f83ccb6940>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_18\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_18/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,32].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_18\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 32), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83cb25600>, <__main__.Block object at 0x77f83ccd98c0>, <__main__.Block object at 0x77f83ccba900>, <__main__.Block object at 0x77f83cb910c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 4s 10ms/step - loss: 2.4046 - accuracy: 0.1158 - val_loss: 2.7354 - val_accuracy: 0.1660\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.2541 - accuracy: 0.2058 - val_loss: 2.3047 - val_accuracy: 0.2380\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.0453 - accuracy: 0.2880 - val_loss: 3.7802 - val_accuracy: 0.1800\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8959 - accuracy: 0.3413 - val_loss: 2.4983 - val_accuracy: 0.2880\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.7386 - accuracy: 0.3909 - val_loss: 5.5015 - val_accuracy: 0.1880\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.7363 - accuracy: 0.4362 - val_loss: 2.8913 - val_accuracy: 0.2780\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.6414 - accuracy: 0.4638 - val_loss: 6.7967 - val_accuracy: 0.3660\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.6705 - accuracy: 0.5024 - val_loss: 4.5696 - val_accuracy: 0.2640\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.0328 - accuracy: 0.5411 - val_loss: 2.8591 - val_accuracy: 0.3300\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.2690 - accuracy: 0.5698 - val_loss: 2.4560 - val_accuracy: 0.4400\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.2172 - accuracy: 0.5967 - val_loss: 3.3173 - val_accuracy: 0.4160\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.1065 - accuracy: 0.6242 - val_loss: 2.3776 - val_accuracy: 0.4320\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.9770 - accuracy: 0.6553 - val_loss: 3.4066 - val_accuracy: 0.4200\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.9664 - accuracy: 0.6984 - val_loss: 6.3181 - val_accuracy: 0.3720\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.9515 - accuracy: 0.7249 - val_loss: 3.6440 - val_accuracy: 0.4100\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.8418 - accuracy: 0.7547 - val_loss: 2.6180 - val_accuracy: 0.5200\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.7293 - accuracy: 0.7760 - val_loss: 6.1040 - val_accuracy: 0.4500\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.6643 - accuracy: 0.8002 - val_loss: 3.8679 - val_accuracy: 0.3900\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.7347 - accuracy: 0.8178 - val_loss: 5.8599 - val_accuracy: 0.4540\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.7409 - accuracy: 0.8404 - val_loss: 3.1841 - val_accuracy: 0.4560\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5140 - accuracy: 0.8609 - val_loss: 7.6238 - val_accuracy: 0.4360\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4561 - accuracy: 0.8689 - val_loss: 5.7751 - val_accuracy: 0.4780\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5475 - accuracy: 0.8796 - val_loss: 4.3389 - val_accuracy: 0.4920\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3531 - accuracy: 0.8976 - val_loss: 8.8028 - val_accuracy: 0.4900\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4030 - accuracy: 0.9011 - val_loss: 5.3287 - val_accuracy: 0.4520\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3737 - accuracy: 0.9124 - val_loss: 8.2930 - val_accuracy: 0.4400\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5062 - accuracy: 0.9107 - val_loss: 5.0433 - val_accuracy: 0.5040\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3298 - accuracy: 0.9140 - val_loss: 7.7234 - val_accuracy: 0.5240\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.9890 - accuracy: 0.9189 - val_loss: 7.9840 - val_accuracy: 0.3980\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2920 - accuracy: 0.9327 - val_loss: 6.0656 - val_accuracy: 0.5100\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5033 - accuracy: 0.9291 - val_loss: 11.1906 - val_accuracy: 0.5260\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.8932 - accuracy: 0.9327 - val_loss: 6.6732 - val_accuracy: 0.4780\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3490 - accuracy: 0.9380 - val_loss: 17.3184 - val_accuracy: 0.5180\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4840 - accuracy: 0.9338 - val_loss: 7.7993 - val_accuracy: 0.4300\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.3879 - accuracy: 0.9324 - val_loss: 9.1904 - val_accuracy: 0.4980\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.3595 - accuracy: 0.9418 - val_loss: 6.5349 - val_accuracy: 0.4900\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3584 - accuracy: 0.9384 - val_loss: 4.2416 - val_accuracy: 0.4940\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2338 - accuracy: 0.9398 - val_loss: 5.6263 - val_accuracy: 0.5340\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3353 - accuracy: 0.9369 - val_loss: 3.8860 - val_accuracy: 0.4980\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2174 - accuracy: 0.9424 - val_loss: 10.3435 - val_accuracy: 0.5580\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.2868 - accuracy: 0.9500 - val_loss: 6.1084 - val_accuracy: 0.5360\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.3965 - accuracy: 0.9476 - val_loss: 31.4987 - val_accuracy: 0.5060\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 3.0932 - accuracy: 0.9436 - val_loss: 6.8716 - val_accuracy: 0.4240\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2569 - accuracy: 0.9429 - val_loss: 8.4214 - val_accuracy: 0.4960\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3542 - accuracy: 0.9451 - val_loss: 13.4543 - val_accuracy: 0.4600\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4130 - accuracy: 0.9533 - val_loss: 5.3539 - val_accuracy: 0.5040\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2160 - accuracy: 0.9458 - val_loss: 3.6804 - val_accuracy: 0.5140\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1817 - accuracy: 0.9524 - val_loss: 3.6873 - val_accuracy: 0.5340\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4166 - accuracy: 0.9484 - val_loss: 5.4518 - val_accuracy: 0.4980\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2136 - accuracy: 0.9493 - val_loss: 4.2360 - val_accuracy: 0.5520\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 0.2136378288269043\n",
      "Training Accuracy: 0.9493333101272583\n",
      "Validation Loss: 4.235955238342285\n",
      "Validation Accuracy: 0.5519999861717224\n",
      "Classification Error Rate: 0.4480000138282776\n",
      "----->Evolution: Child net_12 with fitness 4.235955238342285 replaces parent net_3 with fitness 8.257669448852539\n",
      "\n",
      "Creating Child 3\n",
      "----->Tournament selection\n",
      "Selected net_1 and net_8 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fcf0186cc0>, <__main__.Block object at 0x77fc70c79240>, <__main__.Block object at 0x77fc707b60c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 6ms/step - loss: 2.4957 - accuracy: 0.1402 - val_loss: 2.2775 - val_accuracy: 0.1500\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 2.1274 - accuracy: 0.2602 - val_loss: 1.9718 - val_accuracy: 0.3140\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.8313 - accuracy: 0.3580 - val_loss: 1.7937 - val_accuracy: 0.3180\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.6182 - accuracy: 0.4364 - val_loss: 1.7469 - val_accuracy: 0.4200\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.3885 - accuracy: 0.5207 - val_loss: 1.8694 - val_accuracy: 0.4200\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.1377 - accuracy: 0.6029 - val_loss: 2.2879 - val_accuracy: 0.3460\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9104 - accuracy: 0.6833 - val_loss: 2.1085 - val_accuracy: 0.3900\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7066 - accuracy: 0.7627 - val_loss: 2.7307 - val_accuracy: 0.4120\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5154 - accuracy: 0.8298 - val_loss: 3.8596 - val_accuracy: 0.3940\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3990 - accuracy: 0.8744 - val_loss: 3.9125 - val_accuracy: 0.3800\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2697 - accuracy: 0.9133 - val_loss: 5.7081 - val_accuracy: 0.3940\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2279 - accuracy: 0.9289 - val_loss: 5.3014 - val_accuracy: 0.3740\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1871 - accuracy: 0.9389 - val_loss: 6.7316 - val_accuracy: 0.4000\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1721 - accuracy: 0.9518 - val_loss: 6.8651 - val_accuracy: 0.4000\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1586 - accuracy: 0.9607 - val_loss: 7.1846 - val_accuracy: 0.3980\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1535 - accuracy: 0.9560 - val_loss: 7.6969 - val_accuracy: 0.3600\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1395 - accuracy: 0.9638 - val_loss: 9.1439 - val_accuracy: 0.3820\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1076 - accuracy: 0.9673 - val_loss: 8.4290 - val_accuracy: 0.4020\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1469 - accuracy: 0.9702 - val_loss: 8.6388 - val_accuracy: 0.3940\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1145 - accuracy: 0.9693 - val_loss: 8.8643 - val_accuracy: 0.3540\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1166 - accuracy: 0.9724 - val_loss: 9.1390 - val_accuracy: 0.4000\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0956 - accuracy: 0.9760 - val_loss: 9.6149 - val_accuracy: 0.3880\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1106 - accuracy: 0.9751 - val_loss: 11.5511 - val_accuracy: 0.3740\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0805 - accuracy: 0.9824 - val_loss: 10.5063 - val_accuracy: 0.3880\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0877 - accuracy: 0.9800 - val_loss: 11.1910 - val_accuracy: 0.4020\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0959 - accuracy: 0.9789 - val_loss: 13.0244 - val_accuracy: 0.3740\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1082 - accuracy: 0.9800 - val_loss: 14.3616 - val_accuracy: 0.3820\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1017 - accuracy: 0.9796 - val_loss: 14.3503 - val_accuracy: 0.3880\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1411 - accuracy: 0.9773 - val_loss: 13.3553 - val_accuracy: 0.3860\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1011 - accuracy: 0.9813 - val_loss: 15.7794 - val_accuracy: 0.3820\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1400 - accuracy: 0.9784 - val_loss: 15.0897 - val_accuracy: 0.3920\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0641 - accuracy: 0.9836 - val_loss: 15.4201 - val_accuracy: 0.4000\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1256 - accuracy: 0.9829 - val_loss: 14.9724 - val_accuracy: 0.3980\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1201 - accuracy: 0.9804 - val_loss: 14.4183 - val_accuracy: 0.3800\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1300 - accuracy: 0.9771 - val_loss: 18.6307 - val_accuracy: 0.3820\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1033 - accuracy: 0.9844 - val_loss: 17.3111 - val_accuracy: 0.4100\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1231 - accuracy: 0.9820 - val_loss: 18.7838 - val_accuracy: 0.3680\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1308 - accuracy: 0.9816 - val_loss: 17.1613 - val_accuracy: 0.3880\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1160 - accuracy: 0.9838 - val_loss: 19.6341 - val_accuracy: 0.3860\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0888 - accuracy: 0.9858 - val_loss: 21.6207 - val_accuracy: 0.3760\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1105 - accuracy: 0.9864 - val_loss: 19.6676 - val_accuracy: 0.3860\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0983 - accuracy: 0.9849 - val_loss: 19.4804 - val_accuracy: 0.3800\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1276 - accuracy: 0.9804 - val_loss: 21.8224 - val_accuracy: 0.3880\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1240 - accuracy: 0.9842 - val_loss: 20.7106 - val_accuracy: 0.3760\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0905 - accuracy: 0.9844 - val_loss: 22.9579 - val_accuracy: 0.3900\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1128 - accuracy: 0.9840 - val_loss: 18.1415 - val_accuracy: 0.3780\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0838 - accuracy: 0.9862 - val_loss: 24.5359 - val_accuracy: 0.3800\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1548 - accuracy: 0.9827 - val_loss: 19.8459 - val_accuracy: 0.3840\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1242 - accuracy: 0.9849 - val_loss: 26.1152 - val_accuracy: 0.3780\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1474 - accuracy: 0.9816 - val_loss: 22.2610 - val_accuracy: 0.3980\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 0.1473693996667862\n",
      "Training Accuracy: 0.9815555810928345\n",
      "Validation Loss: 22.261005401611328\n",
      "Validation Accuracy: 0.39800000190734863\n",
      "Classification Error Rate: 0.6019999980926514\n",
      "----->Evolution: Child net_13 with fitness 22.261005401611328 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 4\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  64.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc709dd7c0>, <__main__.Block object at 0x77fc70910540>, <__main__.Block object at 0x77fc70ab9f40>, <__main__.Block object at 0x77fc72531240>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 4s 10ms/step - loss: 2.5606 - accuracy: 0.1136 - val_loss: 2.8650 - val_accuracy: 0.0960\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.3017 - accuracy: 0.1367 - val_loss: 3.8661 - val_accuracy: 0.1920\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.1848 - accuracy: 0.2227 - val_loss: 6.4164 - val_accuracy: 0.1540\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.9922 - accuracy: 0.2896 - val_loss: 2.5763 - val_accuracy: 0.2920\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.8257 - accuracy: 0.3518 - val_loss: 3.3635 - val_accuracy: 0.3320\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.7515 - accuracy: 0.3940 - val_loss: 3.3783 - val_accuracy: 0.2340\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.5827 - accuracy: 0.4364 - val_loss: 2.4657 - val_accuracy: 0.4280\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4945 - accuracy: 0.4702 - val_loss: 2.8502 - val_accuracy: 0.3320\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4414 - accuracy: 0.4956 - val_loss: 2.3872 - val_accuracy: 0.4180\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3616 - accuracy: 0.5391 - val_loss: 2.1805 - val_accuracy: 0.3840\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.2006 - accuracy: 0.5740 - val_loss: 6.2658 - val_accuracy: 0.3840\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.1092 - accuracy: 0.6184 - val_loss: 2.0571 - val_accuracy: 0.4640\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.9955 - accuracy: 0.6516 - val_loss: 2.2118 - val_accuracy: 0.4760\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.9190 - accuracy: 0.6862 - val_loss: 4.5343 - val_accuracy: 0.4280\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8857 - accuracy: 0.7224 - val_loss: 3.4820 - val_accuracy: 0.4800\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.7372 - accuracy: 0.7587 - val_loss: 2.0863 - val_accuracy: 0.4860\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.6811 - accuracy: 0.7704 - val_loss: 3.2354 - val_accuracy: 0.4860\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.7226 - accuracy: 0.7956 - val_loss: 3.0491 - val_accuracy: 0.4400\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5564 - accuracy: 0.8229 - val_loss: 3.4228 - val_accuracy: 0.4800\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5425 - accuracy: 0.8378 - val_loss: 4.3252 - val_accuracy: 0.4180\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4810 - accuracy: 0.8513 - val_loss: 8.3821 - val_accuracy: 0.4420\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.6862 - accuracy: 0.8693 - val_loss: 4.4520 - val_accuracy: 0.4500\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5426 - accuracy: 0.8707 - val_loss: 4.4105 - val_accuracy: 0.4580\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4329 - accuracy: 0.8847 - val_loss: 3.8736 - val_accuracy: 0.4660\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4325 - accuracy: 0.8800 - val_loss: 5.2949 - val_accuracy: 0.4560\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5348 - accuracy: 0.8960 - val_loss: 6.7425 - val_accuracy: 0.3600\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4399 - accuracy: 0.8878 - val_loss: 4.1565 - val_accuracy: 0.4700\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4089 - accuracy: 0.9058 - val_loss: 5.9391 - val_accuracy: 0.4620\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5220 - accuracy: 0.9051 - val_loss: 6.2098 - val_accuracy: 0.4240\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4467 - accuracy: 0.9147 - val_loss: 9.1727 - val_accuracy: 0.4380\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4614 - accuracy: 0.9133 - val_loss: 5.6892 - val_accuracy: 0.4640\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4109 - accuracy: 0.9104 - val_loss: 4.7639 - val_accuracy: 0.4860\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5191 - accuracy: 0.9120 - val_loss: 5.6066 - val_accuracy: 0.4820\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4474 - accuracy: 0.9233 - val_loss: 15.3753 - val_accuracy: 0.4200\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.6395 - accuracy: 0.9178 - val_loss: 10.6792 - val_accuracy: 0.4220\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.5452 - accuracy: 0.9209 - val_loss: 6.4840 - val_accuracy: 0.4660\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.3675 - accuracy: 0.9173 - val_loss: 14.6396 - val_accuracy: 0.4580\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.0329 - accuracy: 0.9233 - val_loss: 9.0206 - val_accuracy: 0.4920\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5617 - accuracy: 0.9200 - val_loss: 10.1536 - val_accuracy: 0.4420\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.6015 - accuracy: 0.9138 - val_loss: 7.8556 - val_accuracy: 0.4640\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.4460 - accuracy: 0.9213 - val_loss: 11.9081 - val_accuracy: 0.4360\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5409 - accuracy: 0.9251 - val_loss: 10.2457 - val_accuracy: 0.4440\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.7905 - accuracy: 0.9240 - val_loss: 10.1112 - val_accuracy: 0.4580\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.7096 - accuracy: 0.9216 - val_loss: 9.3653 - val_accuracy: 0.4180\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.6227 - accuracy: 0.9273 - val_loss: 15.0686 - val_accuracy: 0.4000\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.0123 - accuracy: 0.9231 - val_loss: 8.5199 - val_accuracy: 0.4860\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8295 - accuracy: 0.9324 - val_loss: 12.6445 - val_accuracy: 0.4200\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.6641 - accuracy: 0.9336 - val_loss: 10.4160 - val_accuracy: 0.4160\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.6033 - accuracy: 0.9151 - val_loss: 16.3259 - val_accuracy: 0.4540\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5794 - accuracy: 0.9249 - val_loss: 11.7917 - val_accuracy: 0.4460\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.5793876051902771\n",
      "Training Accuracy: 0.9248889088630676\n",
      "Validation Loss: 11.79173469543457\n",
      "Validation Accuracy: 0.44600000977516174\n",
      "Classification Error Rate: 0.5539999902248383\n",
      "----->Evolution: Child net_10 with fitness 11.79173469543457 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  256.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc72d757c0>, <__main__.Block object at 0x77f8372d8540>, <__main__.Block object at 0x77fcd7ff5580>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 7ms/step - loss: 2.6656 - accuracy: 0.1338 - val_loss: 2.1933 - val_accuracy: 0.1800\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.1375 - accuracy: 0.2420 - val_loss: 3.7322 - val_accuracy: 0.1280\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.8484 - accuracy: 0.3553 - val_loss: 1.8257 - val_accuracy: 0.3580\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.6124 - accuracy: 0.4313 - val_loss: 1.6761 - val_accuracy: 0.4120\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.4283 - accuracy: 0.4982 - val_loss: 1.8029 - val_accuracy: 0.4040\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.2180 - accuracy: 0.5689 - val_loss: 1.8882 - val_accuracy: 0.4380\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.0171 - accuracy: 0.6482 - val_loss: 2.0079 - val_accuracy: 0.4340\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.8634 - accuracy: 0.7040 - val_loss: 2.3118 - val_accuracy: 0.4040\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.7016 - accuracy: 0.7631 - val_loss: 2.7479 - val_accuracy: 0.4380\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.5973 - accuracy: 0.8009 - val_loss: 3.1622 - val_accuracy: 0.4400\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.5058 - accuracy: 0.8436 - val_loss: 3.3529 - val_accuracy: 0.4560\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.5014 - accuracy: 0.8533 - val_loss: 4.4311 - val_accuracy: 0.4260\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.4828 - accuracy: 0.8720 - val_loss: 5.5861 - val_accuracy: 0.4400\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.4673 - accuracy: 0.8822 - val_loss: 4.6095 - val_accuracy: 0.4580\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.4257 - accuracy: 0.8931 - val_loss: 5.6264 - val_accuracy: 0.4480\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.5186 - accuracy: 0.8889 - val_loss: 6.2680 - val_accuracy: 0.4500\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.4255 - accuracy: 0.9067 - val_loss: 8.4881 - val_accuracy: 0.4380\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.5750 - accuracy: 0.8996 - val_loss: 10.0742 - val_accuracy: 0.3800\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.7178 - accuracy: 0.8882 - val_loss: 11.0546 - val_accuracy: 0.4200\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.5574 - accuracy: 0.9058 - val_loss: 8.9165 - val_accuracy: 0.4340\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6594 - accuracy: 0.9071 - val_loss: 11.9999 - val_accuracy: 0.4360\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6242 - accuracy: 0.9160 - val_loss: 14.4214 - val_accuracy: 0.4380\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6502 - accuracy: 0.9204 - val_loss: 14.1586 - val_accuracy: 0.4480\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6543 - accuracy: 0.9198 - val_loss: 15.1715 - val_accuracy: 0.4320\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6766 - accuracy: 0.9224 - val_loss: 14.1969 - val_accuracy: 0.4460\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.6628 - accuracy: 0.9347 - val_loss: 18.0784 - val_accuracy: 0.4400\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.7737 - accuracy: 0.9298 - val_loss: 16.4133 - val_accuracy: 0.4220\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6342 - accuracy: 0.9324 - val_loss: 15.3140 - val_accuracy: 0.4100\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6365 - accuracy: 0.9369 - val_loss: 26.6878 - val_accuracy: 0.4160\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.7703 - accuracy: 0.9389 - val_loss: 20.2458 - val_accuracy: 0.4300\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.7991 - accuracy: 0.9333 - val_loss: 26.9908 - val_accuracy: 0.3860\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.0677 - accuracy: 0.9347 - val_loss: 36.0203 - val_accuracy: 0.4640\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.0167 - accuracy: 0.9396 - val_loss: 21.6788 - val_accuracy: 0.4500\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.8046 - accuracy: 0.9496 - val_loss: 33.4200 - val_accuracy: 0.4480\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.0077 - accuracy: 0.9402 - val_loss: 36.8608 - val_accuracy: 0.4460\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.9539 - accuracy: 0.9487 - val_loss: 45.5576 - val_accuracy: 0.4300\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.1111 - accuracy: 0.9487 - val_loss: 34.7923 - val_accuracy: 0.4000\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.7847 - accuracy: 0.9558 - val_loss: 41.5248 - val_accuracy: 0.4320\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.1787 - accuracy: 0.9476 - val_loss: 43.2041 - val_accuracy: 0.4480\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.2205 - accuracy: 0.9524 - val_loss: 48.8285 - val_accuracy: 0.4720\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.2611 - accuracy: 0.9520 - val_loss: 44.0575 - val_accuracy: 0.4420\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.0412 - accuracy: 0.9556 - val_loss: 51.2663 - val_accuracy: 0.4420\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.0354 - accuracy: 0.9576 - val_loss: 67.6231 - val_accuracy: 0.4420\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.7983 - accuracy: 0.9476 - val_loss: 65.4211 - val_accuracy: 0.4300\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.0280 - accuracy: 0.9531 - val_loss: 69.1436 - val_accuracy: 0.4380\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.8480 - accuracy: 0.9531 - val_loss: 82.5155 - val_accuracy: 0.4480\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.1544 - accuracy: 0.9558 - val_loss: 85.8425 - val_accuracy: 0.4400\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.0336 - accuracy: 0.9511 - val_loss: 74.4124 - val_accuracy: 0.4400\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.7782 - accuracy: 0.9589 - val_loss: 61.7325 - val_accuracy: 0.4520\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.9292 - accuracy: 0.9567 - val_loss: 96.2712 - val_accuracy: 0.4400\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 1.9291621446609497\n",
      "Training Accuracy: 0.9566666483879089\n",
      "Validation Loss: 96.27122497558594\n",
      "Validation Accuracy: 0.4399999976158142\n",
      "Classification Error Rate: 0.5600000023841858\n",
      "----->Evolution: Child net_11 with fitness 96.27122497558594 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  128.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83cfdd600>, <__main__.Block object at 0x77fcdc6c0540>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 6ms/step - loss: 3.6237 - accuracy: 0.2284 - val_loss: 2.0901 - val_accuracy: 0.2520\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.8288 - accuracy: 0.3507 - val_loss: 1.8402 - val_accuracy: 0.3740\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.4929 - accuracy: 0.4691 - val_loss: 1.6922 - val_accuracy: 0.4280\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2092 - accuracy: 0.5649 - val_loss: 1.8288 - val_accuracy: 0.4120\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9220 - accuracy: 0.6753 - val_loss: 1.7471 - val_accuracy: 0.4520\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6484 - accuracy: 0.7851 - val_loss: 1.9057 - val_accuracy: 0.4200\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.4441 - accuracy: 0.8498 - val_loss: 2.4795 - val_accuracy: 0.4460\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2994 - accuracy: 0.8962 - val_loss: 2.2619 - val_accuracy: 0.4600\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1929 - accuracy: 0.9411 - val_loss: 2.5113 - val_accuracy: 0.4560\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1380 - accuracy: 0.9580 - val_loss: 2.8062 - val_accuracy: 0.4480\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1039 - accuracy: 0.9673 - val_loss: 3.1859 - val_accuracy: 0.4520\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0763 - accuracy: 0.9733 - val_loss: 3.1403 - val_accuracy: 0.4560\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0615 - accuracy: 0.9807 - val_loss: 3.4431 - val_accuracy: 0.4700\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0394 - accuracy: 0.9887 - val_loss: 4.0371 - val_accuracy: 0.4760\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0435 - accuracy: 0.9876 - val_loss: 3.7700 - val_accuracy: 0.4960\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0440 - accuracy: 0.9860 - val_loss: 3.9110 - val_accuracy: 0.4540\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9898 - val_loss: 4.1377 - val_accuracy: 0.4820\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0302 - accuracy: 0.9913 - val_loss: 4.2086 - val_accuracy: 0.4680\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0276 - accuracy: 0.9909 - val_loss: 4.2667 - val_accuracy: 0.4740\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0122 - accuracy: 0.9973 - val_loss: 4.6564 - val_accuracy: 0.4660\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0152 - accuracy: 0.9964 - val_loss: 5.0094 - val_accuracy: 0.4740\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0204 - accuracy: 0.9924 - val_loss: 5.1096 - val_accuracy: 0.4680\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 5.3221 - val_accuracy: 0.4680\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0193 - accuracy: 0.9929 - val_loss: 5.3435 - val_accuracy: 0.4840\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 5.3970 - val_accuracy: 0.4600\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 5.6903 - val_accuracy: 0.5020\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0311 - accuracy: 0.9904 - val_loss: 4.9088 - val_accuracy: 0.4860\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0224 - accuracy: 0.9933 - val_loss: 5.8269 - val_accuracy: 0.4560\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 5.9560 - val_accuracy: 0.4740\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 6.0513 - val_accuracy: 0.5000\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9931 - val_loss: 6.5878 - val_accuracy: 0.5080\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 6.4626 - val_accuracy: 0.4800\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0281 - accuracy: 0.9911 - val_loss: 6.6236 - val_accuracy: 0.4900\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0183 - accuracy: 0.9933 - val_loss: 6.3964 - val_accuracy: 0.4560\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 6.1293 - val_accuracy: 0.4780\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 0.9960 - val_loss: 6.1940 - val_accuracy: 0.5160\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 7.0193 - val_accuracy: 0.4980\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0318 - accuracy: 0.9909 - val_loss: 6.7072 - val_accuracy: 0.4720\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0177 - accuracy: 0.9949 - val_loss: 7.3424 - val_accuracy: 0.4820\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 6.8114 - val_accuracy: 0.4720\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0126 - accuracy: 0.9956 - val_loss: 7.1648 - val_accuracy: 0.4740\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0182 - accuracy: 0.9949 - val_loss: 7.4049 - val_accuracy: 0.4620\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 7.8864 - val_accuracy: 0.4520\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0234 - accuracy: 0.9936 - val_loss: 8.2417 - val_accuracy: 0.4800\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0326 - accuracy: 0.9920 - val_loss: 7.1242 - val_accuracy: 0.4940\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 7.3517 - val_accuracy: 0.5120\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0217 - accuracy: 0.9951 - val_loss: 7.7791 - val_accuracy: 0.4560\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0178 - accuracy: 0.9953 - val_loss: 8.2704 - val_accuracy: 0.4640\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0329 - accuracy: 0.9918 - val_loss: 8.4693 - val_accuracy: 0.4800\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0164 - accuracy: 0.9958 - val_loss: 7.8725 - val_accuracy: 0.4780\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 0.016359437257051468\n",
      "Training Accuracy: 0.9957777857780457\n",
      "Validation Loss: 7.872542381286621\n",
      "Validation Accuracy: 0.4779999852180481\n",
      "Classification Error Rate: 0.5220000147819519\n",
      "----->Evolution: Child net_12 with fitness 7.872542381286621 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc70445600>, <__main__.Block object at 0x77fc72ea5b80>, <__main__.Block object at 0x77fc7286d7c0>, <__main__.Block object at 0x77fc72e88ec0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_99. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 4s 12ms/step - loss: 2.7247 - accuracy: 0.1044 - val_loss: 3.5406 - val_accuracy: 0.1220\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 2.3844 - accuracy: 0.1442 - val_loss: 2.1721 - val_accuracy: 0.1840\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 2.1417 - accuracy: 0.2167 - val_loss: 2.3298 - val_accuracy: 0.1600\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.9693 - accuracy: 0.2678 - val_loss: 2.0053 - val_accuracy: 0.2880\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.8816 - accuracy: 0.3111 - val_loss: 1.9073 - val_accuracy: 0.2900\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.7608 - accuracy: 0.3511 - val_loss: 2.1072 - val_accuracy: 0.3140\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.6621 - accuracy: 0.4058 - val_loss: 2.0468 - val_accuracy: 0.3340\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.5697 - accuracy: 0.4298 - val_loss: 1.7628 - val_accuracy: 0.3520\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.4876 - accuracy: 0.4660 - val_loss: 1.7346 - val_accuracy: 0.3860\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.4202 - accuracy: 0.4900 - val_loss: 1.6778 - val_accuracy: 0.4800\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.3381 - accuracy: 0.5202 - val_loss: 1.9199 - val_accuracy: 0.3680\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.2429 - accuracy: 0.5451 - val_loss: 1.7077 - val_accuracy: 0.4540\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.1952 - accuracy: 0.5813 - val_loss: 1.8623 - val_accuracy: 0.4540\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.0856 - accuracy: 0.6198 - val_loss: 2.1981 - val_accuracy: 0.4080\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.0189 - accuracy: 0.6364 - val_loss: 2.8652 - val_accuracy: 0.4060\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.9441 - accuracy: 0.6600 - val_loss: 2.1374 - val_accuracy: 0.4160\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.9033 - accuracy: 0.6922 - val_loss: 1.9668 - val_accuracy: 0.4120\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.8051 - accuracy: 0.7153 - val_loss: 2.5012 - val_accuracy: 0.4300\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.7375 - accuracy: 0.7393 - val_loss: 2.4006 - val_accuracy: 0.4400\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.6835 - accuracy: 0.7653 - val_loss: 3.8245 - val_accuracy: 0.4120\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.6134 - accuracy: 0.7844 - val_loss: 3.0285 - val_accuracy: 0.3980\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.6072 - accuracy: 0.7958 - val_loss: 2.4682 - val_accuracy: 0.4540\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.5711 - accuracy: 0.8036 - val_loss: 3.3357 - val_accuracy: 0.4400\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.5440 - accuracy: 0.8209 - val_loss: 2.3674 - val_accuracy: 0.4780\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.5244 - accuracy: 0.8264 - val_loss: 2.8489 - val_accuracy: 0.3500\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.4908 - accuracy: 0.8429 - val_loss: 3.1674 - val_accuracy: 0.4360\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.4641 - accuracy: 0.8538 - val_loss: 3.4410 - val_accuracy: 0.3980\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.4923 - accuracy: 0.8442 - val_loss: 2.7769 - val_accuracy: 0.4700\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.4372 - accuracy: 0.8620 - val_loss: 4.2903 - val_accuracy: 0.4420\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.4604 - accuracy: 0.8602 - val_loss: 4.4735 - val_accuracy: 0.3780\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.4490 - accuracy: 0.8680 - val_loss: 3.2086 - val_accuracy: 0.5160\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.3747 - accuracy: 0.8847 - val_loss: 4.4607 - val_accuracy: 0.4680\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.4272 - accuracy: 0.8747 - val_loss: 3.9805 - val_accuracy: 0.4460\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.3858 - accuracy: 0.8922 - val_loss: 4.4890 - val_accuracy: 0.4740\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.4635 - accuracy: 0.8724 - val_loss: 4.1842 - val_accuracy: 0.4660\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.3901 - accuracy: 0.8880 - val_loss: 4.0619 - val_accuracy: 0.3960\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.3929 - accuracy: 0.8873 - val_loss: 4.1033 - val_accuracy: 0.4620\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.4305 - accuracy: 0.8907 - val_loss: 4.5333 - val_accuracy: 0.4340\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.4073 - accuracy: 0.8936 - val_loss: 4.9269 - val_accuracy: 0.4640\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.3854 - accuracy: 0.8936 - val_loss: 3.5800 - val_accuracy: 0.4600\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.3730 - accuracy: 0.8978 - val_loss: 6.0336 - val_accuracy: 0.3960\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.4050 - accuracy: 0.8958 - val_loss: 4.5140 - val_accuracy: 0.4560\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.3992 - accuracy: 0.8969 - val_loss: 4.6284 - val_accuracy: 0.4720\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.3699 - accuracy: 0.9051 - val_loss: 6.5411 - val_accuracy: 0.4720\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.3736 - accuracy: 0.9049 - val_loss: 3.7904 - val_accuracy: 0.4460\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.3638 - accuracy: 0.8982 - val_loss: 4.3242 - val_accuracy: 0.4580\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.3913 - accuracy: 0.8971 - val_loss: 4.2364 - val_accuracy: 0.5040\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.3762 - accuracy: 0.9087 - val_loss: 5.6852 - val_accuracy: 0.4560\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.3960 - accuracy: 0.9073 - val_loss: 4.5579 - val_accuracy: 0.4120\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.3909 - accuracy: 0.8998 - val_loss: 5.1981 - val_accuracy: 0.4600\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 0.39087799191474915\n",
      "Training Accuracy: 0.8997777700424194\n",
      "Validation Loss: 5.19811487197876\n",
      "Validation Accuracy: 0.46000000834465027\n",
      "Classification Error Rate: 0.5399999916553497\n",
      "----->Evolution: Child net_13 with fitness 5.19811487197876 replaces parent parent_0 with fitness 7.608337879180908\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 5\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Proportionate selection\n",
      "Selected net_7 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83d73d7c0>, <__main__.Block object at 0x77f83d749300>, <__main__.Block object at 0x77fc72d60980>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 5ms/step - loss: 2.0163 - accuracy: 0.2658 - val_loss: 1.7079 - val_accuracy: 0.3940\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.6250 - accuracy: 0.4218 - val_loss: 1.7430 - val_accuracy: 0.3800\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.4033 - accuracy: 0.5042 - val_loss: 1.5681 - val_accuracy: 0.4440\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.1911 - accuracy: 0.5833 - val_loss: 1.6025 - val_accuracy: 0.4880\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0118 - accuracy: 0.6489 - val_loss: 1.4724 - val_accuracy: 0.5060\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8378 - accuracy: 0.7142 - val_loss: 1.5207 - val_accuracy: 0.5160\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6688 - accuracy: 0.7740 - val_loss: 1.5942 - val_accuracy: 0.5080\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5075 - accuracy: 0.8264 - val_loss: 1.7837 - val_accuracy: 0.5060\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3816 - accuracy: 0.8722 - val_loss: 2.1494 - val_accuracy: 0.4840\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2952 - accuracy: 0.9042 - val_loss: 2.2495 - val_accuracy: 0.5080\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2127 - accuracy: 0.9287 - val_loss: 2.6134 - val_accuracy: 0.5080\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1476 - accuracy: 0.9516 - val_loss: 2.8089 - val_accuracy: 0.4980\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1257 - accuracy: 0.9613 - val_loss: 2.9403 - val_accuracy: 0.4880\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1072 - accuracy: 0.9658 - val_loss: 3.3655 - val_accuracy: 0.4820\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0861 - accuracy: 0.9740 - val_loss: 3.4434 - val_accuracy: 0.5020\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0704 - accuracy: 0.9800 - val_loss: 3.4476 - val_accuracy: 0.5080\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0646 - accuracy: 0.9811 - val_loss: 3.9041 - val_accuracy: 0.4800\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0634 - accuracy: 0.9807 - val_loss: 3.8812 - val_accuracy: 0.5080\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0469 - accuracy: 0.9856 - val_loss: 5.2590 - val_accuracy: 0.4560\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0494 - accuracy: 0.9844 - val_loss: 4.3884 - val_accuracy: 0.4920\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0446 - accuracy: 0.9853 - val_loss: 4.3787 - val_accuracy: 0.4860\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0469 - accuracy: 0.9853 - val_loss: 4.5525 - val_accuracy: 0.4800\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0413 - accuracy: 0.9889 - val_loss: 4.5188 - val_accuracy: 0.5180\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0449 - accuracy: 0.9882 - val_loss: 4.5622 - val_accuracy: 0.4980\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0343 - accuracy: 0.9878 - val_loss: 4.7290 - val_accuracy: 0.4980\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0426 - accuracy: 0.9871 - val_loss: 4.6530 - val_accuracy: 0.5180\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0362 - accuracy: 0.9893 - val_loss: 5.1143 - val_accuracy: 0.4900\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0403 - accuracy: 0.9878 - val_loss: 4.9015 - val_accuracy: 0.5060\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9913 - val_loss: 5.1462 - val_accuracy: 0.4900\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0250 - accuracy: 0.9913 - val_loss: 5.1588 - val_accuracy: 0.5020\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 6.0401 - val_accuracy: 0.5000\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 6.7957 - val_accuracy: 0.4960\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 6.3457 - val_accuracy: 0.4760\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0341 - accuracy: 0.9904 - val_loss: 6.0458 - val_accuracy: 0.4860\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0257 - accuracy: 0.9916 - val_loss: 5.8010 - val_accuracy: 0.5060\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 6.0356 - val_accuracy: 0.5060\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0426 - accuracy: 0.9898 - val_loss: 6.2177 - val_accuracy: 0.5040\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0308 - accuracy: 0.9918 - val_loss: 6.5432 - val_accuracy: 0.4800\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 7.0358 - val_accuracy: 0.4920\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 6.3011 - val_accuracy: 0.4940\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9922 - val_loss: 6.1463 - val_accuracy: 0.5100\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9953 - val_loss: 5.8585 - val_accuracy: 0.5000\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0227 - accuracy: 0.9922 - val_loss: 6.2705 - val_accuracy: 0.4900\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 7.0416 - val_accuracy: 0.4900\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 7.4667 - val_accuracy: 0.4940\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 7.4144 - val_accuracy: 0.4600\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 7.5824 - val_accuracy: 0.4680\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 7.6740 - val_accuracy: 0.4720\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0324 - accuracy: 0.9911 - val_loss: 8.1611 - val_accuracy: 0.4860\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0344 - accuracy: 0.9920 - val_loss: 7.9216 - val_accuracy: 0.4840\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.034398842602968216\n",
      "Training Accuracy: 0.9919999837875366\n",
      "Validation Loss: 7.921642780303955\n",
      "Validation Accuracy: 0.48399999737739563\n",
      "Classification Error Rate: 0.5160000026226044\n",
      "----->Evolution: Child net_10 with fitness 7.921642780303955 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Proportionate selection\n",
      "Selected net_5 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  128.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83d43d7c0>, <__main__.Block object at 0x77f83d4ddb80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 5ms/step - loss: 2.0832 - accuracy: 0.3273 - val_loss: 1.7127 - val_accuracy: 0.3840\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.4328 - accuracy: 0.4840 - val_loss: 1.5877 - val_accuracy: 0.4740\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0487 - accuracy: 0.6360 - val_loss: 1.6682 - val_accuracy: 0.4380\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6982 - accuracy: 0.7642 - val_loss: 1.7781 - val_accuracy: 0.4500\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4213 - accuracy: 0.8613 - val_loss: 1.8672 - val_accuracy: 0.4480\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2431 - accuracy: 0.9238 - val_loss: 2.0579 - val_accuracy: 0.4560\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1450 - accuracy: 0.9576 - val_loss: 2.4406 - val_accuracy: 0.4780\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0898 - accuracy: 0.9789 - val_loss: 2.8332 - val_accuracy: 0.4640\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0657 - accuracy: 0.9809 - val_loss: 2.9546 - val_accuracy: 0.4600\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0503 - accuracy: 0.9860 - val_loss: 3.0025 - val_accuracy: 0.4660\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0433 - accuracy: 0.9880 - val_loss: 3.4147 - val_accuracy: 0.4780\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0325 - accuracy: 0.9911 - val_loss: 3.3081 - val_accuracy: 0.4800\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0293 - accuracy: 0.9916 - val_loss: 3.3351 - val_accuracy: 0.5020\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9924 - val_loss: 3.6574 - val_accuracy: 0.5040\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0213 - accuracy: 0.9949 - val_loss: 3.5280 - val_accuracy: 0.4700\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0136 - accuracy: 0.9969 - val_loss: 3.8662 - val_accuracy: 0.4540\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 0.9958 - val_loss: 4.1220 - val_accuracy: 0.4720\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 4.1307 - val_accuracy: 0.4720\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 4.3426 - val_accuracy: 0.4920\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0136 - accuracy: 0.9967 - val_loss: 4.6159 - val_accuracy: 0.4780\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9947 - val_loss: 4.8169 - val_accuracy: 0.4760\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 5.0341 - val_accuracy: 0.4640\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 5.3872 - val_accuracy: 0.4500\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 5.1865 - val_accuracy: 0.4580\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 5.0168 - val_accuracy: 0.4800\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 5.0894 - val_accuracy: 0.5140\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 4.8644 - val_accuracy: 0.4860\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9978 - val_loss: 5.1794 - val_accuracy: 0.4620\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 5.3022 - val_accuracy: 0.4940\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0125 - accuracy: 0.9958 - val_loss: 5.8836 - val_accuracy: 0.4780\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0147 - accuracy: 0.9947 - val_loss: 5.3419 - val_accuracy: 0.4860\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0263 - accuracy: 0.9920 - val_loss: 5.0108 - val_accuracy: 0.4720\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 5.4319 - val_accuracy: 0.4720\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 5.9264 - val_accuracy: 0.4840\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 5.5945 - val_accuracy: 0.4740\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 6.2560 - val_accuracy: 0.4780\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 6.7453 - val_accuracy: 0.4620\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 7.0090 - val_accuracy: 0.4660\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 7.4886 - val_accuracy: 0.4620\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0147 - accuracy: 0.9951 - val_loss: 6.3372 - val_accuracy: 0.5000\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9976 - val_loss: 6.5243 - val_accuracy: 0.4840\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 7.0373 - val_accuracy: 0.4780\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9967 - val_loss: 6.7584 - val_accuracy: 0.4680\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 7.1617 - val_accuracy: 0.4760\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9956 - val_loss: 6.9521 - val_accuracy: 0.4680\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9964 - val_loss: 8.0190 - val_accuracy: 0.4500\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0252 - accuracy: 0.9931 - val_loss: 6.9752 - val_accuracy: 0.4380\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 7.3850 - val_accuracy: 0.4700\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9980 - val_loss: 7.8631 - val_accuracy: 0.4740\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0213 - accuracy: 0.9953 - val_loss: 7.9796 - val_accuracy: 0.4600\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 0.02134086564183235\n",
      "Training Accuracy: 0.9953333139419556\n",
      "Validation Loss: 7.97959566116333\n",
      "Validation Accuracy: 0.46000000834465027\n",
      "Classification Error Rate: 0.5399999916553497\n",
      "----->Evolution: Child net_11 with fitness 7.97959566116333 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Proportionate selection\n",
      "Selected net_5 and net_9 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83d34d600>, <__main__.Block object at 0x77f817f88540>, <__main__.Block object at 0x77f83416db80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 5ms/step - loss: 2.1588 - accuracy: 0.2664 - val_loss: 2.1953 - val_accuracy: 0.2960\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.6326 - accuracy: 0.4224 - val_loss: 1.6009 - val_accuracy: 0.4200\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.3338 - accuracy: 0.5329 - val_loss: 1.7002 - val_accuracy: 0.4280\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0657 - accuracy: 0.6280 - val_loss: 1.6001 - val_accuracy: 0.4600\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8081 - accuracy: 0.7260 - val_loss: 1.7414 - val_accuracy: 0.4640\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5827 - accuracy: 0.7962 - val_loss: 1.9379 - val_accuracy: 0.4600\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4203 - accuracy: 0.8562 - val_loss: 2.1225 - val_accuracy: 0.4860\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2624 - accuracy: 0.9149 - val_loss: 2.4329 - val_accuracy: 0.4660\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2039 - accuracy: 0.9322 - val_loss: 2.8138 - val_accuracy: 0.4580\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1471 - accuracy: 0.9540 - val_loss: 2.9797 - val_accuracy: 0.4460\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1291 - accuracy: 0.9627 - val_loss: 3.1123 - val_accuracy: 0.4860\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1060 - accuracy: 0.9638 - val_loss: 3.5787 - val_accuracy: 0.4880\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0984 - accuracy: 0.9702 - val_loss: 3.4589 - val_accuracy: 0.4300\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0893 - accuracy: 0.9693 - val_loss: 3.7763 - val_accuracy: 0.4700\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0799 - accuracy: 0.9753 - val_loss: 4.4850 - val_accuracy: 0.4500\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0715 - accuracy: 0.9729 - val_loss: 4.6299 - val_accuracy: 0.4380\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0582 - accuracy: 0.9820 - val_loss: 4.9747 - val_accuracy: 0.4640\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0782 - accuracy: 0.9776 - val_loss: 5.0257 - val_accuracy: 0.4300\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0677 - accuracy: 0.9800 - val_loss: 4.6389 - val_accuracy: 0.4780\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0525 - accuracy: 0.9836 - val_loss: 5.2882 - val_accuracy: 0.4760\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0691 - accuracy: 0.9782 - val_loss: 5.6069 - val_accuracy: 0.4600\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0573 - accuracy: 0.9822 - val_loss: 6.2783 - val_accuracy: 0.4420\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0591 - accuracy: 0.9804 - val_loss: 6.6320 - val_accuracy: 0.4300\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0652 - accuracy: 0.9804 - val_loss: 6.6197 - val_accuracy: 0.4120\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0518 - accuracy: 0.9833 - val_loss: 5.5069 - val_accuracy: 0.4660\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0520 - accuracy: 0.9878 - val_loss: 6.3193 - val_accuracy: 0.4660\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0464 - accuracy: 0.9878 - val_loss: 6.1107 - val_accuracy: 0.4380\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9860 - val_loss: 6.0279 - val_accuracy: 0.4760\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0427 - accuracy: 0.9867 - val_loss: 6.3286 - val_accuracy: 0.4680\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0484 - accuracy: 0.9876 - val_loss: 6.4844 - val_accuracy: 0.4800\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0515 - accuracy: 0.9891 - val_loss: 8.2332 - val_accuracy: 0.4280\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0517 - accuracy: 0.9871 - val_loss: 8.4072 - val_accuracy: 0.4580\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0584 - accuracy: 0.9858 - val_loss: 7.3401 - val_accuracy: 0.4800\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0570 - accuracy: 0.9856 - val_loss: 8.1517 - val_accuracy: 0.4700\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0580 - accuracy: 0.9873 - val_loss: 8.4064 - val_accuracy: 0.4400\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0573 - accuracy: 0.9856 - val_loss: 8.2741 - val_accuracy: 0.4640\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0557 - accuracy: 0.9856 - val_loss: 8.4570 - val_accuracy: 0.4180\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0649 - accuracy: 0.9847 - val_loss: 8.3580 - val_accuracy: 0.4300\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0601 - accuracy: 0.9869 - val_loss: 9.2798 - val_accuracy: 0.4420\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0418 - accuracy: 0.9893 - val_loss: 9.0595 - val_accuracy: 0.4560\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0711 - accuracy: 0.9844 - val_loss: 10.8891 - val_accuracy: 0.4440\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0526 - accuracy: 0.9893 - val_loss: 9.2016 - val_accuracy: 0.4440\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0613 - accuracy: 0.9853 - val_loss: 10.3764 - val_accuracy: 0.4600\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0600 - accuracy: 0.9849 - val_loss: 8.9205 - val_accuracy: 0.4580\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0641 - accuracy: 0.9849 - val_loss: 9.2977 - val_accuracy: 0.4300\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0414 - accuracy: 0.9909 - val_loss: 11.0522 - val_accuracy: 0.4400\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0701 - accuracy: 0.9862 - val_loss: 10.9075 - val_accuracy: 0.4580\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0711 - accuracy: 0.9860 - val_loss: 11.0018 - val_accuracy: 0.4640\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0494 - accuracy: 0.9893 - val_loss: 10.2319 - val_accuracy: 0.4420\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0435 - accuracy: 0.9898 - val_loss: 10.4191 - val_accuracy: 0.4420\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 0.0434684231877327\n",
      "Training Accuracy: 0.9897778034210205\n",
      "Validation Loss: 10.419135093688965\n",
      "Validation Accuracy: 0.44200000166893005\n",
      "Classification Error Rate: 0.55799999833107\n",
      "----->Evolution: Child net_12 with fitness 10.419135093688965 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Proportionate selection\n",
      "Selected net_1 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  64.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f817ff6a00>, <__main__.Block object at 0x77f83c980540>, <__main__.Block object at 0x77f83c951240>, <__main__.Block object at 0x77f83c8c5580>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 9ms/step - loss: 2.4166 - accuracy: 0.1318 - val_loss: 2.7291 - val_accuracy: 0.2160\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.1860 - accuracy: 0.2456 - val_loss: 2.6394 - val_accuracy: 0.2680\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8529 - accuracy: 0.3302 - val_loss: 3.0286 - val_accuracy: 0.3040\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8121 - accuracy: 0.3749 - val_loss: 3.0871 - val_accuracy: 0.2800\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.7468 - accuracy: 0.4324 - val_loss: 2.6832 - val_accuracy: 0.2880\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.5778 - accuracy: 0.4827 - val_loss: 2.9457 - val_accuracy: 0.3860\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3862 - accuracy: 0.5269 - val_loss: 4.5603 - val_accuracy: 0.2980\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.2632 - accuracy: 0.5742 - val_loss: 2.9657 - val_accuracy: 0.4120\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.1569 - accuracy: 0.6282 - val_loss: 3.4581 - val_accuracy: 0.4100\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.9948 - accuracy: 0.6744 - val_loss: 5.9313 - val_accuracy: 0.4180\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.1725 - accuracy: 0.7171 - val_loss: 3.3865 - val_accuracy: 0.3700\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.7643 - accuracy: 0.7656 - val_loss: 4.8670 - val_accuracy: 0.3560\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.7773 - accuracy: 0.7911 - val_loss: 4.3263 - val_accuracy: 0.4440\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5932 - accuracy: 0.8247 - val_loss: 8.1721 - val_accuracy: 0.3380\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.7021 - accuracy: 0.8382 - val_loss: 4.2378 - val_accuracy: 0.4140\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5458 - accuracy: 0.8678 - val_loss: 5.7901 - val_accuracy: 0.3740\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4642 - accuracy: 0.8811 - val_loss: 4.5606 - val_accuracy: 0.3900\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4929 - accuracy: 0.8836 - val_loss: 4.6857 - val_accuracy: 0.4300\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5387 - accuracy: 0.8984 - val_loss: 4.9243 - val_accuracy: 0.4760\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4666 - accuracy: 0.9009 - val_loss: 5.4199 - val_accuracy: 0.4580\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4887 - accuracy: 0.8984 - val_loss: 6.0029 - val_accuracy: 0.4180\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3642 - accuracy: 0.9149 - val_loss: 7.4822 - val_accuracy: 0.4580\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4357 - accuracy: 0.9089 - val_loss: 6.5734 - val_accuracy: 0.4540\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5012 - accuracy: 0.9156 - val_loss: 8.4195 - val_accuracy: 0.4740\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.3930 - accuracy: 0.9222 - val_loss: 6.6634 - val_accuracy: 0.4600\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4514 - accuracy: 0.9189 - val_loss: 6.4413 - val_accuracy: 0.4360\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3542 - accuracy: 0.9249 - val_loss: 6.1173 - val_accuracy: 0.4540\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4996 - accuracy: 0.9222 - val_loss: 7.7945 - val_accuracy: 0.4640\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.8766 - accuracy: 0.9253 - val_loss: 6.1236 - val_accuracy: 0.4560\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4204 - accuracy: 0.9204 - val_loss: 4.4426 - val_accuracy: 0.4580\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3365 - accuracy: 0.9280 - val_loss: 5.3304 - val_accuracy: 0.4740\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3254 - accuracy: 0.9273 - val_loss: 8.5918 - val_accuracy: 0.4460\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5837 - accuracy: 0.9360 - val_loss: 7.9129 - val_accuracy: 0.4040\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5121 - accuracy: 0.9253 - val_loss: 6.5969 - val_accuracy: 0.4580\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5802 - accuracy: 0.9329 - val_loss: 8.4452 - val_accuracy: 0.4780\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4696 - accuracy: 0.9329 - val_loss: 7.6380 - val_accuracy: 0.4860\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3500 - accuracy: 0.9349 - val_loss: 6.8807 - val_accuracy: 0.4640\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2979 - accuracy: 0.9307 - val_loss: 9.3650 - val_accuracy: 0.4420\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5663 - accuracy: 0.9304 - val_loss: 7.2721 - val_accuracy: 0.4640\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.3096 - accuracy: 0.9340 - val_loss: 7.2717 - val_accuracy: 0.4740\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3419 - accuracy: 0.9307 - val_loss: 8.4948 - val_accuracy: 0.4520\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3935 - accuracy: 0.9260 - val_loss: 8.5057 - val_accuracy: 0.4760\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3472 - accuracy: 0.9300 - val_loss: 7.9544 - val_accuracy: 0.4540\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4174 - accuracy: 0.9369 - val_loss: 6.3629 - val_accuracy: 0.5080\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.2802 - accuracy: 0.9373 - val_loss: 6.4257 - val_accuracy: 0.4840\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4803 - accuracy: 0.9318 - val_loss: 17.4996 - val_accuracy: 0.4460\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.6833 - accuracy: 0.9309 - val_loss: 15.3901 - val_accuracy: 0.3220\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4614 - accuracy: 0.9300 - val_loss: 6.5505 - val_accuracy: 0.4600\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.3173 - accuracy: 0.9342 - val_loss: 10.3503 - val_accuracy: 0.4780\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.7175 - accuracy: 0.9362 - val_loss: 6.0090 - val_accuracy: 0.4340\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 0.7174825072288513\n",
      "Training Accuracy: 0.9362221956253052\n",
      "Validation Loss: 6.008974075317383\n",
      "Validation Accuracy: 0.4339999854564667\n",
      "Classification Error Rate: 0.5660000145435333\n",
      "----->Evolution: Child net_13 with fitness 6.008974075317383 replaces parent net_7 with fitness 7.485652446746826\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 6\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Proportionate selection\n",
      "Selected net_2 and net_6 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc70281040>, <__main__.Block object at 0x77fc70123500>, <__main__.Block object at 0x77f837225b00>, <__main__.Block object at 0x77f837225600>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_35\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_35/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_35\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83c3f2f80>, <__main__.Block object at 0x77f83c3f3b00>, <__main__.Block object at 0x77f83c3f3d40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Input 0 of layer \"average_pooling2d_39\" is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 10)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 2)]\n",
      "Creating a new block with two Convolutional layers and a Pooling layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  128.0\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83c5ecec0>, <__main__.Block object at 0x77f83c6b4a00>, <__main__.Block object at 0x77f83c53a300>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 7ms/step - loss: 3.6481 - accuracy: 0.1684 - val_loss: 17.3270 - val_accuracy: 0.1480\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 3.9366 - accuracy: 0.2880 - val_loss: 20.0337 - val_accuracy: 0.1460\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 6.1198 - accuracy: 0.3967 - val_loss: 18.9948 - val_accuracy: 0.1520\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 4.6662 - accuracy: 0.4887 - val_loss: 34.3230 - val_accuracy: 0.2480\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 4.8856 - accuracy: 0.6000 - val_loss: 39.0829 - val_accuracy: 0.2320\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 6.2309 - accuracy: 0.7031 - val_loss: 45.9522 - val_accuracy: 0.3420\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 5.7008 - accuracy: 0.7858 - val_loss: 55.6662 - val_accuracy: 0.3560\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 8.2352 - accuracy: 0.8573 - val_loss: 41.2188 - val_accuracy: 0.3720\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 5.7953 - accuracy: 0.9040 - val_loss: 69.3976 - val_accuracy: 0.3740\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 5.4971 - accuracy: 0.9207 - val_loss: 60.6259 - val_accuracy: 0.3800\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 6.5012 - accuracy: 0.9284 - val_loss: 44.7385 - val_accuracy: 0.3560\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 7.7290 - accuracy: 0.9396 - val_loss: 50.9956 - val_accuracy: 0.3740\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 5.1810 - accuracy: 0.9462 - val_loss: 75.0970 - val_accuracy: 0.3600\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 6.3235 - accuracy: 0.9573 - val_loss: 110.5901 - val_accuracy: 0.3480\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 10.7552 - accuracy: 0.9562 - val_loss: 99.1545 - val_accuracy: 0.3920\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 14.6421 - accuracy: 0.9622 - val_loss: 168.2016 - val_accuracy: 0.3720\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 18.6527 - accuracy: 0.9580 - val_loss: 104.4445 - val_accuracy: 0.3960\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 6.7853 - accuracy: 0.9560 - val_loss: 111.9667 - val_accuracy: 0.3660\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 8.9491 - accuracy: 0.9593 - val_loss: 136.2588 - val_accuracy: 0.3580\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 11.8773 - accuracy: 0.9616 - val_loss: 216.9517 - val_accuracy: 0.3680\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 27.2729 - accuracy: 0.9611 - val_loss: 168.6851 - val_accuracy: 0.3620\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 15.4055 - accuracy: 0.9673 - val_loss: 171.1904 - val_accuracy: 0.3480\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 13.4505 - accuracy: 0.9664 - val_loss: 185.4444 - val_accuracy: 0.3820\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 22.1945 - accuracy: 0.9667 - val_loss: 232.6359 - val_accuracy: 0.3820\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 24.2298 - accuracy: 0.9662 - val_loss: 246.3404 - val_accuracy: 0.3760\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 28.8067 - accuracy: 0.9680 - val_loss: 197.8781 - val_accuracy: 0.4000\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 24.8604 - accuracy: 0.9680 - val_loss: 150.3759 - val_accuracy: 0.3920\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 20.2453 - accuracy: 0.9740 - val_loss: 94.2146 - val_accuracy: 0.3960\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 20.0555 - accuracy: 0.9671 - val_loss: 297.3259 - val_accuracy: 0.3960\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 22.8065 - accuracy: 0.9704 - val_loss: 360.4950 - val_accuracy: 0.3720\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 39.7277 - accuracy: 0.9738 - val_loss: 396.2847 - val_accuracy: 0.3940\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 42.4780 - accuracy: 0.9789 - val_loss: 388.5982 - val_accuracy: 0.3680\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 41.7636 - accuracy: 0.9722 - val_loss: 244.0856 - val_accuracy: 0.3700\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 21.4013 - accuracy: 0.9713 - val_loss: 434.4129 - val_accuracy: 0.4200\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 45.2977 - accuracy: 0.9684 - val_loss: 491.2353 - val_accuracy: 0.3720\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 49.3073 - accuracy: 0.9667 - val_loss: 282.1245 - val_accuracy: 0.3640\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 44.7365 - accuracy: 0.9749 - val_loss: 432.1401 - val_accuracy: 0.3860\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 39.4438 - accuracy: 0.9736 - val_loss: 787.6210 - val_accuracy: 0.3960\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 64.8505 - accuracy: 0.9773 - val_loss: 314.4651 - val_accuracy: 0.3820\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 20.8029 - accuracy: 0.9693 - val_loss: 425.0387 - val_accuracy: 0.3840\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 31.8873 - accuracy: 0.9711 - val_loss: 374.5551 - val_accuracy: 0.3700\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 39.0777 - accuracy: 0.9722 - val_loss: 508.0492 - val_accuracy: 0.3580\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 54.8153 - accuracy: 0.9753 - val_loss: 446.6501 - val_accuracy: 0.3920\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 55.9327 - accuracy: 0.9716 - val_loss: 746.7272 - val_accuracy: 0.3740\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 89.3064 - accuracy: 0.9787 - val_loss: 594.0923 - val_accuracy: 0.4080\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 80.6772 - accuracy: 0.9778 - val_loss: 510.8718 - val_accuracy: 0.3900\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 42.3426 - accuracy: 0.9778 - val_loss: 523.5473 - val_accuracy: 0.4040\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 53.1781 - accuracy: 0.9773 - val_loss: 573.0033 - val_accuracy: 0.4040\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 56.5009 - accuracy: 0.9764 - val_loss: 791.4761 - val_accuracy: 0.3980\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 58.1175 - accuracy: 0.9789 - val_loss: 945.2695 - val_accuracy: 0.3320\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 58.117523193359375\n",
      "Training Accuracy: 0.9788888692855835\n",
      "Validation Loss: 945.2694702148438\n",
      "Validation Accuracy: 0.3319999873638153\n",
      "Classification Error Rate: 0.6680000126361847\n",
      "----->Evolution: Child net_10 with fitness 945.2694702148438 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Proportionate selection\n",
      "Selected net_9 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83794d600>, <__main__.Block object at 0x77f8378b8540>, <__main__.Block object at 0x77f8378cef40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 6ms/step - loss: 2.0113 - accuracy: 0.2744 - val_loss: 1.9306 - val_accuracy: 0.3020\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.6316 - accuracy: 0.4109 - val_loss: 2.0849 - val_accuracy: 0.3100\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.4353 - accuracy: 0.4902 - val_loss: 1.6864 - val_accuracy: 0.4560\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.2764 - accuracy: 0.5513 - val_loss: 2.5271 - val_accuracy: 0.3020\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.1174 - accuracy: 0.6149 - val_loss: 1.4420 - val_accuracy: 0.4960\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.9844 - accuracy: 0.6618 - val_loss: 1.8695 - val_accuracy: 0.4600\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8542 - accuracy: 0.6973 - val_loss: 1.8969 - val_accuracy: 0.4220\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.7062 - accuracy: 0.7571 - val_loss: 2.0803 - val_accuracy: 0.4160\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.5853 - accuracy: 0.7938 - val_loss: 2.3070 - val_accuracy: 0.4380\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4764 - accuracy: 0.8369 - val_loss: 2.0666 - val_accuracy: 0.5180\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3883 - accuracy: 0.8691 - val_loss: 3.0609 - val_accuracy: 0.4340\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3167 - accuracy: 0.8967 - val_loss: 2.8850 - val_accuracy: 0.5040\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2476 - accuracy: 0.9162 - val_loss: 2.9465 - val_accuracy: 0.5240\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1995 - accuracy: 0.9391 - val_loss: 3.2416 - val_accuracy: 0.5280\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1961 - accuracy: 0.9478 - val_loss: 4.0787 - val_accuracy: 0.4240\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1377 - accuracy: 0.9600 - val_loss: 3.7716 - val_accuracy: 0.5280\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1153 - accuracy: 0.9616 - val_loss: 3.9708 - val_accuracy: 0.4920\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1266 - accuracy: 0.9629 - val_loss: 5.3576 - val_accuracy: 0.4700\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1106 - accuracy: 0.9676 - val_loss: 5.0101 - val_accuracy: 0.4660\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1421 - accuracy: 0.9713 - val_loss: 5.9024 - val_accuracy: 0.4240\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0980 - accuracy: 0.9727 - val_loss: 3.8356 - val_accuracy: 0.5480\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0971 - accuracy: 0.9729 - val_loss: 3.7292 - val_accuracy: 0.5480\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0856 - accuracy: 0.9771 - val_loss: 4.5856 - val_accuracy: 0.4760\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0866 - accuracy: 0.9756 - val_loss: 4.1430 - val_accuracy: 0.5520\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0746 - accuracy: 0.9767 - val_loss: 4.4406 - val_accuracy: 0.5520\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0905 - accuracy: 0.9751 - val_loss: 6.0512 - val_accuracy: 0.4780\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0790 - accuracy: 0.9822 - val_loss: 6.7085 - val_accuracy: 0.4920\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1116 - accuracy: 0.9731 - val_loss: 5.5313 - val_accuracy: 0.5040\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0817 - accuracy: 0.9798 - val_loss: 6.6038 - val_accuracy: 0.5020\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1044 - accuracy: 0.9787 - val_loss: 5.6235 - val_accuracy: 0.4860\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0888 - accuracy: 0.9764 - val_loss: 6.9525 - val_accuracy: 0.4720\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0796 - accuracy: 0.9789 - val_loss: 7.1037 - val_accuracy: 0.4700\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0821 - accuracy: 0.9796 - val_loss: 5.4480 - val_accuracy: 0.5060\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0709 - accuracy: 0.9822 - val_loss: 6.5211 - val_accuracy: 0.5100\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0564 - accuracy: 0.9824 - val_loss: 5.0983 - val_accuracy: 0.5660\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0672 - accuracy: 0.9862 - val_loss: 10.9928 - val_accuracy: 0.3860\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0948 - accuracy: 0.9804 - val_loss: 5.5293 - val_accuracy: 0.5460\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0856 - accuracy: 0.9829 - val_loss: 9.5023 - val_accuracy: 0.4600\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0938 - accuracy: 0.9833 - val_loss: 8.0619 - val_accuracy: 0.4580\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1067 - accuracy: 0.9791 - val_loss: 6.9704 - val_accuracy: 0.5220\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0796 - accuracy: 0.9838 - val_loss: 7.2652 - val_accuracy: 0.4720\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1270 - accuracy: 0.9778 - val_loss: 6.7755 - val_accuracy: 0.5300\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0668 - accuracy: 0.9838 - val_loss: 7.4194 - val_accuracy: 0.5220\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0703 - accuracy: 0.9853 - val_loss: 6.4797 - val_accuracy: 0.4940\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0858 - accuracy: 0.9858 - val_loss: 6.2924 - val_accuracy: 0.5680\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0904 - accuracy: 0.9836 - val_loss: 6.5395 - val_accuracy: 0.5220\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0748 - accuracy: 0.9882 - val_loss: 8.6552 - val_accuracy: 0.5200\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0960 - accuracy: 0.9847 - val_loss: 6.9782 - val_accuracy: 0.5620\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0948 - accuracy: 0.9873 - val_loss: 6.9166 - val_accuracy: 0.4860\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1067 - accuracy: 0.9833 - val_loss: 9.4731 - val_accuracy: 0.5100\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 0.10674520581960678\n",
      "Training Accuracy: 0.9833333492279053\n",
      "Validation Loss: 9.473109245300293\n",
      "Validation Accuracy: 0.5099999904632568\n",
      "Classification Error Rate: 0.49000000953674316\n",
      "----->Evolution: Child net_11 with fitness 9.473109245300293 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Proportionate selection\n",
      "Selected net_3 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f8379a7700>, <__main__.Block object at 0x77f83d575b80>, <__main__.Block object at 0x77f8341657c0>, <__main__.Block object at 0x77fc7220c300>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 4s 9ms/step - loss: 2.3415 - accuracy: 0.1593 - val_loss: 2.3479 - val_accuracy: 0.2300\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.0247 - accuracy: 0.2793 - val_loss: 2.1023 - val_accuracy: 0.2600\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.7961 - accuracy: 0.3753 - val_loss: 2.8074 - val_accuracy: 0.2300\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.5785 - accuracy: 0.4482 - val_loss: 2.5419 - val_accuracy: 0.2680\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.4108 - accuracy: 0.5058 - val_loss: 2.6122 - val_accuracy: 0.2940\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.2425 - accuracy: 0.5636 - val_loss: 1.8184 - val_accuracy: 0.4240\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.0838 - accuracy: 0.6244 - val_loss: 2.2404 - val_accuracy: 0.4040\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.9279 - accuracy: 0.6918 - val_loss: 3.2552 - val_accuracy: 0.3540\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.7406 - accuracy: 0.7513 - val_loss: 3.4626 - val_accuracy: 0.4340\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.6440 - accuracy: 0.7987 - val_loss: 3.2979 - val_accuracy: 0.3980\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5243 - accuracy: 0.8316 - val_loss: 3.6885 - val_accuracy: 0.4280\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4743 - accuracy: 0.8598 - val_loss: 3.4661 - val_accuracy: 0.4200\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3944 - accuracy: 0.8871 - val_loss: 2.7243 - val_accuracy: 0.5060\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3743 - accuracy: 0.8887 - val_loss: 5.0581 - val_accuracy: 0.4720\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3359 - accuracy: 0.9087 - val_loss: 3.4744 - val_accuracy: 0.4500\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3727 - accuracy: 0.9153 - val_loss: 3.0860 - val_accuracy: 0.4700\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2761 - accuracy: 0.9231 - val_loss: 7.2881 - val_accuracy: 0.4360\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2994 - accuracy: 0.9242 - val_loss: 3.9897 - val_accuracy: 0.4480\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3191 - accuracy: 0.9216 - val_loss: 5.5317 - val_accuracy: 0.4580\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3321 - accuracy: 0.9304 - val_loss: 4.7417 - val_accuracy: 0.4520\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2773 - accuracy: 0.9278 - val_loss: 6.8292 - val_accuracy: 0.4560\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3015 - accuracy: 0.9244 - val_loss: 3.7304 - val_accuracy: 0.4580\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3766 - accuracy: 0.9262 - val_loss: 7.8546 - val_accuracy: 0.4780\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3057 - accuracy: 0.9287 - val_loss: 6.2251 - val_accuracy: 0.4740\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.2830 - accuracy: 0.9398 - val_loss: 6.6708 - val_accuracy: 0.4340\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4658 - accuracy: 0.9393 - val_loss: 9.8304 - val_accuracy: 0.4480\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4517 - accuracy: 0.9249 - val_loss: 6.6220 - val_accuracy: 0.4320\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3034 - accuracy: 0.9324 - val_loss: 9.7025 - val_accuracy: 0.4640\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3256 - accuracy: 0.9360 - val_loss: 6.0120 - val_accuracy: 0.4520\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3872 - accuracy: 0.9320 - val_loss: 7.9602 - val_accuracy: 0.4800\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3034 - accuracy: 0.9384 - val_loss: 9.5769 - val_accuracy: 0.5100\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3880 - accuracy: 0.9300 - val_loss: 11.8914 - val_accuracy: 0.4480\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4293 - accuracy: 0.9318 - val_loss: 5.5724 - val_accuracy: 0.4740\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3885 - accuracy: 0.9342 - val_loss: 6.3680 - val_accuracy: 0.4800\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3651 - accuracy: 0.9367 - val_loss: 11.6232 - val_accuracy: 0.4640\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4597 - accuracy: 0.9293 - val_loss: 10.8388 - val_accuracy: 0.4900\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4768 - accuracy: 0.9404 - val_loss: 7.2151 - val_accuracy: 0.4200\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3399 - accuracy: 0.9318 - val_loss: 11.4531 - val_accuracy: 0.5000\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3999 - accuracy: 0.9384 - val_loss: 7.9501 - val_accuracy: 0.4900\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4474 - accuracy: 0.9402 - val_loss: 14.1466 - val_accuracy: 0.4240\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4466 - accuracy: 0.9351 - val_loss: 12.3477 - val_accuracy: 0.4300\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5037 - accuracy: 0.9400 - val_loss: 17.7965 - val_accuracy: 0.4560\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5524 - accuracy: 0.9391 - val_loss: 10.6924 - val_accuracy: 0.4620\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5117 - accuracy: 0.9304 - val_loss: 6.7616 - val_accuracy: 0.4680\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4012 - accuracy: 0.9333 - val_loss: 6.1436 - val_accuracy: 0.4760\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3334 - accuracy: 0.9407 - val_loss: 10.4688 - val_accuracy: 0.4600\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4641 - accuracy: 0.9353 - val_loss: 11.5335 - val_accuracy: 0.4480\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4642 - accuracy: 0.9351 - val_loss: 9.4411 - val_accuracy: 0.4420\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4473 - accuracy: 0.9247 - val_loss: 7.2585 - val_accuracy: 0.4720\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5183 - accuracy: 0.9311 - val_loss: 13.5264 - val_accuracy: 0.4920\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 0.5183345079421997\n",
      "Training Accuracy: 0.9311110973358154\n",
      "Validation Loss: 13.526358604431152\n",
      "Validation Accuracy: 0.492000013589859\n",
      "Classification Error Rate: 0.507999986410141\n",
      "----->Evolution: Child net_12 with fitness 13.526358604431152 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Proportionate selection\n",
      "Selected parent_0 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  64.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83c7b57c0>, <__main__.Block object at 0x77f83c7a8540>, <__main__.Block object at 0x77f83d6db300>, <__main__.Block object at 0x77f83d6d9e40>, <__main__.Block object at 0x77f83ca0d640>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_146\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_146/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_146/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,32].\n",
      "\n",
      "Call arguments received by layer \"conv2d_146\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_41\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_41/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,64].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_41\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 64), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 2)]\n",
      "Removing a Pooling/Dropout layer at 1\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  64.0\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc72c321c0>, <__main__.Block object at 0x77f8341657c0>, <__main__.Block object at 0x77fc72c31cc0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 7ms/step - loss: 2.2009 - accuracy: 0.2480 - val_loss: 1.8566 - val_accuracy: 0.3520\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.6907 - accuracy: 0.3936 - val_loss: 1.6641 - val_accuracy: 0.4300\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.4169 - accuracy: 0.4882 - val_loss: 1.6496 - val_accuracy: 0.4480\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.1750 - accuracy: 0.5791 - val_loss: 1.5773 - val_accuracy: 0.4880\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.9314 - accuracy: 0.6722 - val_loss: 1.3864 - val_accuracy: 0.5440\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6943 - accuracy: 0.7613 - val_loss: 1.4863 - val_accuracy: 0.5300\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.4790 - accuracy: 0.8378 - val_loss: 1.8176 - val_accuracy: 0.5140\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3038 - accuracy: 0.8971 - val_loss: 2.0102 - val_accuracy: 0.5480\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2131 - accuracy: 0.9342 - val_loss: 2.4482 - val_accuracy: 0.5020\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1643 - accuracy: 0.9482 - val_loss: 2.3530 - val_accuracy: 0.5380\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1247 - accuracy: 0.9596 - val_loss: 2.5692 - val_accuracy: 0.5500\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1235 - accuracy: 0.9618 - val_loss: 3.1405 - val_accuracy: 0.5220\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1069 - accuracy: 0.9673 - val_loss: 2.9235 - val_accuracy: 0.5320\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0970 - accuracy: 0.9680 - val_loss: 2.9818 - val_accuracy: 0.5500\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0862 - accuracy: 0.9751 - val_loss: 3.9269 - val_accuracy: 0.5380\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0818 - accuracy: 0.9738 - val_loss: 3.5776 - val_accuracy: 0.5500\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0863 - accuracy: 0.9751 - val_loss: 4.0076 - val_accuracy: 0.5380\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0911 - accuracy: 0.9762 - val_loss: 4.1060 - val_accuracy: 0.5600\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0953 - accuracy: 0.9729 - val_loss: 4.3246 - val_accuracy: 0.5280\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0799 - accuracy: 0.9738 - val_loss: 4.2740 - val_accuracy: 0.5360\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0804 - accuracy: 0.9764 - val_loss: 4.3293 - val_accuracy: 0.5300\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0838 - accuracy: 0.9771 - val_loss: 4.5707 - val_accuracy: 0.5460\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0880 - accuracy: 0.9751 - val_loss: 4.9343 - val_accuracy: 0.5440\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0841 - accuracy: 0.9787 - val_loss: 5.3067 - val_accuracy: 0.5320\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0728 - accuracy: 0.9811 - val_loss: 5.5012 - val_accuracy: 0.5240\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0758 - accuracy: 0.9791 - val_loss: 5.8907 - val_accuracy: 0.5160\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0670 - accuracy: 0.9816 - val_loss: 5.5470 - val_accuracy: 0.5420\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0823 - accuracy: 0.9818 - val_loss: 5.5900 - val_accuracy: 0.5680\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0925 - accuracy: 0.9824 - val_loss: 6.4608 - val_accuracy: 0.5140\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0761 - accuracy: 0.9822 - val_loss: 6.3419 - val_accuracy: 0.5760\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0751 - accuracy: 0.9849 - val_loss: 7.5653 - val_accuracy: 0.5100\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1019 - accuracy: 0.9782 - val_loss: 6.4603 - val_accuracy: 0.5680\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0788 - accuracy: 0.9838 - val_loss: 6.8906 - val_accuracy: 0.5400\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0891 - accuracy: 0.9827 - val_loss: 7.1434 - val_accuracy: 0.5100\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0573 - accuracy: 0.9869 - val_loss: 7.4897 - val_accuracy: 0.5340\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0526 - accuracy: 0.9893 - val_loss: 8.1171 - val_accuracy: 0.5680\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0970 - accuracy: 0.9836 - val_loss: 8.0194 - val_accuracy: 0.5500\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.0918 - accuracy: 0.9851 - val_loss: 9.4579 - val_accuracy: 0.5340\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1114 - accuracy: 0.9782 - val_loss: 10.0738 - val_accuracy: 0.5520\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0964 - accuracy: 0.9818 - val_loss: 8.2212 - val_accuracy: 0.5580\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0658 - accuracy: 0.9858 - val_loss: 10.2722 - val_accuracy: 0.5480\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1160 - accuracy: 0.9827 - val_loss: 10.6613 - val_accuracy: 0.5300\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0989 - accuracy: 0.9844 - val_loss: 9.8822 - val_accuracy: 0.5380\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0979 - accuracy: 0.9840 - val_loss: 9.6427 - val_accuracy: 0.5280\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0757 - accuracy: 0.9858 - val_loss: 9.0736 - val_accuracy: 0.5520\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0753 - accuracy: 0.9864 - val_loss: 9.2666 - val_accuracy: 0.5640\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0648 - accuracy: 0.9884 - val_loss: 10.1566 - val_accuracy: 0.5360\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1091 - accuracy: 0.9851 - val_loss: 10.6275 - val_accuracy: 0.5160\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0884 - accuracy: 0.9856 - val_loss: 11.5030 - val_accuracy: 0.5360\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0928 - accuracy: 0.9853 - val_loss: 10.8259 - val_accuracy: 0.5300\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 0.09284941107034683\n",
      "Training Accuracy: 0.9853333234786987\n",
      "Validation Loss: 10.825913429260254\n",
      "Validation Accuracy: 0.5299999713897705\n",
      "Classification Error Rate: 0.4700000286102295\n",
      "----->Evolution: Child net_13 with fitness 10.825913429260254 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 7\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Tournament selection\n",
      "Selected net_9 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83ccc5580>, <__main__.Block object at 0x77fc723f0540>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 6ms/step - loss: 5.6559 - accuracy: 0.2378 - val_loss: 2.0010 - val_accuracy: 0.2820\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.8598 - accuracy: 0.3647 - val_loss: 1.7561 - val_accuracy: 0.4080\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.4899 - accuracy: 0.4718 - val_loss: 1.8746 - val_accuracy: 0.3640\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.2030 - accuracy: 0.5664 - val_loss: 1.8981 - val_accuracy: 0.3800\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.9399 - accuracy: 0.6704 - val_loss: 1.9621 - val_accuracy: 0.4420\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6871 - accuracy: 0.7622 - val_loss: 1.9497 - val_accuracy: 0.4720\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.4848 - accuracy: 0.8362 - val_loss: 2.0371 - val_accuracy: 0.4280\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3216 - accuracy: 0.8931 - val_loss: 2.2346 - val_accuracy: 0.4680\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2025 - accuracy: 0.9360 - val_loss: 2.5352 - val_accuracy: 0.4660\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1413 - accuracy: 0.9589 - val_loss: 2.8316 - val_accuracy: 0.4660\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1011 - accuracy: 0.9667 - val_loss: 3.1649 - val_accuracy: 0.4700\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0738 - accuracy: 0.9769 - val_loss: 3.2268 - val_accuracy: 0.4580\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0623 - accuracy: 0.9793 - val_loss: 4.3200 - val_accuracy: 0.4660\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0499 - accuracy: 0.9840 - val_loss: 3.9619 - val_accuracy: 0.4560\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0507 - accuracy: 0.9833 - val_loss: 4.1453 - val_accuracy: 0.4500\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0643 - accuracy: 0.9822 - val_loss: 4.3014 - val_accuracy: 0.4420\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0509 - accuracy: 0.9849 - val_loss: 4.0796 - val_accuracy: 0.4840\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0320 - accuracy: 0.9911 - val_loss: 4.2754 - val_accuracy: 0.4460\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0340 - accuracy: 0.9891 - val_loss: 4.5025 - val_accuracy: 0.4700\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0370 - accuracy: 0.9891 - val_loss: 4.7963 - val_accuracy: 0.4560\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0202 - accuracy: 0.9931 - val_loss: 4.9102 - val_accuracy: 0.4540\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0149 - accuracy: 0.9962 - val_loss: 6.0975 - val_accuracy: 0.4600\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 5.8465 - val_accuracy: 0.4280\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0126 - accuracy: 0.9947 - val_loss: 5.9271 - val_accuracy: 0.4400\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0270 - accuracy: 0.9918 - val_loss: 5.7183 - val_accuracy: 0.4700\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 5.1322 - val_accuracy: 0.4540\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0201 - accuracy: 0.9949 - val_loss: 5.6453 - val_accuracy: 0.4620\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 6.2128 - val_accuracy: 0.4520\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0257 - accuracy: 0.9929 - val_loss: 6.2611 - val_accuracy: 0.4440\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0346 - accuracy: 0.9884 - val_loss: 6.9441 - val_accuracy: 0.4460\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0288 - accuracy: 0.9913 - val_loss: 6.2662 - val_accuracy: 0.4540\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0303 - accuracy: 0.9898 - val_loss: 6.8753 - val_accuracy: 0.4500\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0434 - accuracy: 0.9876 - val_loss: 6.7026 - val_accuracy: 0.4540\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 7.3816 - val_accuracy: 0.4540\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0179 - accuracy: 0.9964 - val_loss: 7.3950 - val_accuracy: 0.4580\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0156 - accuracy: 0.9944 - val_loss: 7.2023 - val_accuracy: 0.4500\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0162 - accuracy: 0.9960 - val_loss: 7.5567 - val_accuracy: 0.4500\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 7.0494 - val_accuracy: 0.4700\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0186 - accuracy: 0.9922 - val_loss: 7.3183 - val_accuracy: 0.4620\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0391 - accuracy: 0.9913 - val_loss: 8.4928 - val_accuracy: 0.4260\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0328 - accuracy: 0.9920 - val_loss: 7.8979 - val_accuracy: 0.4480\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0308 - accuracy: 0.9931 - val_loss: 7.5360 - val_accuracy: 0.4500\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0256 - accuracy: 0.9931 - val_loss: 7.9938 - val_accuracy: 0.4640\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0186 - accuracy: 0.9951 - val_loss: 7.8812 - val_accuracy: 0.4580\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 8.6022 - val_accuracy: 0.4600\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0267 - accuracy: 0.9949 - val_loss: 8.5917 - val_accuracy: 0.4680\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0299 - accuracy: 0.9938 - val_loss: 8.7779 - val_accuracy: 0.4600\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0232 - accuracy: 0.9947 - val_loss: 8.7398 - val_accuracy: 0.4500\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0228 - accuracy: 0.9947 - val_loss: 9.2429 - val_accuracy: 0.4580\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0049 - accuracy: 0.9982 - val_loss: 9.6972 - val_accuracy: 0.4580\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.004922176245599985\n",
      "Training Accuracy: 0.9982222318649292\n",
      "Validation Loss: 9.6972017288208\n",
      "Validation Accuracy: 0.4580000042915344\n",
      "Classification Error Rate: 0.5419999957084656\n",
      "----->Evolution: Child net_10 with fitness 9.6972017288208 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Tournament selection\n",
      "Selected net_8 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  128.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83ce2a940>, <__main__.Block object at 0x77f83c508540>, <__main__.Block object at 0x77f83cd457c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 10ms/step - loss: 5.4903 - accuracy: 0.1476 - val_loss: 26.8571 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 2.9958 - accuracy: 0.1867 - val_loss: 227.6944 - val_accuracy: 0.1240\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 3.7111 - accuracy: 0.2849 - val_loss: 3.7408 - val_accuracy: 0.2900\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 2.2128 - accuracy: 0.3264 - val_loss: 35.2571 - val_accuracy: 0.1900\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.1930 - accuracy: 0.3684 - val_loss: 25.0641 - val_accuracy: 0.1200\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 2.3955 - accuracy: 0.4082 - val_loss: 6.1907 - val_accuracy: 0.3580\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.8014 - accuracy: 0.4616 - val_loss: 12.0360 - val_accuracy: 0.3620\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.9695 - accuracy: 0.4927 - val_loss: 9.0405 - val_accuracy: 0.3360\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.9374 - accuracy: 0.5369 - val_loss: 6.7681 - val_accuracy: 0.3660\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.6316 - accuracy: 0.5831 - val_loss: 12.2987 - val_accuracy: 0.4000\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 2.1713 - accuracy: 0.6124 - val_loss: 3.4464 - val_accuracy: 0.4300\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.1886 - accuracy: 0.6447 - val_loss: 14.2405 - val_accuracy: 0.4140\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.9430 - accuracy: 0.6722 - val_loss: 7.7441 - val_accuracy: 0.4320\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.1110 - accuracy: 0.7222 - val_loss: 19.3766 - val_accuracy: 0.4220\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 2.4376 - accuracy: 0.7347 - val_loss: 18.2575 - val_accuracy: 0.2920\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.0637 - accuracy: 0.7833 - val_loss: 9.0681 - val_accuracy: 0.3720\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.3124 - accuracy: 0.7958 - val_loss: 28.2777 - val_accuracy: 0.3960\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.5928 - accuracy: 0.8149 - val_loss: 9.7905 - val_accuracy: 0.3600\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.0041 - accuracy: 0.8289 - val_loss: 29.7421 - val_accuracy: 0.3940\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.9008 - accuracy: 0.8480 - val_loss: 15.2126 - val_accuracy: 0.4040\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.7898 - accuracy: 0.8540 - val_loss: 28.7383 - val_accuracy: 0.3720\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.4120 - accuracy: 0.8882 - val_loss: 16.4343 - val_accuracy: 0.3720\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.9724 - accuracy: 0.8798 - val_loss: 13.6408 - val_accuracy: 0.3180\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.7254 - accuracy: 0.8789 - val_loss: 30.5617 - val_accuracy: 0.4080\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.9359 - accuracy: 0.9120 - val_loss: 13.9653 - val_accuracy: 0.3660\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.7910 - accuracy: 0.8991 - val_loss: 19.3184 - val_accuracy: 0.3660\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4141 - accuracy: 0.8898 - val_loss: 29.6317 - val_accuracy: 0.3920\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.0465 - accuracy: 0.9153 - val_loss: 22.7205 - val_accuracy: 0.3820\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 3.3258 - accuracy: 0.8933 - val_loss: 19.2305 - val_accuracy: 0.4300\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.7501 - accuracy: 0.9209 - val_loss: 28.1700 - val_accuracy: 0.3720\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.6659 - accuracy: 0.8829 - val_loss: 21.9516 - val_accuracy: 0.4440\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.6355 - accuracy: 0.9238 - val_loss: 26.2093 - val_accuracy: 0.4200\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.3191 - accuracy: 0.9169 - val_loss: 25.1533 - val_accuracy: 0.3980\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.6752 - accuracy: 0.9151 - val_loss: 34.1668 - val_accuracy: 0.3900\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.9466 - accuracy: 0.9227 - val_loss: 19.1029 - val_accuracy: 0.4040\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.2831 - accuracy: 0.9289 - val_loss: 31.3088 - val_accuracy: 0.3800\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.1092 - accuracy: 0.9249 - val_loss: 40.9110 - val_accuracy: 0.4180\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 2.2413 - accuracy: 0.9229 - val_loss: 26.4786 - val_accuracy: 0.3940\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.6000 - accuracy: 0.9278 - val_loss: 37.2605 - val_accuracy: 0.4160\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.4636 - accuracy: 0.9320 - val_loss: 24.2625 - val_accuracy: 0.4160\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.4807 - accuracy: 0.9260 - val_loss: 39.1721 - val_accuracy: 0.4260\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 2.1299 - accuracy: 0.9311 - val_loss: 22.9304 - val_accuracy: 0.4260\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.4624 - accuracy: 0.9351 - val_loss: 47.5657 - val_accuracy: 0.4020\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 3.1894 - accuracy: 0.9358 - val_loss: 50.7658 - val_accuracy: 0.4100\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 2.1130 - accuracy: 0.9404 - val_loss: 79.4846 - val_accuracy: 0.3640\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 2.3955 - accuracy: 0.9304 - val_loss: 31.7251 - val_accuracy: 0.4060\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.5652 - accuracy: 0.9327 - val_loss: 42.6060 - val_accuracy: 0.3280\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 2.0087 - accuracy: 0.9269 - val_loss: 40.2245 - val_accuracy: 0.4060\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 2.6065 - accuracy: 0.9322 - val_loss: 44.8425 - val_accuracy: 0.3900\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.8767 - accuracy: 0.9307 - val_loss: 53.6811 - val_accuracy: 0.4140\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 1.8766790628433228\n",
      "Training Accuracy: 0.9306666851043701\n",
      "Validation Loss: 53.68114471435547\n",
      "Validation Accuracy: 0.414000004529953\n",
      "Classification Error Rate: 0.585999995470047\n",
      "----->Evolution: Child net_11 with fitness 53.68114471435547 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Tournament selection\n",
      "Selected net_3 and net_6 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83ca557c0>, <__main__.Block object at 0x77f83d9d1f00>, <__main__.Block object at 0x77f83c63b040>, <__main__.Block object at 0x77f83d9c93c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 9ms/step - loss: 2.3755 - accuracy: 0.1440 - val_loss: 2.0685 - val_accuracy: 0.2000\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.0490 - accuracy: 0.2549 - val_loss: 2.0939 - val_accuracy: 0.2500\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8805 - accuracy: 0.3124 - val_loss: 1.7166 - val_accuracy: 0.3760\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.7280 - accuracy: 0.3824 - val_loss: 1.9380 - val_accuracy: 0.2560\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.5977 - accuracy: 0.4327 - val_loss: 1.7096 - val_accuracy: 0.4280\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.4841 - accuracy: 0.4642 - val_loss: 1.5355 - val_accuracy: 0.4520\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.3780 - accuracy: 0.5029 - val_loss: 1.5726 - val_accuracy: 0.4720\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.2638 - accuracy: 0.5458 - val_loss: 1.3925 - val_accuracy: 0.4980\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.1729 - accuracy: 0.5869 - val_loss: 1.4955 - val_accuracy: 0.4900\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.0848 - accuracy: 0.6096 - val_loss: 1.4964 - val_accuracy: 0.5120\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.9613 - accuracy: 0.6618 - val_loss: 1.5823 - val_accuracy: 0.4940\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.8823 - accuracy: 0.6847 - val_loss: 1.5116 - val_accuracy: 0.5260\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.7806 - accuracy: 0.7236 - val_loss: 1.5236 - val_accuracy: 0.5320\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.7084 - accuracy: 0.7562 - val_loss: 1.8097 - val_accuracy: 0.5000\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.6036 - accuracy: 0.7902 - val_loss: 1.8588 - val_accuracy: 0.5160\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5530 - accuracy: 0.8078 - val_loss: 2.0399 - val_accuracy: 0.5120\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4854 - accuracy: 0.8304 - val_loss: 2.2325 - val_accuracy: 0.4940\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4054 - accuracy: 0.8598 - val_loss: 2.4059 - val_accuracy: 0.4820\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3971 - accuracy: 0.8662 - val_loss: 2.2448 - val_accuracy: 0.5480\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3519 - accuracy: 0.8753 - val_loss: 2.6148 - val_accuracy: 0.5280\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3164 - accuracy: 0.8940 - val_loss: 2.3339 - val_accuracy: 0.5420\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3113 - accuracy: 0.8942 - val_loss: 2.6711 - val_accuracy: 0.5160\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2817 - accuracy: 0.9082 - val_loss: 2.5080 - val_accuracy: 0.5380\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2681 - accuracy: 0.9156 - val_loss: 2.8353 - val_accuracy: 0.5640\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2543 - accuracy: 0.9209 - val_loss: 4.0281 - val_accuracy: 0.5040\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2530 - accuracy: 0.9227 - val_loss: 2.9135 - val_accuracy: 0.5480\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2243 - accuracy: 0.9249 - val_loss: 3.2873 - val_accuracy: 0.5400\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2051 - accuracy: 0.9353 - val_loss: 3.2132 - val_accuracy: 0.5440\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2189 - accuracy: 0.9347 - val_loss: 3.2932 - val_accuracy: 0.5520\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2172 - accuracy: 0.9338 - val_loss: 4.5868 - val_accuracy: 0.4940\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2337 - accuracy: 0.9344 - val_loss: 3.4742 - val_accuracy: 0.5580\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2049 - accuracy: 0.9382 - val_loss: 3.7888 - val_accuracy: 0.4980\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2207 - accuracy: 0.9378 - val_loss: 4.3846 - val_accuracy: 0.5320\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1789 - accuracy: 0.9467 - val_loss: 4.1050 - val_accuracy: 0.5300\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1893 - accuracy: 0.9464 - val_loss: 4.2275 - val_accuracy: 0.5420\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1980 - accuracy: 0.9442 - val_loss: 4.1852 - val_accuracy: 0.5400\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2108 - accuracy: 0.9407 - val_loss: 4.1661 - val_accuracy: 0.5200\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1746 - accuracy: 0.9487 - val_loss: 5.4484 - val_accuracy: 0.4740\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1767 - accuracy: 0.9491 - val_loss: 4.6928 - val_accuracy: 0.5380\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2030 - accuracy: 0.9484 - val_loss: 4.5937 - val_accuracy: 0.5500\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2042 - accuracy: 0.9516 - val_loss: 4.5319 - val_accuracy: 0.5040\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.2002 - accuracy: 0.9473 - val_loss: 4.8528 - val_accuracy: 0.5240\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1954 - accuracy: 0.9487 - val_loss: 5.5103 - val_accuracy: 0.5360\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1853 - accuracy: 0.9496 - val_loss: 5.7448 - val_accuracy: 0.5180\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2116 - accuracy: 0.9467 - val_loss: 4.6100 - val_accuracy: 0.5360\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1345 - accuracy: 0.9618 - val_loss: 5.4516 - val_accuracy: 0.5360\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1960 - accuracy: 0.9482 - val_loss: 5.2132 - val_accuracy: 0.5460\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1627 - accuracy: 0.9562 - val_loss: 5.6607 - val_accuracy: 0.5240\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2132 - accuracy: 0.9473 - val_loss: 4.9636 - val_accuracy: 0.5420\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1551 - accuracy: 0.9569 - val_loss: 5.4149 - val_accuracy: 0.5580\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 0.1550925076007843\n",
      "Training Accuracy: 0.9568889141082764\n",
      "Validation Loss: 5.4149088859558105\n",
      "Validation Accuracy: 0.5580000281333923\n",
      "Classification Error Rate: 0.44199997186660767\n",
      "----->Evolution: Child net_12 with fitness 5.4149088859558105 replaces parent net_1 with fitness 7.2743377685546875\n",
      "\n",
      "Creating Child 3\n",
      "----->Tournament selection\n",
      "Selected net_5 and net_7 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83a7957c0>, <__main__.Block object at 0x77f83a83e240>, <__main__.Block object at 0x77fd045d2180>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 10ms/step - loss: 31.3714 - accuracy: 0.1491 - val_loss: 172.8746 - val_accuracy: 0.1060\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 21.6789 - accuracy: 0.2591 - val_loss: 174.9180 - val_accuracy: 0.1000\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 15.0420 - accuracy: 0.3356 - val_loss: 77.0631 - val_accuracy: 0.1100\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 7.9926 - accuracy: 0.4013 - val_loss: 155.4302 - val_accuracy: 0.1600\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 16.4229 - accuracy: 0.4611 - val_loss: 138.0665 - val_accuracy: 0.2240\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 21.7108 - accuracy: 0.5327 - val_loss: 96.2768 - val_accuracy: 0.3100\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 16.0533 - accuracy: 0.6349 - val_loss: 155.0304 - val_accuracy: 0.2960\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 24.1114 - accuracy: 0.7216 - val_loss: 178.7894 - val_accuracy: 0.2720\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 22.2991 - accuracy: 0.7900 - val_loss: 89.9072 - val_accuracy: 0.3200\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 7.9807 - accuracy: 0.8582 - val_loss: 137.3848 - val_accuracy: 0.3120\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 12.2855 - accuracy: 0.9011 - val_loss: 110.4398 - val_accuracy: 0.3120\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 12.7483 - accuracy: 0.9122 - val_loss: 75.9141 - val_accuracy: 0.3480\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 7.0249 - accuracy: 0.9364 - val_loss: 229.9297 - val_accuracy: 0.3760\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 26.2598 - accuracy: 0.9402 - val_loss: 231.3995 - val_accuracy: 0.4080\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 19.5927 - accuracy: 0.9584 - val_loss: 98.3370 - val_accuracy: 0.3900\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 9.9507 - accuracy: 0.9551 - val_loss: 126.2095 - val_accuracy: 0.3760\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 11.4084 - accuracy: 0.9607 - val_loss: 245.1202 - val_accuracy: 0.3780\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 19.3563 - accuracy: 0.9627 - val_loss: 167.8046 - val_accuracy: 0.3620\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 16.2139 - accuracy: 0.9638 - val_loss: 178.2863 - val_accuracy: 0.3940\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 23.8174 - accuracy: 0.9664 - val_loss: 233.1557 - val_accuracy: 0.3540\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 27.6567 - accuracy: 0.9751 - val_loss: 151.4631 - val_accuracy: 0.3660\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 14.3598 - accuracy: 0.9678 - val_loss: 155.3991 - val_accuracy: 0.3260\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 19.8731 - accuracy: 0.9667 - val_loss: 193.0098 - val_accuracy: 0.3740\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 15.2937 - accuracy: 0.9667 - val_loss: 237.1177 - val_accuracy: 0.4100\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 33.0302 - accuracy: 0.9720 - val_loss: 256.0422 - val_accuracy: 0.3660\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 23.1615 - accuracy: 0.9707 - val_loss: 278.3178 - val_accuracy: 0.3540\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 15.1999 - accuracy: 0.9742 - val_loss: 285.6197 - val_accuracy: 0.4020\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 29.5666 - accuracy: 0.9693 - val_loss: 403.5586 - val_accuracy: 0.3840\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 29.1214 - accuracy: 0.9729 - val_loss: 320.2273 - val_accuracy: 0.3640\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 48.1873 - accuracy: 0.9727 - val_loss: 587.2978 - val_accuracy: 0.3900\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 40.2834 - accuracy: 0.9764 - val_loss: 545.7504 - val_accuracy: 0.3860\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 59.3118 - accuracy: 0.9724 - val_loss: 385.9758 - val_accuracy: 0.3680\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 44.8614 - accuracy: 0.9691 - val_loss: 324.1957 - val_accuracy: 0.3640\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 34.5883 - accuracy: 0.9738 - val_loss: 316.0872 - val_accuracy: 0.3740\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 34.1631 - accuracy: 0.9771 - val_loss: 396.1297 - val_accuracy: 0.4220\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 38.5545 - accuracy: 0.9731 - val_loss: 341.6217 - val_accuracy: 0.4240\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 26.8086 - accuracy: 0.9731 - val_loss: 471.2430 - val_accuracy: 0.3880\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 52.0067 - accuracy: 0.9740 - val_loss: 559.7042 - val_accuracy: 0.3720\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 30.1989 - accuracy: 0.9782 - val_loss: 356.5965 - val_accuracy: 0.3840\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 52.9875 - accuracy: 0.9758 - val_loss: 339.8363 - val_accuracy: 0.4000\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 51.8177 - accuracy: 0.9798 - val_loss: 439.6098 - val_accuracy: 0.3960\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 39.4918 - accuracy: 0.9767 - val_loss: 466.3682 - val_accuracy: 0.3640\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 49.6201 - accuracy: 0.9758 - val_loss: 584.7402 - val_accuracy: 0.3820\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 60.7687 - accuracy: 0.9769 - val_loss: 307.2387 - val_accuracy: 0.3880\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 33.9778 - accuracy: 0.9809 - val_loss: 704.5847 - val_accuracy: 0.3780\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 66.0156 - accuracy: 0.9829 - val_loss: 201.0524 - val_accuracy: 0.3800\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 32.6716 - accuracy: 0.9800 - val_loss: 503.3286 - val_accuracy: 0.4160\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 72.9389 - accuracy: 0.9811 - val_loss: 433.2387 - val_accuracy: 0.4160\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 15.3697 - accuracy: 0.9818 - val_loss: 667.0814 - val_accuracy: 0.4020\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 36.4994 - accuracy: 0.9804 - val_loss: 551.2252 - val_accuracy: 0.4060\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 36.499351501464844\n",
      "Training Accuracy: 0.9804444313049316\n",
      "Validation Loss: 551.2252197265625\n",
      "Validation Accuracy: 0.4059999883174896\n",
      "Classification Error Rate: 0.5940000116825104\n",
      "----->Evolution: Child net_13 with fitness 551.2252197265625 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 8\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Proportionate selection\n",
      "Selected net_3 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83a31d7c0>, <__main__.Block object at 0x77f83a33db80>, <__main__.Block object at 0x77f83a376940>, <__main__.Block object at 0x77f83a312940>, <__main__.Block object at 0x77f83a349e40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 4s 10ms/step - loss: 2.3655 - accuracy: 0.1396 - val_loss: 2.4178 - val_accuracy: 0.1400\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.1105 - accuracy: 0.2238 - val_loss: 2.7207 - val_accuracy: 0.2700\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.9041 - accuracy: 0.3049 - val_loss: 2.1862 - val_accuracy: 0.2940\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.7809 - accuracy: 0.3662 - val_loss: 2.5132 - val_accuracy: 0.2000\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.6553 - accuracy: 0.4176 - val_loss: 2.1065 - val_accuracy: 0.3520\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.5595 - accuracy: 0.4569 - val_loss: 2.5908 - val_accuracy: 0.2800\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.4305 - accuracy: 0.4931 - val_loss: 3.2362 - val_accuracy: 0.2900\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3833 - accuracy: 0.5304 - val_loss: 2.6239 - val_accuracy: 0.3780\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.3437 - accuracy: 0.5700 - val_loss: 4.1311 - val_accuracy: 0.2940\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.2615 - accuracy: 0.5944 - val_loss: 5.3307 - val_accuracy: 0.2540\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.0997 - accuracy: 0.6302 - val_loss: 4.2283 - val_accuracy: 0.3200\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.0153 - accuracy: 0.6667 - val_loss: 4.5370 - val_accuracy: 0.3840\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.9480 - accuracy: 0.6829 - val_loss: 3.3560 - val_accuracy: 0.4240\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.9402 - accuracy: 0.7162 - val_loss: 3.4947 - val_accuracy: 0.4260\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8344 - accuracy: 0.7351 - val_loss: 4.2675 - val_accuracy: 0.3640\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.7549 - accuracy: 0.7544 - val_loss: 5.4901 - val_accuracy: 0.4660\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.6749 - accuracy: 0.7831 - val_loss: 3.4812 - val_accuracy: 0.4000\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.6472 - accuracy: 0.8002 - val_loss: 5.2844 - val_accuracy: 0.4140\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.6528 - accuracy: 0.8187 - val_loss: 4.2939 - val_accuracy: 0.4540\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.6469 - accuracy: 0.8262 - val_loss: 6.5872 - val_accuracy: 0.4180\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5666 - accuracy: 0.8487 - val_loss: 5.4436 - val_accuracy: 0.4140\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5440 - accuracy: 0.8507 - val_loss: 7.4138 - val_accuracy: 0.4160\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5711 - accuracy: 0.8544 - val_loss: 8.3638 - val_accuracy: 0.3940\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5646 - accuracy: 0.8676 - val_loss: 8.0735 - val_accuracy: 0.4080\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5541 - accuracy: 0.8620 - val_loss: 7.5999 - val_accuracy: 0.3880\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.6358 - accuracy: 0.8780 - val_loss: 5.9055 - val_accuracy: 0.4520\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5832 - accuracy: 0.8840 - val_loss: 9.4189 - val_accuracy: 0.3920\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 0.4870 - accuracy: 0.8944 - val_loss: 5.6500 - val_accuracy: 0.4480\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4905 - accuracy: 0.8873 - val_loss: 6.4507 - val_accuracy: 0.4740\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5265 - accuracy: 0.8938 - val_loss: 6.4554 - val_accuracy: 0.4520\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4731 - accuracy: 0.8927 - val_loss: 8.7561 - val_accuracy: 0.4680\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.7526 - accuracy: 0.8887 - val_loss: 6.0713 - val_accuracy: 0.4520\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4979 - accuracy: 0.8920 - val_loss: 12.4985 - val_accuracy: 0.3980\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5969 - accuracy: 0.8951 - val_loss: 8.6405 - val_accuracy: 0.4780\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.5274 - accuracy: 0.8987 - val_loss: 10.2844 - val_accuracy: 0.4460\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5526 - accuracy: 0.9058 - val_loss: 9.0570 - val_accuracy: 0.4200\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4520 - accuracy: 0.9044 - val_loss: 8.6024 - val_accuracy: 0.4080\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4498 - accuracy: 0.9018 - val_loss: 7.6737 - val_accuracy: 0.4380\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4389 - accuracy: 0.9053 - val_loss: 8.5765 - val_accuracy: 0.4360\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.4970 - accuracy: 0.9004 - val_loss: 11.7227 - val_accuracy: 0.4400\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.6687 - accuracy: 0.9124 - val_loss: 8.3034 - val_accuracy: 0.4700\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5546 - accuracy: 0.9127 - val_loss: 12.9531 - val_accuracy: 0.4460\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5169 - accuracy: 0.9100 - val_loss: 9.7805 - val_accuracy: 0.4360\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5245 - accuracy: 0.9182 - val_loss: 8.6530 - val_accuracy: 0.4480\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.6721 - accuracy: 0.9100 - val_loss: 10.5718 - val_accuracy: 0.4720\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5512 - accuracy: 0.9104 - val_loss: 8.9611 - val_accuracy: 0.4680\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5247 - accuracy: 0.9133 - val_loss: 7.4846 - val_accuracy: 0.4440\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5341 - accuracy: 0.9029 - val_loss: 9.5199 - val_accuracy: 0.4040\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5815 - accuracy: 0.9140 - val_loss: 15.5634 - val_accuracy: 0.3220\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.6656 - accuracy: 0.9062 - val_loss: 12.7955 - val_accuracy: 0.3980\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.6655988693237305\n",
      "Training Accuracy: 0.9062222242355347\n",
      "Validation Loss: 12.795494079589844\n",
      "Validation Accuracy: 0.39800000190734863\n",
      "Classification Error Rate: 0.6019999980926514\n",
      "----->Evolution: Child net_10 with fitness 12.795494079589844 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Proportionate selection\n",
      "Selected net_9 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  256.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83921d600>, <__main__.Block object at 0x77f83927ef40>, <__main__.Block object at 0x77f8392c57c0>, <__main__.Block object at 0x77f838026940>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 4s 10ms/step - loss: 2.2622 - accuracy: 0.1558 - val_loss: 2.0282 - val_accuracy: 0.2560\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.9772 - accuracy: 0.2538 - val_loss: 1.9100 - val_accuracy: 0.2940\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.8590 - accuracy: 0.2856 - val_loss: 1.9837 - val_accuracy: 0.2940\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.7320 - accuracy: 0.3507 - val_loss: 1.7605 - val_accuracy: 0.3420\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.6250 - accuracy: 0.3909 - val_loss: 1.5708 - val_accuracy: 0.4260\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.5416 - accuracy: 0.4338 - val_loss: 1.5594 - val_accuracy: 0.4320\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.4482 - accuracy: 0.4627 - val_loss: 1.6730 - val_accuracy: 0.4040\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.3607 - accuracy: 0.5000 - val_loss: 1.6298 - val_accuracy: 0.4140\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.2778 - accuracy: 0.5318 - val_loss: 1.3963 - val_accuracy: 0.4960\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.1685 - accuracy: 0.5804 - val_loss: 1.7896 - val_accuracy: 0.4720\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.1080 - accuracy: 0.5991 - val_loss: 1.3243 - val_accuracy: 0.5360\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.9873 - accuracy: 0.6444 - val_loss: 1.3494 - val_accuracy: 0.5340\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.8915 - accuracy: 0.6787 - val_loss: 1.6716 - val_accuracy: 0.5100\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8082 - accuracy: 0.7229 - val_loss: 1.4013 - val_accuracy: 0.5820\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.6999 - accuracy: 0.7469 - val_loss: 1.5350 - val_accuracy: 0.5580\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.5978 - accuracy: 0.7869 - val_loss: 1.8244 - val_accuracy: 0.5340\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5126 - accuracy: 0.8207 - val_loss: 2.5495 - val_accuracy: 0.4640\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4507 - accuracy: 0.8489 - val_loss: 2.1035 - val_accuracy: 0.5520\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3935 - accuracy: 0.8636 - val_loss: 2.5503 - val_accuracy: 0.5000\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3445 - accuracy: 0.8864 - val_loss: 2.4464 - val_accuracy: 0.5140\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3041 - accuracy: 0.8980 - val_loss: 2.1111 - val_accuracy: 0.5620\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2897 - accuracy: 0.9118 - val_loss: 2.4712 - val_accuracy: 0.5360\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2618 - accuracy: 0.9220 - val_loss: 2.9114 - val_accuracy: 0.5240\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2444 - accuracy: 0.9313 - val_loss: 2.6161 - val_accuracy: 0.5520\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.2301 - accuracy: 0.9316 - val_loss: 2.6375 - val_accuracy: 0.5680\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1836 - accuracy: 0.9449 - val_loss: 2.7194 - val_accuracy: 0.5500\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1933 - accuracy: 0.9491 - val_loss: 3.2763 - val_accuracy: 0.5480\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1829 - accuracy: 0.9467 - val_loss: 3.2926 - val_accuracy: 0.5180\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1711 - accuracy: 0.9531 - val_loss: 3.4195 - val_accuracy: 0.5000\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1906 - accuracy: 0.9464 - val_loss: 3.3912 - val_accuracy: 0.5220\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1836 - accuracy: 0.9511 - val_loss: 3.1590 - val_accuracy: 0.5120\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1598 - accuracy: 0.9542 - val_loss: 3.0316 - val_accuracy: 0.5260\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1716 - accuracy: 0.9560 - val_loss: 3.6537 - val_accuracy: 0.5160\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1674 - accuracy: 0.9627 - val_loss: 3.9266 - val_accuracy: 0.5600\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1552 - accuracy: 0.9580 - val_loss: 3.9302 - val_accuracy: 0.5460\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.1589 - accuracy: 0.9553 - val_loss: 3.8073 - val_accuracy: 0.5040\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1398 - accuracy: 0.9676 - val_loss: 4.0646 - val_accuracy: 0.5180\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1439 - accuracy: 0.9576 - val_loss: 4.2103 - val_accuracy: 0.5300\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.1249 - accuracy: 0.9653 - val_loss: 5.4921 - val_accuracy: 0.5300\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.1760 - accuracy: 0.9558 - val_loss: 4.0624 - val_accuracy: 0.5180\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.1283 - accuracy: 0.9649 - val_loss: 4.1539 - val_accuracy: 0.5280\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.1500 - accuracy: 0.9616 - val_loss: 3.5063 - val_accuracy: 0.4940\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1100 - accuracy: 0.9700 - val_loss: 4.4350 - val_accuracy: 0.5420\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1240 - accuracy: 0.9678 - val_loss: 4.4943 - val_accuracy: 0.5200\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1237 - accuracy: 0.9733 - val_loss: 4.0915 - val_accuracy: 0.5400\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1146 - accuracy: 0.9744 - val_loss: 5.3220 - val_accuracy: 0.4740\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.1435 - accuracy: 0.9651 - val_loss: 3.9271 - val_accuracy: 0.5140\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1187 - accuracy: 0.9702 - val_loss: 3.6547 - val_accuracy: 0.5600\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.1141 - accuracy: 0.9687 - val_loss: 4.0383 - val_accuracy: 0.5280\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1168 - accuracy: 0.9702 - val_loss: 4.5373 - val_accuracy: 0.4980\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 0.11682158708572388\n",
      "Training Accuracy: 0.9702222347259521\n",
      "Validation Loss: 4.537270545959473\n",
      "Validation Accuracy: 0.49799999594688416\n",
      "Classification Error Rate: 0.5020000040531158\n",
      "----->Evolution: Child net_11 with fitness 4.537270545959473 replaces parent net_9 with fitness 7.191214561462402\n",
      "\n",
      "Creating Child 2\n",
      "----->Proportionate selection\n",
      "Selected net_7 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  128.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f839a16d00>, <__main__.Block object at 0x77f8398cdac0>, <__main__.Block object at 0x77f83971ca80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 6ms/step - loss: 2.0851 - accuracy: 0.2300 - val_loss: 1.8860 - val_accuracy: 0.3080\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.7340 - accuracy: 0.3736 - val_loss: 1.5888 - val_accuracy: 0.4420\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.5580 - accuracy: 0.4451 - val_loss: 1.5786 - val_accuracy: 0.4440\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.4522 - accuracy: 0.4864 - val_loss: 1.4713 - val_accuracy: 0.4780\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.3611 - accuracy: 0.5207 - val_loss: 1.4812 - val_accuracy: 0.5020\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2595 - accuracy: 0.5558 - val_loss: 1.4549 - val_accuracy: 0.4800\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.1854 - accuracy: 0.5916 - val_loss: 1.5763 - val_accuracy: 0.4520\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.1008 - accuracy: 0.6202 - val_loss: 1.5350 - val_accuracy: 0.4720\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0277 - accuracy: 0.6364 - val_loss: 1.4255 - val_accuracy: 0.5120\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9494 - accuracy: 0.6658 - val_loss: 1.4484 - val_accuracy: 0.4820\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8683 - accuracy: 0.6927 - val_loss: 1.5226 - val_accuracy: 0.5220\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7976 - accuracy: 0.7198 - val_loss: 1.5173 - val_accuracy: 0.5340\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7293 - accuracy: 0.7400 - val_loss: 1.5814 - val_accuracy: 0.5120\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6668 - accuracy: 0.7733 - val_loss: 1.5202 - val_accuracy: 0.5260\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6006 - accuracy: 0.7876 - val_loss: 1.7268 - val_accuracy: 0.5280\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5328 - accuracy: 0.8122 - val_loss: 1.7745 - val_accuracy: 0.5340\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4753 - accuracy: 0.8302 - val_loss: 1.7847 - val_accuracy: 0.5300\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4171 - accuracy: 0.8509 - val_loss: 1.8579 - val_accuracy: 0.5340\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3729 - accuracy: 0.8649 - val_loss: 2.0985 - val_accuracy: 0.5340\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3362 - accuracy: 0.8829 - val_loss: 2.3544 - val_accuracy: 0.5020\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2869 - accuracy: 0.9016 - val_loss: 2.4539 - val_accuracy: 0.5040\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2522 - accuracy: 0.9151 - val_loss: 2.4028 - val_accuracy: 0.5120\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.2205 - accuracy: 0.9242 - val_loss: 2.3654 - val_accuracy: 0.5420\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1954 - accuracy: 0.9336 - val_loss: 2.4869 - val_accuracy: 0.5480\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1752 - accuracy: 0.9400 - val_loss: 2.6574 - val_accuracy: 0.5240\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1633 - accuracy: 0.9418 - val_loss: 2.8221 - val_accuracy: 0.5140\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1395 - accuracy: 0.9547 - val_loss: 3.5171 - val_accuracy: 0.4900\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1293 - accuracy: 0.9540 - val_loss: 3.3451 - val_accuracy: 0.5200\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1339 - accuracy: 0.9551 - val_loss: 3.4686 - val_accuracy: 0.5360\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1197 - accuracy: 0.9613 - val_loss: 3.5760 - val_accuracy: 0.5400\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1037 - accuracy: 0.9656 - val_loss: 3.6423 - val_accuracy: 0.5380\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1108 - accuracy: 0.9642 - val_loss: 3.4916 - val_accuracy: 0.5180\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1218 - accuracy: 0.9640 - val_loss: 3.9145 - val_accuracy: 0.5160\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0835 - accuracy: 0.9731 - val_loss: 4.0970 - val_accuracy: 0.5060\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0871 - accuracy: 0.9724 - val_loss: 3.6301 - val_accuracy: 0.5280\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0855 - accuracy: 0.9751 - val_loss: 4.1474 - val_accuracy: 0.5320\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0973 - accuracy: 0.9671 - val_loss: 4.2353 - val_accuracy: 0.5180\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0872 - accuracy: 0.9756 - val_loss: 4.5526 - val_accuracy: 0.4840\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0911 - accuracy: 0.9702 - val_loss: 4.3146 - val_accuracy: 0.5360\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0881 - accuracy: 0.9713 - val_loss: 4.3728 - val_accuracy: 0.5200\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0744 - accuracy: 0.9758 - val_loss: 4.8074 - val_accuracy: 0.5200\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0719 - accuracy: 0.9756 - val_loss: 5.3558 - val_accuracy: 0.5080\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0662 - accuracy: 0.9769 - val_loss: 4.5503 - val_accuracy: 0.5360\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0730 - accuracy: 0.9784 - val_loss: 4.4979 - val_accuracy: 0.5200\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0839 - accuracy: 0.9753 - val_loss: 5.2144 - val_accuracy: 0.5000\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0697 - accuracy: 0.9764 - val_loss: 4.8065 - val_accuracy: 0.5300\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0792 - accuracy: 0.9758 - val_loss: 5.3354 - val_accuracy: 0.5180\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0742 - accuracy: 0.9773 - val_loss: 5.5600 - val_accuracy: 0.4880\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0749 - accuracy: 0.9796 - val_loss: 4.9801 - val_accuracy: 0.5360\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0835 - accuracy: 0.9736 - val_loss: 5.2055 - val_accuracy: 0.5320\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 0.0834696963429451\n",
      "Training Accuracy: 0.9735555648803711\n",
      "Validation Loss: 5.205547332763672\n",
      "Validation Accuracy: 0.5320000052452087\n",
      "Classification Error Rate: 0.46799999475479126\n",
      "----->Evolution: Child net_12 with fitness 5.205547332763672 replaces parent net_4 with fitness 7.039821147918701\n",
      "\n",
      "Creating Child 3\n",
      "----->Proportionate selection\n",
      "Selected net_1 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f8394ed7c0>, <__main__.Block object at 0x77f839469240>, <__main__.Block object at 0x77fc729b2380>, <__main__.Block object at 0x77f8372c8a40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 8ms/step - loss: 2.4975 - accuracy: 0.1151 - val_loss: 2.2615 - val_accuracy: 0.1580\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 2.1830 - accuracy: 0.2158 - val_loss: 2.0606 - val_accuracy: 0.2600\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.9555 - accuracy: 0.2971 - val_loss: 1.9273 - val_accuracy: 0.2980\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.7680 - accuracy: 0.3578 - val_loss: 1.7779 - val_accuracy: 0.3620\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.6667 - accuracy: 0.3962 - val_loss: 1.8983 - val_accuracy: 0.3520\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.5647 - accuracy: 0.4389 - val_loss: 1.6239 - val_accuracy: 0.4260\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.4657 - accuracy: 0.4664 - val_loss: 1.6919 - val_accuracy: 0.4440\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.3805 - accuracy: 0.5004 - val_loss: 1.7001 - val_accuracy: 0.4460\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.3090 - accuracy: 0.5356 - val_loss: 1.7613 - val_accuracy: 0.4080\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.2254 - accuracy: 0.5671 - val_loss: 1.7478 - val_accuracy: 0.3960\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.1434 - accuracy: 0.5991 - val_loss: 1.7146 - val_accuracy: 0.4520\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.0627 - accuracy: 0.6307 - val_loss: 1.9684 - val_accuracy: 0.4260\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.9968 - accuracy: 0.6496 - val_loss: 2.0893 - val_accuracy: 0.4020\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.9355 - accuracy: 0.6680 - val_loss: 1.9554 - val_accuracy: 0.4480\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.8526 - accuracy: 0.7004 - val_loss: 2.1164 - val_accuracy: 0.4400\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.8131 - accuracy: 0.7169 - val_loss: 2.1909 - val_accuracy: 0.4560\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.7609 - accuracy: 0.7393 - val_loss: 2.4112 - val_accuracy: 0.4260\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.6735 - accuracy: 0.7629 - val_loss: 2.4817 - val_accuracy: 0.4060\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.6509 - accuracy: 0.7771 - val_loss: 2.5247 - val_accuracy: 0.4440\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5855 - accuracy: 0.7962 - val_loss: 2.7129 - val_accuracy: 0.4480\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5558 - accuracy: 0.8069 - val_loss: 3.0736 - val_accuracy: 0.4080\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4832 - accuracy: 0.8313 - val_loss: 3.3633 - val_accuracy: 0.4300\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4670 - accuracy: 0.8336 - val_loss: 3.3657 - val_accuracy: 0.4460\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4425 - accuracy: 0.8433 - val_loss: 3.8730 - val_accuracy: 0.4140\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4091 - accuracy: 0.8596 - val_loss: 3.8971 - val_accuracy: 0.4520\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3907 - accuracy: 0.8649 - val_loss: 4.1841 - val_accuracy: 0.4380\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3781 - accuracy: 0.8769 - val_loss: 4.2225 - val_accuracy: 0.4360\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3560 - accuracy: 0.8767 - val_loss: 4.4288 - val_accuracy: 0.4280\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3401 - accuracy: 0.8876 - val_loss: 4.2994 - val_accuracy: 0.4420\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2956 - accuracy: 0.9053 - val_loss: 5.2454 - val_accuracy: 0.3700\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3228 - accuracy: 0.8944 - val_loss: 4.8935 - val_accuracy: 0.4140\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3189 - accuracy: 0.9007 - val_loss: 5.0353 - val_accuracy: 0.4420\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3132 - accuracy: 0.9078 - val_loss: 5.7176 - val_accuracy: 0.4600\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3285 - accuracy: 0.9020 - val_loss: 5.3434 - val_accuracy: 0.4500\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2779 - accuracy: 0.9184 - val_loss: 5.8841 - val_accuracy: 0.4040\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2924 - accuracy: 0.9140 - val_loss: 6.0700 - val_accuracy: 0.4340\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3084 - accuracy: 0.9140 - val_loss: 8.9453 - val_accuracy: 0.4060\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2887 - accuracy: 0.9160 - val_loss: 6.7075 - val_accuracy: 0.4240\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3034 - accuracy: 0.9193 - val_loss: 7.3836 - val_accuracy: 0.4060\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2676 - accuracy: 0.9318 - val_loss: 7.1780 - val_accuracy: 0.4240\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3245 - accuracy: 0.9198 - val_loss: 7.7318 - val_accuracy: 0.4140\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2584 - accuracy: 0.9291 - val_loss: 7.6161 - val_accuracy: 0.4320\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2699 - accuracy: 0.9298 - val_loss: 7.2627 - val_accuracy: 0.4180\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3369 - accuracy: 0.9224 - val_loss: 7.9726 - val_accuracy: 0.3820\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2944 - accuracy: 0.9282 - val_loss: 8.0857 - val_accuracy: 0.4220\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3366 - accuracy: 0.9278 - val_loss: 10.5024 - val_accuracy: 0.3800\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3351 - accuracy: 0.9218 - val_loss: 8.5230 - val_accuracy: 0.4300\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3227 - accuracy: 0.9251 - val_loss: 9.0606 - val_accuracy: 0.4140\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2773 - accuracy: 0.9371 - val_loss: 9.3352 - val_accuracy: 0.4100\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3165 - accuracy: 0.9284 - val_loss: 8.7445 - val_accuracy: 0.4540\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 0.31654590368270874\n",
      "Training Accuracy: 0.9284444451332092\n",
      "Validation Loss: 8.744542121887207\n",
      "Validation Accuracy: 0.45399999618530273\n",
      "Classification Error Rate: 0.5460000038146973\n",
      "----->Evolution: Child net_13 with fitness 8.744542121887207 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 9\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83ce2a940>, <__main__.Block object at 0x77f839968540>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 2s 5ms/step - loss: 2.8425 - accuracy: 0.2580 - val_loss: 1.8086 - val_accuracy: 0.3640\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.6855 - accuracy: 0.3973 - val_loss: 1.7853 - val_accuracy: 0.3720\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.3631 - accuracy: 0.5260 - val_loss: 1.7498 - val_accuracy: 0.4100\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0348 - accuracy: 0.6280 - val_loss: 1.8923 - val_accuracy: 0.4380\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7409 - accuracy: 0.7407 - val_loss: 1.9156 - val_accuracy: 0.4420\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.4720 - accuracy: 0.8433 - val_loss: 1.9528 - val_accuracy: 0.4640\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.3160 - accuracy: 0.8931 - val_loss: 2.2819 - val_accuracy: 0.4700\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1882 - accuracy: 0.9402 - val_loss: 2.5614 - val_accuracy: 0.4900\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.1354 - accuracy: 0.9622 - val_loss: 2.9601 - val_accuracy: 0.4960\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0778 - accuracy: 0.9771 - val_loss: 2.9204 - val_accuracy: 0.5000\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0704 - accuracy: 0.9787 - val_loss: 3.0109 - val_accuracy: 0.5100\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0468 - accuracy: 0.9889 - val_loss: 3.4133 - val_accuracy: 0.5080\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0453 - accuracy: 0.9856 - val_loss: 3.5280 - val_accuracy: 0.4940\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0436 - accuracy: 0.9867 - val_loss: 3.8252 - val_accuracy: 0.5060\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0410 - accuracy: 0.9884 - val_loss: 4.0104 - val_accuracy: 0.4960\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0307 - accuracy: 0.9900 - val_loss: 3.9725 - val_accuracy: 0.4880\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 3.9605 - val_accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0361 - accuracy: 0.9882 - val_loss: 4.2943 - val_accuracy: 0.5000\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0200 - accuracy: 0.9931 - val_loss: 4.7607 - val_accuracy: 0.4980\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0320 - accuracy: 0.9896 - val_loss: 4.9171 - val_accuracy: 0.4940\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0200 - accuracy: 0.9947 - val_loss: 5.1435 - val_accuracy: 0.4900\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0259 - accuracy: 0.9900 - val_loss: 5.7315 - val_accuracy: 0.4860\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 4.8943 - val_accuracy: 0.4880\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9922 - val_loss: 5.1053 - val_accuracy: 0.5000\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0238 - accuracy: 0.9938 - val_loss: 5.0491 - val_accuracy: 0.5000\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0164 - accuracy: 0.9940 - val_loss: 5.0922 - val_accuracy: 0.4900\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 5.7222 - val_accuracy: 0.4660\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 5.6775 - val_accuracy: 0.5180\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 0.9962 - val_loss: 6.2331 - val_accuracy: 0.4800\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0209 - accuracy: 0.9940 - val_loss: 5.5056 - val_accuracy: 0.4840\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 6.1304 - val_accuracy: 0.4780\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 6.9342 - val_accuracy: 0.4840\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 6.1206 - val_accuracy: 0.4940\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0149 - accuracy: 0.9949 - val_loss: 7.6130 - val_accuracy: 0.4380\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0180 - accuracy: 0.9942 - val_loss: 6.3959 - val_accuracy: 0.4900\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0245 - accuracy: 0.9942 - val_loss: 6.6592 - val_accuracy: 0.4780\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0249 - accuracy: 0.9944 - val_loss: 6.6985 - val_accuracy: 0.4840\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9976 - val_loss: 7.0601 - val_accuracy: 0.4800\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 7.6604 - val_accuracy: 0.4640\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0218 - accuracy: 0.9942 - val_loss: 7.3446 - val_accuracy: 0.4780\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0126 - accuracy: 0.9962 - val_loss: 6.6307 - val_accuracy: 0.4820\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 7.0848 - val_accuracy: 0.4520\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9964 - val_loss: 6.9005 - val_accuracy: 0.4800\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 6.8615 - val_accuracy: 0.4800\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 7.3051 - val_accuracy: 0.4720\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 7.3555 - val_accuracy: 0.4840\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 7.6286 - val_accuracy: 0.4640\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 7.2016 - val_accuracy: 0.4800\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 7.4775 - val_accuracy: 0.4960\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 8.0728 - val_accuracy: 0.4800\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.0145585797727108\n",
      "Training Accuracy: 0.9957777857780457\n",
      "Validation Loss: 8.07280158996582\n",
      "Validation Accuracy: 0.47999998927116394\n",
      "Classification Error Rate: 0.5200000107288361\n",
      "----->Evolution: Child net_10 with fitness 8.07280158996582 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fd0430fdc0>, <__main__.Block object at 0x77f83950ef40>, <__main__.Block object at 0x77f839646ac0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 7ms/step - loss: 2.3767 - accuracy: 0.1704 - val_loss: 1.9979 - val_accuracy: 0.3180\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.9041 - accuracy: 0.3184 - val_loss: 1.8346 - val_accuracy: 0.3440\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.6010 - accuracy: 0.4302 - val_loss: 1.6782 - val_accuracy: 0.3700\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.3458 - accuracy: 0.5222 - val_loss: 1.5870 - val_accuracy: 0.4500\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.0907 - accuracy: 0.6171 - val_loss: 1.6203 - val_accuracy: 0.4640\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.8372 - accuracy: 0.7100 - val_loss: 1.8087 - val_accuracy: 0.4660\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.5953 - accuracy: 0.7891 - val_loss: 2.5170 - val_accuracy: 0.3900\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.3972 - accuracy: 0.8547 - val_loss: 2.2417 - val_accuracy: 0.4720\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.2538 - accuracy: 0.9158 - val_loss: 3.0671 - val_accuracy: 0.4440\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1949 - accuracy: 0.9373 - val_loss: 3.0459 - val_accuracy: 0.4780\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1459 - accuracy: 0.9542 - val_loss: 3.6633 - val_accuracy: 0.4660\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1241 - accuracy: 0.9607 - val_loss: 3.7355 - val_accuracy: 0.4500\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1139 - accuracy: 0.9656 - val_loss: 4.5618 - val_accuracy: 0.4320\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1110 - accuracy: 0.9664 - val_loss: 4.3676 - val_accuracy: 0.4740\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0921 - accuracy: 0.9700 - val_loss: 4.8730 - val_accuracy: 0.4720\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0826 - accuracy: 0.9753 - val_loss: 5.1417 - val_accuracy: 0.4680\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0859 - accuracy: 0.9762 - val_loss: 4.4659 - val_accuracy: 0.4860\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0815 - accuracy: 0.9771 - val_loss: 4.9997 - val_accuracy: 0.4760\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0737 - accuracy: 0.9793 - val_loss: 5.5614 - val_accuracy: 0.4700\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0603 - accuracy: 0.9802 - val_loss: 6.4848 - val_accuracy: 0.4800\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0844 - accuracy: 0.9762 - val_loss: 5.3685 - val_accuracy: 0.4640\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0677 - accuracy: 0.9816 - val_loss: 6.0638 - val_accuracy: 0.4780\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0588 - accuracy: 0.9813 - val_loss: 5.6501 - val_accuracy: 0.4780\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0717 - accuracy: 0.9791 - val_loss: 6.9446 - val_accuracy: 0.4660\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0732 - accuracy: 0.9802 - val_loss: 5.9443 - val_accuracy: 0.4600\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0630 - accuracy: 0.9842 - val_loss: 6.6189 - val_accuracy: 0.4640\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0587 - accuracy: 0.9822 - val_loss: 7.1353 - val_accuracy: 0.4740\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0584 - accuracy: 0.9864 - val_loss: 7.7381 - val_accuracy: 0.4840\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0651 - accuracy: 0.9842 - val_loss: 7.7877 - val_accuracy: 0.4580\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0824 - accuracy: 0.9804 - val_loss: 7.8969 - val_accuracy: 0.4840\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0623 - accuracy: 0.9836 - val_loss: 7.1831 - val_accuracy: 0.4820\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0603 - accuracy: 0.9842 - val_loss: 7.4116 - val_accuracy: 0.4640\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0655 - accuracy: 0.9856 - val_loss: 8.3864 - val_accuracy: 0.4600\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0533 - accuracy: 0.9856 - val_loss: 9.0952 - val_accuracy: 0.4320\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0767 - accuracy: 0.9827 - val_loss: 9.5748 - val_accuracy: 0.4400\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0668 - accuracy: 0.9867 - val_loss: 8.5880 - val_accuracy: 0.5000\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0699 - accuracy: 0.9847 - val_loss: 8.8386 - val_accuracy: 0.4840\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0734 - accuracy: 0.9860 - val_loss: 9.2344 - val_accuracy: 0.4900\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0681 - accuracy: 0.9869 - val_loss: 9.8649 - val_accuracy: 0.4440\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0594 - accuracy: 0.9864 - val_loss: 10.0543 - val_accuracy: 0.4540\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1053 - accuracy: 0.9827 - val_loss: 12.2814 - val_accuracy: 0.4400\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0871 - accuracy: 0.9842 - val_loss: 10.0154 - val_accuracy: 0.4640\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0662 - accuracy: 0.9858 - val_loss: 10.4618 - val_accuracy: 0.4920\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1072 - accuracy: 0.9824 - val_loss: 9.9102 - val_accuracy: 0.4820\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0619 - accuracy: 0.9873 - val_loss: 11.0423 - val_accuracy: 0.4560\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0733 - accuracy: 0.9847 - val_loss: 11.8878 - val_accuracy: 0.4880\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0997 - accuracy: 0.9831 - val_loss: 11.2520 - val_accuracy: 0.4920\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0768 - accuracy: 0.9869 - val_loss: 13.4651 - val_accuracy: 0.4760\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.1021 - accuracy: 0.9836 - val_loss: 14.7997 - val_accuracy: 0.4680\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.0751 - accuracy: 0.9864 - val_loss: 14.2058 - val_accuracy: 0.4400\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 0.07505977153778076\n",
      "Training Accuracy: 0.9864444732666016\n",
      "Validation Loss: 14.205779075622559\n",
      "Validation Accuracy: 0.4399999976158142\n",
      "Classification Error Rate: 0.5600000023841858\n",
      "----->Evolution: Child net_11 with fitness 14.205779075622559 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_8 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83a94fdc0>, <__main__.Block object at 0x77fc72ce5b80>, <__main__.Block object at 0x77fc71e01f00>, <__main__.Block object at 0x77fd044b9e40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 8ms/step - loss: 2.9205 - accuracy: 0.1220 - val_loss: 2.3005 - val_accuracy: 0.1240\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3132 - accuracy: 0.1358 - val_loss: 2.1486 - val_accuracy: 0.2180\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.2054 - accuracy: 0.1916 - val_loss: 2.1877 - val_accuracy: 0.1940\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.1135 - accuracy: 0.2271 - val_loss: 2.2307 - val_accuracy: 0.2760\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.0605 - accuracy: 0.2558 - val_loss: 2.1785 - val_accuracy: 0.1840\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.0709 - accuracy: 0.2524 - val_loss: 2.0632 - val_accuracy: 0.2000\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.0733 - accuracy: 0.2562 - val_loss: 2.0332 - val_accuracy: 0.2780\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.0789 - accuracy: 0.2589 - val_loss: 2.1902 - val_accuracy: 0.1820\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.1022 - accuracy: 0.2498 - val_loss: 2.5321 - val_accuracy: 0.2220\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.1019 - accuracy: 0.2622 - val_loss: 2.1293 - val_accuracy: 0.2580\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.0608 - accuracy: 0.2647 - val_loss: 2.1270 - val_accuracy: 0.2240\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.1114 - accuracy: 0.2284 - val_loss: 2.1448 - val_accuracy: 0.1700\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.1467 - accuracy: 0.2198 - val_loss: 2.0514 - val_accuracy: 0.2260\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.1201 - accuracy: 0.2302 - val_loss: 1.9558 - val_accuracy: 0.2400\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.1704 - accuracy: 0.1998 - val_loss: 2.2740 - val_accuracy: 0.2280\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.1283 - accuracy: 0.2027 - val_loss: 4.3237 - val_accuracy: 0.2300\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.1919 - accuracy: 0.2007 - val_loss: 2.0099 - val_accuracy: 0.2120\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.2004 - accuracy: 0.1827 - val_loss: 2.1467 - val_accuracy: 0.1800\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.4880 - accuracy: 0.1718 - val_loss: 2.1502 - val_accuracy: 0.1760\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.2182 - accuracy: 0.1742 - val_loss: 2.0515 - val_accuracy: 0.1800\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.2459 - accuracy: 0.1800 - val_loss: 2.3444 - val_accuracy: 0.1500\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.2855 - accuracy: 0.1538 - val_loss: 2.2890 - val_accuracy: 0.1680\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.2399 - accuracy: 0.1598 - val_loss: 2.2069 - val_accuracy: 0.1460\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.2914 - accuracy: 0.1429 - val_loss: 2.3310 - val_accuracy: 0.1060\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3328 - accuracy: 0.1109 - val_loss: 2.3068 - val_accuracy: 0.1000\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3075 - accuracy: 0.0989 - val_loss: 2.3029 - val_accuracy: 0.1040\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3063 - accuracy: 0.1040 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3038 - accuracy: 0.0998 - val_loss: 2.3036 - val_accuracy: 0.0940\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3044 - accuracy: 0.0931 - val_loss: 2.3025 - val_accuracy: 0.1040\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3039 - accuracy: 0.0913 - val_loss: 2.3026 - val_accuracy: 0.1040\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3039 - accuracy: 0.0982 - val_loss: 2.3042 - val_accuracy: 0.1000\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.3039 - accuracy: 0.0987 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3041 - accuracy: 0.0927 - val_loss: 2.3039 - val_accuracy: 0.1000\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3039 - accuracy: 0.0964 - val_loss: 2.3028 - val_accuracy: 0.1040\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3036 - accuracy: 0.0993 - val_loss: 2.3018 - val_accuracy: 0.1040\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3035 - accuracy: 0.0960 - val_loss: 2.3038 - val_accuracy: 0.1000\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3038 - accuracy: 0.0967 - val_loss: 2.3041 - val_accuracy: 0.0960\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3039 - accuracy: 0.0927 - val_loss: 2.3029 - val_accuracy: 0.1040\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3037 - accuracy: 0.0969 - val_loss: 2.3023 - val_accuracy: 0.0960\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3036 - accuracy: 0.0978 - val_loss: 2.3039 - val_accuracy: 0.1040\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3039 - accuracy: 0.1024 - val_loss: 2.3029 - val_accuracy: 0.0960\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3037 - accuracy: 0.1004 - val_loss: 2.3036 - val_accuracy: 0.0960\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3034 - accuracy: 0.1031 - val_loss: 2.3033 - val_accuracy: 0.1040\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3037 - accuracy: 0.0951 - val_loss: 2.3032 - val_accuracy: 0.1040\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3037 - accuracy: 0.0996 - val_loss: 2.3034 - val_accuracy: 0.1040\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3036 - accuracy: 0.0951 - val_loss: 2.3034 - val_accuracy: 0.1040\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3036 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1040\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3037 - accuracy: 0.0971 - val_loss: 2.3032 - val_accuracy: 0.1040\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3036 - accuracy: 0.0976 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3035 - accuracy: 0.1013 - val_loss: 2.3029 - val_accuracy: 0.0960\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 2.3035497665405273\n",
      "Training Accuracy: 0.10133333504199982\n",
      "Validation Loss: 2.302902936935425\n",
      "Validation Accuracy: 0.09600000083446503\n",
      "Classification Error Rate: 0.903999999165535\n",
      "----->Evolution: Child net_12 with fitness 2.302902936935425 replaces parent net_2 with fitness 6.189674377441406\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_2 and net_8 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  128.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83a7fca40>, <__main__.Block object at 0x77f83a559240>, <__main__.Block object at 0x77fd0419ff40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 6ms/step - loss: 2.4737 - accuracy: 0.1976 - val_loss: 3.9936 - val_accuracy: 0.2320\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.8518 - accuracy: 0.3620 - val_loss: 2.1596 - val_accuracy: 0.3620\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.5693 - accuracy: 0.4718 - val_loss: 5.1001 - val_accuracy: 0.2900\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.3054 - accuracy: 0.5829 - val_loss: 5.4360 - val_accuracy: 0.3940\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.2436 - accuracy: 0.6716 - val_loss: 4.4660 - val_accuracy: 0.4020\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9679 - accuracy: 0.7891 - val_loss: 5.9528 - val_accuracy: 0.3220\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.7216 - accuracy: 0.8584 - val_loss: 8.5043 - val_accuracy: 0.3840\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5522 - accuracy: 0.9131 - val_loss: 9.4897 - val_accuracy: 0.4100\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6990 - accuracy: 0.9344 - val_loss: 11.2643 - val_accuracy: 0.3660\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.7118 - accuracy: 0.9540 - val_loss: 10.1522 - val_accuracy: 0.4020\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6267 - accuracy: 0.9667 - val_loss: 12.5115 - val_accuracy: 0.3520\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.5472 - accuracy: 0.9673 - val_loss: 12.2430 - val_accuracy: 0.3920\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6554 - accuracy: 0.9678 - val_loss: 15.1227 - val_accuracy: 0.3420\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.7038 - accuracy: 0.9736 - val_loss: 15.2476 - val_accuracy: 0.4260\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6913 - accuracy: 0.9702 - val_loss: 20.8491 - val_accuracy: 0.3240\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.1544 - accuracy: 0.9764 - val_loss: 23.6416 - val_accuracy: 0.3840\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.7086 - accuracy: 0.9773 - val_loss: 28.4224 - val_accuracy: 0.3280\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6415 - accuracy: 0.9729 - val_loss: 23.8589 - val_accuracy: 0.4020\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.1238 - accuracy: 0.9758 - val_loss: 27.2978 - val_accuracy: 0.3960\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.9722 - accuracy: 0.9773 - val_loss: 16.2317 - val_accuracy: 0.3760\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.8349 - accuracy: 0.9742 - val_loss: 32.5874 - val_accuracy: 0.3760\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.2725 - accuracy: 0.9749 - val_loss: 25.3803 - val_accuracy: 0.3500\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.0731 - accuracy: 0.9764 - val_loss: 26.9117 - val_accuracy: 0.3960\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.4955 - accuracy: 0.9762 - val_loss: 19.2455 - val_accuracy: 0.4140\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.6734 - accuracy: 0.9756 - val_loss: 24.8011 - val_accuracy: 0.4540\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.0570 - accuracy: 0.9807 - val_loss: 19.4337 - val_accuracy: 0.4480\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.8739 - accuracy: 0.9820 - val_loss: 19.8913 - val_accuracy: 0.4020\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 0.9760 - accuracy: 0.9800 - val_loss: 36.0448 - val_accuracy: 0.3560\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.8115 - accuracy: 0.9827 - val_loss: 36.8240 - val_accuracy: 0.3780\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.9690 - accuracy: 0.9802 - val_loss: 34.5760 - val_accuracy: 0.4060\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.0208 - accuracy: 0.9784 - val_loss: 29.6701 - val_accuracy: 0.4340\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.2780 - accuracy: 0.9813 - val_loss: 36.3140 - val_accuracy: 0.3840\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.8324 - accuracy: 0.9798 - val_loss: 39.1443 - val_accuracy: 0.4300\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.7724 - accuracy: 0.9798 - val_loss: 52.0918 - val_accuracy: 0.3940\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3872 - accuracy: 0.9840 - val_loss: 29.5497 - val_accuracy: 0.4160\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.9044 - accuracy: 0.9822 - val_loss: 30.7511 - val_accuracy: 0.4000\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 2.0610 - accuracy: 0.9822 - val_loss: 37.0542 - val_accuracy: 0.4000\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.4710 - accuracy: 0.9818 - val_loss: 41.7941 - val_accuracy: 0.4320\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.5614 - accuracy: 0.9800 - val_loss: 33.6343 - val_accuracy: 0.4420\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.9365 - accuracy: 0.9784 - val_loss: 38.2691 - val_accuracy: 0.4020\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 0.6592 - accuracy: 0.9833 - val_loss: 34.8839 - val_accuracy: 0.4380\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.6908 - accuracy: 0.9811 - val_loss: 64.0481 - val_accuracy: 0.3720\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 2.4127 - accuracy: 0.9784 - val_loss: 43.6897 - val_accuracy: 0.4540\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 2.7584 - accuracy: 0.9809 - val_loss: 45.1379 - val_accuracy: 0.4320\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 1.1708 - accuracy: 0.9847 - val_loss: 54.9992 - val_accuracy: 0.4080\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.8497 - accuracy: 0.9822 - val_loss: 34.8646 - val_accuracy: 0.4320\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.3457 - accuracy: 0.9811 - val_loss: 44.6129 - val_accuracy: 0.4100\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.3983 - accuracy: 0.9802 - val_loss: 80.1409 - val_accuracy: 0.3980\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 4.0558 - accuracy: 0.9829 - val_loss: 52.3156 - val_accuracy: 0.4360\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 1.9799 - accuracy: 0.9809 - val_loss: 62.2179 - val_accuracy: 0.4300\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 1.979897379875183\n",
      "Training Accuracy: 0.9808889031410217\n",
      "Validation Loss: 62.217891693115234\n",
      "Validation Accuracy: 0.4300000071525574\n",
      "Classification Error Rate: 0.5699999928474426\n",
      "----->Evolution: Child net_13 with fitness 62.217891693115234 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 10\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_2 and net_8 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  64.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f83a695b80>, <__main__.Block object at 0x77f83aaa0540>, <__main__.Block object at 0x77f837ebef40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_10\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 7ms/step - loss: 2.2492 - accuracy: 0.1720 - val_loss: 2.5866 - val_accuracy: 0.1840\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.9021 - accuracy: 0.3151 - val_loss: 1.8299 - val_accuracy: 0.3880\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.6656 - accuracy: 0.4049 - val_loss: 1.8282 - val_accuracy: 0.3860\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.5120 - accuracy: 0.4658 - val_loss: 1.8842 - val_accuracy: 0.3840\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.3469 - accuracy: 0.5220 - val_loss: 2.1520 - val_accuracy: 0.4240\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.1704 - accuracy: 0.5884 - val_loss: 2.0996 - val_accuracy: 0.4100\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.0193 - accuracy: 0.6449 - val_loss: 1.9273 - val_accuracy: 0.4520\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.8430 - accuracy: 0.7122 - val_loss: 2.1551 - val_accuracy: 0.4260\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.6974 - accuracy: 0.7644 - val_loss: 2.5184 - val_accuracy: 0.4120\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5563 - accuracy: 0.8198 - val_loss: 3.4553 - val_accuracy: 0.4160\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4628 - accuracy: 0.8582 - val_loss: 3.6936 - val_accuracy: 0.3940\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3578 - accuracy: 0.8891 - val_loss: 3.9883 - val_accuracy: 0.4220\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3208 - accuracy: 0.9027 - val_loss: 4.1493 - val_accuracy: 0.4080\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2728 - accuracy: 0.9198 - val_loss: 5.3483 - val_accuracy: 0.3840\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2572 - accuracy: 0.9278 - val_loss: 5.8762 - val_accuracy: 0.3940\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2608 - accuracy: 0.9358 - val_loss: 5.8406 - val_accuracy: 0.4280\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2270 - accuracy: 0.9424 - val_loss: 6.0846 - val_accuracy: 0.4420\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2185 - accuracy: 0.9484 - val_loss: 5.7710 - val_accuracy: 0.4300\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2323 - accuracy: 0.9409 - val_loss: 6.2704 - val_accuracy: 0.4400\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2883 - accuracy: 0.9493 - val_loss: 7.4223 - val_accuracy: 0.4340\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2511 - accuracy: 0.9498 - val_loss: 7.5963 - val_accuracy: 0.4420\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2271 - accuracy: 0.9536 - val_loss: 7.3827 - val_accuracy: 0.4040\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2472 - accuracy: 0.9531 - val_loss: 9.3383 - val_accuracy: 0.4140\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2158 - accuracy: 0.9573 - val_loss: 8.8690 - val_accuracy: 0.4360\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2261 - accuracy: 0.9540 - val_loss: 9.1621 - val_accuracy: 0.4060\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2271 - accuracy: 0.9522 - val_loss: 7.4768 - val_accuracy: 0.4420\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2290 - accuracy: 0.9549 - val_loss: 9.9799 - val_accuracy: 0.4260\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2576 - accuracy: 0.9584 - val_loss: 8.6456 - val_accuracy: 0.4160\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2455 - accuracy: 0.9591 - val_loss: 9.3873 - val_accuracy: 0.4100\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2328 - accuracy: 0.9564 - val_loss: 9.3715 - val_accuracy: 0.4380\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2278 - accuracy: 0.9624 - val_loss: 9.5214 - val_accuracy: 0.3900\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3441 - accuracy: 0.9587 - val_loss: 13.9780 - val_accuracy: 0.3960\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1889 - accuracy: 0.9647 - val_loss: 10.1253 - val_accuracy: 0.4440\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2270 - accuracy: 0.9644 - val_loss: 9.6862 - val_accuracy: 0.3860\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3391 - accuracy: 0.9633 - val_loss: 9.5079 - val_accuracy: 0.4220\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1935 - accuracy: 0.9689 - val_loss: 9.4338 - val_accuracy: 0.4500\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1718 - accuracy: 0.9682 - val_loss: 12.2429 - val_accuracy: 0.3820\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2690 - accuracy: 0.9656 - val_loss: 11.9258 - val_accuracy: 0.4260\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2799 - accuracy: 0.9649 - val_loss: 10.0854 - val_accuracy: 0.4440\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2060 - accuracy: 0.9722 - val_loss: 11.1999 - val_accuracy: 0.4100\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2643 - accuracy: 0.9660 - val_loss: 13.4802 - val_accuracy: 0.4120\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2115 - accuracy: 0.9676 - val_loss: 12.3659 - val_accuracy: 0.4480\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2385 - accuracy: 0.9693 - val_loss: 12.2335 - val_accuracy: 0.4100\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3023 - accuracy: 0.9716 - val_loss: 13.9916 - val_accuracy: 0.3880\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2150 - accuracy: 0.9767 - val_loss: 13.0384 - val_accuracy: 0.4500\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2354 - accuracy: 0.9664 - val_loss: 14.0045 - val_accuracy: 0.4020\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2495 - accuracy: 0.9687 - val_loss: 14.6070 - val_accuracy: 0.4060\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2636 - accuracy: 0.9693 - val_loss: 13.7361 - val_accuracy: 0.4360\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2982 - accuracy: 0.9693 - val_loss: 14.0208 - val_accuracy: 0.4300\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3284 - accuracy: 0.9713 - val_loss: 16.5435 - val_accuracy: 0.4220\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.32844603061676025\n",
      "Training Accuracy: 0.9713333249092102\n",
      "Validation Loss: 16.543529510498047\n",
      "Validation Accuracy: 0.421999990940094\n",
      "Classification Error Rate: 0.578000009059906\n",
      "----->Evolution: Child net_10 with fitness 16.543529510498047 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_2 and net_8 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  32.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77f837d1d8c0>, <__main__.Block object at 0x77fc71508540>, <__main__.Block object at 0x77fc71506f40>, <__main__.Block object at 0x77fc7169eac0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_11\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 4s 9ms/step - loss: 2.6734 - accuracy: 0.1069 - val_loss: 2.3014 - val_accuracy: 0.1000\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3006 - accuracy: 0.1191 - val_loss: 2.2796 - val_accuracy: 0.1340\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3346 - accuracy: 0.1422 - val_loss: 2.3916 - val_accuracy: 0.1600\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.2449 - accuracy: 0.1818 - val_loss: 4.3901 - val_accuracy: 0.0980\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.2257 - accuracy: 0.2162 - val_loss: 2.8297 - val_accuracy: 0.2580\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.1776 - accuracy: 0.2471 - val_loss: 8.5202 - val_accuracy: 0.2120\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.4989 - accuracy: 0.2582 - val_loss: 2.7640 - val_accuracy: 0.1680\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.1304 - accuracy: 0.2762 - val_loss: 2.7660 - val_accuracy: 0.2580\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.1321 - accuracy: 0.2758 - val_loss: 15.9907 - val_accuracy: 0.1300\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.1689 - accuracy: 0.3038 - val_loss: 5.4252 - val_accuracy: 0.1300\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.0844 - accuracy: 0.2882 - val_loss: 4.4783 - val_accuracy: 0.2340\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.2056 - accuracy: 0.2996 - val_loss: 7.5898 - val_accuracy: 0.2000\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3155 - accuracy: 0.2964 - val_loss: 4.9613 - val_accuracy: 0.2500\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.2165 - accuracy: 0.3127 - val_loss: 15.6000 - val_accuracy: 0.2580\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 3.2346 - accuracy: 0.3096 - val_loss: 8.7491 - val_accuracy: 0.3220\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.5003 - accuracy: 0.3307 - val_loss: 2.1853 - val_accuracy: 0.2700\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.1516 - accuracy: 0.3162 - val_loss: 2.1195 - val_accuracy: 0.3000\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.0393 - accuracy: 0.3078 - val_loss: 1.9138 - val_accuracy: 0.3060\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.9286 - accuracy: 0.3040 - val_loss: 1.9385 - val_accuracy: 0.3000\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.0607 - accuracy: 0.3120 - val_loss: 2.4341 - val_accuracy: 0.2440\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.9083 - accuracy: 0.3200 - val_loss: 9.5729 - val_accuracy: 0.1640\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.1841 - accuracy: 0.2709 - val_loss: 1.9550 - val_accuracy: 0.3080\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.2496 - accuracy: 0.1582 - val_loss: 2.3160 - val_accuracy: 0.1040\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3161 - accuracy: 0.1040 - val_loss: 2.3090 - val_accuracy: 0.1040\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.1958 - accuracy: 0.1831 - val_loss: 2.4728 - val_accuracy: 0.1420\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.1007 - accuracy: 0.2218 - val_loss: 2.0442 - val_accuracy: 0.2760\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.0519 - accuracy: 0.2387 - val_loss: 2.0648 - val_accuracy: 0.2680\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.1385 - accuracy: 0.2102 - val_loss: 2.0163 - val_accuracy: 0.2600\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.1896 - accuracy: 0.1667 - val_loss: 2.3083 - val_accuracy: 0.1040\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.2094 - accuracy: 0.1733 - val_loss: 2.1289 - val_accuracy: 0.2020\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.1444 - accuracy: 0.1916 - val_loss: 2.3069 - val_accuracy: 0.1840\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.0754 - accuracy: 0.2153 - val_loss: 2.0366 - val_accuracy: 0.2280\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.0422 - accuracy: 0.2284 - val_loss: 2.0254 - val_accuracy: 0.2500\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.0230 - accuracy: 0.2451 - val_loss: 2.0103 - val_accuracy: 0.2460\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.0240 - accuracy: 0.2500 - val_loss: 64.2318 - val_accuracy: 0.2060\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 9.9035 - accuracy: 0.2591 - val_loss: 2.1781 - val_accuracy: 0.2200\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.9792 - accuracy: 0.2587 - val_loss: 1.9964 - val_accuracy: 0.2720\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.9478 - accuracy: 0.2844 - val_loss: 5.3826 - val_accuracy: 0.1520\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.9606 - accuracy: 0.2911 - val_loss: 1.9082 - val_accuracy: 0.3000\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.1680 - accuracy: 0.2756 - val_loss: 2.3043 - val_accuracy: 0.1780\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.9915 - accuracy: 0.2682 - val_loss: 1.9294 - val_accuracy: 0.2740\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.0893 - accuracy: 0.2744 - val_loss: 2.1393 - val_accuracy: 0.2440\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.1400 - accuracy: 0.1936 - val_loss: 2.0290 - val_accuracy: 0.2540\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.9106 - accuracy: 0.2909 - val_loss: 1.9419 - val_accuracy: 0.2660\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.8836 - accuracy: 0.3038 - val_loss: 1.9229 - val_accuracy: 0.3060\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 1.8632 - accuracy: 0.3122 - val_loss: 1.9364 - val_accuracy: 0.3020\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.1008 - accuracy: 0.2338 - val_loss: 2.1775 - val_accuracy: 0.2360\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8947 - accuracy: 0.2882 - val_loss: 1.8681 - val_accuracy: 0.3440\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8727 - accuracy: 0.3131 - val_loss: 1.8766 - val_accuracy: 0.3160\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8373 - accuracy: 0.3273 - val_loss: 1.8886 - val_accuracy: 0.3480\n",
      "SUMMARY OF net_11\n",
      "Training Loss: 1.837336778640747\n",
      "Training Accuracy: 0.32733333110809326\n",
      "Validation Loss: 1.888641119003296\n",
      "Validation Accuracy: 0.3479999899864197\n",
      "Classification Error Rate: 0.6520000100135803\n",
      "----->Evolution: Child net_11 with fitness 1.888641119003296 replaces parent net_7 with fitness 6.008974075317383\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_7 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  32.0  to  16.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc712fd7c0>, <__main__.Block object at 0x77f83c6c53c0>, <__main__.Block object at 0x77f83c32a7c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_12\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 3s 7ms/step - loss: 4.3918 - accuracy: 0.0962 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3026 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.1040\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3025 - accuracy: 0.0958 - val_loss: 2.3027 - val_accuracy: 0.1040\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3025 - accuracy: 0.1020 - val_loss: 2.3027 - val_accuracy: 0.1040\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3028 - val_accuracy: 0.1040\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1027 - val_loss: 2.3028 - val_accuracy: 0.1040\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3029 - val_accuracy: 0.1040\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1036 - val_loss: 2.3029 - val_accuracy: 0.1040\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1024 - val_loss: 2.3028 - val_accuracy: 0.1040\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1020 - val_loss: 2.3029 - val_accuracy: 0.1040\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1033 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1007 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1022 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3024 - accuracy: 0.1004 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3024 - accuracy: 0.1007 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1031 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1022 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1011 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1000 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1027 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1029 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1033 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.0998 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1033 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1027 - val_loss: 2.3029 - val_accuracy: 0.1040\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3023 - accuracy: 0.1022 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1036 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1031 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1027 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1004 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1033 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.0967 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3023 - accuracy: 0.0984 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1013 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3024 - accuracy: 0.1040 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3024 - accuracy: 0.1009 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3024 - accuracy: 0.0998 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 2.3024 - accuracy: 0.1031 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3023 - accuracy: 0.0980 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1007 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.0982 - val_loss: 2.3031 - val_accuracy: 0.1040\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.0982 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 5ms/step - loss: 2.3024 - accuracy: 0.1002 - val_loss: 2.3030 - val_accuracy: 0.1040\n",
      "SUMMARY OF net_12\n",
      "Training Loss: 2.3023722171783447\n",
      "Training Accuracy: 0.10022222250699997\n",
      "Validation Loss: 2.3030107021331787\n",
      "Validation Accuracy: 0.10400000214576721\n",
      "Classification Error Rate: 0.8959999978542328\n",
      "----->Evolution: Child net_12 with fitness 2.3030107021331787 replaces parent net_5 with fitness 5.805016994476318\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_7 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  256.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fcdc7b9000>, <__main__.Block object at 0x77fc710cea00>, <__main__.Block object at 0x77f837c61f00>, <__main__.Block object at 0x77f837c10b40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_13\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 4s 9ms/step - loss: 2.4720 - accuracy: 0.1178 - val_loss: 2.2189 - val_accuracy: 0.1480\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.1306 - accuracy: 0.2256 - val_loss: 1.9006 - val_accuracy: 0.3320\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.8843 - accuracy: 0.3231 - val_loss: 1.9354 - val_accuracy: 0.3040\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.7044 - accuracy: 0.3807 - val_loss: 1.7147 - val_accuracy: 0.4020\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.5643 - accuracy: 0.4384 - val_loss: 1.8780 - val_accuracy: 0.3880\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.4285 - accuracy: 0.4838 - val_loss: 1.5805 - val_accuracy: 0.4160\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.2786 - accuracy: 0.5469 - val_loss: 1.7104 - val_accuracy: 0.3880\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 1.1102 - accuracy: 0.5956 - val_loss: 1.5598 - val_accuracy: 0.4880\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.9260 - accuracy: 0.6762 - val_loss: 1.6693 - val_accuracy: 0.4860\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.7651 - accuracy: 0.7316 - val_loss: 1.9846 - val_accuracy: 0.4540\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.5780 - accuracy: 0.7909 - val_loss: 2.1567 - val_accuracy: 0.4840\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4627 - accuracy: 0.8444 - val_loss: 2.7220 - val_accuracy: 0.4640\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3729 - accuracy: 0.8729 - val_loss: 3.6298 - val_accuracy: 0.4220\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3484 - accuracy: 0.8836 - val_loss: 3.2498 - val_accuracy: 0.4260\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2873 - accuracy: 0.9031 - val_loss: 3.7008 - val_accuracy: 0.4540\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3090 - accuracy: 0.9091 - val_loss: 4.0248 - val_accuracy: 0.4640\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2842 - accuracy: 0.9196 - val_loss: 3.8214 - val_accuracy: 0.4220\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2505 - accuracy: 0.9264 - val_loss: 4.7563 - val_accuracy: 0.4040\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2296 - accuracy: 0.9360 - val_loss: 4.3679 - val_accuracy: 0.4380\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2593 - accuracy: 0.9289 - val_loss: 5.6628 - val_accuracy: 0.4060\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2640 - accuracy: 0.9273 - val_loss: 5.4734 - val_accuracy: 0.4320\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2551 - accuracy: 0.9329 - val_loss: 5.6486 - val_accuracy: 0.4300\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1915 - accuracy: 0.9476 - val_loss: 6.1718 - val_accuracy: 0.4040\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2360 - accuracy: 0.9364 - val_loss: 5.7841 - val_accuracy: 0.4440\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2322 - accuracy: 0.9409 - val_loss: 6.9078 - val_accuracy: 0.3980\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2259 - accuracy: 0.9436 - val_loss: 6.4565 - val_accuracy: 0.4160\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.1966 - accuracy: 0.9547 - val_loss: 7.2406 - val_accuracy: 0.4420\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.2222 - accuracy: 0.9484 - val_loss: 8.4472 - val_accuracy: 0.3940\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.2631 - accuracy: 0.9398 - val_loss: 7.9426 - val_accuracy: 0.4420\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.2412 - accuracy: 0.9469 - val_loss: 7.7715 - val_accuracy: 0.4440\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2491 - accuracy: 0.9520 - val_loss: 6.7794 - val_accuracy: 0.4240\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2480 - accuracy: 0.9511 - val_loss: 7.5029 - val_accuracy: 0.4020\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2550 - accuracy: 0.9464 - val_loss: 6.9597 - val_accuracy: 0.4440\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2236 - accuracy: 0.9540 - val_loss: 10.2348 - val_accuracy: 0.4240\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2598 - accuracy: 0.9524 - val_loss: 8.0145 - val_accuracy: 0.4260\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2625 - accuracy: 0.9509 - val_loss: 10.6828 - val_accuracy: 0.4100\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.2278 - accuracy: 0.9576 - val_loss: 9.2575 - val_accuracy: 0.4480\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2757 - accuracy: 0.9507 - val_loss: 10.0671 - val_accuracy: 0.4320\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2820 - accuracy: 0.9522 - val_loss: 10.0129 - val_accuracy: 0.4140\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2761 - accuracy: 0.9567 - val_loss: 11.9443 - val_accuracy: 0.3900\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3031 - accuracy: 0.9542 - val_loss: 10.0131 - val_accuracy: 0.4120\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2657 - accuracy: 0.9560 - val_loss: 10.3616 - val_accuracy: 0.4420\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.2346 - accuracy: 0.9600 - val_loss: 10.1632 - val_accuracy: 0.4440\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.2186 - accuracy: 0.9642 - val_loss: 9.9793 - val_accuracy: 0.4560\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.1995 - accuracy: 0.9676 - val_loss: 12.6482 - val_accuracy: 0.4240\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3236 - accuracy: 0.9571 - val_loss: 12.4504 - val_accuracy: 0.4520\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3214 - accuracy: 0.9553 - val_loss: 13.6447 - val_accuracy: 0.4260\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3237 - accuracy: 0.9576 - val_loss: 18.9785 - val_accuracy: 0.4000\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.4420 - accuracy: 0.9469 - val_loss: 13.0128 - val_accuracy: 0.4020\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.3155 - accuracy: 0.9531 - val_loss: 14.8042 - val_accuracy: 0.3780\n",
      "SUMMARY OF net_13\n",
      "Training Loss: 0.315483033657074\n",
      "Training Accuracy: 0.9531111121177673\n",
      "Validation Loss: 14.804173469543457\n",
      "Validation Accuracy: 0.3779999911785126\n",
      "Classification Error Rate: 0.6220000088214874\n",
      "----->Evolution: Child net_13 with fitness 14.804173469543457 is discarded\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "Final Population\n",
      "-------------------------------------\n",
      "\n",
      "net_7 :  1.888641119003296\n",
      "net_2 :  2.302902936935425\n",
      "net_5 :  2.3030107021331787\n",
      "net_8 :  2.3030927181243896\n",
      "net_3 :  4.235955238342285\n",
      "net_9 :  4.537270545959473\n",
      "parent_0 :  5.19811487197876\n",
      "net_4 :  5.205547332763672\n",
      "net_1 :  5.4149088859558105\n",
      "net_6 :  5.557051658630371\n",
      "\n",
      "-------------------------------------\n",
      "Stats\n",
      "Best individual at generation 1 has fitness 2.3030927181243896 and parameters 589610\n",
      "Best individual at generation 2 has fitness 1.888641119003296 and parameters 250570\n",
      "-------------------------------------\n",
      "\n",
      "The block is:\n",
      "[<__main__.Block object at 0x77fc71336880>, <__main__.Block object at 0x77fc711cf600>, <__main__.Block object at 0x77fc7120a380>, <__main__.Block object at 0x77fc7122eac0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 5s 17ms/step - loss: 2.6407 - accuracy: 0.1191 - val_loss: 2.3581 - val_accuracy: 0.1038\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 2.2960 - accuracy: 0.1453 - val_loss: 4.2278 - val_accuracy: 0.0924\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 2.2762 - accuracy: 0.1776 - val_loss: 10.4585 - val_accuracy: 0.1203\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 2.3231 - accuracy: 0.2131 - val_loss: 2.5219 - val_accuracy: 0.1931\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 2.1265 - accuracy: 0.2364 - val_loss: 2.8520 - val_accuracy: 0.2129\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 2s 13ms/step - loss: 2.0520 - accuracy: 0.2591 - val_loss: 4.2379 - val_accuracy: 0.1666\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 2.0456 - accuracy: 0.2691 - val_loss: 4.9379 - val_accuracy: 0.1750\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 2.0270 - accuracy: 0.2758 - val_loss: 16.6132 - val_accuracy: 0.1373\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 2.0517 - accuracy: 0.2729 - val_loss: 1.8531 - val_accuracy: 0.3238\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.9326 - accuracy: 0.2931 - val_loss: 22.8538 - val_accuracy: 0.1249\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.9823 - accuracy: 0.3064 - val_loss: 1.9227 - val_accuracy: 0.3201\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 2s 15ms/step - loss: 1.8150 - accuracy: 0.3260 - val_loss: 1.7918 - val_accuracy: 0.3419\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.8124 - accuracy: 0.3267 - val_loss: 1.9793 - val_accuracy: 0.3055\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.8714 - accuracy: 0.3231 - val_loss: 2.0901 - val_accuracy: 0.2435\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 2.7819 - accuracy: 0.3084 - val_loss: 8.7640 - val_accuracy: 0.1469\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.8790 - accuracy: 0.3373 - val_loss: 6.5833 - val_accuracy: 0.1365\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 2.6697 - accuracy: 0.3578 - val_loss: 15.0074 - val_accuracy: 0.1824\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.8362 - accuracy: 0.3624 - val_loss: 13.3881 - val_accuracy: 0.1943\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 1.9196 - accuracy: 0.3627 - val_loss: 1.7549 - val_accuracy: 0.3547\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 4.0413 - accuracy: 0.3136 - val_loss: 1.8376 - val_accuracy: 0.3514\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.6984 - accuracy: 0.3569 - val_loss: 1.7725 - val_accuracy: 0.3681\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.8257 - accuracy: 0.3471 - val_loss: 7.3725 - val_accuracy: 0.1849\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 2s 15ms/step - loss: 1.7974 - accuracy: 0.3513 - val_loss: 1.8538 - val_accuracy: 0.3431\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.7795 - accuracy: 0.3331 - val_loss: 2.3182 - val_accuracy: 0.2555\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 2.2164 - accuracy: 0.3580 - val_loss: 1.7629 - val_accuracy: 0.3398\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 2s 13ms/step - loss: 1.7671 - accuracy: 0.3571 - val_loss: 14.1816 - val_accuracy: 0.2716\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 2s 13ms/step - loss: 1.6897 - accuracy: 0.3893 - val_loss: 1.7901 - val_accuracy: 0.3438\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 2s 13ms/step - loss: 2.6783 - accuracy: 0.3569 - val_loss: 10.0558 - val_accuracy: 0.2193\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.7163 - accuracy: 0.3773 - val_loss: 1.7656 - val_accuracy: 0.3586\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.9559 - accuracy: 0.3629 - val_loss: 1.6906 - val_accuracy: 0.3812\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.6647 - accuracy: 0.3813 - val_loss: 1.7652 - val_accuracy: 0.3762\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.6629 - accuracy: 0.3769 - val_loss: 4.3301 - val_accuracy: 0.2116\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 3.2512 - accuracy: 0.3769 - val_loss: 6.6893 - val_accuracy: 0.1550\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.9607 - accuracy: 0.3184 - val_loss: 1.8479 - val_accuracy: 0.3406\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.7174 - accuracy: 0.3758 - val_loss: 1.7402 - val_accuracy: 0.3591\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.6309 - accuracy: 0.3809 - val_loss: 1.7004 - val_accuracy: 0.3864\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.7007 - accuracy: 0.3709 - val_loss: 1.9134 - val_accuracy: 0.3299\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.6607 - accuracy: 0.3764 - val_loss: 1.8309 - val_accuracy: 0.3415\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.6239 - accuracy: 0.3789 - val_loss: 1.7042 - val_accuracy: 0.3647\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.6536 - accuracy: 0.3871 - val_loss: 2.3727 - val_accuracy: 0.2650\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 2.2774 - accuracy: 0.3869 - val_loss: 4.7256 - val_accuracy: 0.1295\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 2.2519 - accuracy: 0.2613 - val_loss: 1.7325 - val_accuracy: 0.3579\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.6521 - accuracy: 0.3856 - val_loss: 1.7684 - val_accuracy: 0.3557\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.6390 - accuracy: 0.3736 - val_loss: 1.7319 - val_accuracy: 0.3530\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.6225 - accuracy: 0.3993 - val_loss: 1.7212 - val_accuracy: 0.3795\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.6372 - accuracy: 0.3940 - val_loss: 1.7360 - val_accuracy: 0.3632\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 2s 14ms/step - loss: 1.6878 - accuracy: 0.3976 - val_loss: 1.7800 - val_accuracy: 0.3639\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 2s 13ms/step - loss: 1.6783 - accuracy: 0.3856 - val_loss: 1.8286 - val_accuracy: 0.3828\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.6551 - accuracy: 0.3918 - val_loss: 1.7625 - val_accuracy: 0.3760\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 2s 12ms/step - loss: 1.6321 - accuracy: 0.3858 - val_loss: 1.8532 - val_accuracy: 0.3403\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "The Final CNN has been evolved successfully in the individual net_7\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "Summary of initial CNN\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               401536    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 468394 (1.79 MB)\n",
      "Trainable params: 468394 (1.79 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fitness of initial CNN: 9.107863426208496\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "Summary of evolved individual\n",
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_238 (Conv2D)         (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_239 (Conv2D)         (None, 32, 32, 128)       36992     \n",
      "                                                                 \n",
      " max_pooling2d_67 (MaxPooli  (None, 16, 16, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_240 (Conv2D)         (None, 16, 16, 32)        36896     \n",
      "                                                                 \n",
      " conv2d_241 (Conv2D)         (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_242 (Conv2D)         (None, 14, 14, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_243 (Conv2D)         (None, 14, 14, 32)        36896     \n",
      "                                                                 \n",
      " conv2d_244 (Conv2D)         (None, 14, 14, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_245 (Conv2D)         (None, 12, 12, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_68 (MaxPooli  (None, 6, 6, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " max_pooling2d_69 (MaxPooli  (None, 3, 3, 32)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_51 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 32)                9248      \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 250570 (978.79 KB)\n",
      "Trainable params: 250570 (978.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fitness of the evolved individual: 1.8532007932662964\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from random import sample\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)      # suppress messages from Tensorflow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "def initialize_population(population_size, dataset):\n",
    "    print(\"----->Initializing Population\")\n",
    "    daddy = compute_parent(dataset)                                 # load parent from input\n",
    "    population = [daddy]\n",
    "    for it in range(1, population_size):\n",
    "        population.append(daddy.asexual_reproduction(it, dataset))\n",
    "\n",
    "    # sort population on ascending order based on fitness\n",
    "    return sorted(population, key=lambda cnn: cnn.fitness)\n",
    "\n",
    "\n",
    "def selection(k, population, num_population):\n",
    "    if k == 0:                                              # elitism selection\n",
    "        print(\"----->Elitism selection\")\n",
    "        return population[0], population[1]\n",
    "    elif k == 1:                                            # tournament selection\n",
    "        print(\"----->Tournament selection\")\n",
    "        i = randint(0, num_population - 1)\n",
    "        j = i\n",
    "        while j < num_population - 1:\n",
    "            j += 1\n",
    "            if randint(1, 100) <= 50:\n",
    "                return population[i], population[j]\n",
    "        return population[i], population[0]\n",
    "    else:                                                   # proportionate selection\n",
    "        print(\"----->Proportionate selection\")\n",
    "        cum_sum = 0\n",
    "        for i in range(num_population):\n",
    "            cum_sum += population[i].fitness\n",
    "        perc_range = []\n",
    "        for i in range(num_population):\n",
    "            count = 100 - int(100 * population[i].fitness / cum_sum)\n",
    "            for j in range(count):\n",
    "                perc_range.append(i)\n",
    "        i, j = sample(range(1, len(perc_range)), 2)\n",
    "        while i == j:\n",
    "            i, j = sample(range(1, len(perc_range)), 2)\n",
    "        return population[perc_range[i]], population[perc_range[j]]\n",
    "\n",
    "\n",
    "def crossover(parent1, parent2, it):\n",
    "    print(\"----->Crossover\")\n",
    "    child = Network(it)\n",
    "\n",
    "    first, second = None, None\n",
    "    if randint(0, 1):\n",
    "        first = parent1\n",
    "        second = parent2\n",
    "    else:\n",
    "        first = parent2\n",
    "        second = parent1\n",
    "\n",
    "    child.block_list = deepcopy(first.block_list[:randint(1, len(first.block_list) - 1)]) \\\n",
    "                       + deepcopy(second.block_list[randint(1, len(second.block_list) - 1):])\n",
    "\n",
    "    order_indexes(child)                            # order the indexes of the blocks\n",
    "\n",
    "    return child\n",
    "\n",
    "\n",
    "def genetic_algorithm(num_population, num_generation, num_offspring, dataset, early_stopping_generations=3):\n",
    "    print(\"Genetic Algorithm\")\n",
    "\n",
    "    population = initialize_population(num_population, dataset)\n",
    "\n",
    "    print(\"\\n-------------------------------------\")\n",
    "    print(\"Initial Population:\")\n",
    "    for cnn in population:\n",
    "        print(cnn.name, ': ', cnn.fitness)\n",
    "    print(\"--------------------------------------\\n\")\n",
    "\n",
    "    # for printing statistics about fitness and the number of parameters of the best individual\n",
    "    stats = [(population[0].fitness, population[0].model.count_params())]\n",
    "\n",
    "    # Initialize a variable to keep track of consecutive generations with the same best fitness\n",
    "    consecutive_same_fitness = 0\n",
    "\n",
    "    for gen in range(1, num_generation + 1):\n",
    "        '''\n",
    "            k is the selection parameter:\n",
    "                k = 0 -> elitism selection\n",
    "                k = 1 -> tournament selection\n",
    "                k = 2 -> proportionate selection\n",
    "        '''\n",
    "        k = randint(0, 2)\n",
    "\n",
    "        print(\"\\n------------------------------------\")\n",
    "        print(\"Generation -----------------------------------------------------------------------------------\", gen)\n",
    "        print(\"-------------------------------------\")\n",
    "\n",
    "        for c in range(num_offspring):\n",
    "\n",
    "            print(\"\\nCreating Child\", c)\n",
    "\n",
    "            parent1, parent2 = selection(k, population, num_population)                 # selection\n",
    "            print(\"Selected\", parent1.name, \"and\", parent2.name, \"for reproduction\")\n",
    "\n",
    "            child = crossover(parent1, parent2, c + num_population)                     # crossover\n",
    "            print(\"Child has been created\")\n",
    "\n",
    "            print(\"----->Soft Mutation\")\n",
    "            child.layer_mutation(dataset)                                               # mutation\n",
    "            child.parameters_mutation()\n",
    "            print(\"Child has been mutated\")\n",
    "\n",
    "            model = child.build_model()                                                 # evaluation\n",
    "\n",
    "            while model == -1:\n",
    "                child = crossover(parent1, parent2, c + num_population)\n",
    "                child.block_mutation(dataset)\n",
    "                child.layer_mutation(dataset)\n",
    "                child.parameters_mutation()\n",
    "                model = child.build_model()\n",
    "\n",
    "            child.train_and_evaluate(model, dataset)\n",
    "\n",
    "            if child.fitness < population[-1].fitness:                                  # evolve population\n",
    "                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"replaces parent \", end=\"\")\n",
    "                print(population[-1].name, \"with fitness\", population[-1].fitness)\n",
    "                name = population[-1].name\n",
    "\n",
    "                child.save_network(\"child_model_info.pkl\", \"child_model.h5\")\n",
    "                population[-1].load_network(\"child_model_info.pkl\", \"child_model.h5\")\n",
    "\n",
    "                population[-1].name = name\n",
    "                population = sorted(population, key=lambda net: net.fitness)\n",
    "            else:\n",
    "                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"is discarded\")\n",
    "        \n",
    "        if gen >= 3 and all(population[i].fitness == population[i + 1].fitness for i in range(-3, -1)):\n",
    "            consecutive_same_fitness += 1\n",
    "            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n",
    "        if consecutive_same_fitness >= 3:\n",
    "            print(\"Stopping the algorithm as the best fitness has remained the same for the last 3 generations.\")\n",
    "            break\n",
    "    else:\n",
    "        consecutive_same_fitness = 0\n",
    "        \n",
    "       #Check if the best fitness has remained the same for the last early_stopping_generations generations\n",
    "        if all(population[i].fitness == population[i + 1].fitness for i in range(-early_stopping_generations, -1)):\n",
    "            consecutive_same_fitness += 1\n",
    "            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n",
    "            if consecutive_same_fitness == early_stopping_generations:\n",
    "                print(f\"Stopping the algorithm as the best fitness has remained the same for {early_stopping_generations} generations.\")\n",
    "        else:\n",
    "            consecutive_same_fitness = 0\n",
    "        stats.append((population[0].fitness, population[0].model.count_params()))\n",
    "\n",
    "    print(\"\\n\\n-------------------------------------\")\n",
    "    print(\"Final Population\")\n",
    "    print(\"-------------------------------------\\n\")\n",
    "    for cnn in population:\n",
    "        print(cnn.name, ': ', cnn.fitness)\n",
    "\n",
    "    print(\"\\n-------------------------------------\")\n",
    "    print(\"Stats\")\n",
    "    for i in range(len(stats)):\n",
    "        print(\"Best individual at generation\", i + 1, \"has fitness\", stats[i][0], \"and parameters\", stats[i][1])\n",
    "    print(\"-------------------------------------\\n\")\n",
    "\n",
    "    # plot the fitness and the number of parameters of the best individual at each iteration\n",
    "    plot_statistics(stats)\n",
    "\n",
    "    return population[0]\n",
    "\n",
    "\n",
    "\n",
    "def main():    \n",
    "        #with strategy.scope():\n",
    "        #from tensorflow.python.client import device_lib\n",
    "        #print(device_lib.list_local_devices())\n",
    "        #batch_size = 8\n",
    "        #batch_size = batch_size * strategy.num_replicas_in_sync\n",
    "        batch_size = 32                       # the number of training examples in one forward/backward pass\n",
    "        num_classes = 10                        # number of cifar-10 dataset classes\n",
    "        epochs =50              # number of forward and backward passes of all the training examples\n",
    "\n",
    "        '''\n",
    "            dataset contains the hyper parameters for loading data and the dataset:\n",
    "                dataset = {\n",
    "                    'batch_size': batch_size,\n",
    "                    'num_classes': num_classes,\n",
    "                    'epochs': epochs,\n",
    "                    'x_train': x_train,\n",
    "                    'x_test': x_test,\n",
    "                    'y_train': y_train,\n",
    "                    'y_test': y_test\n",
    "                }\n",
    "        '''\n",
    "        dataset = load_dataset(batch_size, num_classes, epochs)\n",
    "\n",
    "        num_population = 10\n",
    "        num_generation = 10\n",
    "        num_offspring = 4\n",
    "\n",
    "        # plot the best model obtained\n",
    "        optCNN = genetic_algorithm(num_population, num_generation, num_offspring, dataset)\n",
    "\n",
    "        # plot the training and validation loss and accuracy\n",
    "        num_epoch = 50\n",
    "        model = optCNN.build_model()\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        history = model.fit(dataset['x_train'],\n",
    "                            dataset['y_train'],\n",
    "                            batch_size=dataset['batch_size'],\n",
    "                            epochs=num_epoch,\n",
    "                            validation_data=(dataset['x_test'], dataset['y_test']),\n",
    "                            shuffle=True)\n",
    "        optCNN.model = model                                        # model\n",
    "        optCNN.fitness = history.history['val_loss'][-1]            # fitness\n",
    "\n",
    "        print(\"\\n\\n-------------------------------------\")\n",
    "        print(\"The Final CNN has been evolved successfully in the individual\", optCNN.name)\n",
    "        print(\"-------------------------------------\\n\")\n",
    "        daddy = load_network('parent_0')\n",
    "        model = tf.keras.models.load_model('parent_0.h5')\n",
    "        print(\"\\n\\n-------------------------------------\")\n",
    "        print(\"Summary of initial CNN\")\n",
    "        print(model.summary())\n",
    "        print(\"Fitness of initial CNN:\", daddy.fitness)\n",
    "\n",
    "        print(\"\\n\\n-------------------------------------\")\n",
    "        print(\"Summary of evolved individual\")\n",
    "        print(optCNN.model.summary())\n",
    "        print(\"Fitness of the evolved individual:\", optCNN.fitness)\n",
    "        print(\"-------------------------------------\\n\")\n",
    "\n",
    "        plot_training(history)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82723d01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T03:37:03.229393Z",
     "iopub.status.busy": "2024-02-16T03:37:03.229023Z",
     "iopub.status.idle": "2024-02-16T03:37:03.235988Z",
     "shell.execute_reply": "2024-02-16T03:37:03.235088Z"
    },
    "papermill": {
     "duration": 3.225737,
     "end_time": "2024-02-16T03:37:03.237947",
     "exception": false,
     "start_time": "2024-02-16T03:37:00.012210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"## To remove a folder\\n# Clear output folder\\nimport os\\n\\ndef remove_folder_contents(folder):\\n    for the_file in os.listdir(folder):\\n        file_path = os.path.join(folder, the_file)\\n        try:\\n            if os.path.isfile(file_path):\\n                os.unlink(file_path)\\n            elif os.path.isdir(file_path):\\n                remove_folder_contents(file_path)\\n                os.rmdir(file_path)\\n        except Exception as e:\\n            print(e)\\n\\nfolder_path = '/kaggle/working'\\nremove_folder_contents(folder_path)\\nos.rmdir(folder_path)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"## To remove a folder\n",
    "# Clear output folder\n",
    "import os\n",
    "\n",
    "def remove_folder_contents(folder):\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                remove_folder_contents(file_path)\n",
    "                os.rmdir(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "folder_path = '/kaggle/working'\n",
    "remove_folder_contents(folder_path)\n",
    "os.rmdir(folder_path)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90351f88",
   "metadata": {
    "papermill": {
     "duration": 3.16989,
     "end_time": "2024-02-16T03:37:09.549769",
     "exception": false,
     "start_time": "2024-02-16T03:37:06.379879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30637,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2173.569866,
   "end_time": "2024-02-16T03:37:14.966277",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-16T03:01:01.396411",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
