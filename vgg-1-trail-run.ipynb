{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ba58e5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T07:34:05.932403Z",
     "iopub.status.busy": "2024-04-18T07:34:05.932086Z",
     "iopub.status.idle": "2024-04-18T07:34:17.592502Z",
     "shell.execute_reply": "2024-04-18T07:34:17.591698Z"
    },
    "papermill": {
     "duration": 11.669026,
     "end_time": "2024-04-18T07:34:17.594797",
     "exception": false,
     "start_time": "2024-04-18T07:34:05.925771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "### UTILITIES\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def load_images_from_folder(folder_path, image_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for label, class_folder in enumerate(sorted(os.listdir(folder_path))):\n",
    "        class_path = os.path.join(folder_path, class_folder)\n",
    "        for filename in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, image_size)\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    print(labels)\n",
    "    return images, labels\n",
    "\n",
    "def load_dataset(batch_size, num_classes, epochs, image_size, data_dir):\n",
    "    x_train, y_train = load_images_from_folder(data_dir, image_size)\n",
    "\n",
    "    # Splitting the data into training and testing sets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Normalize pixel values to be between 0 and 1\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    # Randomly select 500 images for validation\n",
    "    random_indices = np.random.choice(len(x_test), size=10000, replace=False)\n",
    "    x_val = x_test[random_indices]\n",
    "    y_val = y_test[random_indices]\n",
    "\n",
    "    dataset = {\n",
    "        'batch_size': batch_size,\n",
    "        'num_classes': num_classes,\n",
    "        'epochs': epochs,\n",
    "        'x_train': x_train,\n",
    "        'y_train': y_train,\n",
    "        'x_val': x_val,\n",
    "        'y_val': y_val,\n",
    "        'x_test': x_test,  \n",
    "        'y_test': y_test\n",
    "    }\n",
    "\n",
    "    print(\"Dataset info\")\n",
    "    print(dataset['x_train'].shape)\n",
    "    print(dataset['y_train'].shape)\n",
    "    print(dataset['y_train'])\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def save_network(network):\n",
    "    #object_file = open(network.name + '.obj', 'wb')\n",
    "    #pickle.dump(network, object_file)\n",
    "    #tf.keras.models.save_model(network, network.name)\n",
    "\n",
    "    model_path = network.name + '_model.h5'\n",
    "    tf.keras.models.save_model(network.model, model_path)\n",
    "\n",
    "    # Save the rest of the network information\n",
    "    network_info = {\n",
    "        'name': network.name,\n",
    "        'block_list': network.block_list,\n",
    "        'fitness': network.fitness\n",
    "    }\n",
    "    network_info_path = network.name + '_info.pkl'\n",
    "    with open(network_info_path, 'wb') as info_file:\n",
    "        pickle.dump(network_info, info_file)\n",
    "\n",
    "\n",
    "def load_network(name):\n",
    "    model_path = name + '_model.h5'\n",
    "    loaded_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # Load the network information\n",
    "    info_path = name + '_info.pkl'\n",
    "    with open(info_path, 'rb') as info_file:\n",
    "        network_info = pickle.load(info_file)\n",
    "\n",
    "    # Create a new Network instance\n",
    "    loaded_network = Network(0)  # Update with appropriate 'it' value\n",
    "\n",
    "    # Set the attributes of the loaded network\n",
    "    loaded_network.name = network_info['name']\n",
    "    loaded_network.block_list = network_info['block_list']\n",
    "    loaded_network.fitness = network_info['fitness']\n",
    "    loaded_network.model = loaded_model\n",
    "\n",
    "    return loaded_network\n",
    "\n",
    "\n",
    "\n",
    "def order_indexes(self):\n",
    "    i = 0\n",
    "    for block in self.block_list:\n",
    "        block.index = i\n",
    "        i += 1\n",
    "\n",
    "\n",
    "def plot_training(history):                                           # plot diagnostic learning curves\n",
    "    plt.figure(figsize=[8, 6])  # accuracy curves\n",
    "    plt.plot(history.history['accuracy'], 'r', linewidth=3.0)\n",
    "    plt.plot(history.history['val_accuracy'], 'b', linewidth=3.0)  # <-- Change 'val_acc' to 'val_accuracy'\n",
    "    plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n",
    "    plt.xlabel('Epochs ', fontsize=16)\n",
    "    plt.ylabel('Accuracy', fontsize=16)\n",
    "    plt.title('Accuracy Curves', fontsize=16)\n",
    "\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_acc_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def plot_statistics(stats):\n",
    "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# fitness curves\n",
    "    plt.plot([s[0] for s in stats], 'r', linewidth=3.0)\n",
    "    plt.plot([stats[0][0]] * len(stats), 'b', linewidth=3.0)\n",
    "    plt.legend(['BestFitness', 'InitialFitness'], fontsize=18)\n",
    "    plt.xlabel('Generations', fontsize=16)\n",
    "    plt.ylabel('FitnessValue', fontsize=16)\n",
    "    plt.title('Fitness Curve', fontsize=16)\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_fitness_plot.png')\n",
    "\n",
    "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# parameters curves\n",
    "    plt.plot([s[1] for s in stats], 'r', linewidth=3.0)\n",
    "    plt.plot([stats[0][1]] * len(stats), 'b', linewidth=3.0)\n",
    "    plt.legend(['BestParamsNum', 'InitialParamsNum'], fontsize=18)\n",
    "    plt.xlabel('Generations', fontsize=16)\n",
    "    plt.ylabel('ParamsNum', fontsize=16)\n",
    "    plt.title('Parameters Curve', fontsize=16)\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_params_plot.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43581ff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T07:34:17.605247Z",
     "iopub.status.busy": "2024-04-18T07:34:17.604658Z",
     "iopub.status.idle": "2024-04-18T07:34:17.623744Z",
     "shell.execute_reply": "2024-04-18T07:34:17.622843Z"
    },
    "papermill": {
     "duration": 0.026396,
     "end_time": "2024-04-18T07:34:17.625816",
     "exception": false,
     "start_time": "2024-04-18T07:34:17.599420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INOUT\n",
    "import os\n",
    "def compute_parent(dataset):\n",
    "    if os.path.isfile('parent_0.h5'):\n",
    "        daddy = load_network('parent_0')\n",
    "        model = tf.keras.models.load_model('parent_0.h5')\n",
    "        print(\"Loading parent_0\")\n",
    "        print(\"SUMMARY OF\", daddy.name)\n",
    "        print(model.summary())\n",
    "        print(\"FITNESS:\", daddy.fitness)\n",
    "        return daddy\n",
    "\n",
    "    daddy = Network(0)\n",
    "    \n",
    "    \n",
    "    #INI BLOCK\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=32, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:])\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(0, 0, layerList1, layerList2))\n",
    "    \n",
    "    #MIDDLE BLOCK 1\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=64, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(1, 1, layerList1, layerList2))\n",
    "\n",
    "     #MIDDLE BLOCK 2\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "        Convolutional(filters=128, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:])\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(1, 2, layerList1, layerList2))\n",
    "\n",
    "    \n",
    "    #MIDDLE BLOCK 3\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=256, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "        Convolutional(filters=256, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:])\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(1, 3, layerList1, layerList2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #MIDDLE BLOCK 4\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=512, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "        Convolutional(filters=512, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:])\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(1, 4, layerList1, layerList2))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #FULLY CONNECTED LAYER\n",
    "    layerList1 = [\n",
    "        FlattenLayer(),\n",
    "        FullyConnected(units=128, num_classes=dataset['num_classes'])\n",
    "    ]\n",
    "    layerList2 = []\n",
    "    daddy.block_list.append(Block(2, 5, layerList1, layerList2))\n",
    "    \n",
    "    \n",
    "\n",
    "    model = daddy.build_model()\n",
    "    print(\"Type of model_final:\", type(model))\n",
    "    daddy.train_and_evaluate(model, dataset)\n",
    "    return daddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed0886e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T07:34:17.635632Z",
     "iopub.status.busy": "2024-04-18T07:34:17.635323Z",
     "iopub.status.idle": "2024-04-18T07:34:17.684744Z",
     "shell.execute_reply": "2024-04-18T07:34:17.683844Z"
    },
    "papermill": {
     "duration": 0.056621,
     "end_time": "2024-04-18T07:34:17.686618",
     "exception": false,
     "start_time": "2024-04-18T07:34:17.629997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NETWORK\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Sequential\n",
    "from random import randint, choice\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class Network:\n",
    "    __slots__ = ('name', 'block_list', 'fitness', 'model')\n",
    "\n",
    "    def __init__(self, it):\n",
    "        self.name = 'parent_' + str(it) if it == 0 else 'net_' + str(it)\n",
    "        self.block_list = []\n",
    "        self.fitness = None\n",
    "        self.model = None\n",
    "\n",
    "    \"\"\"def build_model(self):\n",
    "        model = Sequential()                                # create model\n",
    "        for block in self.block_list:\n",
    "            for layer in block.get_layers():                # build model\n",
    "                try:\n",
    "                    layer.build_layer(model)\n",
    "                except:\n",
    "                    print(\"\\nINDIVIDUAL ABORTED, CREATING A NEW ONE\\n\")\n",
    "                    return -1\n",
    "        return model\"\"\"\n",
    "    def build_model(self):\n",
    "        model = Sequential()              \n",
    "        print(\"The block is:\")\n",
    "        print(self.block_list)                 # create model\n",
    "        for block in self.block_list:\n",
    "            #print(\"Building block type:\", block.type)\n",
    "            #print(\"TOTAL :::\")\n",
    "            #print(block.get_layer_name())\n",
    "            for layer in block.get_layers():                # build model\n",
    "                #print(\"Adding layer:\", layer.name)\n",
    "                try:\n",
    "                    layer.build_layer(model)\n",
    "                    print(\"Layer added successfully.\")\n",
    "                except Exception as e:\n",
    "                    print(\"Error occurred while adding layer:\", e)\n",
    "                    print(\"Returning None.\")\n",
    "                    return -1\n",
    "        print(\"Model successfully built.\")\n",
    "        return model\n",
    "\n",
    "    def train_and_evaluate(self, model, dataset):\n",
    "        print(\"Training\", self.name)\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        try:\n",
    "            history = model.fit(dataset['x_train'],\n",
    "                                dataset['y_train'],\n",
    "                                batch_size=dataset['batch_size'],\n",
    "                                epochs=dataset['epochs'],\n",
    "                                validation_data=(dataset['x_val'], dataset['y_val']),\n",
    "                                shuffle=True)\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred during model training:\", e)\n",
    "            return -1\n",
    "            # You can choose to handle the error in a specific way here, like logging it or taking corrective actions.\n",
    "\n",
    "\n",
    "        # Extract metrics from the training history\n",
    "        training_loss = history.history['loss'][-1]\n",
    "        training_accuracy = history.history['accuracy'][-1]\n",
    "        validation_loss = history.history['val_loss'][-1]\n",
    "        validation_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "        # Additional metrics (you can customize this based on your needs)\n",
    "        classification_error_rate = 1.0 - validation_accuracy\n",
    "\n",
    "        self.model = model  # Save the model\n",
    "        self.fitness = validation_loss  # Use validation loss as fitness\n",
    "\n",
    "        # Print metrics\n",
    "        print(\"SUMMARY OF\", self.name)\n",
    "        print(\"Training Loss:\", training_loss)\n",
    "        print(\"Training Accuracy:\", training_accuracy)\n",
    "        print(\"Validation Loss:\", validation_loss)\n",
    "        print(\"Validation Accuracy:\", validation_accuracy)\n",
    "        print(\"Classification Error Rate:\", classification_error_rate)\n",
    "\n",
    "        tf.keras.models.save_model(model, self.name + '.h5')         # save model\n",
    "        #model.save(self.name + '.h5')                       # save model\n",
    "        save_network(self)                                  # save topology, model and fitness\n",
    "\n",
    "    def asexual_reproduction(self, it, dataset):\n",
    "\n",
    "        # if the individual already exists, just load it\n",
    "        if os.path.isfile('net_' + str(it) + '.h5'):\n",
    "            print(\"\\n-------------------------------------\")\n",
    "            print(\"Loading individual net_\" + str(it))\n",
    "            print(\"--------------------------------------\\n\")\n",
    "            individual = load_network('net_' + str(it))\n",
    "            model = tf.keras.models.load_model(individual.name + '.h5')\n",
    "            print(\"SUMMARY OF\", individual.name)\n",
    "            print(model.summary())\n",
    "            print(\"FITNESS: \", individual.fitness)\n",
    "            return individual\n",
    "\n",
    "        # otherwise, create the individual by mutating the parent\n",
    "        individual = Network(it)\n",
    "\n",
    "        print(\"\\n-------------------------------------\")\n",
    "        print(\"\\nCreating individual\", individual.name)\n",
    "        print(\"--------------------------------------\\n\")\n",
    "\n",
    "        individual.block_list = deepcopy(self.block_list)           # copy the layer list from parent\n",
    "\n",
    "        print(\"----->Strong Mutation\")\n",
    "        individual.block_mutation(dataset)                          # mutate a block\n",
    "        individual.layer_mutation(dataset)                          # mutate a layer\n",
    "        individual.parameters_mutation()                            # mutate some parameters\n",
    "\n",
    "        model = individual.build_model()\n",
    "        \n",
    "        if model == -1:\n",
    "            return self.asexual_reproduction(it, dataset)\n",
    "        \n",
    "        if(individual.train_and_evaluate(model, dataset)==-1):\n",
    "            return self.asexual_reproduction(it, dataset)\n",
    "        else:\n",
    "            return individual\n",
    "            \n",
    "\n",
    "    def block_mutation(self, dataset):\n",
    "        try:\n",
    "            print(\"Block Mutation\")\n",
    "\n",
    "            print([(block.index, block.type) for block in self.block_list])\n",
    "\n",
    "            # block list containing all the blocks with type = 1\n",
    "            bl = [block.index for block in self.block_list if block.type == 1]\n",
    "\n",
    "            if len(bl) == 0:\n",
    "                print(\"Creating a new block with two Convolutional layers and a Pooling layer\")\n",
    "                self.block_list[1].index = 2\n",
    "                layerList1 = [\n",
    "                    Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                  filter_size=(3, 3),\n",
    "                                  stride_size=(1, 1),\n",
    "                                  padding='same',\n",
    "                                  input_shape=dataset['x_train'].shape[1:]),\n",
    "                    Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                  filter_size=(3, 3),\n",
    "                                  stride_size=(1, 1),\n",
    "                                  padding='same',\n",
    "                                  input_shape=dataset['x_train'].shape[1:])\n",
    "                ]\n",
    "                layerList2 = [\n",
    "                    Pooling(pool_size=(2, 2),\n",
    "                            stride_size=(2, 2),\n",
    "                            padding='same')\n",
    "                ]\n",
    "                b = Block(1, 1, layerList1, layerList2)\n",
    "                self.block_list.insert(1, b)\n",
    "                return\n",
    "\n",
    "            block_idx = randint(1, max(bl))         # pick a random block among all the blocks with type = 1\n",
    "            block_type_idx = randint(0, 1)          # 1 -> Conv2D; 0 -> Pooling or Dropout\n",
    "            mutation_type = randint(0, 1)           # 1 -> remove; 0 -> add\n",
    "\n",
    "            # list of layers of the selected block\n",
    "            layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
    "            length = len(layerList)\n",
    "\n",
    "            if mutation_type:                                       # remove\n",
    "                if length == 1:\n",
    "                    del self.block_list[block_idx]\n",
    "                elif block_type_idx:\n",
    "                    pos = randint(0, length - 1)\n",
    "                    print(\"Removing a Conv2D layer at\", pos)\n",
    "                    del layerList[pos]\n",
    "                else:\n",
    "                    pos = randint(0, length - 1)\n",
    "                    print(\"Removing a Pooling/Dropout layer at\", pos)\n",
    "                    del layerList[pos]\n",
    "            else:                                                   # add\n",
    "                if block_type_idx:\n",
    "                    print(\"Inserting a Convolutional layer\")\n",
    "                    layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                          filter_size=(3, 3),\n",
    "                                          stride_size=(1, 1),\n",
    "                                          padding='same',\n",
    "                                          input_shape=dataset['x_train'].shape[1:])\n",
    "                    layerList.insert(randint(0, length - 1), layer)\n",
    "                else:\n",
    "                    if randint(0, 1):                               # 1 -> Pooling; 0 -> Dropout\n",
    "                        print(\"Inserting a Pooling layer\")\n",
    "                        layer = Pooling(pool_size=(2, 2),\n",
    "                                        stride_size=(2, 2),\n",
    "                                        padding='same')\n",
    "                        layerList.insert(randint(0, length - 1), layer)\n",
    "                    else:\n",
    "                        print(\"Inserting a Dropout layer\")\n",
    "                        rate = choice([0.15, 0.25, 0.35, 0.50])\n",
    "                        layer = Dropout(rate=rate)\n",
    "                        layerList.insert(randint(0, length - 1), layer)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred during block mutation: {e}\")\n",
    "            return None\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "    \"\"\"def layer_mutation(self, dataset):\n",
    "        print(\"Layer Mutation\")\n",
    "\n",
    "        # pick a random block among all the blocks with type = 1\n",
    "        bl = [block.index for block in self.block_list if block.type == 1]\n",
    "\n",
    "        if len(bl) == 0:\n",
    "            return\n",
    "\n",
    "        block_idx = randint(1, max(bl))\n",
    "        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n",
    "\n",
    "        # list of layers of the selected block\n",
    "        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
    "\n",
    "        if len(layerList) == 0:\n",
    "            if block_type_idx:\n",
    "                layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                      filter_size=(3, 3),\n",
    "                                      stride_size=(1, 1),\n",
    "                                      padding='same',\n",
    "                                      input_shape=dataset['x_train'].shape[1:])\n",
    "                self.block_list[block_idx].layerList1.append(layer)\n",
    "                return\n",
    "            else:\n",
    "                layer = Pooling(pool_size=(2, 2),\n",
    "                                stride_size=(2, 2),\n",
    "                                padding='same')\n",
    "                self.block_list[block_idx].layerList2.append(layer)\n",
    "\n",
    "        idx = randint(0, len(layerList) - 1)\n",
    "        layer = layerList[idx]\n",
    "\n",
    "        if layer.name == 'Conv2D':\n",
    "            print(\"Splitting Conv2D layer at index\", idx)\n",
    "            layer.filters = int(layer.filters * 0.5)\n",
    "            layerList.insert(idx, deepcopy(layer))\n",
    "        elif layer.name == 'MaxPooling2D' or layer.name == 'AveragePooling2D':\n",
    "            print(\"Changing Pooling layer at index\", idx, \"with Conv2D layer\")\n",
    "            del layerList[idx]\n",
    "            conv_layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                       filter_size=(3, 3),\n",
    "                                       stride_size=(2, 2),\n",
    "                                       padding=layer.padding,\n",
    "                                       input_shape=dataset['x_train'].shape[1:])\n",
    "            layerList.insert(idx, conv_layer)\"\"\"\n",
    "    \n",
    "    def layer_mutation(self, dataset):\n",
    "        print(\"Layer Mutation\")\n",
    "\n",
    "        # Determine the maximum number of layers that can be added or removed\n",
    "        max_layers_to_add = 16 - sum(len(block.layerList1) + len(block.layerList2) for block in self.block_list)\n",
    "        max_layers_to_remove = sum(len(block.layerList1) + len(block.layerList2) - 1 for block in self.block_list)\n",
    "\n",
    "        if max_layers_to_add == 0 and max_layers_to_remove == 0:\n",
    "            return\n",
    "\n",
    "        # Pick a random block among all the blocks with type = 1\n",
    "        bl = [block.index for block in self.block_list if block.type == 1]\n",
    "\n",
    "        if len(bl) == 0:\n",
    "            return\n",
    "\n",
    "        block_idx = randint(1, max(bl))\n",
    "        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n",
    "\n",
    "        # List of layers of the selected block\n",
    "        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
    "\n",
    "        if len(layerList) == 0:\n",
    "            if block_type_idx:\n",
    "                layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                      filter_size=(3, 3),\n",
    "                                      stride_size=(1, 1),\n",
    "                                      padding='same',\n",
    "                                      input_shape=dataset['x_train'].shape[1:])\n",
    "                self.block_list[block_idx].layerList1.append(layer)\n",
    "            else:\n",
    "                layer = Pooling(pool_size=(2, 2),\n",
    "                                stride_size=(2, 2),\n",
    "                                padding='same')\n",
    "                self.block_list[block_idx].layerList2.append(layer)\n",
    "        else:\n",
    "            # Randomly choose whether to add or remove a layer\n",
    "            add_layer = bool(randint(0, 1))\n",
    "\n",
    "            if add_layer and max_layers_to_add > 0:\n",
    "                # Add a layer\n",
    "                layer = self.create_random_layer(dataset)\n",
    "                layerList.insert(randint(0, len(layerList)), layer)\n",
    "            elif not add_layer and max_layers_to_remove > 0:\n",
    "                # Remove a layer\n",
    "                idx = randint(0, len(layerList) - 1)\n",
    "                del layerList[idx]\n",
    "\n",
    "        # Ensure the total number of layers in the block doesn't exceed 16\n",
    "        if len(self.block_list[block_idx].layerList1) + len(self.block_list[block_idx].layerList2) > 16:\n",
    "            # Remove a random layer to maintain the total count of 16 layers\n",
    "            block_layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
    "            del block_layerList[randint(0, len(block_layerList) - 1)]\n",
    "\n",
    "    def create_random_layer(self, dataset):\n",
    "        # Create a random layer (Conv2D or Pooling)\n",
    "        if randint(0, 1):\n",
    "            # Conv2D layer\n",
    "            return Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                 filter_size=(3, 3),\n",
    "                                 stride_size=(1, 1),\n",
    "                                 padding='same',\n",
    "                                 input_shape=dataset['x_train'].shape[1:])\n",
    "        else:\n",
    "            # Pooling layer\n",
    "            return Pooling(pool_size=(2, 2),\n",
    "                           stride_size=(2, 2),\n",
    "                           padding='same')\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "    def parameters_mutation(self):\n",
    "        print(\"Parameters Mutation\")\n",
    "        for block in self.block_list:\n",
    "            for layer in block.get_layers():\n",
    "                if randint(0, 1):\n",
    "                    layer.mutate_parameters()\n",
    "\n",
    "    def save_network_info(self, info_filename):\n",
    "        network_info = {\n",
    "            'name': self.name,\n",
    "            'block_list': self.block_list,\n",
    "            'fitness': self.fitness\n",
    "        }\n",
    "\n",
    "        with open(info_filename, 'wb') as info_file:\n",
    "            pickle.dump(network_info, info_file)\n",
    "\n",
    "    def load_network_info(self, info_filename):\n",
    "        with open(info_filename, 'rb') as info_file:\n",
    "            network_info = pickle.load(info_file)\n",
    "\n",
    "        self.name = network_info['name']\n",
    "        self.block_list = network_info['block_list']\n",
    "        self.fitness = network_info['fitness']\n",
    "\n",
    "    def save_model(self, model_filename):\n",
    "        self.model.save(model_filename)\n",
    "\n",
    "    def load_model(self, model_filename):\n",
    "        self.model = tf.keras.models.load_model(model_filename)\n",
    "\n",
    "    def save_network(self, network_info_filename, model_filename):\n",
    "        # Save non-model attributes\n",
    "        self.save_network_info(network_info_filename)\n",
    "\n",
    "        # Save the model separately\n",
    "        self.save_model(model_filename)\n",
    "\n",
    "    def load_network(self, network_info_filename, model_filename):\n",
    "        # Load non-model attributes\n",
    "        self.load_network_info(network_info_filename)\n",
    "\n",
    "        # Load the model separately\n",
    "        self.load_model(model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4825ac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T07:34:17.697661Z",
     "iopub.status.busy": "2024-04-18T07:34:17.697363Z",
     "iopub.status.idle": "2024-04-18T07:34:17.729565Z",
     "shell.execute_reply": "2024-04-18T07:34:17.728685Z"
    },
    "papermill": {
     "duration": 0.039572,
     "end_time": "2024-04-18T07:34:17.731454",
     "exception": false,
     "start_time": "2024-04-18T07:34:17.691882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TOPOLOGY\n",
    "\n",
    "import keras.layers\n",
    "from random import randint\n",
    "\n",
    "\n",
    "class Block:\n",
    "\t__slots__ = ('type', 'index', 'layerList1', 'layerList2')\n",
    "\n",
    "\tdef __init__(self, type, index, layerList1, layerList2):\n",
    "\t\tself.type = type\t\t\t\t\t\t\t\t\t\t# 0 -> initial layer; 1 -> mid layers; 2 -> final layer\n",
    "\t\tself.index = index\t\t\t\t\t\t\t\t\t\t# block index among all the blocks\n",
    "\t\tself.layerList1 = layerList1\t\t\t\t\t\t\t# Convolutional layers\n",
    "\t\tself.layerList2 = layerList2\t\t\t\t\t\t\t# Pooling and Dropout layers\n",
    "\n",
    "\tdef get_layers(self):\n",
    "\t\treturn self.layerList1 + self.layerList2\n",
    "\n",
    "\tdef get_size(self):\n",
    "\t\treturn len(self.get_layers())\n",
    "\n",
    "\n",
    "class Convolutional:\n",
    "\t# __slots__ = ('name', 'filters', 'padding', 'filter_size', 'stride_size', 'input_shape')\n",
    "\n",
    "\tdef __init__(self, filters, padding, filter_size, stride_size, input_shape):\n",
    "\t\tself.name = 'Conv2D'\n",
    "\t\tself.filters = filters\n",
    "\t\tself.padding = padding\n",
    "\t\tself.filter_size = filter_size\n",
    "\t\tself.stride_size = stride_size\n",
    "\t\tself.input_shape = input_shape\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\ttry:\n",
    "\t\t\tmodel.add(keras.layers.Conv2D(filters=self.filters,\n",
    "\t\t\t\t\t\t\t\t\t\t\tkernel_size=self.filter_size,\n",
    "\t\t\t\t\t\t\t\t\t\t\tstrides=self.stride_size,\n",
    "\t\t\t\t\t\t\t\t\t\t\tpadding=self.padding,\n",
    "\t\t\t\t\t\t\t\t\t\t\tactivation='relu',\n",
    "\t\t\t\t\t\t\t\t\t\t\tkernel_initializer='he_uniform',\n",
    "\t\t\t\t\t\t\t\t\t\t\tinput_shape=self.input_shape))\n",
    "\t\texcept ValueError as e:\n",
    "\t\t\tprint(\"Error occurred while adding layer:\", e)\n",
    "\t\t\tprint(\"Skipping current architecture.\")\n",
    "\t\t\treturn  # Skip adding this layer\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tmutation = randint(0, 2)  # Adjusted the number of mutations\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tif mutation == 0 and self.filters >= 64:  # Adjusted the filter reduction threshold\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters = int(self.filters / 2)\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 1 and self.filters <= 256:  # Adjusted the filter increase threshold\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters *= 2\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 2:\n",
    "\t\t\tif self.padding == 'valid':\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'same'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'valid'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\t\"\"\"def mutate_parameters(self):\n",
    "\t\tmutation = randint(0, 4)\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tif mutation == 0 and self.filters >= 32:\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters = int(self.filters / 2)\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 1 and self.filters >= 32:\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters = int(self.filters / 2)\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 2 and self.filters <= 512:\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters *= 2\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 3 and self.filters <= 512:\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters *= 2\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 4:\n",
    "\t\t\tif self.padding == 'valid':\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'same'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'valid'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\"\"\"\n",
    "    \n",
    "\n",
    "'''\n",
    "elif mutation is 4:\n",
    "\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n",
    "\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n",
    "\tprint(\"to \", self.stride_size, \" and \", end=\"\")\n",
    "\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n",
    "\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n",
    "\tprint(\"to \", self.stride_size)\n",
    "'''\n",
    "\n",
    "\n",
    "class Pooling:\n",
    "\t__slots__ = ('name', 'pool_size', 'stride_size', 'padding')\n",
    "\n",
    "\tdef __init__(self, pool_size, stride_size, padding):\n",
    "\t\tself.name = 'MaxPooling2D'\n",
    "\t\tself.pool_size = pool_size\n",
    "\t\tself.stride_size = stride_size\n",
    "\t\tself.padding = padding\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\tif self.name == 'MaxPooling2D':\n",
    "\t\t\tmodel.add(keras.layers.MaxPooling2D(self.pool_size, self.stride_size, self.padding))\n",
    "\t\telif self.name == 'AveragePooling2D':\n",
    "\t\t\tmodel.add(keras.layers.AveragePooling2D(self.pool_size, self.stride_size, self.padding))\n",
    "\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tmutation = randint(0, 1)\n",
    "\t\tif mutation == 0:\n",
    "\t\t\tif self.padding == 'valid':\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'same'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'valid'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\telif mutation == 1:\n",
    "\t\t\tif self.name == 'MaxPooling2D':\n",
    "\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n",
    "\t\t\t\tself.name = 'AveragePooling2D'\n",
    "\t\t\t\tprint(\"to \", self.name)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n",
    "\t\t\t\tself.name = 'MaxPooling2D'\n",
    "\t\t\t\tprint(\"to \", self.name)\n",
    "\n",
    "\n",
    "'''\n",
    "if mutation is 0:\n",
    "\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n",
    "\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n",
    "\tprint(\"to \", self.stride_size)\n",
    "'''\n",
    "\n",
    "\n",
    "class FullyConnected:\n",
    "\t__slots__ = ('name', 'units', 'num_classes')\n",
    "\n",
    "\tdef __init__(self, units, num_classes):\n",
    "\t\tself.name = \"FullyConnected\"\n",
    "\t\tself.units = units\n",
    "\t\tself.num_classes = num_classes\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\tmodel.add(keras.layers.Flatten())\n",
    "\t\tmodel.add(keras.layers.Dense(self.units, activation='relu', kernel_initializer='he_uniform'))\n",
    "\t\tmodel.add(keras.layers.Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tmutation = randint(0, 2)\n",
    "\t\tif mutation == 0:\n",
    "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
    "\t\t\tself.units *= 2\n",
    "\t\t\tprint(\"to \", self.units)\n",
    "\t\telif mutation == 1:\n",
    "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
    "\t\t\tself.units *= 2\n",
    "\t\t\tprint(\"to \", self.units)\n",
    "\t\telif mutation == 2:\n",
    "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
    "\t\t\tself.units /= 2\n",
    "\t\t\tprint(\"to \", self.units)\n",
    "\n",
    "\n",
    "'''\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(self.num_classes, activation='softmax'))\n",
    "'''\n",
    "\n",
    "\n",
    "class Dropout:\n",
    "\t__slots__ = ('name', 'rate')\n",
    "\n",
    "\tdef __init__(self, rate):\n",
    "\t\tself.name = \"Dropout\"\n",
    "\t\tself.rate = rate\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\tmodel.add(keras.layers.Dropout(self.rate))\n",
    "\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tmutation = randint(0, 3)\n",
    "\t\tif mutation == 0 and self.rate <= 0.85:\n",
    "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate + 0.10\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\t\telif mutation == 1 and self.rate <= 0.90:\n",
    "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate + 0.05\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\t\telif mutation == 2 and self.rate >= 0.15:\n",
    "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate - 0.10\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\t\telif mutation == 3 and self.rate >= 0.10:\n",
    "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate - 0.05\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\n",
    "class FlattenLayer:\n",
    "    def __init__(self):\n",
    "        self.name = 'Flatten'\n",
    "\n",
    "    def build_layer(self, model):\n",
    "        model.add(keras.layers.Flatten())\n",
    "\n",
    "    def mutate_parameters(self):\n",
    "        # The Flatten layer does not have any parameters to mutate\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "538446b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T07:34:17.741371Z",
     "iopub.status.busy": "2024-04-18T07:34:17.741090Z",
     "iopub.status.idle": "2024-04-18T11:12:08.564984Z",
     "shell.execute_reply": "2024-04-18T11:12:08.564040Z"
    },
    "papermill": {
     "duration": 13076.716892,
     "end_time": "2024-04-18T11:12:14.452518",
     "exception": false,
     "start_time": "2024-04-18T07:34:17.735626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 9 9 9]\n",
      "Dataset info\n",
      "(48000, 32, 32, 3)\n",
      "(48000, 10)\n",
      "[[0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "Genetic Algorithm\n",
      "----->Initializing Population\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c22257e2480>, <__main__.Block object at 0x7c22254b2800>, <__main__.Block object at 0x7c22254b2880>, <__main__.Block object at 0x7c22254b2980>, <__main__.Block object at 0x7c22254b2a80>, <__main__.Block object at 0x7c22254b2b00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Type of model_final: <class 'keras.src.engine.sequential.Sequential'>\n",
      "Training parent_0\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 18s 8ms/step - loss: 0.6459 - accuracy: 0.7790 - val_loss: 0.5595 - val_accuracy: 0.8246\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.4293 - accuracy: 0.8571 - val_loss: 0.4642 - val_accuracy: 0.8298\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.4376 - accuracy: 0.8561 - val_loss: 0.5383 - val_accuracy: 0.8518\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.4811 - accuracy: 0.8519 - val_loss: 0.5051 - val_accuracy: 0.8491\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.4954 - accuracy: 0.8519 - val_loss: 0.5263 - val_accuracy: 0.8649\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.5134 - accuracy: 0.8476 - val_loss: 0.5553 - val_accuracy: 0.8310\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.5255 - accuracy: 0.8462 - val_loss: 0.6174 - val_accuracy: 0.8534\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.6060 - accuracy: 0.8313 - val_loss: 0.6271 - val_accuracy: 0.8394\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.7216 - accuracy: 0.8034 - val_loss: 0.6069 - val_accuracy: 0.7889\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.9216 - accuracy: 0.7566 - val_loss: 1.3927 - val_accuracy: 0.7660\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 1.5303 - accuracy: 0.6187 - val_loss: 1.2708 - val_accuracy: 0.6319\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 3.8002 - accuracy: 0.4979 - val_loss: 2.6157 - val_accuracy: 0.4730\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.9353 - accuracy: 0.2955 - val_loss: 3.3556 - val_accuracy: 0.1960\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.1690 - accuracy: 0.1890 - val_loss: 2.0884 - val_accuracy: 0.1763\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.4245 - accuracy: 0.2284 - val_loss: 2.2114 - val_accuracy: 0.1925\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 4.2794 - accuracy: 0.2437 - val_loss: 1.9117 - val_accuracy: 0.2637\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 3.4128 - accuracy: 0.3369 - val_loss: 1.9111 - val_accuracy: 0.3882\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 5.0711 - accuracy: 0.3310 - val_loss: 2.4926 - val_accuracy: 0.3916\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.7681 - accuracy: 0.3351 - val_loss: 1.9464 - val_accuracy: 0.2548\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 3.5507 - accuracy: 0.3167 - val_loss: 2.0528 - val_accuracy: 0.2195\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 4.0875 - accuracy: 0.3536 - val_loss: 2.5372 - val_accuracy: 0.3861\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 4.6026 - accuracy: 0.3474 - val_loss: 2.0293 - val_accuracy: 0.2275\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 5.7070 - accuracy: 0.2734 - val_loss: 2.0826 - val_accuracy: 0.2270\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 6.1372 - accuracy: 0.2498 - val_loss: 1.8805 - val_accuracy: 0.3104\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 3.1273 - accuracy: 0.3566 - val_loss: 2.8482 - val_accuracy: 0.2777\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 3.8322 - accuracy: 0.3888 - val_loss: 2.5224 - val_accuracy: 0.3147\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 6.2260 - accuracy: 0.2830 - val_loss: 4.5698 - val_accuracy: 0.2801\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 10.3478 - accuracy: 0.2573 - val_loss: 1.8923 - val_accuracy: 0.2604\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.4215 - accuracy: 0.2660 - val_loss: 1.8366 - val_accuracy: 0.2772\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 3.1874 - accuracy: 0.2441 - val_loss: 1.9690 - val_accuracy: 0.2239\n",
      "SUMMARY OF parent_0\n",
      "Training Loss: 3.1874136924743652\n",
      "Training Accuracy: 0.24410416185855865\n",
      "Validation Loss: 1.968990445137024\n",
      "Validation Accuracy: 0.22390000522136688\n",
      "Classification Error Rate: 0.7760999947786331\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_1\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Inserting a Pooling layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c21ec252900>, <__main__.Block object at 0x7c21ec1c8100>, <__main__.Block object at 0x7c21ec12a4c0>, <__main__.Block object at 0x7c221cc39fc0>, <__main__.Block object at 0x7c21ec638440>, <__main__.Block object at 0x7c21e7f4b200>]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26/67157677.py:86: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model, self.name + '.h5')         # save model\n",
      "/tmp/ipykernel_26/3885683771.py:72: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(network.model, model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_16. Consider increasing the input size. Received input shape [None, 1, 1, 512] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_1\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 14s 7ms/step - loss: 0.6110 - accuracy: 0.7805 - val_loss: 0.4399 - val_accuracy: 0.8388\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.4146 - accuracy: 0.8575 - val_loss: 0.3515 - val_accuracy: 0.8762\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.4012 - accuracy: 0.8667 - val_loss: 0.4594 - val_accuracy: 0.8499\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.4036 - accuracy: 0.8691 - val_loss: 0.4336 - val_accuracy: 0.8576\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.3931 - accuracy: 0.8738 - val_loss: 0.3691 - val_accuracy: 0.8791\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.4140 - accuracy: 0.8708 - val_loss: 0.4651 - val_accuracy: 0.8789\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.4439 - accuracy: 0.8646 - val_loss: 0.5008 - val_accuracy: 0.8629\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.4726 - accuracy: 0.8601 - val_loss: 0.3709 - val_accuracy: 0.8824\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.4910 - accuracy: 0.8568 - val_loss: 0.5619 - val_accuracy: 0.7701\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.5658 - accuracy: 0.8431 - val_loss: 0.5284 - val_accuracy: 0.8284\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.5978 - accuracy: 0.8322 - val_loss: 0.8748 - val_accuracy: 0.8155\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.7928 - accuracy: 0.7935 - val_loss: 1.0917 - val_accuracy: 0.7847\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 1.0940 - accuracy: 0.7226 - val_loss: 1.2340 - val_accuracy: 0.7175\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 1.1425 - accuracy: 0.7176 - val_loss: 1.0719 - val_accuracy: 0.6858\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 1.3255 - accuracy: 0.6367 - val_loss: 1.5735 - val_accuracy: 0.6066\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 2.0629 - accuracy: 0.5876 - val_loss: 2.0524 - val_accuracy: 0.5858\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 2.8963 - accuracy: 0.4867 - val_loss: 1.8117 - val_accuracy: 0.3219\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 2.9493 - accuracy: 0.4429 - val_loss: 1.2780 - val_accuracy: 0.4970\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 4.0979 - accuracy: 0.4543 - val_loss: 2.2935 - val_accuracy: 0.3574\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 6.8797 - accuracy: 0.3659 - val_loss: 1.8424 - val_accuracy: 0.3428\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 4.6563 - accuracy: 0.3167 - val_loss: 2.3505 - val_accuracy: 0.2692\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 6.5465 - accuracy: 0.4047 - val_loss: 3.1802 - val_accuracy: 0.4539\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 2.2606 - accuracy: 0.4219 - val_loss: 1.5632 - val_accuracy: 0.4287\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 3.3566 - accuracy: 0.4254 - val_loss: 1.8932 - val_accuracy: 0.4535\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 4.0045 - accuracy: 0.4173 - val_loss: 1.5660 - val_accuracy: 0.4055\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 2.3967 - accuracy: 0.4121 - val_loss: 1.9740 - val_accuracy: 0.2733\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 6.2771 - accuracy: 0.4003 - val_loss: 2.3153 - val_accuracy: 0.3700\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 2.2133 - accuracy: 0.4188 - val_loss: 2.0149 - val_accuracy: 0.4225\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 2.2649 - accuracy: 0.4276 - val_loss: 1.5344 - val_accuracy: 0.4568\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 2.2456 - accuracy: 0.4241 - val_loss: 1.7427 - val_accuracy: 0.4581\n",
      "SUMMARY OF net_1\n",
      "Training Loss: 2.245636463165283\n",
      "Training Accuracy: 0.42406249046325684\n",
      "Validation Loss: 1.7427148818969727\n",
      "Validation Accuracy: 0.45809999108314514\n",
      "Classification Error Rate: 0.5419000089168549\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_2\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Removing a Conv2D layer at 0\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d16aaf240>, <__main__.Block object at 0x7c1cf0d07180>, <__main__.Block object at 0x7c1cf0d92480>, <__main__.Block object at 0x7c1cf0d85a00>, <__main__.Block object at 0x7c1d169d30c0>, <__main__.Block object at 0x7c1cf0d1d4c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_12\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_12/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_12\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_2\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cf0de2c80>, <__main__.Block object at 0x7c1cf0de2ac0>, <__main__.Block object at 0x7c1cf0de3100>, <__main__.Block object at 0x7c1cf0de3000>, <__main__.Block object at 0x7c1cf0de35c0>, <__main__.Block object at 0x7c1cf0de3880>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_2\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 07:49:00.357549: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_3/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 18s 10ms/step - loss: 0.7956 - accuracy: 0.7409 - val_loss: 0.4769 - val_accuracy: 0.8331\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 0.5876 - accuracy: 0.8217 - val_loss: 0.7244 - val_accuracy: 0.7651\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.7543 - accuracy: 0.7980 - val_loss: 0.8981 - val_accuracy: 0.8231\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 1.1925 - accuracy: 0.6970 - val_loss: 1.8264 - val_accuracy: 0.3055\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 2.5171 - accuracy: 0.4423 - val_loss: 1.9524 - val_accuracy: 0.2848\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3635 - accuracy: 0.1100 - val_loss: 2.3034 - val_accuracy: 0.0990\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.0997\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3027 - accuracy: 0.0980 - val_loss: 2.3028 - val_accuracy: 0.0997\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3027 - accuracy: 0.0981 - val_loss: 2.3029 - val_accuracy: 0.0971\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3027 - accuracy: 0.0962 - val_loss: 2.3029 - val_accuracy: 0.0971\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3027 - accuracy: 0.1003 - val_loss: 2.3027 - val_accuracy: 0.0991\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3026 - accuracy: 0.0977 - val_loss: 2.3029 - val_accuracy: 0.0990\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3027 - accuracy: 0.0980 - val_loss: 2.3027 - val_accuracy: 0.0990\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.0998\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3027 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.0991\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3027 - accuracy: 0.0980 - val_loss: 2.3028 - val_accuracy: 0.0998\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 2.3027 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.0991\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3026 - accuracy: 0.0974 - val_loss: 2.3025 - val_accuracy: 0.1042\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3026 - accuracy: 0.0979 - val_loss: 2.3027 - val_accuracy: 0.0971\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.2996 - accuracy: 0.1013 - val_loss: 2.2406 - val_accuracy: 0.1236\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.4624 - accuracy: 0.1082 - val_loss: 2.3022 - val_accuracy: 0.0994\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3018 - accuracy: 0.0960 - val_loss: 2.3022 - val_accuracy: 0.0994\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3240 - accuracy: 0.0996 - val_loss: 2.3027 - val_accuracy: 0.0990\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3028 - val_accuracy: 0.0991\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.0998\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 2.3028 - accuracy: 0.0957 - val_loss: 2.3026 - val_accuracy: 0.0998\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3027 - val_accuracy: 0.0971\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 2.3028 - accuracy: 0.0974 - val_loss: 2.3029 - val_accuracy: 0.0971\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3028 - accuracy: 0.0978 - val_loss: 2.3028 - val_accuracy: 0.0971\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3030 - val_accuracy: 0.0971\n",
      "SUMMARY OF net_2\n",
      "Training Loss: 2.3027496337890625\n",
      "Training Accuracy: 0.09831249713897705\n",
      "Validation Loss: 2.3029544353485107\n",
      "Validation Accuracy: 0.09709999710321426\n",
      "Classification Error Rate: 0.9029000028967857\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_3\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d16bae940>, <__main__.Block object at 0x7c1cc055bb80>, <__main__.Block object at 0x7c1d16aaf240>, <__main__.Block object at 0x7c1cf0d55500>, <__main__.Block object at 0x7c1cf0d421c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Input 0 of layer \"max_pooling2d_19\" is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: (None, 10)\n",
      "Returning None.\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_3\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cf24ca640>, <__main__.Block object at 0x7c1cf23e3f80>, <__main__.Block object at 0x7c1d3894d640>, <__main__.Block object at 0x7c1cf25f0680>, <__main__.Block object at 0x7c1cf2389e40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_3\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 24s 14ms/step - loss: 0.9136 - accuracy: 0.7920 - val_loss: 0.4452 - val_accuracy: 0.8546\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 20s 14ms/step - loss: 0.3958 - accuracy: 0.8603 - val_loss: 0.4861 - val_accuracy: 0.8461\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.3892 - accuracy: 0.8666 - val_loss: 0.4126 - val_accuracy: 0.8565\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.3929 - accuracy: 0.8680 - val_loss: 0.3867 - val_accuracy: 0.8647\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.4277 - accuracy: 0.8617 - val_loss: 0.4035 - val_accuracy: 0.8654\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.4789 - accuracy: 0.8573 - val_loss: 0.5237 - val_accuracy: 0.8285\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.4719 - accuracy: 0.8545 - val_loss: 0.4254 - val_accuracy: 0.8668\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.5219 - accuracy: 0.8493 - val_loss: 0.4376 - val_accuracy: 0.8609\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.5340 - accuracy: 0.8467 - val_loss: 0.5935 - val_accuracy: 0.8100\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 20s 14ms/step - loss: 0.5417 - accuracy: 0.8453 - val_loss: 0.5739 - val_accuracy: 0.8447\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.6813 - accuracy: 0.8309 - val_loss: 0.5341 - val_accuracy: 0.8407\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.7162 - accuracy: 0.8230 - val_loss: 0.6580 - val_accuracy: 0.8162\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.9366 - accuracy: 0.7875 - val_loss: 0.8419 - val_accuracy: 0.8231\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 20s 14ms/step - loss: 1.3186 - accuracy: 0.7541 - val_loss: 1.5628 - val_accuracy: 0.4115\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 1.5616 - accuracy: 0.6275 - val_loss: 1.6483 - val_accuracy: 0.4783\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 1.9087 - accuracy: 0.4023 - val_loss: 2.4124 - val_accuracy: 0.3801\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 20s 14ms/step - loss: 2.3193 - accuracy: 0.3020 - val_loss: 1.8298 - val_accuracy: 0.4185\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 20s 14ms/step - loss: 5.4415 - accuracy: 0.3164 - val_loss: 1.9592 - val_accuracy: 0.2565\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 20s 14ms/step - loss: 3.1618 - accuracy: 0.2451 - val_loss: 2.0527 - val_accuracy: 0.2170\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 2.2862 - accuracy: 0.2393 - val_loss: 2.0550 - val_accuracy: 0.2602\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 4.6284 - accuracy: 0.2720 - val_loss: 2.3711 - val_accuracy: 0.2661\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 20s 14ms/step - loss: 6.6362 - accuracy: 0.2641 - val_loss: 2.4330 - val_accuracy: 0.0990\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 20s 14ms/step - loss: 2.3541 - accuracy: 0.1007 - val_loss: 2.3106 - val_accuracy: 0.0991\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 2.3046 - accuracy: 0.0995 - val_loss: 2.3029 - val_accuracy: 0.0971\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3027 - val_accuracy: 0.0991\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 20s 14ms/step - loss: 2.3027 - accuracy: 0.1010 - val_loss: 2.3027 - val_accuracy: 0.0990\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 2.3028 - accuracy: 0.0978 - val_loss: 2.3028 - val_accuracy: 0.0971\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 20s 14ms/step - loss: 2.3028 - accuracy: 0.0991 - val_loss: 2.3028 - val_accuracy: 0.0971\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 2.3027 - accuracy: 0.0968 - val_loss: 2.3025 - val_accuracy: 0.1042\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 2.3028 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.0990\n",
      "SUMMARY OF net_3\n",
      "Training Loss: 2.302760362625122\n",
      "Training Accuracy: 0.09941666573286057\n",
      "Validation Loss: 2.3027217388153076\n",
      "Validation Accuracy: 0.0989999994635582\n",
      "Classification Error Rate: 0.9010000005364418\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_4\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cc0d45500>, <__main__.Block object at 0x7c1cc0d03840>, <__main__.Block object at 0x7c1cc02cc540>, <__main__.Block object at 0x7c1cf23f4800>, <__main__.Block object at 0x7c1d16bae940>, <__main__.Block object at 0x7c1cf247bf80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_4\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 15s 8ms/step - loss: 0.7066 - accuracy: 0.7607 - val_loss: 0.4767 - val_accuracy: 0.8449\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.4536 - accuracy: 0.8533 - val_loss: 0.4776 - val_accuracy: 0.8725\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.4596 - accuracy: 0.8548 - val_loss: 0.4887 - val_accuracy: 0.8472\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.4900 - accuracy: 0.8525 - val_loss: 0.7766 - val_accuracy: 0.8665\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.5021 - accuracy: 0.8496 - val_loss: 0.5734 - val_accuracy: 0.8529\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.5135 - accuracy: 0.8492 - val_loss: 0.4697 - val_accuracy: 0.8510\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.5332 - accuracy: 0.8433 - val_loss: 0.6206 - val_accuracy: 0.8752\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.6217 - accuracy: 0.8323 - val_loss: 0.6919 - val_accuracy: 0.8232\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.7472 - accuracy: 0.8131 - val_loss: 1.0198 - val_accuracy: 0.8010\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 1.0448 - accuracy: 0.7655 - val_loss: 0.8764 - val_accuracy: 0.7874\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 1.2435 - accuracy: 0.7022 - val_loss: 1.8418 - val_accuracy: 0.3132\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.1437 - accuracy: 0.5363 - val_loss: 2.5817 - val_accuracy: 0.3147\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 4.0607 - accuracy: 0.3046 - val_loss: 2.0821 - val_accuracy: 0.3117\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 3.9138 - accuracy: 0.2902 - val_loss: 2.0121 - val_accuracy: 0.2492\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.7364 - accuracy: 0.3176 - val_loss: 1.7279 - val_accuracy: 0.3257\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.6010 - accuracy: 0.3881 - val_loss: 1.6144 - val_accuracy: 0.4344\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 3.1990 - accuracy: 0.3350 - val_loss: 1.5934 - val_accuracy: 0.3384\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 1.9879 - accuracy: 0.3990 - val_loss: 2.2369 - val_accuracy: 0.4650\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.2336 - accuracy: 0.4196 - val_loss: 2.0172 - val_accuracy: 0.2611\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 3.0427 - accuracy: 0.3958 - val_loss: 2.0607 - val_accuracy: 0.4602\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.1935 - accuracy: 0.3912 - val_loss: 1.7365 - val_accuracy: 0.4553\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.1905 - accuracy: 0.3718 - val_loss: 1.9297 - val_accuracy: 0.2945\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.2306 - accuracy: 0.4007 - val_loss: 1.5258 - val_accuracy: 0.4308\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 1.8903 - accuracy: 0.4141 - val_loss: 2.5931 - val_accuracy: 0.4329\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.1137 - accuracy: 0.4180 - val_loss: 1.7050 - val_accuracy: 0.3951\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.2286 - accuracy: 0.4082 - val_loss: 5.5738 - val_accuracy: 0.4247\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 1.9853 - accuracy: 0.4009 - val_loss: 3.2387 - val_accuracy: 0.4564\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.0967 - accuracy: 0.4065 - val_loss: 1.7107 - val_accuracy: 0.3776\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.0544 - accuracy: 0.3965 - val_loss: 2.5166 - val_accuracy: 0.4360\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.2769 - accuracy: 0.3758 - val_loss: 1.5197 - val_accuracy: 0.4139\n",
      "SUMMARY OF net_4\n",
      "Training Loss: 2.2769460678100586\n",
      "Training Accuracy: 0.37581250071525574\n",
      "Validation Loss: 1.519719123840332\n",
      "Validation Accuracy: 0.4138999879360199\n",
      "Classification Error Rate: 0.5861000120639801\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_5\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d1336a680>, <__main__.Block object at 0x7c1d1331bb80>, <__main__.Block object at 0x7c1d134bfe00>, <__main__.Block object at 0x7c1d1335ddc0>, <__main__.Block object at 0x7c1cc02bcb80>, <__main__.Block object at 0x7c1d14d2da00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_5\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 16s 9ms/step - loss: 0.8167 - accuracy: 0.7626 - val_loss: 0.3853 - val_accuracy: 0.8585\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.4097 - accuracy: 0.8576 - val_loss: 0.3654 - val_accuracy: 0.8783\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3905 - accuracy: 0.8720 - val_loss: 0.3760 - val_accuracy: 0.8743\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.4102 - accuracy: 0.8680 - val_loss: 0.4072 - val_accuracy: 0.8597\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.4170 - accuracy: 0.8706 - val_loss: 0.3861 - val_accuracy: 0.8754\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.4447 - accuracy: 0.8650 - val_loss: 0.5121 - val_accuracy: 0.8667\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.5078 - accuracy: 0.8518 - val_loss: 0.5573 - val_accuracy: 0.8121\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.5728 - accuracy: 0.8372 - val_loss: 0.8142 - val_accuracy: 0.8040\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.7768 - accuracy: 0.7834 - val_loss: 0.8995 - val_accuracy: 0.6890\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 1.2174 - accuracy: 0.6869 - val_loss: 1.1085 - val_accuracy: 0.6600\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.3426 - accuracy: 0.3695 - val_loss: 1.1786 - val_accuracy: 0.6001\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 5.1502 - accuracy: 0.3860 - val_loss: 1.8492 - val_accuracy: 0.4148\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 3.5709 - accuracy: 0.2645 - val_loss: 1.8983 - val_accuracy: 0.2685\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 3.0177 - accuracy: 0.2858 - val_loss: 1.9457 - val_accuracy: 0.2377\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 5.3920 - accuracy: 0.2555 - val_loss: 2.0296 - val_accuracy: 0.2293\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 4.4769 - accuracy: 0.2702 - val_loss: 1.7253 - val_accuracy: 0.3223\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 4.9421 - accuracy: 0.3047 - val_loss: 1.8046 - val_accuracy: 0.3547\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 3.1631 - accuracy: 0.2187 - val_loss: 2.3283 - val_accuracy: 0.1101\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.6214 - accuracy: 0.2433 - val_loss: 2.1557 - val_accuracy: 0.2253\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 3.6837 - accuracy: 0.2498 - val_loss: 1.8266 - val_accuracy: 0.2854\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 5.8397 - accuracy: 0.2958 - val_loss: 2.1088 - val_accuracy: 0.2309\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 7.2229 - accuracy: 0.3044 - val_loss: 3.1812 - val_accuracy: 0.3408\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.4315 - accuracy: 0.3131 - val_loss: 3.9511 - val_accuracy: 0.3292\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.8978 - accuracy: 0.3071 - val_loss: 1.7701 - val_accuracy: 0.3073\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 3.0113 - accuracy: 0.3231 - val_loss: 1.9529 - val_accuracy: 0.2447\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.7716 - accuracy: 0.3055 - val_loss: 1.7433 - val_accuracy: 0.3042\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.4437 - accuracy: 0.1626 - val_loss: 2.3266 - val_accuracy: 0.0997\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.3078 - accuracy: 0.0986 - val_loss: 2.3030 - val_accuracy: 0.0998\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.3028 - accuracy: 0.0974 - val_loss: 2.3028 - val_accuracy: 0.0971\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.3028 - accuracy: 0.0985 - val_loss: 2.3028 - val_accuracy: 0.0971\n",
      "SUMMARY OF net_5\n",
      "Training Loss: 2.302765130996704\n",
      "Training Accuracy: 0.09849999845027924\n",
      "Validation Loss: 2.302821397781372\n",
      "Validation Accuracy: 0.09709999710321426\n",
      "Classification Error Rate: 0.9029000028967857\n",
      "\n",
      "-------------------------------------\n",
      "Initial Population:\n",
      "net_4 :  1.519719123840332\n",
      "net_1 :  1.7427148818969727\n",
      "parent_0 :  1.968990445137024\n",
      "net_3 :  2.3027217388153076\n",
      "net_5 :  2.302821397781372\n",
      "net_2 :  2.3029544353485107\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 1\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Tournament selection\n",
      "Selected net_3 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d125ff240>, <__main__.Block object at 0x7c1d128abb80>, <__main__.Block object at 0x7c1d127c8100>, <__main__.Block object at 0x7c216d1efd80>, <__main__.Block object at 0x7c216d1eff00>, <__main__.Block object at 0x7c216d1fc540>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 14s 8ms/step - loss: 0.5980 - accuracy: 0.7878 - val_loss: 0.3843 - val_accuracy: 0.8617\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.4054 - accuracy: 0.8622 - val_loss: 0.5045 - val_accuracy: 0.8182\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.4025 - accuracy: 0.8674 - val_loss: 0.4164 - val_accuracy: 0.8699\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.4127 - accuracy: 0.8665 - val_loss: 0.3977 - val_accuracy: 0.8692\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.4570 - accuracy: 0.8600 - val_loss: 0.4761 - val_accuracy: 0.8384\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.4660 - accuracy: 0.8568 - val_loss: 0.4639 - val_accuracy: 0.8418\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.5512 - accuracy: 0.8430 - val_loss: 0.4504 - val_accuracy: 0.8555\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.5855 - accuracy: 0.8303 - val_loss: 0.7689 - val_accuracy: 0.8393\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.7405 - accuracy: 0.7963 - val_loss: 1.1377 - val_accuracy: 0.8480\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 1.2894 - accuracy: 0.7142 - val_loss: 3.5283 - val_accuracy: 0.5047\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 1.9347 - accuracy: 0.4358 - val_loss: 1.7047 - val_accuracy: 0.4098\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 2.0875 - accuracy: 0.4525 - val_loss: 1.3965 - val_accuracy: 0.4412\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 2.4455 - accuracy: 0.4375 - val_loss: 1.2255 - val_accuracy: 0.5073\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 2.2949 - accuracy: 0.4263 - val_loss: 1.7327 - val_accuracy: 0.3671\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 3.2700 - accuracy: 0.3722 - val_loss: 1.7006 - val_accuracy: 0.3608\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 2.5068 - accuracy: 0.3661 - val_loss: 1.7148 - val_accuracy: 0.3391\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 2.1429 - accuracy: 0.3950 - val_loss: 1.6437 - val_accuracy: 0.3893\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 2.0832 - accuracy: 0.3292 - val_loss: 1.8525 - val_accuracy: 0.3136\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 2.3340 - accuracy: 0.3158 - val_loss: 2.1689 - val_accuracy: 0.3506\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 2.5163 - accuracy: 0.3260 - val_loss: 1.8732 - val_accuracy: 0.2826\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 2.6543 - accuracy: 0.3440 - val_loss: 2.4184 - val_accuracy: 0.2876\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 3.4272 - accuracy: 0.3034 - val_loss: 1.8466 - val_accuracy: 0.2724\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 3.1343 - accuracy: 0.1887 - val_loss: 2.3460 - val_accuracy: 0.0979\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 2.6016 - accuracy: 0.2159 - val_loss: 3.9551 - val_accuracy: 0.1648\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 3.3464 - accuracy: 0.2432 - val_loss: 1.9279 - val_accuracy: 0.2466\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 4.9273 - accuracy: 0.2201 - val_loss: 2.0704 - val_accuracy: 0.1851\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 7.5902 - accuracy: 0.2534 - val_loss: 2.5005 - val_accuracy: 0.2043\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 7.2822 - accuracy: 0.2033 - val_loss: 2.3315 - val_accuracy: 0.0990\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 2.3107 - accuracy: 0.1006 - val_loss: 2.3033 - val_accuracy: 0.0991\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 2.3028 - accuracy: 0.1012 - val_loss: 2.3028 - val_accuracy: 0.0990\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 2.3028392791748047\n",
      "Training Accuracy: 0.10118749737739563\n",
      "Validation Loss: 2.3027615547180176\n",
      "Validation Accuracy: 0.0989999994635582\n",
      "Classification Error Rate: 0.9010000005364418\n",
      "----->Evolution: Child net_6 with fitness 2.3027615547180176 replaces parent net_2 with fitness 2.3029544353485107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Child 1\n",
      "----->Tournament selection\n",
      "Selected net_4 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cf0dd6300>, <__main__.Block object at 0x7c1d11390100>, <__main__.Block object at 0x7c1d0fdf9e80>, <__main__.Block object at 0x7c1d112f7a40>, <__main__.Block object at 0x7c1d0da79ec0>, <__main__.Block object at 0x7c1d10b1a680>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 18s 10ms/step - loss: 0.7493 - accuracy: 0.7558 - val_loss: 0.4250 - val_accuracy: 0.8623\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.4108 - accuracy: 0.8606 - val_loss: 0.4059 - val_accuracy: 0.8678\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.3882 - accuracy: 0.8720 - val_loss: 0.4096 - val_accuracy: 0.8832\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.3921 - accuracy: 0.8747 - val_loss: 0.4773 - val_accuracy: 0.8525\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.3989 - accuracy: 0.8742 - val_loss: 0.3618 - val_accuracy: 0.8940\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.3969 - accuracy: 0.8791 - val_loss: 0.4071 - val_accuracy: 0.8551\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.4188 - accuracy: 0.8755 - val_loss: 0.4200 - val_accuracy: 0.8751\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.4097 - accuracy: 0.8791 - val_loss: 0.4138 - val_accuracy: 0.8466\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.4536 - accuracy: 0.8727 - val_loss: 0.5265 - val_accuracy: 0.8808\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.5506 - accuracy: 0.8610 - val_loss: 0.5136 - val_accuracy: 0.8398\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.5942 - accuracy: 0.8525 - val_loss: 1.5454 - val_accuracy: 0.8067\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.7381 - accuracy: 0.8395 - val_loss: 0.7126 - val_accuracy: 0.8486\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.8797 - accuracy: 0.8070 - val_loss: 1.1685 - val_accuracy: 0.7625\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 2.2386 - accuracy: 0.5388 - val_loss: 1.8376 - val_accuracy: 0.3741\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 3.3314 - accuracy: 0.3753 - val_loss: 2.1187 - val_accuracy: 0.3732\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 2.7579 - accuracy: 0.4497 - val_loss: 1.9546 - val_accuracy: 0.5316\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 2.1952 - accuracy: 0.4741 - val_loss: 1.9673 - val_accuracy: 0.4095\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 3.4872 - accuracy: 0.1650 - val_loss: 2.3544 - val_accuracy: 0.1019\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 4.9763 - accuracy: 0.3049 - val_loss: 2.1966 - val_accuracy: 0.3364\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 3.4636 - accuracy: 0.3409 - val_loss: 2.4385 - val_accuracy: 0.4657\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 2.6748 - accuracy: 0.3532 - val_loss: 2.2698 - val_accuracy: 0.2796\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 2.7423 - accuracy: 0.3113 - val_loss: 2.1406 - val_accuracy: 0.3705\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 2.5991 - accuracy: 0.3727 - val_loss: 2.1258 - val_accuracy: 0.3624\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 1.9985 - accuracy: 0.3718 - val_loss: 1.7694 - val_accuracy: 0.3569\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 2.1421 - accuracy: 0.3467 - val_loss: 2.1926 - val_accuracy: 0.3671\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 1.9383 - accuracy: 0.3446 - val_loss: 1.7737 - val_accuracy: 0.3241\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 1.9084 - accuracy: 0.3428 - val_loss: 1.6972 - val_accuracy: 0.3570\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 1.8784 - accuracy: 0.3461 - val_loss: 1.9916 - val_accuracy: 0.3618\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 1.7724 - accuracy: 0.3350 - val_loss: 1.9112 - val_accuracy: 0.3464\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 2.4728 - accuracy: 0.3010 - val_loss: 1.7541 - val_accuracy: 0.3085\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 2.4727916717529297\n",
      "Training Accuracy: 0.3010416626930237\n",
      "Validation Loss: 1.7541035413742065\n",
      "Validation Accuracy: 0.3084999918937683\n",
      "Classification Error Rate: 0.6915000081062317\n",
      "----->Evolution: Child net_7 with fitness 1.7541035413742065 replaces parent net_5 with fitness 2.302821397781372\n",
      "\n",
      "Creating Child 2\n",
      "----->Tournament selection\n",
      "Selected net_3 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  512\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d13313900>, <__main__.Block object at 0x7c1d1331c500>, <__main__.Block object at 0x7c1d14e9f440>, <__main__.Block object at 0x7c221ca61d00>, <__main__.Block object at 0x7c1d0ec42a40>, <__main__.Block object at 0x7c1d13391900>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 22s 12ms/step - loss: 4.5568 - accuracy: 0.6058 - val_loss: 0.9749 - val_accuracy: 0.7286\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 0.9563 - accuracy: 0.7090 - val_loss: 0.7165 - val_accuracy: 0.7360\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 1.6629 - accuracy: 0.5960 - val_loss: 2.2143 - val_accuracy: 0.1480\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.4629 - accuracy: 0.1260 - val_loss: 2.3033 - val_accuracy: 0.0990\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3029 - accuracy: 0.0984 - val_loss: 2.3029 - val_accuracy: 0.0971\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.0969 - val_loss: 2.3027 - val_accuracy: 0.0971\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.0984 - val_loss: 2.3027 - val_accuracy: 0.0991\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.0991\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3027 - accuracy: 0.1009 - val_loss: 2.3028 - val_accuracy: 0.0971\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3027 - val_accuracy: 0.0971\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3027 - val_accuracy: 0.0971\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.0979 - val_loss: 2.3028 - val_accuracy: 0.0971\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3027 - accuracy: 0.1016 - val_loss: 2.3028 - val_accuracy: 0.0971\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3028 - val_accuracy: 0.0990\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3027 - accuracy: 0.0987 - val_loss: 2.3027 - val_accuracy: 0.0998\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.0983 - val_loss: 2.3027 - val_accuracy: 0.0990\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.0990\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3027 - accuracy: 0.1011 - val_loss: 2.3027 - val_accuracy: 0.0991\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.1015\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.0990\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.0972 - val_loss: 2.3027 - val_accuracy: 0.0988\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.0972 - val_loss: 2.3027 - val_accuracy: 0.0971\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.0968 - val_loss: 2.3027 - val_accuracy: 0.0971\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.0984 - val_loss: 2.3027 - val_accuracy: 0.0990\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.0971\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.0950 - val_loss: 2.3026 - val_accuracy: 0.0998\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.0990\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.0969 - val_loss: 2.3027 - val_accuracy: 0.0997\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.0985 - val_loss: 2.3028 - val_accuracy: 0.0990\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 18s 12ms/step - loss: 2.3028 - accuracy: 0.0972 - val_loss: 2.3027 - val_accuracy: 0.0997\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 2.3027894496917725\n",
      "Training Accuracy: 0.09716666489839554\n",
      "Validation Loss: 2.302687644958496\n",
      "Validation Accuracy: 0.09969999641180038\n",
      "Classification Error Rate: 0.9003000035881996\n",
      "----->Evolution: Child net_8 with fitness 2.302687644958496 replaces parent net_2 with fitness 2.3027615547180176\n",
      "\n",
      "Creating Child 3\n",
      "----->Tournament selection\n",
      "Selected net_4 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d0d127980>, <__main__.Block object at 0x7c1d17728c80>, <__main__.Block object at 0x7c1d11337700>, <__main__.Block object at 0x7c1d1143de80>, <__main__.Block object at 0x7c1d113278c0>, <__main__.Block object at 0x7c1d11327c00>, <__main__.Block object at 0x7c1d10bb3100>, <__main__.Block object at 0x7c1d10958a40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_105. Consider increasing the input size. Received input shape [None, 1, 1, 512] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_41\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_41/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_41\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2)]\n",
      "Removing a Conv2D layer at 0\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d176f8500>, <__main__.Block object at 0x7c1d17730940>, <__main__.Block object at 0x7c1d17745200>, <__main__.Block object at 0x7c1d17745300>, <__main__.Block object at 0x7c1d17745a40>, <__main__.Block object at 0x7c1d17745a80>, <__main__.Block object at 0x7c1d17745b80>, <__main__.Block object at 0x7c1d17745d00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_115. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_45\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_45/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_45\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d17776280>, <__main__.Block object at 0x7c1d177376c0>, <__main__.Block object at 0x7c1d17774ec0>, <__main__.Block object at 0x7c1d17776600>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 15s 8ms/step - loss: 0.6467 - accuracy: 0.8145 - val_loss: 0.9567 - val_accuracy: 0.8603\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3940 - accuracy: 0.8631 - val_loss: 8.9570 - val_accuracy: 0.8560\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.4225 - accuracy: 0.8599 - val_loss: 24.1704 - val_accuracy: 0.8000\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.4617 - accuracy: 0.8533 - val_loss: 40.7251 - val_accuracy: 0.8243\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.5011 - accuracy: 0.8455 - val_loss: 93.7938 - val_accuracy: 0.8467\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.5313 - accuracy: 0.8428 - val_loss: 245.1652 - val_accuracy: 0.8349\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.5915 - accuracy: 0.8311 - val_loss: 747.7319 - val_accuracy: 0.8005\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.6430 - accuracy: 0.8214 - val_loss: 1081.0859 - val_accuracy: 0.8115\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.7443 - accuracy: 0.7997 - val_loss: 1134.2228 - val_accuracy: 0.8026\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.8099 - accuracy: 0.7876 - val_loss: 1962.7168 - val_accuracy: 0.7373\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 1.0415 - accuracy: 0.7515 - val_loss: 3050.0559 - val_accuracy: 0.7544\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 1.2456 - accuracy: 0.7050 - val_loss: 4283.7334 - val_accuracy: 0.6356\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 1.4631 - accuracy: 0.6844 - val_loss: 4848.9336 - val_accuracy: 0.7066\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 1.6725 - accuracy: 0.6161 - val_loss: 5529.0420 - val_accuracy: 0.5343\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.8692 - accuracy: 0.3947 - val_loss: 5079.2041 - val_accuracy: 0.3838\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.6661 - accuracy: 0.3079 - val_loss: 2525.6711 - val_accuracy: 0.3571\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 4.7676 - accuracy: 0.2215 - val_loss: 3596.0237 - val_accuracy: 0.2069\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.7269 - accuracy: 0.1752 - val_loss: 4851.5474 - val_accuracy: 0.1884\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 5.0078 - accuracy: 0.1780 - val_loss: 3638.0583 - val_accuracy: 0.1086\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.3260 - accuracy: 0.1076 - val_loss: 4174.1841 - val_accuracy: 0.1099\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.4471 - accuracy: 0.1494 - val_loss: 6246.7817 - val_accuracy: 0.0970\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.3062 - accuracy: 0.0975 - val_loss: 6246.7681 - val_accuracy: 0.0995\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.3028 - accuracy: 0.0986 - val_loss: 6246.7681 - val_accuracy: 0.0985\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.3027 - accuracy: 0.1006 - val_loss: 6246.7681 - val_accuracy: 0.0990\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.3028 - accuracy: 0.0991 - val_loss: 6246.7681 - val_accuracy: 0.0990\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.3028 - accuracy: 0.0970 - val_loss: 6246.7676 - val_accuracy: 0.0990\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.3028 - accuracy: 0.0957 - val_loss: 6246.7681 - val_accuracy: 0.0989\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.3028 - accuracy: 0.0985 - val_loss: 6246.7681 - val_accuracy: 0.0990\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.3028 - accuracy: 0.0983 - val_loss: 6246.7676 - val_accuracy: 0.0989\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.3028 - accuracy: 0.0989 - val_loss: 6246.7690 - val_accuracy: 0.0970\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 2.30275559425354\n",
      "Training Accuracy: 0.0988541692495346\n",
      "Validation Loss: 6246.76904296875\n",
      "Validation Accuracy: 0.09700000286102295\n",
      "Classification Error Rate: 0.902999997138977\n",
      "----->Evolution: Child net_9 with fitness 6246.76904296875 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 2\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_4 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d035bf240>, <__main__.Block object at 0x7c1d03673b80>, <__main__.Block object at 0x7c1cfe44a080>, <__main__.Block object at 0x7c1d0358dac0>, <__main__.Block object at 0x7c1d00565940>, <__main__.Block object at 0x7c1d03643340>, <__main__.Block object at 0x7c1d034a7b00>, <__main__.Block object at 0x7c1d034c54c0>, <__main__.Block object at 0x7c1d03683f40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_129. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_131. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_132. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_21\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_21/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_21\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d034f8e00>, <__main__.Block object at 0x7c1d0364ce80>, <__main__.Block object at 0x7c1d034f9040>, <__main__.Block object at 0x7c1d034f8980>, <__main__.Block object at 0x7c1d034fa7c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_50\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_50/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_50\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d0351b140>, <__main__.Block object at 0x7c1d0350b840>, <__main__.Block object at 0x7c1d0352a580>, <__main__.Block object at 0x7c1d0352a940>, <__main__.Block object at 0x7c1d0352ae40>, <__main__.Block object at 0x7c1d0352ae80>, <__main__.Block object at 0x7c1d0352af80>, <__main__.Block object at 0x7c1d0352b080>, <__main__.Block object at 0x7c1d0352b300>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_148. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_54\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_54/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_54\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d03510500>, <__main__.Block object at 0x7c1d034f97c0>, <__main__.Block object at 0x7c1d034f2bc0>, <__main__.Block object at 0x7c1d034f3000>, <__main__.Block object at 0x7c1d034f0580>, <__main__.Block object at 0x7c1d034f20c0>, <__main__.Block object at 0x7c1d034f3d40>, <__main__.Block object at 0x7c1d034f3940>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_154\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_154/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_154/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,64], [3,3,64,128].\n",
      "\n",
      "Call arguments received by layer \"conv2d_154\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 64), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_30\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_30/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_30\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d03633140>, <__main__.Block object at 0x7c1d03530dc0>, <__main__.Block object at 0x7c1d03530e00>, <__main__.Block object at 0x7c1d03531240>, <__main__.Block object at 0x7c1d03531300>, <__main__.Block object at 0x7c1d03531500>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_33\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_33/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,64].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_33\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 64), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.25  to  0.3\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d03555780>, <__main__.Block object at 0x7c1d03554ec0>, <__main__.Block object at 0x7c1d03555680>, <__main__.Block object at 0x7c1d03555800>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_6\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 08:47:27.765752: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_19/dropout_1/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 11s 6ms/step - loss: 0.5961 - accuracy: 0.7874 - val_loss: 0.4241 - val_accuracy: 0.8426\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4103 - accuracy: 0.8523 - val_loss: 0.3693 - val_accuracy: 0.8678\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3799 - accuracy: 0.8638 - val_loss: 0.4221 - val_accuracy: 0.8381\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3892 - accuracy: 0.8639 - val_loss: 0.4103 - val_accuracy: 0.8528\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4235 - accuracy: 0.8573 - val_loss: 0.4553 - val_accuracy: 0.8425\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4405 - accuracy: 0.8550 - val_loss: 0.3963 - val_accuracy: 0.8600\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4694 - accuracy: 0.8505 - val_loss: 0.4087 - val_accuracy: 0.8588\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5066 - accuracy: 0.8450 - val_loss: 0.5481 - val_accuracy: 0.8333\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5444 - accuracy: 0.8382 - val_loss: 0.5474 - val_accuracy: 0.8006\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5872 - accuracy: 0.8313 - val_loss: 0.5022 - val_accuracy: 0.8222\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.6682 - accuracy: 0.8130 - val_loss: 0.7539 - val_accuracy: 0.7377\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.7646 - accuracy: 0.7979 - val_loss: 0.7309 - val_accuracy: 0.8225\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 1.0119 - accuracy: 0.7682 - val_loss: 0.7382 - val_accuracy: 0.8235\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 1.3361 - accuracy: 0.7185 - val_loss: 0.9203 - val_accuracy: 0.7392\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 1.9732 - accuracy: 0.5602 - val_loss: 1.6964 - val_accuracy: 0.5054\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 3.1569 - accuracy: 0.3385 - val_loss: 2.0243 - val_accuracy: 0.3430\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 4.0349 - accuracy: 0.2625 - val_loss: 2.7410 - val_accuracy: 0.2199\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 3.5680 - accuracy: 0.2267 - val_loss: 2.1158 - val_accuracy: 0.1680\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.2719 - accuracy: 0.1587 - val_loss: 2.0742 - val_accuracy: 0.1834\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 3.2184 - accuracy: 0.1752 - val_loss: 2.0727 - val_accuracy: 0.1836\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 3.4235 - accuracy: 0.1855 - val_loss: 2.0736 - val_accuracy: 0.1842\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 3.8124 - accuracy: 0.1897 - val_loss: 2.1068 - val_accuracy: 0.1804\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 10.2635 - accuracy: 0.2022 - val_loss: 2.2832 - val_accuracy: 0.1284\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 2.4348 - accuracy: 0.1697 - val_loss: 2.0946 - val_accuracy: 0.1839\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 2.5660 - accuracy: 0.1642 - val_loss: 2.4450 - val_accuracy: 0.2302\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 4.0117 - accuracy: 0.1745 - val_loss: 2.3551 - val_accuracy: 0.0981\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 2.1391 - accuracy: 0.1670 - val_loss: 2.1056 - val_accuracy: 0.1877\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.6103 - accuracy: 0.1875 - val_loss: 2.0015 - val_accuracy: 0.2233\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3864 - accuracy: 0.1831 - val_loss: 2.0879 - val_accuracy: 0.1752\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 2.6405 - accuracy: 0.1743 - val_loss: 2.3872 - val_accuracy: 0.0998\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 2.64048433303833\n",
      "Training Accuracy: 0.17425000667572021\n",
      "Validation Loss: 2.387223720550537\n",
      "Validation Accuracy: 0.0997999981045723\n",
      "Classification Error Rate: 0.9002000018954277\n",
      "----->Evolution: Child net_6 with fitness 2.387223720550537 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_4 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d1686e240>, <__main__.Block object at 0x7c1d2bec3b80>, <__main__.Block object at 0x7c1d166da080>, <__main__.Block object at 0x7c1d16685dc0>, <__main__.Block object at 0x7c1d16838b80>, <__main__.Block object at 0x7c1d2a7bdac0>, <__main__.Block object at 0x7c1d16657240>, <__main__.Block object at 0x7c1d16654d40>, <__main__.Block object at 0x7c1d1661fd80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_38\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_38/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,64].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_38\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 64), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d16529040>, <__main__.Block object at 0x7c1d16820580>, <__main__.Block object at 0x7c1d16528d40>, <__main__.Block object at 0x7c1d165293c0>, <__main__.Block object at 0x7c1d16529640>, <__main__.Block object at 0x7c1d165298c0>, <__main__.Block object at 0x7c1d16529900>, <__main__.Block object at 0x7c1d165299c0>, <__main__.Block object at 0x7c1d16529a40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_64\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_64/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_64\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d16540dc0>, <__main__.Block object at 0x7c1d1652b840>, <__main__.Block object at 0x7c1d16542240>, <__main__.Block object at 0x7c1d16540500>, <__main__.Block object at 0x7c1d16542700>, <__main__.Block object at 0x7c1d16542800>, <__main__.Block object at 0x7c1d16542880>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_194\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_194/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_194/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,128], [3,3,128,512].\n",
      "\n",
      "Call arguments received by layer \"conv2d_194\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 128), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_195. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_70\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_70/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_70\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d1653a700>, <__main__.Block object at 0x7c1d16793200>, <__main__.Block object at 0x7c1d1653b140>, <__main__.Block object at 0x7c1d1653a500>, <__main__.Block object at 0x7c1d16539fc0>, <__main__.Block object at 0x7c1d165385c0>, <__main__.Block object at 0x7c1d1653bdc0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_75\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_75/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_75\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Inserting a Pooling layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d16527680>, <__main__.Block object at 0x7c1d167e8940>, <__main__.Block object at 0x7c1d16526ec0>, <__main__.Block object at 0x7c1d16524e40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 12s 7ms/step - loss: 0.5890 - accuracy: 0.7943 - val_loss: 0.3666 - val_accuracy: 0.8694\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.3738 - accuracy: 0.8698 - val_loss: 0.3832 - val_accuracy: 0.8637\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.3685 - accuracy: 0.8747 - val_loss: 0.3923 - val_accuracy: 0.8714\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3840 - accuracy: 0.8739 - val_loss: 0.3647 - val_accuracy: 0.8706\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.3852 - accuracy: 0.8765 - val_loss: 0.4038 - val_accuracy: 0.8951\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.4135 - accuracy: 0.8705 - val_loss: 0.6146 - val_accuracy: 0.8713\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4360 - accuracy: 0.8686 - val_loss: 0.4425 - val_accuracy: 0.8896\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4510 - accuracy: 0.8632 - val_loss: 0.5909 - val_accuracy: 0.8096\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4918 - accuracy: 0.8594 - val_loss: 0.5284 - val_accuracy: 0.8518\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4901 - accuracy: 0.8638 - val_loss: 0.4735 - val_accuracy: 0.8593\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5337 - accuracy: 0.8589 - val_loss: 0.5641 - val_accuracy: 0.8395\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.5903 - accuracy: 0.8474 - val_loss: 0.4690 - val_accuracy: 0.8680\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.7202 - accuracy: 0.8407 - val_loss: 0.7821 - val_accuracy: 0.8394\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.8361 - accuracy: 0.8219 - val_loss: 0.6892 - val_accuracy: 0.8102\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.8805 - accuracy: 0.8085 - val_loss: 0.9544 - val_accuracy: 0.7678\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.9789 - accuracy: 0.7735 - val_loss: 0.8030 - val_accuracy: 0.7283\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.4594 - accuracy: 0.7560 - val_loss: 1.4556 - val_accuracy: 0.8180\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 1.7805 - accuracy: 0.7209 - val_loss: 1.2307 - val_accuracy: 0.5275\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 2.0499 - accuracy: 0.6327 - val_loss: 1.9944 - val_accuracy: 0.6755\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 2.9112 - accuracy: 0.4073 - val_loss: 1.4072 - val_accuracy: 0.4718\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 2.7329 - accuracy: 0.4843 - val_loss: 1.5645 - val_accuracy: 0.4614\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.4903 - accuracy: 0.4499 - val_loss: 1.3893 - val_accuracy: 0.4532\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 3.1808 - accuracy: 0.4376 - val_loss: 2.0065 - val_accuracy: 0.3307\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 4.3907 - accuracy: 0.4257 - val_loss: 1.7223 - val_accuracy: 0.3792\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 5.1667 - accuracy: 0.4053 - val_loss: 1.8445 - val_accuracy: 0.4278\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 3.8881 - accuracy: 0.3947 - val_loss: 1.7441 - val_accuracy: 0.3914\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 5.3451 - accuracy: 0.3988 - val_loss: 1.8758 - val_accuracy: 0.4686\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 4.0515 - accuracy: 0.4093 - val_loss: 1.7493 - val_accuracy: 0.3609\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 5.4881 - accuracy: 0.3879 - val_loss: 2.6502 - val_accuracy: 0.4102\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 9.7249 - accuracy: 0.4055 - val_loss: 1.7604 - val_accuracy: 0.4355\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 9.724923133850098\n",
      "Training Accuracy: 0.40547916293144226\n",
      "Validation Loss: 1.7603943347930908\n",
      "Validation Accuracy: 0.43549999594688416\n",
      "Classification Error Rate: 0.5645000040531158\n",
      "----->Evolution: Child net_7 with fitness 1.7603943347930908 replaces parent net_3 with fitness 2.3027217388153076\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_4 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d0efff980>, <__main__.Block object at 0x7c1d0f0d76c0>, <__main__.Block object at 0x7c1cf0c24d80>, <__main__.Block object at 0x7c1cf24c37c0>, <__main__.Block object at 0x7c1cf2303600>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_216\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_216/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_216/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,64], [3,3,64,256].\n",
      "\n",
      "Call arguments received by layer \"conv2d_216\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 64), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 10s 5ms/step - loss: 0.4761 - accuracy: 0.8258 - val_loss: 0.3260 - val_accuracy: 0.8831\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3016 - accuracy: 0.8926 - val_loss: 0.2991 - val_accuracy: 0.9008\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2693 - accuracy: 0.9037 - val_loss: 0.2646 - val_accuracy: 0.9112\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2575 - accuracy: 0.9106 - val_loss: 0.3303 - val_accuracy: 0.8948\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2577 - accuracy: 0.9116 - val_loss: 0.2866 - val_accuracy: 0.8986\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2629 - accuracy: 0.9124 - val_loss: 0.3658 - val_accuracy: 0.8835\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2652 - accuracy: 0.9132 - val_loss: 0.3389 - val_accuracy: 0.9085\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2617 - accuracy: 0.9140 - val_loss: 0.3735 - val_accuracy: 0.8893\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2666 - accuracy: 0.9133 - val_loss: 0.4121 - val_accuracy: 0.9139\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2792 - accuracy: 0.9116 - val_loss: 0.3767 - val_accuracy: 0.8645\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2928 - accuracy: 0.9094 - val_loss: 0.3996 - val_accuracy: 0.9077\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3030 - accuracy: 0.9072 - val_loss: 0.3640 - val_accuracy: 0.9052\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3263 - accuracy: 0.9024 - val_loss: 0.4831 - val_accuracy: 0.9085\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3420 - accuracy: 0.9020 - val_loss: 0.4766 - val_accuracy: 0.8122\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3602 - accuracy: 0.8962 - val_loss: 0.4781 - val_accuracy: 0.8829\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4088 - accuracy: 0.8882 - val_loss: 0.4224 - val_accuracy: 0.8646\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4485 - accuracy: 0.8842 - val_loss: 0.4455 - val_accuracy: 0.8971\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4831 - accuracy: 0.8768 - val_loss: 0.4632 - val_accuracy: 0.8379\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5444 - accuracy: 0.8730 - val_loss: 1.1039 - val_accuracy: 0.8759\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5636 - accuracy: 0.8763 - val_loss: 0.5112 - val_accuracy: 0.8822\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5656 - accuracy: 0.8723 - val_loss: 0.6254 - val_accuracy: 0.8436\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5661 - accuracy: 0.8643 - val_loss: 0.5952 - val_accuracy: 0.8553\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5977 - accuracy: 0.8652 - val_loss: 0.6983 - val_accuracy: 0.8338\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.6049 - accuracy: 0.8674 - val_loss: 0.4682 - val_accuracy: 0.8940\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.6202 - accuracy: 0.8621 - val_loss: 0.9072 - val_accuracy: 0.8536\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.6836 - accuracy: 0.8593 - val_loss: 0.9073 - val_accuracy: 0.8625\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.6768 - accuracy: 0.8570 - val_loss: 1.1458 - val_accuracy: 0.8117\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.6675 - accuracy: 0.8529 - val_loss: 1.0098 - val_accuracy: 0.8775\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.7244 - accuracy: 0.8459 - val_loss: 0.7130 - val_accuracy: 0.8507\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.7343 - accuracy: 0.8541 - val_loss: 0.5385 - val_accuracy: 0.8607\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 0.734263002872467\n",
      "Training Accuracy: 0.8541458249092102\n",
      "Validation Loss: 0.5385181903839111\n",
      "Validation Accuracy: 0.8607000112533569\n",
      "Classification Error Rate: 0.13929998874664307\n",
      "----->Evolution: Child net_8 with fitness 0.5385181903839111 replaces parent net_2 with fitness 2.302687644958496\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_2 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d0aee7980>, <__main__.Block object at 0x7c1d0859a080>, <__main__.Block object at 0x7c1d2a66d080>, <__main__.Block object at 0x7c1d0d09b7c0>, <__main__.Block object at 0x7c1d0e4f8480>, <__main__.Block object at 0x7c1d2a7e2f00>, <__main__.Block object at 0x7c1d2a5cb5c0>, <__main__.Block object at 0x7c1d0e592f40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_226. Consider increasing the input size. Received input shape [None, 1, 1, 256] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_84\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_84/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_84\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d0af64d40>, <__main__.Block object at 0x7c1d0af64600>, <__main__.Block object at 0x7c1d0af64bc0>, <__main__.Block object at 0x7c1d0af65040>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_9\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 08:59:37.949013: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_27/dropout_3/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 13s 7ms/step - loss: 0.6168 - accuracy: 0.7892 - val_loss: 0.4615 - val_accuracy: 0.8399\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.4947 - accuracy: 0.8360 - val_loss: 0.4788 - val_accuracy: 0.8362\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.5262 - accuracy: 0.8330 - val_loss: 0.5107 - val_accuracy: 0.8467\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.6006 - accuracy: 0.8204 - val_loss: 0.6134 - val_accuracy: 0.8197\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.7284 - accuracy: 0.8021 - val_loss: 0.7248 - val_accuracy: 0.7868\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.9026 - accuracy: 0.7638 - val_loss: 1.2955 - val_accuracy: 0.6237\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 1.2320 - accuracy: 0.7138 - val_loss: 1.1582 - val_accuracy: 0.6043\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 1.5297 - accuracy: 0.6651 - val_loss: 1.2302 - val_accuracy: 0.5383\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 1.6826 - accuracy: 0.6201 - val_loss: 1.2919 - val_accuracy: 0.5378\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 2.1837 - accuracy: 0.5245 - val_loss: 1.3197 - val_accuracy: 0.5137\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 2.2937 - accuracy: 0.5323 - val_loss: 1.1075 - val_accuracy: 0.5707\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 2.7530 - accuracy: 0.4659 - val_loss: 2.1921 - val_accuracy: 0.4638\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 2.9997 - accuracy: 0.3934 - val_loss: 1.9617 - val_accuracy: 0.2894\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 8.3120 - accuracy: 0.3592 - val_loss: 1.9144 - val_accuracy: 0.3464\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 4.2035 - accuracy: 0.4138 - val_loss: 2.1277 - val_accuracy: 0.5063\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 4.1630 - accuracy: 0.4203 - val_loss: 2.8589 - val_accuracy: 0.3734\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 4.1696 - accuracy: 0.3793 - val_loss: 1.6020 - val_accuracy: 0.4415\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 6.5953 - accuracy: 0.3774 - val_loss: 2.3369 - val_accuracy: 0.3287\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 4.7090 - accuracy: 0.2607 - val_loss: 1.6733 - val_accuracy: 0.3869\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 5.5082 - accuracy: 0.2992 - val_loss: 2.0826 - val_accuracy: 0.1965\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 11.2319 - accuracy: 0.3177 - val_loss: 2.0533 - val_accuracy: 0.4206\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 10.8660 - accuracy: 0.3322 - val_loss: 1.7771 - val_accuracy: 0.3945\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 5.5022 - accuracy: 0.2601 - val_loss: 2.0970 - val_accuracy: 0.2310\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 11.0832 - accuracy: 0.3063 - val_loss: 2.3163 - val_accuracy: 0.2509\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 10.4308 - accuracy: 0.2751 - val_loss: 3.7740 - val_accuracy: 0.3078\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 7.6697 - accuracy: 0.2254 - val_loss: 9.8262 - val_accuracy: 0.2262\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 4.5461 - accuracy: 0.2265 - val_loss: 2.2578 - val_accuracy: 0.1275\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 26.4542 - accuracy: 0.2884 - val_loss: 1.6388 - val_accuracy: 0.3639\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 9.6168 - accuracy: 0.3476 - val_loss: 1.6677 - val_accuracy: 0.3490\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 12.9130 - accuracy: 0.3435 - val_loss: 1.7905 - val_accuracy: 0.3195\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 12.912992477416992\n",
      "Training Accuracy: 0.3434999883174896\n",
      "Validation Loss: 1.7905080318450928\n",
      "Validation Accuracy: 0.31949999928474426\n",
      "Classification Error Rate: 0.6805000007152557\n",
      "----->Evolution: Child net_9 with fitness 1.7905080318450928 replaces parent parent_0 with fitness 1.968990445137024\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 3\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Proportionate selection\n",
      "Selected net_3 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d09270500>, <__main__.Block object at 0x7c1d09d12080>, <__main__.Block object at 0x7c2225497f80>, <__main__.Block object at 0x7c22e4e6cc00>, <__main__.Block object at 0x7c1d09e97a80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 9s 5ms/step - loss: 0.5138 - accuracy: 0.8113 - val_loss: 0.3959 - val_accuracy: 0.8560\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3097 - accuracy: 0.8870 - val_loss: 0.2938 - val_accuracy: 0.8966\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2767 - accuracy: 0.8998 - val_loss: 0.2697 - val_accuracy: 0.9085\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2605 - accuracy: 0.9084 - val_loss: 0.2828 - val_accuracy: 0.9029\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2524 - accuracy: 0.9091 - val_loss: 0.2739 - val_accuracy: 0.9002\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2516 - accuracy: 0.9121 - val_loss: 0.2933 - val_accuracy: 0.9033\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2561 - accuracy: 0.9118 - val_loss: 0.3166 - val_accuracy: 0.9117\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2633 - accuracy: 0.9128 - val_loss: 0.3172 - val_accuracy: 0.8914\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2686 - accuracy: 0.9105 - val_loss: 0.3175 - val_accuracy: 0.9073\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2782 - accuracy: 0.9070 - val_loss: 0.6543 - val_accuracy: 0.8421\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2923 - accuracy: 0.9075 - val_loss: 0.3611 - val_accuracy: 0.8920\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3003 - accuracy: 0.9035 - val_loss: 0.4156 - val_accuracy: 0.8539\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3228 - accuracy: 0.9000 - val_loss: 0.4178 - val_accuracy: 0.8958\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3248 - accuracy: 0.9025 - val_loss: 0.4486 - val_accuracy: 0.8584\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3453 - accuracy: 0.8991 - val_loss: 0.4112 - val_accuracy: 0.8780\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3491 - accuracy: 0.8992 - val_loss: 0.3446 - val_accuracy: 0.9029\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3648 - accuracy: 0.8973 - val_loss: 0.4474 - val_accuracy: 0.8938\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3708 - accuracy: 0.8953 - val_loss: 0.3904 - val_accuracy: 0.8865\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3761 - accuracy: 0.8972 - val_loss: 0.5415 - val_accuracy: 0.8526\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4037 - accuracy: 0.8936 - val_loss: 0.4354 - val_accuracy: 0.8974\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4203 - accuracy: 0.8923 - val_loss: 0.3839 - val_accuracy: 0.8975\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4348 - accuracy: 0.8896 - val_loss: 0.7685 - val_accuracy: 0.8481\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4799 - accuracy: 0.8801 - val_loss: 0.4800 - val_accuracy: 0.8937\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5604 - accuracy: 0.8714 - val_loss: 0.4426 - val_accuracy: 0.8732\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5646 - accuracy: 0.8772 - val_loss: 0.8674 - val_accuracy: 0.8366\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5807 - accuracy: 0.8750 - val_loss: 0.6532 - val_accuracy: 0.8323\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6085 - accuracy: 0.8738 - val_loss: 0.4715 - val_accuracy: 0.8830\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.6625 - accuracy: 0.8651 - val_loss: 0.7855 - val_accuracy: 0.8651\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.7058 - accuracy: 0.8596 - val_loss: 1.7656 - val_accuracy: 0.8543\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.7552 - accuracy: 0.8599 - val_loss: 2.3011 - val_accuracy: 0.8205\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 0.7551587820053101\n",
      "Training Accuracy: 0.8599374890327454\n",
      "Validation Loss: 2.3011019229888916\n",
      "Validation Accuracy: 0.8205000162124634\n",
      "Classification Error Rate: 0.17949998378753662\n",
      "----->Evolution: Child net_6 with fitness 2.3011019229888916 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Proportionate selection\n",
      "Selected net_2 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d0990f240>, <__main__.Block object at 0x7c1d0971b840>, <__main__.Block object at 0x7c1d11754540>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 9s 5ms/step - loss: 0.5354 - accuracy: 0.8345 - val_loss: 0.3488 - val_accuracy: 0.8803\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3305 - accuracy: 0.8877 - val_loss: 0.3213 - val_accuracy: 0.8941\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3094 - accuracy: 0.9001 - val_loss: 0.3355 - val_accuracy: 0.8897\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3089 - accuracy: 0.9068 - val_loss: 0.3761 - val_accuracy: 0.8937\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3203 - accuracy: 0.9074 - val_loss: 0.4285 - val_accuracy: 0.8846\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3222 - accuracy: 0.9094 - val_loss: 0.4845 - val_accuracy: 0.8911\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3267 - accuracy: 0.9117 - val_loss: 0.4973 - val_accuracy: 0.8922\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3259 - accuracy: 0.9126 - val_loss: 0.4914 - val_accuracy: 0.8977\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3246 - accuracy: 0.9138 - val_loss: 0.5984 - val_accuracy: 0.8852\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3465 - accuracy: 0.9133 - val_loss: 0.7152 - val_accuracy: 0.8778\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3449 - accuracy: 0.9123 - val_loss: 0.5999 - val_accuracy: 0.8952\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3485 - accuracy: 0.9162 - val_loss: 0.7015 - val_accuracy: 0.8962\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3620 - accuracy: 0.9173 - val_loss: 0.6176 - val_accuracy: 0.8929\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3825 - accuracy: 0.9122 - val_loss: 0.7840 - val_accuracy: 0.8881\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3956 - accuracy: 0.9096 - val_loss: 0.7661 - val_accuracy: 0.8826\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4289 - accuracy: 0.9095 - val_loss: 0.7737 - val_accuracy: 0.8885\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4114 - accuracy: 0.9103 - val_loss: 0.7990 - val_accuracy: 0.8690\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4377 - accuracy: 0.9099 - val_loss: 1.0397 - val_accuracy: 0.8881\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4796 - accuracy: 0.9118 - val_loss: 1.2167 - val_accuracy: 0.8823\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4620 - accuracy: 0.9073 - val_loss: 1.1812 - val_accuracy: 0.8789\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4777 - accuracy: 0.9069 - val_loss: 0.8775 - val_accuracy: 0.8883\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4756 - accuracy: 0.9072 - val_loss: 1.3620 - val_accuracy: 0.8893\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4938 - accuracy: 0.9061 - val_loss: 1.1640 - val_accuracy: 0.8713\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4722 - accuracy: 0.9057 - val_loss: 1.2936 - val_accuracy: 0.8792\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5036 - accuracy: 0.9046 - val_loss: 1.3866 - val_accuracy: 0.8842\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5325 - accuracy: 0.9013 - val_loss: 1.0322 - val_accuracy: 0.8725\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5036 - accuracy: 0.9036 - val_loss: 1.3815 - val_accuracy: 0.8609\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5034 - accuracy: 0.9036 - val_loss: 1.3362 - val_accuracy: 0.8688\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5115 - accuracy: 0.9035 - val_loss: 1.7935 - val_accuracy: 0.8745\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5363 - accuracy: 0.8992 - val_loss: 1.1361 - val_accuracy: 0.8733\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 0.5362642407417297\n",
      "Training Accuracy: 0.8992291688919067\n",
      "Validation Loss: 1.1361205577850342\n",
      "Validation Accuracy: 0.8733000159263611\n",
      "Classification Error Rate: 0.12669998407363892\n",
      "----->Evolution: Child net_7 with fitness 1.1361205577850342 replaces parent parent_0 with fitness 1.7905080318450928\n",
      "\n",
      "Creating Child 2\n",
      "----->Proportionate selection\n",
      "Selected net_4 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d0907f980>, <__main__.Block object at 0x7c1d04f0fe00>, <__main__.Block object at 0x7c1d09eb7440>, <__main__.Block object at 0x7c1d0931da00>, <__main__.Block object at 0x7c1d0932ef80>, <__main__.Block object at 0x7c1d095e8d40>, <__main__.Block object at 0x7c1d09e20040>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_249\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_249/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_249/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,256], [3,3,256,64].\n",
      "\n",
      "Call arguments received by layer \"conv2d_249\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 256), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_96\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_96/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_96\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 2)]\n",
      "Creating a new block with two Convolutional layers and a Pooling layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d0e426c80>, <__main__.Block object at 0x7c1d0e426fc0>, <__main__.Block object at 0x7c1d0e40b840>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 11s 6ms/step - loss: 3.0109 - accuracy: 0.6597 - val_loss: 1.3448 - val_accuracy: 0.6099\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.9722 - accuracy: 0.5570 - val_loss: 1.9572 - val_accuracy: 0.4755\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.8304 - accuracy: 0.3895 - val_loss: 2.0059 - val_accuracy: 0.4187\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.4679 - accuracy: 0.4094 - val_loss: 3.6828 - val_accuracy: 0.3895\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.1316 - accuracy: 0.3471 - val_loss: 4.7888 - val_accuracy: 0.3646\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.8951 - accuracy: 0.3450 - val_loss: 5.2194 - val_accuracy: 0.3040\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.5015 - accuracy: 0.2690 - val_loss: 6.4756 - val_accuracy: 0.2189\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 3.5015 - accuracy: 0.2356 - val_loss: 6.2720 - val_accuracy: 0.2657\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 3.9183 - accuracy: 0.2576 - val_loss: 9.0616 - val_accuracy: 0.2871\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 3.7303 - accuracy: 0.2834 - val_loss: 5.9267 - val_accuracy: 0.2464\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 3.7993 - accuracy: 0.2828 - val_loss: 6.1742 - val_accuracy: 0.3400\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.1557 - accuracy: 0.3027 - val_loss: 8.2510 - val_accuracy: 0.3350\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.3690 - accuracy: 0.2694 - val_loss: 9.1434 - val_accuracy: 0.2294\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.0836 - accuracy: 0.2372 - val_loss: 10.5129 - val_accuracy: 0.2237\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.0519 - accuracy: 0.2568 - val_loss: 11.6296 - val_accuracy: 0.2450\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.0204 - accuracy: 0.2521 - val_loss: 12.9615 - val_accuracy: 0.2522\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.1431 - accuracy: 0.2467 - val_loss: 12.2558 - val_accuracy: 0.2493\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.8905 - accuracy: 0.2595 - val_loss: 12.7012 - val_accuracy: 0.2657\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.0961 - accuracy: 0.2975 - val_loss: 15.1157 - val_accuracy: 0.3178\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.4377 - accuracy: 0.2896 - val_loss: 25.9217 - val_accuracy: 0.2447\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.9720 - accuracy: 0.2697 - val_loss: 23.9656 - val_accuracy: 0.2806\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.1918 - accuracy: 0.2898 - val_loss: 22.5283 - val_accuracy: 0.3174\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.3294 - accuracy: 0.2788 - val_loss: 16.8081 - val_accuracy: 0.2643\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.2466 - accuracy: 0.2788 - val_loss: 24.4294 - val_accuracy: 0.2824\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.9139 - accuracy: 0.2768 - val_loss: 20.5407 - val_accuracy: 0.2536\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.9183 - accuracy: 0.2560 - val_loss: 19.7627 - val_accuracy: 0.2552\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.0324 - accuracy: 0.2588 - val_loss: 15.2594 - val_accuracy: 0.2691\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.1043 - accuracy: 0.2875 - val_loss: 16.6230 - val_accuracy: 0.2470\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.0327 - accuracy: 0.2534 - val_loss: 13.6890 - val_accuracy: 0.2486\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.6505 - accuracy: 0.2583 - val_loss: 13.3972 - val_accuracy: 0.2476\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 2.650500535964966\n",
      "Training Accuracy: 0.25829166173934937\n",
      "Validation Loss: 13.397186279296875\n",
      "Validation Accuracy: 0.2476000040769577\n",
      "Classification Error Rate: 0.7523999959230423\n",
      "----->Evolution: Child net_8 with fitness 13.397186279296875 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Proportionate selection\n",
      "Selected net_4 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  512\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d03707240>, <__main__.Block object at 0x7c1d00bebb80>, <__main__.Block object at 0x7c1d0ddcfe00>, <__main__.Block object at 0x7c1d0e40b180>, <__main__.Block object at 0x7c1d0376eb00>, <__main__.Block object at 0x7c1d0378e240>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 21s 12ms/step - loss: 1.0506 - accuracy: 0.7645 - val_loss: 0.4612 - val_accuracy: 0.8460\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 0.4684 - accuracy: 0.8376 - val_loss: 0.6021 - val_accuracy: 0.8289\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 0.4973 - accuracy: 0.8433 - val_loss: 0.5115 - val_accuracy: 0.8387\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 0.4941 - accuracy: 0.8403 - val_loss: 0.4687 - val_accuracy: 0.8423\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 0.5014 - accuracy: 0.8419 - val_loss: 0.4753 - val_accuracy: 0.8374\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 0.5204 - accuracy: 0.8443 - val_loss: 0.5801 - val_accuracy: 0.8353\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 0.6380 - accuracy: 0.8280 - val_loss: 0.4114 - val_accuracy: 0.8593\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 0.5851 - accuracy: 0.8344 - val_loss: 0.5771 - val_accuracy: 0.8411\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 0.6376 - accuracy: 0.8230 - val_loss: 0.8959 - val_accuracy: 0.8240\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 1.1594 - accuracy: 0.7732 - val_loss: 0.6306 - val_accuracy: 0.7653\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 1.0542 - accuracy: 0.7401 - val_loss: 0.8284 - val_accuracy: 0.6608\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 1.6796 - accuracy: 0.5531 - val_loss: 1.7937 - val_accuracy: 0.3721\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 4.1642 - accuracy: 0.1370 - val_loss: 2.3065 - val_accuracy: 0.0990\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 2.3043 - accuracy: 0.0979 - val_loss: 2.3029 - val_accuracy: 0.0990\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 2.3028 - accuracy: 0.0978 - val_loss: 2.3029 - val_accuracy: 0.0991\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 2.3028 - accuracy: 0.0996 - val_loss: 2.3027 - val_accuracy: 0.0971\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 2.3028 - accuracy: 0.0998 - val_loss: 2.3028 - val_accuracy: 0.0988\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 2.3028 - accuracy: 0.0990 - val_loss: 2.3028 - val_accuracy: 0.0971\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 2.3028 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.0998\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.0990\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 2.3028 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.0971\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 2.3028 - accuracy: 0.1002 - val_loss: 2.3027 - val_accuracy: 0.0990\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 2.3028 - accuracy: 0.0977 - val_loss: 2.3027 - val_accuracy: 0.0991\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 2.3028 - accuracy: 0.0979 - val_loss: 2.3027 - val_accuracy: 0.0971\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 2.3028 - accuracy: 0.0984 - val_loss: 2.3027 - val_accuracy: 0.0971\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 2.3028 - accuracy: 0.1005 - val_loss: 2.3026 - val_accuracy: 0.0991\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 2.3028 - accuracy: 0.0997 - val_loss: 2.3028 - val_accuracy: 0.0991\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 2.3028 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.0991\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 2.3028 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.0991\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 17s 11ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3027 - val_accuracy: 0.0998\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 2.3027095794677734\n",
      "Training Accuracy: 0.0988750010728836\n",
      "Validation Loss: 2.3027405738830566\n",
      "Validation Accuracy: 0.0997999981045723\n",
      "Classification Error Rate: 0.9002000018954277\n",
      "----->Evolution: Child net_9 with fitness 2.3027405738830566 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 4\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Proportionate selection\n",
      "Selected parent_0 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d0111f240>, <__main__.Block object at 0x7c1d00f43840>, <__main__.Block object at 0x7c1d00c33180>, <__main__.Block object at 0x7c1d01165940>, <__main__.Block object at 0x7c1d01247f80>, <__main__.Block object at 0x7c1d00ead2c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_269\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_269/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_269/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,64], [3,3,64,512].\n",
      "\n",
      "Call arguments received by layer \"conv2d_269\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 64), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_270. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 14s 8ms/step - loss: 0.6150 - accuracy: 0.7950 - val_loss: 0.4597 - val_accuracy: 0.8432\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.3921 - accuracy: 0.8600 - val_loss: 0.4026 - val_accuracy: 0.8613\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.3844 - accuracy: 0.8661 - val_loss: 0.3493 - val_accuracy: 0.8792\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.3967 - accuracy: 0.8650 - val_loss: 0.3867 - val_accuracy: 0.8639\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.4144 - accuracy: 0.8598 - val_loss: 0.4464 - val_accuracy: 0.8322\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.4274 - accuracy: 0.8609 - val_loss: 0.4950 - val_accuracy: 0.8293\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.4522 - accuracy: 0.8599 - val_loss: 0.5322 - val_accuracy: 0.8566\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.4729 - accuracy: 0.8554 - val_loss: 0.4712 - val_accuracy: 0.8464\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.4965 - accuracy: 0.8522 - val_loss: 0.4549 - val_accuracy: 0.8463\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.5396 - accuracy: 0.8457 - val_loss: 0.5656 - val_accuracy: 0.8281\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.5927 - accuracy: 0.8365 - val_loss: 0.5343 - val_accuracy: 0.8253\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.6532 - accuracy: 0.8276 - val_loss: 0.6220 - val_accuracy: 0.8591\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.7033 - accuracy: 0.8311 - val_loss: 0.7626 - val_accuracy: 0.8438\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.7458 - accuracy: 0.8259 - val_loss: 0.5499 - val_accuracy: 0.8515\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.7730 - accuracy: 0.8095 - val_loss: 0.7223 - val_accuracy: 0.7968\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.8422 - accuracy: 0.8081 - val_loss: 0.7376 - val_accuracy: 0.8391\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.8816 - accuracy: 0.8085 - val_loss: 0.9041 - val_accuracy: 0.8456\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 0.8700 - accuracy: 0.7994 - val_loss: 0.7687 - val_accuracy: 0.8128\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.9442 - accuracy: 0.7815 - val_loss: 0.8195 - val_accuracy: 0.7999\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 1.1299 - accuracy: 0.7542 - val_loss: 0.8451 - val_accuracy: 0.7842\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 1.2157 - accuracy: 0.7304 - val_loss: 0.9832 - val_accuracy: 0.7357\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 1.1706 - accuracy: 0.7487 - val_loss: 0.7630 - val_accuracy: 0.7764\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 1.0923 - accuracy: 0.7496 - val_loss: 1.2860 - val_accuracy: 0.6992\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 1.2443 - accuracy: 0.7372 - val_loss: 1.0403 - val_accuracy: 0.7621\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 1.3615 - accuracy: 0.7224 - val_loss: 1.6614 - val_accuracy: 0.7450\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 1.3727 - accuracy: 0.7106 - val_loss: 1.3127 - val_accuracy: 0.6616\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 1.5823 - accuracy: 0.7047 - val_loss: 1.0349 - val_accuracy: 0.7302\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 11s 7ms/step - loss: 1.7949 - accuracy: 0.6586 - val_loss: 1.2645 - val_accuracy: 0.6936\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.0193 - accuracy: 0.6268 - val_loss: 1.1352 - val_accuracy: 0.5882\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.0149 - accuracy: 0.5792 - val_loss: 2.3474 - val_accuracy: 0.5582\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 2.014909505844116\n",
      "Training Accuracy: 0.5791875123977661\n",
      "Validation Loss: 2.347379684448242\n",
      "Validation Accuracy: 0.5582000017166138\n",
      "Classification Error Rate: 0.44179999828338623\n",
      "----->Evolution: Child net_6 with fitness 2.347379684448242 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Proportionate selection\n",
      "Selected net_1 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d1237d4c0>, <__main__.Block object at 0x7c1cfebf3b80>, <__main__.Block object at 0x7c1d0d7f4b80>, <__main__.Block object at 0x7c1cfeb0d940>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 9s 5ms/step - loss: 0.4529 - accuracy: 0.8425 - val_loss: 0.3954 - val_accuracy: 0.8617\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3083 - accuracy: 0.8904 - val_loss: 0.3549 - val_accuracy: 0.8820\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2903 - accuracy: 0.8978 - val_loss: 0.2841 - val_accuracy: 0.9012\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2865 - accuracy: 0.9027 - val_loss: 0.3367 - val_accuracy: 0.8918\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3004 - accuracy: 0.8979 - val_loss: 0.3825 - val_accuracy: 0.8702\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3103 - accuracy: 0.8970 - val_loss: 0.3009 - val_accuracy: 0.8986\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3349 - accuracy: 0.8902 - val_loss: 0.3692 - val_accuracy: 0.8755\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3508 - accuracy: 0.8869 - val_loss: 0.3489 - val_accuracy: 0.8891\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3682 - accuracy: 0.8840 - val_loss: 0.4247 - val_accuracy: 0.8633\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3893 - accuracy: 0.8806 - val_loss: 0.4402 - val_accuracy: 0.8600\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4082 - accuracy: 0.8768 - val_loss: 0.4023 - val_accuracy: 0.8885\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4160 - accuracy: 0.8742 - val_loss: 0.3892 - val_accuracy: 0.8585\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4440 - accuracy: 0.8693 - val_loss: 0.6544 - val_accuracy: 0.8378\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4458 - accuracy: 0.8675 - val_loss: 0.4065 - val_accuracy: 0.8701\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4479 - accuracy: 0.8665 - val_loss: 0.4697 - val_accuracy: 0.8341\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4584 - accuracy: 0.8635 - val_loss: 0.4687 - val_accuracy: 0.8477\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4789 - accuracy: 0.8647 - val_loss: 0.5336 - val_accuracy: 0.8336\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4823 - accuracy: 0.8626 - val_loss: 0.3904 - val_accuracy: 0.8667\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4827 - accuracy: 0.8616 - val_loss: 0.5647 - val_accuracy: 0.8664\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5343 - accuracy: 0.8597 - val_loss: 0.4860 - val_accuracy: 0.8639\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5323 - accuracy: 0.8596 - val_loss: 0.4161 - val_accuracy: 0.8656\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5104 - accuracy: 0.8562 - val_loss: 0.5130 - val_accuracy: 0.8340\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5105 - accuracy: 0.8569 - val_loss: 2.6586 - val_accuracy: 0.7518\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5324 - accuracy: 0.8547 - val_loss: 0.4221 - val_accuracy: 0.8611\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5404 - accuracy: 0.8572 - val_loss: 0.5716 - val_accuracy: 0.8416\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5509 - accuracy: 0.8512 - val_loss: 0.6099 - val_accuracy: 0.8702\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5427 - accuracy: 0.8552 - val_loss: 0.5343 - val_accuracy: 0.8515\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5908 - accuracy: 0.8472 - val_loss: 0.5083 - val_accuracy: 0.8474\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5945 - accuracy: 0.8459 - val_loss: 0.5018 - val_accuracy: 0.8492\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.6101 - accuracy: 0.8390 - val_loss: 0.5255 - val_accuracy: 0.8533\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 0.610068142414093\n",
      "Training Accuracy: 0.838979184627533\n",
      "Validation Loss: 0.5254846215248108\n",
      "Validation Accuracy: 0.8532999753952026\n",
      "Classification Error Rate: 0.14670002460479736\n",
      "----->Evolution: Child net_7 with fitness 0.5254846215248108 replaces parent net_3 with fitness 1.7603943347930908\n",
      "\n",
      "Creating Child 2\n",
      "----->Proportionate selection\n",
      "Selected net_1 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d0ef09b00>, <__main__.Block object at 0x7c1d0d92e340>, <__main__.Block object at 0x7c1d0d9ac7c0>, <__main__.Block object at 0x7c1d0f06dcc0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.6862 - accuracy: 0.7710 - val_loss: 0.5373 - val_accuracy: 0.8147\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4398 - accuracy: 0.8460 - val_loss: 0.5234 - val_accuracy: 0.8345\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4252 - accuracy: 0.8547 - val_loss: 0.4632 - val_accuracy: 0.8648\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4380 - accuracy: 0.8539 - val_loss: 1.0499 - val_accuracy: 0.7070\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4688 - accuracy: 0.8486 - val_loss: 0.4229 - val_accuracy: 0.8568\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4809 - accuracy: 0.8489 - val_loss: 0.5469 - val_accuracy: 0.8426\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4860 - accuracy: 0.8518 - val_loss: 0.4811 - val_accuracy: 0.8467\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5042 - accuracy: 0.8457 - val_loss: 0.7560 - val_accuracy: 0.8019\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5716 - accuracy: 0.8410 - val_loss: 0.5649 - val_accuracy: 0.8573\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6323 - accuracy: 0.8396 - val_loss: 1.1045 - val_accuracy: 0.8233\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6949 - accuracy: 0.8293 - val_loss: 0.7513 - val_accuracy: 0.8501\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.7262 - accuracy: 0.8195 - val_loss: 1.5161 - val_accuracy: 0.7780\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.7857 - accuracy: 0.8084 - val_loss: 0.8911 - val_accuracy: 0.7600\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.1361 - accuracy: 0.7817 - val_loss: 0.8616 - val_accuracy: 0.6922\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.1276 - accuracy: 0.7629 - val_loss: 0.6832 - val_accuracy: 0.7779\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.2564 - accuracy: 0.7398 - val_loss: 0.7727 - val_accuracy: 0.7594\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.4608 - accuracy: 0.7045 - val_loss: 0.9170 - val_accuracy: 0.7066\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.1704 - accuracy: 0.5729 - val_loss: 1.5133 - val_accuracy: 0.4350\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 2.7365 - accuracy: 0.4869 - val_loss: 1.8461 - val_accuracy: 0.5031\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 3.0233 - accuracy: 0.3549 - val_loss: 1.9815 - val_accuracy: 0.2553\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 7.4788 - accuracy: 0.2735 - val_loss: 2.1090 - val_accuracy: 0.2036\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 5.3604 - accuracy: 0.1812 - val_loss: 2.3267 - val_accuracy: 0.0991\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3087 - accuracy: 0.0985 - val_loss: 2.3032 - val_accuracy: 0.0990\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0994 - val_loss: 2.3026 - val_accuracy: 0.0988\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0970 - val_loss: 2.3027 - val_accuracy: 0.0991\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3029 - val_accuracy: 0.0990\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0994 - val_loss: 2.3028 - val_accuracy: 0.0991\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 2.3028 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.0988\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0964 - val_loss: 2.3028 - val_accuracy: 0.0991\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3027 - val_accuracy: 0.0991\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 2.3027756214141846\n",
      "Training Accuracy: 0.09822916984558105\n",
      "Validation Loss: 2.3026797771453857\n",
      "Validation Accuracy: 0.09910000115633011\n",
      "Classification Error Rate: 0.9008999988436699\n",
      "----->Evolution: Child net_8 with fitness 2.3026797771453857 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Proportionate selection\n",
      "Selected net_2 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d11d73180>, <__main__.Block object at 0x7c1d06b83b80>, <__main__.Block object at 0x7c1d06805ac0>, <__main__.Block object at 0x7c1d06aac940>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 8s 4ms/step - loss: 0.6145 - accuracy: 0.7760 - val_loss: 0.4664 - val_accuracy: 0.8245\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4377 - accuracy: 0.8385 - val_loss: 0.3967 - val_accuracy: 0.8594\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3868 - accuracy: 0.8582 - val_loss: 0.4499 - val_accuracy: 0.8392\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3690 - accuracy: 0.8650 - val_loss: 0.3773 - val_accuracy: 0.8716\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3697 - accuracy: 0.8671 - val_loss: 0.4519 - val_accuracy: 0.8384\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3939 - accuracy: 0.8594 - val_loss: 0.5319 - val_accuracy: 0.8510\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4431 - accuracy: 0.8509 - val_loss: 0.4750 - val_accuracy: 0.8330\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4824 - accuracy: 0.8390 - val_loss: 0.5998 - val_accuracy: 0.8043\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4979 - accuracy: 0.8353 - val_loss: 0.4978 - val_accuracy: 0.8437\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5196 - accuracy: 0.8335 - val_loss: 0.5015 - val_accuracy: 0.8253\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5435 - accuracy: 0.8294 - val_loss: 0.6039 - val_accuracy: 0.8084\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5866 - accuracy: 0.8175 - val_loss: 0.6197 - val_accuracy: 0.8110\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6032 - accuracy: 0.8124 - val_loss: 0.5461 - val_accuracy: 0.8277\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6287 - accuracy: 0.8101 - val_loss: 0.5460 - val_accuracy: 0.8289\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6444 - accuracy: 0.8078 - val_loss: 0.5207 - val_accuracy: 0.8230\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.6507 - accuracy: 0.8066 - val_loss: 0.6333 - val_accuracy: 0.8013\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6606 - accuracy: 0.8091 - val_loss: 0.6168 - val_accuracy: 0.8236\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6886 - accuracy: 0.8043 - val_loss: 0.5698 - val_accuracy: 0.8228\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6987 - accuracy: 0.8041 - val_loss: 0.8487 - val_accuracy: 0.7562\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6940 - accuracy: 0.8020 - val_loss: 0.5557 - val_accuracy: 0.8160\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.7797 - accuracy: 0.7970 - val_loss: 3.4833 - val_accuracy: 0.7175\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.8204 - accuracy: 0.7921 - val_loss: 1.2320 - val_accuracy: 0.7556\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.8692 - accuracy: 0.7859 - val_loss: 0.7801 - val_accuracy: 0.7550\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.8552 - accuracy: 0.7810 - val_loss: 0.8060 - val_accuracy: 0.7617\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.8919 - accuracy: 0.7809 - val_loss: 0.6675 - val_accuracy: 0.7797\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.9544 - accuracy: 0.7747 - val_loss: 0.7866 - val_accuracy: 0.7618\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 1.0824 - accuracy: 0.7745 - val_loss: 0.6699 - val_accuracy: 0.7578\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 1.0086 - accuracy: 0.7664 - val_loss: 0.7343 - val_accuracy: 0.7966\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.9939 - accuracy: 0.7704 - val_loss: 0.7988 - val_accuracy: 0.8117\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 1.0474 - accuracy: 0.7661 - val_loss: 0.8292 - val_accuracy: 0.7914\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 1.047417402267456\n",
      "Training Accuracy: 0.7661041617393494\n",
      "Validation Loss: 0.8292027115821838\n",
      "Validation Accuracy: 0.7914000153541565\n",
      "Classification Error Rate: 0.2085999846458435\n",
      "----->Evolution: Child net_9 with fitness 0.8292027115821838 replaces parent net_5 with fitness 1.7541035413742065\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 5\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_3 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d0ec9b800>, <__main__.Block object at 0x7c1d01b6a080>, <__main__.Block object at 0x7c1d0ec8dcc0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 11s 6ms/step - loss: 0.8494 - accuracy: 0.8120 - val_loss: 0.5882 - val_accuracy: 0.8380\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3926 - accuracy: 0.8745 - val_loss: 0.3777 - val_accuracy: 0.8880\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3886 - accuracy: 0.8832 - val_loss: 0.4029 - val_accuracy: 0.8872\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3802 - accuracy: 0.8895 - val_loss: 0.3850 - val_accuracy: 0.8849\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3937 - accuracy: 0.8879 - val_loss: 0.4253 - val_accuracy: 0.8769\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.4134 - accuracy: 0.8892 - val_loss: 0.6228 - val_accuracy: 0.8828\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4134 - accuracy: 0.8879 - val_loss: 0.5404 - val_accuracy: 0.8457\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4795 - accuracy: 0.8838 - val_loss: 0.6103 - val_accuracy: 0.8603\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4618 - accuracy: 0.8866 - val_loss: 0.6923 - val_accuracy: 0.8781\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4535 - accuracy: 0.8846 - val_loss: 0.6288 - val_accuracy: 0.8635\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5408 - accuracy: 0.8784 - val_loss: 0.8506 - val_accuracy: 0.8461\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.6328 - accuracy: 0.8631 - val_loss: 0.7249 - val_accuracy: 0.8642\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.6322 - accuracy: 0.8514 - val_loss: 0.7143 - val_accuracy: 0.8573\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.7791 - accuracy: 0.8359 - val_loss: 0.8711 - val_accuracy: 0.7655\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.8417 - accuracy: 0.8277 - val_loss: 0.7206 - val_accuracy: 0.8187\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.8823 - accuracy: 0.8126 - val_loss: 2.5011 - val_accuracy: 0.8607\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.2004 - accuracy: 0.7530 - val_loss: 1.4249 - val_accuracy: 0.6971\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.2098 - accuracy: 0.7832 - val_loss: 2.1408 - val_accuracy: 0.7513\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.1504 - accuracy: 0.7708 - val_loss: 1.2265 - val_accuracy: 0.7772\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.2717 - accuracy: 0.7139 - val_loss: 2.1933 - val_accuracy: 0.6901\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.2130 - accuracy: 0.7030 - val_loss: 1.4452 - val_accuracy: 0.7399\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.6529 - accuracy: 0.6918 - val_loss: 1.1629 - val_accuracy: 0.6331\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.6697 - accuracy: 0.5975 - val_loss: 3.3168 - val_accuracy: 0.6180\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.3372 - accuracy: 0.5728 - val_loss: 1.8856 - val_accuracy: 0.5620\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.0027 - accuracy: 0.5533 - val_loss: 2.1467 - val_accuracy: 0.4419\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.7555 - accuracy: 0.4296 - val_loss: 1.9991 - val_accuracy: 0.3400\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 4.0177 - accuracy: 0.4232 - val_loss: 1.6843 - val_accuracy: 0.4178\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.1448 - accuracy: 0.3297 - val_loss: 1.8478 - val_accuracy: 0.3054\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 2.8632 - accuracy: 0.4152 - val_loss: 2.4087 - val_accuracy: 0.3426\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 3.3915 - accuracy: 0.3815 - val_loss: 1.8438 - val_accuracy: 0.3188\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 3.3914856910705566\n",
      "Training Accuracy: 0.3814791738986969\n",
      "Validation Loss: 1.8437882661819458\n",
      "Validation Accuracy: 0.3188000023365021\n",
      "Classification Error Rate: 0.6811999976634979\n",
      "----->Evolution: Child net_6 with fitness 1.8437882661819458 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_3 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  512  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d01ecddc0>, <__main__.Block object at 0x7c1d01dabb80>, <__main__.Block object at 0x7c1d043d2480>, <__main__.Block object at 0x7c1d04368880>, <__main__.Block object at 0x7c1d13d1ce80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_291. Consider increasing the input size. Received input shape [None, 1, 1, 64] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_120\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_120/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_120\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 2)]\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d041f3f40>, <__main__.Block object at 0x7c1d04229300>, <__main__.Block object at 0x7c1d04229480>, <__main__.Block object at 0x7c1d04228940>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 8s 4ms/step - loss: 0.4773 - accuracy: 0.8278 - val_loss: 0.3880 - val_accuracy: 0.8579\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3162 - accuracy: 0.8853 - val_loss: 0.3257 - val_accuracy: 0.8830\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2875 - accuracy: 0.8963 - val_loss: 0.3486 - val_accuracy: 0.8757\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2812 - accuracy: 0.9006 - val_loss: 0.3424 - val_accuracy: 0.8788\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2958 - accuracy: 0.8968 - val_loss: 0.3620 - val_accuracy: 0.8781\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3189 - accuracy: 0.8939 - val_loss: 0.3926 - val_accuracy: 0.8729\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3578 - accuracy: 0.8847 - val_loss: 0.4341 - val_accuracy: 0.8778\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3920 - accuracy: 0.8746 - val_loss: 0.4419 - val_accuracy: 0.8696\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4073 - accuracy: 0.8703 - val_loss: 0.6852 - val_accuracy: 0.8535\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4172 - accuracy: 0.8660 - val_loss: 0.4058 - val_accuracy: 0.8682\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4335 - accuracy: 0.8635 - val_loss: 0.4283 - val_accuracy: 0.8641\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4445 - accuracy: 0.8610 - val_loss: 0.4737 - val_accuracy: 0.8696\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4673 - accuracy: 0.8561 - val_loss: 0.4840 - val_accuracy: 0.8431\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4934 - accuracy: 0.8507 - val_loss: 0.5141 - val_accuracy: 0.8451\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5004 - accuracy: 0.8486 - val_loss: 0.5413 - val_accuracy: 0.8588\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5164 - accuracy: 0.8445 - val_loss: 0.4976 - val_accuracy: 0.8582\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5304 - accuracy: 0.8442 - val_loss: 0.5445 - val_accuracy: 0.8286\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5370 - accuracy: 0.8415 - val_loss: 0.6249 - val_accuracy: 0.8144\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5492 - accuracy: 0.8421 - val_loss: 0.5612 - val_accuracy: 0.8477\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5547 - accuracy: 0.8403 - val_loss: 0.5100 - val_accuracy: 0.8525\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5540 - accuracy: 0.8392 - val_loss: 0.4653 - val_accuracy: 0.8454\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5745 - accuracy: 0.8363 - val_loss: 0.4879 - val_accuracy: 0.8397\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5901 - accuracy: 0.8339 - val_loss: 0.5361 - val_accuracy: 0.8398\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6260 - accuracy: 0.8316 - val_loss: 0.5814 - val_accuracy: 0.8346\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6056 - accuracy: 0.8318 - val_loss: 0.5272 - val_accuracy: 0.8348\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6477 - accuracy: 0.8278 - val_loss: 7.3483 - val_accuracy: 0.7248\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.6600 - accuracy: 0.8258 - val_loss: 0.7455 - val_accuracy: 0.8245\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.6303 - accuracy: 0.8245 - val_loss: 0.5147 - val_accuracy: 0.8418\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6650 - accuracy: 0.8276 - val_loss: 0.9579 - val_accuracy: 0.8102\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6981 - accuracy: 0.8208 - val_loss: 0.6253 - val_accuracy: 0.8194\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 0.6981067657470703\n",
      "Training Accuracy: 0.8207916617393494\n",
      "Validation Loss: 0.6252947449684143\n",
      "Validation Accuracy: 0.8194000124931335\n",
      "Classification Error Rate: 0.18059998750686646\n",
      "----->Evolution: Child net_7 with fitness 0.6252947449684143 replaces parent net_1 with fitness 1.7427148818969727\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_3 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  128.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c21ec374c00>, <__main__.Block object at 0x7c1d0a690940>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4439 - accuracy: 0.8478 - val_loss: 0.3176 - val_accuracy: 0.8903\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2686 - accuracy: 0.9060 - val_loss: 0.2909 - val_accuracy: 0.8974\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2191 - accuracy: 0.9213 - val_loss: 0.3118 - val_accuracy: 0.8903\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1822 - accuracy: 0.9357 - val_loss: 0.3464 - val_accuracy: 0.9076\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1576 - accuracy: 0.9449 - val_loss: 0.4250 - val_accuracy: 0.9031\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1362 - accuracy: 0.9542 - val_loss: 0.3981 - val_accuracy: 0.9093\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1216 - accuracy: 0.9593 - val_loss: 0.4399 - val_accuracy: 0.8993\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1043 - accuracy: 0.9651 - val_loss: 0.4434 - val_accuracy: 0.9077\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0941 - accuracy: 0.9695 - val_loss: 0.5537 - val_accuracy: 0.9110\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0869 - accuracy: 0.9729 - val_loss: 0.5777 - val_accuracy: 0.8982\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0731 - accuracy: 0.9776 - val_loss: 0.6271 - val_accuracy: 0.9116\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0709 - accuracy: 0.9781 - val_loss: 0.6011 - val_accuracy: 0.9070\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0601 - accuracy: 0.9823 - val_loss: 0.6655 - val_accuracy: 0.9112\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0566 - accuracy: 0.9836 - val_loss: 1.0806 - val_accuracy: 0.9072\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0540 - accuracy: 0.9850 - val_loss: 0.8620 - val_accuracy: 0.9057\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0530 - accuracy: 0.9857 - val_loss: 0.7868 - val_accuracy: 0.9091\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0435 - accuracy: 0.9875 - val_loss: 0.9359 - val_accuracy: 0.9103\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0421 - accuracy: 0.9891 - val_loss: 0.9547 - val_accuracy: 0.9095\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0369 - accuracy: 0.9899 - val_loss: 1.0211 - val_accuracy: 0.9123\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0359 - accuracy: 0.9904 - val_loss: 1.1440 - val_accuracy: 0.9126\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0328 - accuracy: 0.9914 - val_loss: 1.1612 - val_accuracy: 0.9085\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0326 - accuracy: 0.9915 - val_loss: 1.3638 - val_accuracy: 0.9127\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0359 - accuracy: 0.9912 - val_loss: 1.2818 - val_accuracy: 0.9090\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0317 - accuracy: 0.9929 - val_loss: 1.2637 - val_accuracy: 0.9174\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0253 - accuracy: 0.9935 - val_loss: 1.3502 - val_accuracy: 0.9142\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0274 - accuracy: 0.9937 - val_loss: 1.3833 - val_accuracy: 0.9123\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0317 - accuracy: 0.9931 - val_loss: 1.5672 - val_accuracy: 0.9149\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0274 - accuracy: 0.9945 - val_loss: 1.3631 - val_accuracy: 0.9081\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0250 - accuracy: 0.9944 - val_loss: 1.7397 - val_accuracy: 0.9102\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0269 - accuracy: 0.9939 - val_loss: 1.7379 - val_accuracy: 0.9161\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 0.02693840116262436\n",
      "Training Accuracy: 0.9939166903495789\n",
      "Validation Loss: 1.7378511428833008\n",
      "Validation Accuracy: 0.916100025177002\n",
      "Classification Error Rate: 0.08389997482299805\n",
      "----->Evolution: Child net_8 with fitness 1.7378511428833008 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_3 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  512\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d01667240>, <__main__.Block object at 0x7c1d0149bb80>, <__main__.Block object at 0x7c1d015ca080>, <__main__.Block object at 0x7c1d01c25dc0>, <__main__.Block object at 0x7c1d1078cb80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 9s 5ms/step - loss: 0.5555 - accuracy: 0.8038 - val_loss: 0.3878 - val_accuracy: 0.8655\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3858 - accuracy: 0.8652 - val_loss: 0.4329 - val_accuracy: 0.8369\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3702 - accuracy: 0.8714 - val_loss: 0.3886 - val_accuracy: 0.8603\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3771 - accuracy: 0.8742 - val_loss: 0.3816 - val_accuracy: 0.8681\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3828 - accuracy: 0.8747 - val_loss: 0.4526 - val_accuracy: 0.8742\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3921 - accuracy: 0.8750 - val_loss: 0.7054 - val_accuracy: 0.8756\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4069 - accuracy: 0.8751 - val_loss: 0.4706 - val_accuracy: 0.8475\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4251 - accuracy: 0.8705 - val_loss: 0.4838 - val_accuracy: 0.8593\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4678 - accuracy: 0.8600 - val_loss: 0.4087 - val_accuracy: 0.8738\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4966 - accuracy: 0.8521 - val_loss: 0.5214 - val_accuracy: 0.8568\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5770 - accuracy: 0.8444 - val_loss: 0.5026 - val_accuracy: 0.8670\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.6107 - accuracy: 0.8415 - val_loss: 0.6939 - val_accuracy: 0.8509\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.7599 - accuracy: 0.8192 - val_loss: 0.5959 - val_accuracy: 0.8219\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.8387 - accuracy: 0.8119 - val_loss: 0.5875 - val_accuracy: 0.8366\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.8393 - accuracy: 0.7974 - val_loss: 0.6851 - val_accuracy: 0.8067\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.9096 - accuracy: 0.7954 - val_loss: 0.9416 - val_accuracy: 0.8229\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 1.1160 - accuracy: 0.7576 - val_loss: 0.7966 - val_accuracy: 0.7618\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 1.1920 - accuracy: 0.7473 - val_loss: 1.4310 - val_accuracy: 0.6539\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 1.2953 - accuracy: 0.7282 - val_loss: 1.1241 - val_accuracy: 0.6997\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 1.6656 - accuracy: 0.7185 - val_loss: 1.2708 - val_accuracy: 0.7173\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 1.9227 - accuracy: 0.6411 - val_loss: 1.6244 - val_accuracy: 0.5004\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 2.1324 - accuracy: 0.6283 - val_loss: 2.7767 - val_accuracy: 0.7689\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 2.0548 - accuracy: 0.6564 - val_loss: 1.9346 - val_accuracy: 0.6885\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 2.0478 - accuracy: 0.6496 - val_loss: 1.1061 - val_accuracy: 0.6594\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.6558 - accuracy: 0.6181 - val_loss: 1.3024 - val_accuracy: 0.5201\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.3678 - accuracy: 0.5921 - val_loss: 35.1565 - val_accuracy: 0.4655\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 3.1919 - accuracy: 0.5769 - val_loss: 2.9891 - val_accuracy: 0.6513\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 2.4518 - accuracy: 0.6087 - val_loss: 1.3928 - val_accuracy: 0.6161\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 2.4910 - accuracy: 0.5837 - val_loss: 2.0894 - val_accuracy: 0.5421\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 2.9235 - accuracy: 0.5640 - val_loss: 1.4162 - val_accuracy: 0.5982\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 2.923454999923706\n",
      "Training Accuracy: 0.5639583468437195\n",
      "Validation Loss: 1.416217565536499\n",
      "Validation Accuracy: 0.5982000231742859\n",
      "Classification Error Rate: 0.4017999768257141\n",
      "----->Evolution: Child net_9 with fitness 1.416217565536499 replaces parent net_4 with fitness 1.519719123840332\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 6\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_3 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cc0d33040>, <__main__.Block object at 0x7c1cfe60c540>, <__main__.Block object at 0x7c1cc0d27dc0>, <__main__.Block object at 0x7c1cf72e0d80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 13s 7ms/step - loss: 0.6962 - accuracy: 0.7719 - val_loss: 0.6046 - val_accuracy: 0.8233\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.5519 - accuracy: 0.8171 - val_loss: 0.6516 - val_accuracy: 0.7712\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.5702 - accuracy: 0.8240 - val_loss: 0.5106 - val_accuracy: 0.8217\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.5840 - accuracy: 0.8320 - val_loss: 0.6181 - val_accuracy: 0.8082\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.5757 - accuracy: 0.8322 - val_loss: 0.6244 - val_accuracy: 0.8275\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.6673 - accuracy: 0.8187 - val_loss: 1.0337 - val_accuracy: 0.7346\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.7213 - accuracy: 0.8144 - val_loss: 0.9031 - val_accuracy: 0.7976\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.9242 - accuracy: 0.7857 - val_loss: 1.2275 - val_accuracy: 0.7805\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 1.3079 - accuracy: 0.7391 - val_loss: 1.9376 - val_accuracy: 0.6498\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 1.6083 - accuracy: 0.7058 - val_loss: 1.0614 - val_accuracy: 0.7982\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 1.8678 - accuracy: 0.6802 - val_loss: 1.5460 - val_accuracy: 0.7158\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 2.0571 - accuracy: 0.6542 - val_loss: 1.8027 - val_accuracy: 0.5622\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 2.2247 - accuracy: 0.6340 - val_loss: 2.2755 - val_accuracy: 0.5504\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 3.1702 - accuracy: 0.5567 - val_loss: 2.4344 - val_accuracy: 0.6170\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 3.4572 - accuracy: 0.5317 - val_loss: 1.4946 - val_accuracy: 0.5006\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 3.6351 - accuracy: 0.5079 - val_loss: 2.6011 - val_accuracy: 0.5846\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 3.7660 - accuracy: 0.3982 - val_loss: 2.0898 - val_accuracy: 0.2762\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 6.9933 - accuracy: 0.3596 - val_loss: 1.7757 - val_accuracy: 0.3813\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 7.7684 - accuracy: 0.4424 - val_loss: 2.2751 - val_accuracy: 0.4277\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 8.3174 - accuracy: 0.3269 - val_loss: 4.2591 - val_accuracy: 0.2569\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 3.5751 - accuracy: 0.1896 - val_loss: 2.7218 - val_accuracy: 0.2299\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 6.2959 - accuracy: 0.2923 - val_loss: 2.4815 - val_accuracy: 0.3376\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 5.6109 - accuracy: 0.2882 - val_loss: 2.1100 - val_accuracy: 0.3249\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 12.6918 - accuracy: 0.3482 - val_loss: 2.1530 - val_accuracy: 0.3483\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 10.4124 - accuracy: 0.3590 - val_loss: 2.1104 - val_accuracy: 0.3727\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 13.1559 - accuracy: 0.2385 - val_loss: 3.3012 - val_accuracy: 0.3152\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 5.5994 - accuracy: 0.3036 - val_loss: 2.5051 - val_accuracy: 0.1616\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 15.9781 - accuracy: 0.1713 - val_loss: 2.6408 - val_accuracy: 0.2119\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 8.5706 - accuracy: 0.2103 - val_loss: 4.1180 - val_accuracy: 0.1848\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 23.1360 - accuracy: 0.2814 - val_loss: 11.1027 - val_accuracy: 0.2772\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 23.13604164123535\n",
      "Training Accuracy: 0.281416654586792\n",
      "Validation Loss: 11.102749824523926\n",
      "Validation Accuracy: 0.27720001339912415\n",
      "Classification Error Rate: 0.7227999866008759\n",
      "----->Evolution: Child net_6 with fitness 11.102749824523926 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_3 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cfaa37240>, <__main__.Block object at 0x7c1cfa7c3840>, <__main__.Block object at 0x7c1cfa8f98c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 14s 8ms/step - loss: 1.1784 - accuracy: 0.7776 - val_loss: 0.4776 - val_accuracy: 0.8336\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.7170 - accuracy: 0.8108 - val_loss: 0.7029 - val_accuracy: 0.8166\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.8602 - accuracy: 0.7917 - val_loss: 0.9871 - val_accuracy: 0.7666\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 1.5360 - accuracy: 0.6633 - val_loss: 1.6443 - val_accuracy: 0.4254\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 1.8959 - accuracy: 0.4436 - val_loss: 1.9849 - val_accuracy: 0.4281\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 1.8073 - accuracy: 0.4022 - val_loss: 1.6121 - val_accuracy: 0.3824\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.0750 - accuracy: 0.3570 - val_loss: 2.3909 - val_accuracy: 0.4082\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.0119 - accuracy: 0.3718 - val_loss: 3.1393 - val_accuracy: 0.3317\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.5481 - accuracy: 0.3276 - val_loss: 3.2141 - val_accuracy: 0.3742\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.4533 - accuracy: 0.3706 - val_loss: 7.4828 - val_accuracy: 0.3915\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.3466 - accuracy: 0.2469 - val_loss: 12.8629 - val_accuracy: 0.2455\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.1603 - accuracy: 0.2962 - val_loss: 27.1324 - val_accuracy: 0.2435\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.1500 - accuracy: 0.3187 - val_loss: 13.7147 - val_accuracy: 0.3323\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 1.9713 - accuracy: 0.3320 - val_loss: 8.7639 - val_accuracy: 0.3638\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.3543 - accuracy: 0.2654 - val_loss: 23.2543 - val_accuracy: 0.2398\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.3345 - accuracy: 0.2850 - val_loss: 40.5927 - val_accuracy: 0.2438\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.6376 - accuracy: 0.2635 - val_loss: 78.8560 - val_accuracy: 0.2147\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.5470 - accuracy: 0.2116 - val_loss: 68.7575 - val_accuracy: 0.1438\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.2568 - accuracy: 0.2392 - val_loss: 49.6006 - val_accuracy: 0.2350\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 3.3983 - accuracy: 0.2833 - val_loss: 29.3096 - val_accuracy: 0.2249\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.1640 - accuracy: 0.2203 - val_loss: 32.6717 - val_accuracy: 0.2847\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.3902 - accuracy: 0.2158 - val_loss: 52.0806 - val_accuracy: 0.1634\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.2486 - accuracy: 0.2200 - val_loss: 72.3259 - val_accuracy: 0.2499\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.2473 - accuracy: 0.2183 - val_loss: 52.8243 - val_accuracy: 0.2528\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.2801 - accuracy: 0.2265 - val_loss: 59.6375 - val_accuracy: 0.2408\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.5645 - accuracy: 0.2575 - val_loss: 44.7978 - val_accuracy: 0.2276\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.0891 - accuracy: 0.2773 - val_loss: 53.4650 - val_accuracy: 0.2176\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.4428 - accuracy: 0.2111 - val_loss: 39.8280 - val_accuracy: 0.2663\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 2.8758 - accuracy: 0.2179 - val_loss: 75.1252 - val_accuracy: 0.1652\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 2.4605 - accuracy: 0.2487 - val_loss: 45.1332 - val_accuracy: 0.3033\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 2.460530996322632\n",
      "Training Accuracy: 0.2486875057220459\n",
      "Validation Loss: 45.13318634033203\n",
      "Validation Accuracy: 0.30329999327659607\n",
      "Classification Error Rate: 0.6967000067234039\n",
      "----->Evolution: Child net_7 with fitness 45.13318634033203 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_3 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cf89cf240>, <__main__.Block object at 0x7c1cf88eb840>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4975 - accuracy: 0.8451 - val_loss: 0.3720 - val_accuracy: 0.8719\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3132 - accuracy: 0.8914 - val_loss: 0.3615 - val_accuracy: 0.8759\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2828 - accuracy: 0.9034 - val_loss: 0.3292 - val_accuracy: 0.8994\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2652 - accuracy: 0.9104 - val_loss: 0.3421 - val_accuracy: 0.8997\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2519 - accuracy: 0.9175 - val_loss: 0.3235 - val_accuracy: 0.8993\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2386 - accuracy: 0.9231 - val_loss: 0.3753 - val_accuracy: 0.8997\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2303 - accuracy: 0.9262 - val_loss: 0.3904 - val_accuracy: 0.8986\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2163 - accuracy: 0.9331 - val_loss: 0.4377 - val_accuracy: 0.8976\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2053 - accuracy: 0.9370 - val_loss: 0.4286 - val_accuracy: 0.9008\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2009 - accuracy: 0.9395 - val_loss: 0.5272 - val_accuracy: 0.9068\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1950 - accuracy: 0.9419 - val_loss: 0.4921 - val_accuracy: 0.9035\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1869 - accuracy: 0.9458 - val_loss: 0.6275 - val_accuracy: 0.9007\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1820 - accuracy: 0.9474 - val_loss: 0.6041 - val_accuracy: 0.8935\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1795 - accuracy: 0.9515 - val_loss: 0.6146 - val_accuracy: 0.9038\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1637 - accuracy: 0.9544 - val_loss: 0.6888 - val_accuracy: 0.9010\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1623 - accuracy: 0.9561 - val_loss: 0.6585 - val_accuracy: 0.8946\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1608 - accuracy: 0.9576 - val_loss: 0.6960 - val_accuracy: 0.8985\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1480 - accuracy: 0.9612 - val_loss: 0.6983 - val_accuracy: 0.8950\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1411 - accuracy: 0.9625 - val_loss: 0.9456 - val_accuracy: 0.9002\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1398 - accuracy: 0.9651 - val_loss: 1.1104 - val_accuracy: 0.9010\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1255 - accuracy: 0.9674 - val_loss: 0.9290 - val_accuracy: 0.9046\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1251 - accuracy: 0.9677 - val_loss: 1.0176 - val_accuracy: 0.9045\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1245 - accuracy: 0.9711 - val_loss: 1.0043 - val_accuracy: 0.8966\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1182 - accuracy: 0.9715 - val_loss: 1.0489 - val_accuracy: 0.9013\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1154 - accuracy: 0.9731 - val_loss: 1.1653 - val_accuracy: 0.9038\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.1063 - accuracy: 0.9756 - val_loss: 1.0639 - val_accuracy: 0.8980\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.1066 - accuracy: 0.9757 - val_loss: 1.1521 - val_accuracy: 0.8977\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1003 - accuracy: 0.9772 - val_loss: 1.1929 - val_accuracy: 0.9003\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0919 - accuracy: 0.9789 - val_loss: 1.2975 - val_accuracy: 0.8974\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0878 - accuracy: 0.9796 - val_loss: 1.3175 - val_accuracy: 0.9031\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 0.08775151520967484\n",
      "Training Accuracy: 0.979562520980835\n",
      "Validation Loss: 1.3175450563430786\n",
      "Validation Accuracy: 0.9031000137329102\n",
      "Classification Error Rate: 0.09689998626708984\n",
      "----->Evolution: Child net_8 with fitness 1.3175450563430786 replaces parent net_4 with fitness 1.416217565536499\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_3 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cf731a440>, <__main__.Block object at 0x7c1d0b1c18c0>, <__main__.Block object at 0x7c1cfe5a8cc0>, <__main__.Block object at 0x7c1d0881b840>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 10s 5ms/step - loss: 0.4941 - accuracy: 0.8264 - val_loss: 0.3569 - val_accuracy: 0.8706\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3182 - accuracy: 0.8872 - val_loss: 0.3164 - val_accuracy: 0.8867\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3042 - accuracy: 0.8937 - val_loss: 0.3519 - val_accuracy: 0.8851\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3144 - accuracy: 0.8920 - val_loss: 0.4603 - val_accuracy: 0.8716\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3325 - accuracy: 0.8899 - val_loss: 0.5610 - val_accuracy: 0.8779\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3446 - accuracy: 0.8873 - val_loss: 0.4497 - val_accuracy: 0.8587\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3628 - accuracy: 0.8838 - val_loss: 0.5148 - val_accuracy: 0.8752\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3714 - accuracy: 0.8802 - val_loss: 0.6300 - val_accuracy: 0.8760\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3877 - accuracy: 0.8777 - val_loss: 0.7936 - val_accuracy: 0.8712\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3926 - accuracy: 0.8773 - val_loss: 0.9708 - val_accuracy: 0.8848\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3967 - accuracy: 0.8764 - val_loss: 1.0803 - val_accuracy: 0.8561\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4059 - accuracy: 0.8746 - val_loss: 1.2846 - val_accuracy: 0.8699\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4241 - accuracy: 0.8724 - val_loss: 1.7445 - val_accuracy: 0.8638\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4270 - accuracy: 0.8721 - val_loss: 1.8388 - val_accuracy: 0.8577\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4471 - accuracy: 0.8676 - val_loss: 2.4148 - val_accuracy: 0.8697\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4464 - accuracy: 0.8686 - val_loss: 3.0114 - val_accuracy: 0.8747\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4746 - accuracy: 0.8652 - val_loss: 3.1080 - val_accuracy: 0.8742\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5098 - accuracy: 0.8614 - val_loss: 4.7456 - val_accuracy: 0.8748\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5228 - accuracy: 0.8573 - val_loss: 5.4575 - val_accuracy: 0.8168\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5591 - accuracy: 0.8534 - val_loss: 6.4024 - val_accuracy: 0.8271\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5692 - accuracy: 0.8500 - val_loss: 10.8939 - val_accuracy: 0.8523\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5804 - accuracy: 0.8458 - val_loss: 12.6123 - val_accuracy: 0.8322\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.6315 - accuracy: 0.8412 - val_loss: 11.9795 - val_accuracy: 0.8528\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.6491 - accuracy: 0.8334 - val_loss: 16.7388 - val_accuracy: 0.8487\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.6873 - accuracy: 0.8289 - val_loss: 16.0336 - val_accuracy: 0.8235\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.7905 - accuracy: 0.8117 - val_loss: 14.2605 - val_accuracy: 0.7662\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.8245 - accuracy: 0.8012 - val_loss: 14.6694 - val_accuracy: 0.7904\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.9295 - accuracy: 0.7950 - val_loss: 19.4701 - val_accuracy: 0.6717\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 1.0804 - accuracy: 0.7804 - val_loss: 34.6640 - val_accuracy: 0.7994\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 1.0715 - accuracy: 0.7532 - val_loss: 21.2774 - val_accuracy: 0.7430\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 1.0715312957763672\n",
      "Training Accuracy: 0.7531874775886536\n",
      "Validation Loss: 21.277406692504883\n",
      "Validation Accuracy: 0.7429999709129333\n",
      "Classification Error Rate: 0.25700002908706665\n",
      "----->Evolution: Child net_9 with fitness 21.277406692504883 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 7\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Tournament selection\n",
      "Selected net_2 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  512\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d2bf2f240>, <__main__.Block object at 0x7c1d0cb23b80>, <__main__.Block object at 0x7c1d2bf75ac0>, <__main__.Block object at 0x7c1d0cb8a480>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 8s 4ms/step - loss: 0.5709 - accuracy: 0.8013 - val_loss: 0.4433 - val_accuracy: 0.8448\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4024 - accuracy: 0.8564 - val_loss: 0.3620 - val_accuracy: 0.8676\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3923 - accuracy: 0.8644 - val_loss: 0.3704 - val_accuracy: 0.8764\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3946 - accuracy: 0.8675 - val_loss: 0.4424 - val_accuracy: 0.8571\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3941 - accuracy: 0.8674 - val_loss: 0.5150 - val_accuracy: 0.8259\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4095 - accuracy: 0.8641 - val_loss: 0.3640 - val_accuracy: 0.8718\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4063 - accuracy: 0.8660 - val_loss: 0.4098 - val_accuracy: 0.8609\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4223 - accuracy: 0.8647 - val_loss: 0.3955 - val_accuracy: 0.8817\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4264 - accuracy: 0.8650 - val_loss: 0.4807 - val_accuracy: 0.8471\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4332 - accuracy: 0.8617 - val_loss: 0.3965 - val_accuracy: 0.8782\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4357 - accuracy: 0.8663 - val_loss: 0.4306 - val_accuracy: 0.8770\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4451 - accuracy: 0.8646 - val_loss: 0.4693 - val_accuracy: 0.8626\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4677 - accuracy: 0.8610 - val_loss: 0.6308 - val_accuracy: 0.8494\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4687 - accuracy: 0.8605 - val_loss: 0.4963 - val_accuracy: 0.8663\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4681 - accuracy: 0.8595 - val_loss: 0.5643 - val_accuracy: 0.8667\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4747 - accuracy: 0.8583 - val_loss: 0.5327 - val_accuracy: 0.8542\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4918 - accuracy: 0.8580 - val_loss: 0.4697 - val_accuracy: 0.8756\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5007 - accuracy: 0.8576 - val_loss: 0.7536 - val_accuracy: 0.8115\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4957 - accuracy: 0.8565 - val_loss: 0.4515 - val_accuracy: 0.8644\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5061 - accuracy: 0.8552 - val_loss: 1.4134 - val_accuracy: 0.7780\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5203 - accuracy: 0.8516 - val_loss: 0.5919 - val_accuracy: 0.8218\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5332 - accuracy: 0.8526 - val_loss: 0.4617 - val_accuracy: 0.8625\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5475 - accuracy: 0.8498 - val_loss: 0.6930 - val_accuracy: 0.8367\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5493 - accuracy: 0.8511 - val_loss: 0.4957 - val_accuracy: 0.8590\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5600 - accuracy: 0.8486 - val_loss: 0.6707 - val_accuracy: 0.8470\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5558 - accuracy: 0.8506 - val_loss: 0.6110 - val_accuracy: 0.8203\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5998 - accuracy: 0.8450 - val_loss: 0.4805 - val_accuracy: 0.8671\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.6211 - accuracy: 0.8437 - val_loss: 0.6352 - val_accuracy: 0.8566\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5993 - accuracy: 0.8463 - val_loss: 0.6583 - val_accuracy: 0.8478\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6326 - accuracy: 0.8403 - val_loss: 0.6564 - val_accuracy: 0.8676\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 0.6326099634170532\n",
      "Training Accuracy: 0.8403333425521851\n",
      "Validation Loss: 0.6564016938209534\n",
      "Validation Accuracy: 0.8676000237464905\n",
      "Classification Error Rate: 0.13239997625350952\n",
      "----->Evolution: Child net_6 with fitness 0.6564016938209534 replaces parent net_4 with fitness 1.3175450563430786\n",
      "\n",
      "Creating Child 1\n",
      "----->Tournament selection\n",
      "Selected net_2 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d052f3140>, <__main__.Block object at 0x7c1d05554a80>, <__main__.Block object at 0x7c1cf77f0780>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4683 - accuracy: 0.8330 - val_loss: 0.4265 - val_accuracy: 0.8627\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3681 - accuracy: 0.8753 - val_loss: 0.3579 - val_accuracy: 0.8841\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3585 - accuracy: 0.8826 - val_loss: 0.3643 - val_accuracy: 0.8823\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3727 - accuracy: 0.8830 - val_loss: 0.4306 - val_accuracy: 0.8726\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3936 - accuracy: 0.8842 - val_loss: 0.4666 - val_accuracy: 0.8756\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4153 - accuracy: 0.8809 - val_loss: 0.5836 - val_accuracy: 0.8714\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4593 - accuracy: 0.8770 - val_loss: 0.5781 - val_accuracy: 0.8828\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4745 - accuracy: 0.8763 - val_loss: 0.7553 - val_accuracy: 0.8548\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4678 - accuracy: 0.8762 - val_loss: 0.6028 - val_accuracy: 0.8614\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4739 - accuracy: 0.8760 - val_loss: 0.6093 - val_accuracy: 0.8785\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5006 - accuracy: 0.8753 - val_loss: 0.5646 - val_accuracy: 0.8773\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5222 - accuracy: 0.8735 - val_loss: 0.6564 - val_accuracy: 0.8724\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5275 - accuracy: 0.8725 - val_loss: 0.6425 - val_accuracy: 0.8537\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5535 - accuracy: 0.8707 - val_loss: 0.7582 - val_accuracy: 0.8452\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5578 - accuracy: 0.8678 - val_loss: 2.2532 - val_accuracy: 0.8386\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5958 - accuracy: 0.8655 - val_loss: 0.6177 - val_accuracy: 0.8624\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5912 - accuracy: 0.8630 - val_loss: 0.7907 - val_accuracy: 0.8563\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.5878 - accuracy: 0.8643 - val_loss: 0.9616 - val_accuracy: 0.8397\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6210 - accuracy: 0.8601 - val_loss: 0.9957 - val_accuracy: 0.8596\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6201 - accuracy: 0.8588 - val_loss: 0.8924 - val_accuracy: 0.8460\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.6504 - accuracy: 0.8514 - val_loss: 0.7578 - val_accuracy: 0.8477\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6440 - accuracy: 0.8531 - val_loss: 1.2061 - val_accuracy: 0.8222\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6365 - accuracy: 0.8528 - val_loss: 0.7599 - val_accuracy: 0.8496\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6581 - accuracy: 0.8521 - val_loss: 0.6635 - val_accuracy: 0.8689\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6434 - accuracy: 0.8501 - val_loss: 0.6806 - val_accuracy: 0.8396\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6740 - accuracy: 0.8446 - val_loss: 0.7130 - val_accuracy: 0.8405\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6543 - accuracy: 0.8470 - val_loss: 0.8130 - val_accuracy: 0.8580\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6650 - accuracy: 0.8463 - val_loss: 0.7618 - val_accuracy: 0.8416\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6664 - accuracy: 0.8434 - val_loss: 0.7602 - val_accuracy: 0.8613\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6798 - accuracy: 0.8458 - val_loss: 0.9182 - val_accuracy: 0.8702\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 0.6798315048217773\n",
      "Training Accuracy: 0.8457916378974915\n",
      "Validation Loss: 0.9181622266769409\n",
      "Validation Accuracy: 0.870199978351593\n",
      "Classification Error Rate: 0.12980002164840698\n",
      "----->Evolution: Child net_7 with fitness 0.9181622266769409 replaces parent parent_0 with fitness 1.1361205577850342\n",
      "\n",
      "Creating Child 2\n",
      "----->Tournament selection\n",
      "Selected parent_0 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d0584d180>, <__main__.Block object at 0x7c1d091d2f40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5086 - accuracy: 0.8417 - val_loss: 0.3105 - val_accuracy: 0.8903\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2832 - accuracy: 0.8997 - val_loss: 0.3211 - val_accuracy: 0.8955\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2317 - accuracy: 0.9186 - val_loss: 0.3305 - val_accuracy: 0.8984\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1925 - accuracy: 0.9325 - val_loss: 0.3738 - val_accuracy: 0.9092\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1568 - accuracy: 0.9453 - val_loss: 0.3761 - val_accuracy: 0.9054\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1390 - accuracy: 0.9537 - val_loss: 0.3918 - val_accuracy: 0.9034\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1170 - accuracy: 0.9611 - val_loss: 0.4306 - val_accuracy: 0.9145\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1042 - accuracy: 0.9671 - val_loss: 0.5304 - val_accuracy: 0.9103\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0912 - accuracy: 0.9718 - val_loss: 0.5174 - val_accuracy: 0.9011\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0814 - accuracy: 0.9753 - val_loss: 0.5829 - val_accuracy: 0.9070\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0757 - accuracy: 0.9777 - val_loss: 0.6069 - val_accuracy: 0.9039\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0677 - accuracy: 0.9803 - val_loss: 0.7377 - val_accuracy: 0.9146\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0595 - accuracy: 0.9829 - val_loss: 0.7504 - val_accuracy: 0.9046\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0624 - accuracy: 0.9834 - val_loss: 0.7734 - val_accuracy: 0.9123\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0519 - accuracy: 0.9864 - val_loss: 0.9329 - val_accuracy: 0.9115\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0498 - accuracy: 0.9868 - val_loss: 0.8884 - val_accuracy: 0.9180\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0457 - accuracy: 0.9886 - val_loss: 1.2476 - val_accuracy: 0.9147\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0393 - accuracy: 0.9899 - val_loss: 1.0463 - val_accuracy: 0.9130\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0342 - accuracy: 0.9916 - val_loss: 1.1684 - val_accuracy: 0.9097\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0397 - accuracy: 0.9907 - val_loss: 1.0815 - val_accuracy: 0.9098\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0353 - accuracy: 0.9916 - val_loss: 1.3698 - val_accuracy: 0.9132\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0351 - accuracy: 0.9917 - val_loss: 1.2322 - val_accuracy: 0.9161\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0370 - accuracy: 0.9926 - val_loss: 1.4545 - val_accuracy: 0.9095\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0358 - accuracy: 0.9925 - val_loss: 1.3219 - val_accuracy: 0.9096\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0349 - accuracy: 0.9928 - val_loss: 1.5311 - val_accuracy: 0.9112\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0236 - accuracy: 0.9945 - val_loss: 1.6426 - val_accuracy: 0.9156\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0282 - accuracy: 0.9941 - val_loss: 1.6112 - val_accuracy: 0.9161\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0295 - accuracy: 0.9943 - val_loss: 1.4190 - val_accuracy: 0.9136\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0369 - accuracy: 0.9934 - val_loss: 1.7664 - val_accuracy: 0.9145\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0261 - accuracy: 0.9952 - val_loss: 1.8521 - val_accuracy: 0.9135\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 0.026126904413104057\n",
      "Training Accuracy: 0.9952083230018616\n",
      "Validation Loss: 1.8520941734313965\n",
      "Validation Accuracy: 0.9135000109672546\n",
      "Classification Error Rate: 0.08649998903274536\n",
      "----->Evolution: Child net_8 with fitness 1.8520941734313965 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Tournament selection\n",
      "Selected net_2 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d2ac4f240>, <__main__.Block object at 0x7c1cfd0dbb80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 8s 4ms/step - loss: 0.5931 - accuracy: 0.8294 - val_loss: 0.3971 - val_accuracy: 0.8738\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3229 - accuracy: 0.8879 - val_loss: 0.3293 - val_accuracy: 0.8810\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2964 - accuracy: 0.8983 - val_loss: 0.3879 - val_accuracy: 0.8875\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2834 - accuracy: 0.9064 - val_loss: 0.4495 - val_accuracy: 0.8849\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2720 - accuracy: 0.9131 - val_loss: 0.4876 - val_accuracy: 0.8830\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2644 - accuracy: 0.9153 - val_loss: 0.4062 - val_accuracy: 0.8859\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2599 - accuracy: 0.9195 - val_loss: 0.4469 - val_accuracy: 0.8941\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2480 - accuracy: 0.9229 - val_loss: 0.5292 - val_accuracy: 0.8970\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2370 - accuracy: 0.9269 - val_loss: 0.4926 - val_accuracy: 0.9008\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2364 - accuracy: 0.9283 - val_loss: 0.5635 - val_accuracy: 0.8940\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2212 - accuracy: 0.9326 - val_loss: 0.5244 - val_accuracy: 0.8808\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2228 - accuracy: 0.9333 - val_loss: 0.6087 - val_accuracy: 0.8923\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2265 - accuracy: 0.9352 - val_loss: 0.6425 - val_accuracy: 0.8925\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2097 - accuracy: 0.9382 - val_loss: 0.7323 - val_accuracy: 0.8876\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2077 - accuracy: 0.9407 - val_loss: 0.5911 - val_accuracy: 0.8854\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2090 - accuracy: 0.9421 - val_loss: 0.6761 - val_accuracy: 0.8842\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2096 - accuracy: 0.9419 - val_loss: 0.8839 - val_accuracy: 0.8875\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2098 - accuracy: 0.9437 - val_loss: 0.9911 - val_accuracy: 0.8894\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2120 - accuracy: 0.9441 - val_loss: 0.8753 - val_accuracy: 0.8950\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2027 - accuracy: 0.9451 - val_loss: 0.8577 - val_accuracy: 0.8814\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1980 - accuracy: 0.9469 - val_loss: 1.0584 - val_accuracy: 0.8881\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1992 - accuracy: 0.9488 - val_loss: 0.9212 - val_accuracy: 0.8901\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1976 - accuracy: 0.9506 - val_loss: 0.9682 - val_accuracy: 0.8897\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1942 - accuracy: 0.9515 - val_loss: 0.9797 - val_accuracy: 0.8940\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1838 - accuracy: 0.9526 - val_loss: 0.9287 - val_accuracy: 0.8903\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1925 - accuracy: 0.9529 - val_loss: 1.1555 - val_accuracy: 0.8899\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1752 - accuracy: 0.9541 - val_loss: 1.0047 - val_accuracy: 0.8978\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1895 - accuracy: 0.9546 - val_loss: 1.4477 - val_accuracy: 0.8938\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1845 - accuracy: 0.9558 - val_loss: 1.5347 - val_accuracy: 0.8903\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1824 - accuracy: 0.9561 - val_loss: 1.3280 - val_accuracy: 0.8915\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 0.18240539729595184\n",
      "Training Accuracy: 0.956125020980835\n",
      "Validation Loss: 1.3280224800109863\n",
      "Validation Accuracy: 0.8914999961853027\n",
      "Classification Error Rate: 0.10850000381469727\n",
      "----->Evolution: Child net_9 with fitness 1.3280224800109863 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 8\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Proportionate selection\n",
      "Selected net_5 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  512\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cf9a87240>, <__main__.Block object at 0x7c1cfabf2080>, <__main__.Block object at 0x7c1cfad66940>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4644 - accuracy: 0.8343 - val_loss: 0.3578 - val_accuracy: 0.8729\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3438 - accuracy: 0.8790 - val_loss: 0.3711 - val_accuracy: 0.8789\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3261 - accuracy: 0.8881 - val_loss: 0.4147 - val_accuracy: 0.8628\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3247 - accuracy: 0.8915 - val_loss: 0.3612 - val_accuracy: 0.8898\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3237 - accuracy: 0.8953 - val_loss: 0.3960 - val_accuracy: 0.8823\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3257 - accuracy: 0.8969 - val_loss: 0.4172 - val_accuracy: 0.8762\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3284 - accuracy: 0.8976 - val_loss: 0.4127 - val_accuracy: 0.8816\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3274 - accuracy: 0.9007 - val_loss: 0.4511 - val_accuracy: 0.8863\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3268 - accuracy: 0.8999 - val_loss: 0.4153 - val_accuracy: 0.8934\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3250 - accuracy: 0.9007 - val_loss: 0.4313 - val_accuracy: 0.8882\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3256 - accuracy: 0.9029 - val_loss: 0.4340 - val_accuracy: 0.8859\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3118 - accuracy: 0.9039 - val_loss: 0.4366 - val_accuracy: 0.8866\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3166 - accuracy: 0.9057 - val_loss: 0.4903 - val_accuracy: 0.8811\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3025 - accuracy: 0.9084 - val_loss: 0.4780 - val_accuracy: 0.8856\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3091 - accuracy: 0.9067 - val_loss: 0.4762 - val_accuracy: 0.8725\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3090 - accuracy: 0.9074 - val_loss: 0.4949 - val_accuracy: 0.8876\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3020 - accuracy: 0.9111 - val_loss: 0.4407 - val_accuracy: 0.8830\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2978 - accuracy: 0.9105 - val_loss: 0.4375 - val_accuracy: 0.8877\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3036 - accuracy: 0.9092 - val_loss: 0.4378 - val_accuracy: 0.8881\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3036 - accuracy: 0.9108 - val_loss: 0.5034 - val_accuracy: 0.8838\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3094 - accuracy: 0.9113 - val_loss: 0.6026 - val_accuracy: 0.8585\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3079 - accuracy: 0.9149 - val_loss: 0.5298 - val_accuracy: 0.8938\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3053 - accuracy: 0.9144 - val_loss: 0.4845 - val_accuracy: 0.8893\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2996 - accuracy: 0.9155 - val_loss: 0.4802 - val_accuracy: 0.8879\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3111 - accuracy: 0.9161 - val_loss: 0.5622 - val_accuracy: 0.8859\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3111 - accuracy: 0.9183 - val_loss: 0.5433 - val_accuracy: 0.8874\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3054 - accuracy: 0.9175 - val_loss: 0.6132 - val_accuracy: 0.8923\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3062 - accuracy: 0.9191 - val_loss: 0.5848 - val_accuracy: 0.8829\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3061 - accuracy: 0.9207 - val_loss: 0.8269 - val_accuracy: 0.8699\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3112 - accuracy: 0.9202 - val_loss: 0.6839 - val_accuracy: 0.8898\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 0.3112441897392273\n",
      "Training Accuracy: 0.9202291369438171\n",
      "Validation Loss: 0.6838546395301819\n",
      "Validation Accuracy: 0.8898000121116638\n",
      "Classification Error Rate: 0.11019998788833618\n",
      "----->Evolution: Child net_6 with fitness 0.6838546395301819 replaces parent parent_0 with fitness 0.9181622266769409\n",
      "\n",
      "Creating Child 1\n",
      "----->Proportionate selection\n",
      "Selected net_1 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cf9713c40>, <__main__.Block object at 0x7c1cf7be2080>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5075 - accuracy: 0.8462 - val_loss: 0.3109 - val_accuracy: 0.8891\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2864 - accuracy: 0.9005 - val_loss: 0.3334 - val_accuracy: 0.8901\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2330 - accuracy: 0.9197 - val_loss: 0.3758 - val_accuracy: 0.8904\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2029 - accuracy: 0.9315 - val_loss: 0.3516 - val_accuracy: 0.9025\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1804 - accuracy: 0.9407 - val_loss: 0.4031 - val_accuracy: 0.8982\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1628 - accuracy: 0.9469 - val_loss: 0.4176 - val_accuracy: 0.9019\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1451 - accuracy: 0.9545 - val_loss: 0.4528 - val_accuracy: 0.9088\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1263 - accuracy: 0.9601 - val_loss: 0.4688 - val_accuracy: 0.9024\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1152 - accuracy: 0.9637 - val_loss: 0.5281 - val_accuracy: 0.9143\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1041 - accuracy: 0.9686 - val_loss: 0.5328 - val_accuracy: 0.9086\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0986 - accuracy: 0.9706 - val_loss: 0.5758 - val_accuracy: 0.9090\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0919 - accuracy: 0.9736 - val_loss: 0.5577 - val_accuracy: 0.9105\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0779 - accuracy: 0.9774 - val_loss: 0.7760 - val_accuracy: 0.9098\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0687 - accuracy: 0.9809 - val_loss: 0.8359 - val_accuracy: 0.9120\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0724 - accuracy: 0.9817 - val_loss: 0.8922 - val_accuracy: 0.9081\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0628 - accuracy: 0.9828 - val_loss: 0.8173 - val_accuracy: 0.9120\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0606 - accuracy: 0.9840 - val_loss: 0.9493 - val_accuracy: 0.9104\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0586 - accuracy: 0.9856 - val_loss: 1.0388 - val_accuracy: 0.9144\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0519 - accuracy: 0.9875 - val_loss: 0.9209 - val_accuracy: 0.9108\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0479 - accuracy: 0.9878 - val_loss: 1.0665 - val_accuracy: 0.9154\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0415 - accuracy: 0.9896 - val_loss: 1.0003 - val_accuracy: 0.9103\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0455 - accuracy: 0.9892 - val_loss: 1.2994 - val_accuracy: 0.9162\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0401 - accuracy: 0.9911 - val_loss: 1.4600 - val_accuracy: 0.9164\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0340 - accuracy: 0.9924 - val_loss: 1.3464 - val_accuracy: 0.9139\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0394 - accuracy: 0.9917 - val_loss: 1.4732 - val_accuracy: 0.9160\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0334 - accuracy: 0.9924 - val_loss: 1.5134 - val_accuracy: 0.9148\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0372 - accuracy: 0.9921 - val_loss: 1.6573 - val_accuracy: 0.9180\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0311 - accuracy: 0.9938 - val_loss: 1.6953 - val_accuracy: 0.9120\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0297 - accuracy: 0.9941 - val_loss: 1.5028 - val_accuracy: 0.9154\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0289 - accuracy: 0.9942 - val_loss: 1.6242 - val_accuracy: 0.9152\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 0.028852330520749092\n",
      "Training Accuracy: 0.9942291378974915\n",
      "Validation Loss: 1.6242387294769287\n",
      "Validation Accuracy: 0.9151999950408936\n",
      "Classification Error Rate: 0.08480000495910645\n",
      "----->Evolution: Child net_7 with fitness 1.6242387294769287 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Proportionate selection\n",
      "Selected net_3 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cf4f87240>, <__main__.Block object at 0x7c1cf741bb80>, <__main__.Block object at 0x7c1cf749fe00>, <__main__.Block object at 0x7c1cf298d940>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 9s 5ms/step - loss: 0.4371 - accuracy: 0.8459 - val_loss: 0.3398 - val_accuracy: 0.8766\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2938 - accuracy: 0.8948 - val_loss: 0.2722 - val_accuracy: 0.9048\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2760 - accuracy: 0.9016 - val_loss: 0.3524 - val_accuracy: 0.8917\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2804 - accuracy: 0.9045 - val_loss: 0.2847 - val_accuracy: 0.9039\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2957 - accuracy: 0.9001 - val_loss: 0.3779 - val_accuracy: 0.8951\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3103 - accuracy: 0.8970 - val_loss: 0.4471 - val_accuracy: 0.8980\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3312 - accuracy: 0.8932 - val_loss: 0.3598 - val_accuracy: 0.8874\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3415 - accuracy: 0.8901 - val_loss: 0.3719 - val_accuracy: 0.8879\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3497 - accuracy: 0.8876 - val_loss: 0.3831 - val_accuracy: 0.8691\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3648 - accuracy: 0.8850 - val_loss: 0.3792 - val_accuracy: 0.8651\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3776 - accuracy: 0.8809 - val_loss: 0.4524 - val_accuracy: 0.8739\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3804 - accuracy: 0.8792 - val_loss: 0.3972 - val_accuracy: 0.8640\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3833 - accuracy: 0.8786 - val_loss: 0.3838 - val_accuracy: 0.8736\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3908 - accuracy: 0.8768 - val_loss: 0.5776 - val_accuracy: 0.8769\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3938 - accuracy: 0.8764 - val_loss: 0.3956 - val_accuracy: 0.8770\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4144 - accuracy: 0.8733 - val_loss: 0.3683 - val_accuracy: 0.8759\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4193 - accuracy: 0.8698 - val_loss: 0.4637 - val_accuracy: 0.8637\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4371 - accuracy: 0.8678 - val_loss: 0.3892 - val_accuracy: 0.8625\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4452 - accuracy: 0.8648 - val_loss: 0.3961 - val_accuracy: 0.8797\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4456 - accuracy: 0.8651 - val_loss: 0.6794 - val_accuracy: 0.8539\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4570 - accuracy: 0.8644 - val_loss: 0.4300 - val_accuracy: 0.8617\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4595 - accuracy: 0.8657 - val_loss: 0.4532 - val_accuracy: 0.8646\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4789 - accuracy: 0.8577 - val_loss: 0.4624 - val_accuracy: 0.8389\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4765 - accuracy: 0.8616 - val_loss: 0.4602 - val_accuracy: 0.8513\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5128 - accuracy: 0.8564 - val_loss: 0.8708 - val_accuracy: 0.8158\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4931 - accuracy: 0.8576 - val_loss: 0.4629 - val_accuracy: 0.8564\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.5120 - accuracy: 0.8588 - val_loss: 0.5206 - val_accuracy: 0.8286\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4976 - accuracy: 0.8577 - val_loss: 0.6214 - val_accuracy: 0.8500\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5144 - accuracy: 0.8584 - val_loss: 0.6383 - val_accuracy: 0.8498\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5120 - accuracy: 0.8528 - val_loss: 0.4687 - val_accuracy: 0.8510\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 0.511978268623352\n",
      "Training Accuracy: 0.8528333306312561\n",
      "Validation Loss: 0.46868467330932617\n",
      "Validation Accuracy: 0.8510000109672546\n",
      "Classification Error Rate: 0.14899998903274536\n",
      "----->Evolution: Child net_8 with fitness 0.46868467330932617 replaces parent net_5 with fitness 0.8292027115821838\n",
      "\n",
      "Creating Child 3\n",
      "----->Proportionate selection\n",
      "Selected net_3 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d022b9a80>, <__main__.Block object at 0x7c1cf2d118c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 8s 4ms/step - loss: 0.4542 - accuracy: 0.8521 - val_loss: 0.2962 - val_accuracy: 0.8925\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2783 - accuracy: 0.9009 - val_loss: 0.3390 - val_accuracy: 0.8895\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2431 - accuracy: 0.9158 - val_loss: 0.3035 - val_accuracy: 0.8988\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2090 - accuracy: 0.9287 - val_loss: 0.3544 - val_accuracy: 0.8954\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1867 - accuracy: 0.9365 - val_loss: 0.3262 - val_accuracy: 0.9058\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1727 - accuracy: 0.9434 - val_loss: 0.4210 - val_accuracy: 0.9001\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1670 - accuracy: 0.9469 - val_loss: 0.4497 - val_accuracy: 0.9014\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1454 - accuracy: 0.9542 - val_loss: 0.4631 - val_accuracy: 0.9053\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1440 - accuracy: 0.9576 - val_loss: 0.4518 - val_accuracy: 0.9054\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1284 - accuracy: 0.9618 - val_loss: 0.6629 - val_accuracy: 0.9026\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1263 - accuracy: 0.9656 - val_loss: 0.5134 - val_accuracy: 0.8965\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1188 - accuracy: 0.9692 - val_loss: 0.6943 - val_accuracy: 0.9049\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1079 - accuracy: 0.9723 - val_loss: 0.7506 - val_accuracy: 0.9076\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0929 - accuracy: 0.9759 - val_loss: 0.7429 - val_accuracy: 0.9051\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0919 - accuracy: 0.9766 - val_loss: 1.0366 - val_accuracy: 0.9112\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0759 - accuracy: 0.9810 - val_loss: 0.7226 - val_accuracy: 0.9071\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0785 - accuracy: 0.9813 - val_loss: 1.1435 - val_accuracy: 0.9074\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0724 - accuracy: 0.9838 - val_loss: 1.0097 - val_accuracy: 0.9063\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0690 - accuracy: 0.9846 - val_loss: 1.0415 - val_accuracy: 0.9083\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0688 - accuracy: 0.9857 - val_loss: 1.0865 - val_accuracy: 0.9061\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0626 - accuracy: 0.9869 - val_loss: 1.2549 - val_accuracy: 0.8968\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0585 - accuracy: 0.9879 - val_loss: 1.2815 - val_accuracy: 0.9075\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0552 - accuracy: 0.9887 - val_loss: 1.2232 - val_accuracy: 0.9048\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0573 - accuracy: 0.9880 - val_loss: 1.3642 - val_accuracy: 0.9096\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0451 - accuracy: 0.9899 - val_loss: 1.4625 - val_accuracy: 0.9099\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0441 - accuracy: 0.9914 - val_loss: 1.3591 - val_accuracy: 0.9026\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0381 - accuracy: 0.9927 - val_loss: 1.5365 - val_accuracy: 0.9138\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0366 - accuracy: 0.9928 - val_loss: 1.6715 - val_accuracy: 0.9053\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0390 - accuracy: 0.9928 - val_loss: 1.7088 - val_accuracy: 0.9106\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0397 - accuracy: 0.9924 - val_loss: 1.6305 - val_accuracy: 0.9074\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 0.039667773991823196\n",
      "Training Accuracy: 0.9923750162124634\n",
      "Validation Loss: 1.6304980516433716\n",
      "Validation Accuracy: 0.9074000120162964\n",
      "Classification Error Rate: 0.09259998798370361\n",
      "----->Evolution: Child net_9 with fitness 1.6304980516433716 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 9\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Tournament selection\n",
      "Selected net_5 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  128.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cc1df7240>, <__main__.Block object at 0x7c1cc0cfbb80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4632 - accuracy: 0.8471 - val_loss: 0.3136 - val_accuracy: 0.8896\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2640 - accuracy: 0.9063 - val_loss: 0.2783 - val_accuracy: 0.8991\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2072 - accuracy: 0.9258 - val_loss: 0.2819 - val_accuracy: 0.9086\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1723 - accuracy: 0.9396 - val_loss: 0.2915 - val_accuracy: 0.9103\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1418 - accuracy: 0.9506 - val_loss: 0.3460 - val_accuracy: 0.9061\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1223 - accuracy: 0.9581 - val_loss: 0.4541 - val_accuracy: 0.9028\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.1050 - accuracy: 0.9654 - val_loss: 0.4125 - val_accuracy: 0.9095\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0922 - accuracy: 0.9705 - val_loss: 0.4994 - val_accuracy: 0.9192\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0838 - accuracy: 0.9737 - val_loss: 0.5257 - val_accuracy: 0.9040\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0735 - accuracy: 0.9766 - val_loss: 0.5077 - val_accuracy: 0.9117\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0668 - accuracy: 0.9794 - val_loss: 0.6017 - val_accuracy: 0.9086\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0605 - accuracy: 0.9818 - val_loss: 0.5926 - val_accuracy: 0.9134\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0528 - accuracy: 0.9835 - val_loss: 0.6638 - val_accuracy: 0.9115\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0489 - accuracy: 0.9856 - val_loss: 0.6725 - val_accuracy: 0.9131\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0377 - accuracy: 0.9883 - val_loss: 0.7245 - val_accuracy: 0.9119\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0410 - accuracy: 0.9883 - val_loss: 0.7806 - val_accuracy: 0.9088\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0400 - accuracy: 0.9890 - val_loss: 0.9694 - val_accuracy: 0.9119\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0316 - accuracy: 0.9912 - val_loss: 0.8933 - val_accuracy: 0.9146\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0364 - accuracy: 0.9909 - val_loss: 0.7702 - val_accuracy: 0.9128\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0331 - accuracy: 0.9918 - val_loss: 0.9260 - val_accuracy: 0.9085\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0344 - accuracy: 0.9921 - val_loss: 0.9785 - val_accuracy: 0.9084\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0270 - accuracy: 0.9935 - val_loss: 1.1605 - val_accuracy: 0.9144\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0246 - accuracy: 0.9934 - val_loss: 1.0548 - val_accuracy: 0.9143\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0241 - accuracy: 0.9940 - val_loss: 1.3360 - val_accuracy: 0.9138\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0225 - accuracy: 0.9946 - val_loss: 1.1622 - val_accuracy: 0.9114\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0240 - accuracy: 0.9949 - val_loss: 1.3578 - val_accuracy: 0.9158\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0242 - accuracy: 0.9948 - val_loss: 1.3093 - val_accuracy: 0.9125\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0215 - accuracy: 0.9953 - val_loss: 1.3683 - val_accuracy: 0.9137\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0225 - accuracy: 0.9955 - val_loss: 1.4147 - val_accuracy: 0.9169\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0193 - accuracy: 0.9959 - val_loss: 1.5979 - val_accuracy: 0.9193\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 0.019325941801071167\n",
      "Training Accuracy: 0.9958958625793457\n",
      "Validation Loss: 1.5979448556900024\n",
      "Validation Accuracy: 0.9193000197410583\n",
      "Classification Error Rate: 0.08069998025894165\n",
      "----->Evolution: Child net_6 with fitness 1.5979448556900024 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Tournament selection\n",
      "Selected net_3 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  512\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cc01a49c0>, <__main__.Block object at 0x7c1cac273b80>, <__main__.Block object at 0x7c1cc1a88900>, <__main__.Block object at 0x7c1cac302480>, <__main__.Block object at 0x7c1cbbf3fb00>, <__main__.Block object at 0x7c1cac24e240>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"conv2d_347\" (type Conv2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 3 from 2 for '{{node conv2d_347/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_347/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,32], [3,3,32,256].\n",
      "\n",
      "Call arguments received by layer \"conv2d_347\" (type Conv2D):\n",
      "   inputs=tf.Tensor(shape=(None, 2, 2, 32), dtype=float32)\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_349. Consider increasing the input size. Received input shape [None, 1, 1, 512] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_154\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_154/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,256].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_154\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 256), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Inserting a Pooling layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  512\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cac2c0b80>, <__main__.Block object at 0x7c1cac2b7f00>, <__main__.Block object at 0x7c1cac2b5e40>, <__main__.Block object at 0x7c1cac2b5c80>, <__main__.Block object at 0x7c1cac2b5700>, <__main__.Block object at 0x7c1cac2b7a00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_76\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_76/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_76\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Inserting a Pooling layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cac2d5140>, <__main__.Block object at 0x7c1cbbf8ce80>, <__main__.Block object at 0x7c1cac2d5480>, <__main__.Block object at 0x7c1cac2d5500>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"average_pooling2d_79\" (type AveragePooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node average_pooling2d_79/AvgPool}} = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,512].\n",
      "\n",
      "Call arguments received by layer \"average_pooling2d_79\" (type AveragePooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 512), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  512\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cac2d4ac0>, <__main__.Block object at 0x7c1cac2e3200>, <__main__.Block object at 0x7c1cbbf558c0>, <__main__.Block object at 0x7c1cac2d1a00>, <__main__.Block object at 0x7c1cac2d0380>, <__main__.Block object at 0x7c1cac2d2b40>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_165\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_165/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,64].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_165\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 64), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 2)]\n",
      "Removing a Pooling/Dropout layer at 0\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cc06e40c0>, <__main__.Block object at 0x7c1cac2e2080>, <__main__.Block object at 0x7c1cac26e900>, <__main__.Block object at 0x7c1cac2c0880>, <__main__.Block object at 0x7c1cac2c2e80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 12s 6ms/step - loss: 0.5379 - accuracy: 0.8061 - val_loss: 0.3460 - val_accuracy: 0.8754\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.3397 - accuracy: 0.8789 - val_loss: 0.3157 - val_accuracy: 0.8905\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3051 - accuracy: 0.8949 - val_loss: 0.3907 - val_accuracy: 0.8725\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2893 - accuracy: 0.9001 - val_loss: 0.3919 - val_accuracy: 0.8904\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2842 - accuracy: 0.9040 - val_loss: 0.3385 - val_accuracy: 0.8938\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2774 - accuracy: 0.9063 - val_loss: 0.3896 - val_accuracy: 0.8991\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2747 - accuracy: 0.9082 - val_loss: 0.3613 - val_accuracy: 0.8994\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2778 - accuracy: 0.9079 - val_loss: 0.3960 - val_accuracy: 0.8947\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2855 - accuracy: 0.9083 - val_loss: 0.3612 - val_accuracy: 0.9020\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2846 - accuracy: 0.9091 - val_loss: 0.3773 - val_accuracy: 0.8855\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2892 - accuracy: 0.9082 - val_loss: 0.4715 - val_accuracy: 0.8852\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2963 - accuracy: 0.9103 - val_loss: 0.4271 - val_accuracy: 0.8975\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2974 - accuracy: 0.9097 - val_loss: 0.6452 - val_accuracy: 0.8890\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3340 - accuracy: 0.9042 - val_loss: 0.4650 - val_accuracy: 0.8832\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3420 - accuracy: 0.9052 - val_loss: 0.6024 - val_accuracy: 0.8836\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3430 - accuracy: 0.9036 - val_loss: 0.4654 - val_accuracy: 0.8790\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3800 - accuracy: 0.9004 - val_loss: 0.5365 - val_accuracy: 0.8821\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4172 - accuracy: 0.8876 - val_loss: 0.8721 - val_accuracy: 0.8551\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.5044 - accuracy: 0.8764 - val_loss: 0.5595 - val_accuracy: 0.8494\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5521 - accuracy: 0.8547 - val_loss: 2.0704 - val_accuracy: 0.7981\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.6257 - accuracy: 0.8437 - val_loss: 0.8000 - val_accuracy: 0.8429\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.8850 - accuracy: 0.8054 - val_loss: 1.0010 - val_accuracy: 0.6522\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.3040 - accuracy: 0.7155 - val_loss: 1.5086 - val_accuracy: 0.5738\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.3606 - accuracy: 0.7096 - val_loss: 1.0059 - val_accuracy: 0.7252\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.5428 - accuracy: 0.6520 - val_loss: 1.1186 - val_accuracy: 0.5750\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.9141 - accuracy: 0.5818 - val_loss: 10.1725 - val_accuracy: 0.5653\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.4135 - accuracy: 0.5158 - val_loss: 1.7092 - val_accuracy: 0.4256\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 3.1714 - accuracy: 0.4031 - val_loss: 1.5631 - val_accuracy: 0.4106\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.7781 - accuracy: 0.4412 - val_loss: 1.5470 - val_accuracy: 0.3821\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.4499 - accuracy: 0.3879 - val_loss: 1.8319 - val_accuracy: 0.3166\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 2.44991397857666\n",
      "Training Accuracy: 0.3878958225250244\n",
      "Validation Loss: 1.8319278955459595\n",
      "Validation Accuracy: 0.3165999948978424\n",
      "Classification Error Rate: 0.6834000051021576\n",
      "----->Evolution: Child net_7 with fitness 1.8319278955459595 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Tournament selection\n",
      "Selected net_1 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  512\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cff647240>, <__main__.Block object at 0x7c1cff633b80>, <__main__.Block object at 0x7c1cff5e5a00>, <__main__.Block object at 0x7c1d0b768940>, <__main__.Block object at 0x7c1cff6154c0>, <__main__.Block object at 0x7c1cff7cce80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: One of the dimensions in the output is <= 0 due to downsampling in conv2d_376. Consider increasing the input size. Received input shape [None, 1, 1, 128] which would produce output shape with a zero or negative value in a dimension.\n",
      "Skipping current architecture.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Error occurred while adding layer: Exception encountered when calling layer \"max_pooling2d_173\" (type MaxPooling2D).\n",
      "\n",
      "Negative dimension size caused by subtracting 2 from 1 for '{{node max_pooling2d_173/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,128].\n",
      "\n",
      "Call arguments received by layer \"max_pooling2d_173\" (type MaxPooling2D):\n",
      "   inputs=tf.Tensor(shape=(None, 1, 1, 128), dtype=float32)\n",
      "Returning None.\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Removing a Pooling/Dropout layer at 1\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.name from  AveragePooling2D  to  MaxPooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  512\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d07cbbf00>, <__main__.Block object at 0x7c1cff8076c0>, <__main__.Block object at 0x7c1d07cbb980>, <__main__.Block object at 0x7c1d07cb96c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.8391 - accuracy: 0.7454 - val_loss: 0.6740 - val_accuracy: 0.7855\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6053 - accuracy: 0.7988 - val_loss: 0.6007 - val_accuracy: 0.7977\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6179 - accuracy: 0.8026 - val_loss: 0.7205 - val_accuracy: 0.8029\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6574 - accuracy: 0.7994 - val_loss: 0.7982 - val_accuracy: 0.7754\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6863 - accuracy: 0.7927 - val_loss: 0.8223 - val_accuracy: 0.7786\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.7373 - accuracy: 0.7899 - val_loss: 0.8469 - val_accuracy: 0.7644\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.7599 - accuracy: 0.7869 - val_loss: 0.6799 - val_accuracy: 0.7968\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.8613 - accuracy: 0.7724 - val_loss: 0.8751 - val_accuracy: 0.7477\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.9600 - accuracy: 0.7513 - val_loss: 0.9662 - val_accuracy: 0.7365\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.0572 - accuracy: 0.7170 - val_loss: 1.2291 - val_accuracy: 0.7644\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.1435 - accuracy: 0.6844 - val_loss: 1.2911 - val_accuracy: 0.6622\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.3272 - accuracy: 0.6165 - val_loss: 1.3550 - val_accuracy: 0.6859\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.3188 - accuracy: 0.6360 - val_loss: 1.3458 - val_accuracy: 0.5960\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.3019 - accuracy: 0.6368 - val_loss: 2.0040 - val_accuracy: 0.6433\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.4671 - accuracy: 0.5838 - val_loss: 1.8229 - val_accuracy: 0.5423\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.5624 - accuracy: 0.5276 - val_loss: 3.5152 - val_accuracy: 0.4706\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.7200 - accuracy: 0.5082 - val_loss: 1.8720 - val_accuracy: 0.5681\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.6387 - accuracy: 0.5147 - val_loss: 1.8052 - val_accuracy: 0.4963\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.7425 - accuracy: 0.4884 - val_loss: 1.8134 - val_accuracy: 0.5377\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.7761 - accuracy: 0.4733 - val_loss: 1.9111 - val_accuracy: 0.4322\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.7574 - accuracy: 0.4381 - val_loss: 1.7291 - val_accuracy: 0.4318\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.9527 - accuracy: 0.4047 - val_loss: 1.7421 - val_accuracy: 0.3518\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.9167 - accuracy: 0.4131 - val_loss: 1.7898 - val_accuracy: 0.3433\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 1.9630 - accuracy: 0.3508 - val_loss: 2.9700 - val_accuracy: 0.2792\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.0596 - accuracy: 0.3664 - val_loss: 1.7609 - val_accuracy: 0.3882\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.9794 - accuracy: 0.3926 - val_loss: 1.7116 - val_accuracy: 0.3952\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.9813 - accuracy: 0.3669 - val_loss: 1.9137 - val_accuracy: 0.2938\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.9006 - accuracy: 0.3849 - val_loss: 1.7130 - val_accuracy: 0.3597\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.0758 - accuracy: 0.3691 - val_loss: 1.9672 - val_accuracy: 0.2919\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 2.5347 - accuracy: 0.3468 - val_loss: 2.1303 - val_accuracy: 0.3928\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 2.534693717956543\n",
      "Training Accuracy: 0.34679165482521057\n",
      "Validation Loss: 2.1303317546844482\n",
      "Validation Accuracy: 0.3928000032901764\n",
      "Classification Error Rate: 0.6071999967098236\n",
      "----->Evolution: Child net_8 with fitness 2.1303317546844482 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Tournament selection\n",
      "Selected net_4 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  512  to  1024\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1d0705f240>, <__main__.Block object at 0x7c1d06eb3b80>, <__main__.Block object at 0x7c1cff655500>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.5824 - accuracy: 0.8103 - val_loss: 0.4016 - val_accuracy: 0.8629\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3882 - accuracy: 0.8687 - val_loss: 0.3726 - val_accuracy: 0.8709\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3921 - accuracy: 0.8760 - val_loss: 0.4243 - val_accuracy: 0.8697\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3903 - accuracy: 0.8824 - val_loss: 0.4443 - val_accuracy: 0.8799\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4038 - accuracy: 0.8827 - val_loss: 0.5024 - val_accuracy: 0.8708\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4151 - accuracy: 0.8860 - val_loss: 0.6222 - val_accuracy: 0.8808\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4430 - accuracy: 0.8841 - val_loss: 0.5474 - val_accuracy: 0.8643\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4601 - accuracy: 0.8851 - val_loss: 0.6461 - val_accuracy: 0.8545\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4522 - accuracy: 0.8878 - val_loss: 0.5943 - val_accuracy: 0.8706\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4838 - accuracy: 0.8884 - val_loss: 0.7402 - val_accuracy: 0.8534\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5087 - accuracy: 0.8875 - val_loss: 0.7235 - val_accuracy: 0.8725\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5190 - accuracy: 0.8881 - val_loss: 0.8285 - val_accuracy: 0.8662\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5499 - accuracy: 0.8887 - val_loss: 0.9973 - val_accuracy: 0.8528\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5940 - accuracy: 0.8855 - val_loss: 0.8964 - val_accuracy: 0.8671\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5862 - accuracy: 0.8835 - val_loss: 1.0729 - val_accuracy: 0.8606\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5720 - accuracy: 0.8876 - val_loss: 0.8340 - val_accuracy: 0.8557\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6312 - accuracy: 0.8844 - val_loss: 0.9939 - val_accuracy: 0.8674\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6208 - accuracy: 0.8789 - val_loss: 1.2628 - val_accuracy: 0.8514\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6446 - accuracy: 0.8779 - val_loss: 0.9987 - val_accuracy: 0.8416\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6458 - accuracy: 0.8755 - val_loss: 1.1165 - val_accuracy: 0.8665\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6875 - accuracy: 0.8640 - val_loss: 1.3723 - val_accuracy: 0.8384\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6899 - accuracy: 0.8681 - val_loss: 1.2328 - val_accuracy: 0.8389\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.7321 - accuracy: 0.8624 - val_loss: 0.9906 - val_accuracy: 0.8369\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.7548 - accuracy: 0.8579 - val_loss: 1.5738 - val_accuracy: 0.8396\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.7552 - accuracy: 0.8530 - val_loss: 1.0766 - val_accuracy: 0.8346\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.7597 - accuracy: 0.8500 - val_loss: 1.4393 - val_accuracy: 0.8419\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.8143 - accuracy: 0.8450 - val_loss: 1.4290 - val_accuracy: 0.8318\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.8052 - accuracy: 0.8420 - val_loss: 1.8812 - val_accuracy: 0.8361\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.7980 - accuracy: 0.8457 - val_loss: 1.3191 - val_accuracy: 0.8082\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.8537 - accuracy: 0.8357 - val_loss: 2.6042 - val_accuracy: 0.8021\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 0.8536651134490967\n",
      "Training Accuracy: 0.835687518119812\n",
      "Validation Loss: 2.6042187213897705\n",
      "Validation Accuracy: 0.8021000027656555\n",
      "Classification Error Rate: 0.19789999723434448\n",
      "----->Evolution: Child net_9 with fitness 2.6042187213897705 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 10\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_5 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  128.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cf4097240>, <__main__.Block object at 0x7c1cf53134c0>, <__main__.Block object at 0x7c1cf413b200>, <__main__.Block object at 0x7c1cf40c7f80>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 12s 6ms/step - loss: 0.4601 - accuracy: 0.8363 - val_loss: 0.2930 - val_accuracy: 0.8918\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2760 - accuracy: 0.9011 - val_loss: 0.2811 - val_accuracy: 0.8957\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2533 - accuracy: 0.9103 - val_loss: 0.2976 - val_accuracy: 0.9038\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2525 - accuracy: 0.9136 - val_loss: 0.3116 - val_accuracy: 0.8914\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2638 - accuracy: 0.9104 - val_loss: 0.3181 - val_accuracy: 0.9017\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2743 - accuracy: 0.9110 - val_loss: 0.3599 - val_accuracy: 0.8788\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2813 - accuracy: 0.9088 - val_loss: 0.3623 - val_accuracy: 0.8930\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3174 - accuracy: 0.9033 - val_loss: 0.4207 - val_accuracy: 0.8889\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3435 - accuracy: 0.8970 - val_loss: 0.3584 - val_accuracy: 0.9076\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3610 - accuracy: 0.8939 - val_loss: 0.5088 - val_accuracy: 0.8904\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3585 - accuracy: 0.8955 - val_loss: 0.4707 - val_accuracy: 0.8833\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3947 - accuracy: 0.8916 - val_loss: 0.3578 - val_accuracy: 0.8986\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4293 - accuracy: 0.8874 - val_loss: 0.4308 - val_accuracy: 0.8873\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4610 - accuracy: 0.8822 - val_loss: 0.4794 - val_accuracy: 0.8874\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.4960 - accuracy: 0.8710 - val_loss: 0.5483 - val_accuracy: 0.8490\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.5467 - accuracy: 0.8631 - val_loss: 0.6078 - val_accuracy: 0.8733\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.6383 - accuracy: 0.8574 - val_loss: 1.6810 - val_accuracy: 0.8458\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.7700 - accuracy: 0.8525 - val_loss: 1.1068 - val_accuracy: 0.8640\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.8098 - accuracy: 0.8328 - val_loss: 0.6861 - val_accuracy: 0.8612\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.8404 - accuracy: 0.8305 - val_loss: 0.8714 - val_accuracy: 0.8526\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.9790 - accuracy: 0.8137 - val_loss: 0.5910 - val_accuracy: 0.8203\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.8915 - accuracy: 0.8146 - val_loss: 0.6240 - val_accuracy: 0.8417\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.1047 - accuracy: 0.8109 - val_loss: 2.0954 - val_accuracy: 0.7984\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.1095 - accuracy: 0.7885 - val_loss: 0.6858 - val_accuracy: 0.8037\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.2152 - accuracy: 0.7927 - val_loss: 1.7556 - val_accuracy: 0.7219\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.4253 - accuracy: 0.7673 - val_loss: 0.6679 - val_accuracy: 0.7687\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.2753 - accuracy: 0.7693 - val_loss: 1.0392 - val_accuracy: 0.8035\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.2968 - accuracy: 0.7337 - val_loss: 0.9600 - val_accuracy: 0.7704\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.5315 - accuracy: 0.7377 - val_loss: 0.9100 - val_accuracy: 0.7487\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 1.8905 - accuracy: 0.6914 - val_loss: 0.9594 - val_accuracy: 0.7005\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 1.8904672861099243\n",
      "Training Accuracy: 0.6913541555404663\n",
      "Validation Loss: 0.9593932628631592\n",
      "Validation Accuracy: 0.7005000114440918\n",
      "Classification Error Rate: 0.2994999885559082\n",
      "----->Evolution: Child net_6 with fitness 0.9593932628631592 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_5 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cf571f240>, <__main__.Block object at 0x7c1cf5723840>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.5496 - accuracy: 0.8373 - val_loss: 0.3849 - val_accuracy: 0.8694\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3009 - accuracy: 0.8942 - val_loss: 0.3137 - val_accuracy: 0.8992\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2497 - accuracy: 0.9135 - val_loss: 0.3257 - val_accuracy: 0.8983\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2159 - accuracy: 0.9280 - val_loss: 0.3539 - val_accuracy: 0.9047\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1856 - accuracy: 0.9387 - val_loss: 0.4425 - val_accuracy: 0.8919\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1693 - accuracy: 0.9455 - val_loss: 0.4098 - val_accuracy: 0.9110\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1542 - accuracy: 0.9526 - val_loss: 0.4081 - val_accuracy: 0.9077\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1356 - accuracy: 0.9583 - val_loss: 0.4429 - val_accuracy: 0.9089\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1220 - accuracy: 0.9626 - val_loss: 0.5183 - val_accuracy: 0.9056\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1104 - accuracy: 0.9665 - val_loss: 0.5826 - val_accuracy: 0.8980\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0986 - accuracy: 0.9709 - val_loss: 0.5693 - val_accuracy: 0.9132\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0958 - accuracy: 0.9723 - val_loss: 0.6337 - val_accuracy: 0.9024\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0904 - accuracy: 0.9757 - val_loss: 0.5885 - val_accuracy: 0.9078\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0800 - accuracy: 0.9782 - val_loss: 0.6912 - val_accuracy: 0.9107\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0736 - accuracy: 0.9799 - val_loss: 0.8550 - val_accuracy: 0.9051\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0756 - accuracy: 0.9811 - val_loss: 0.8506 - val_accuracy: 0.9125\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0666 - accuracy: 0.9835 - val_loss: 0.9221 - val_accuracy: 0.8909\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0585 - accuracy: 0.9859 - val_loss: 1.0727 - val_accuracy: 0.9095\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0561 - accuracy: 0.9863 - val_loss: 0.9253 - val_accuracy: 0.9161\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0521 - accuracy: 0.9872 - val_loss: 0.9869 - val_accuracy: 0.9150\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0473 - accuracy: 0.9883 - val_loss: 0.9094 - val_accuracy: 0.9144\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0459 - accuracy: 0.9896 - val_loss: 1.3869 - val_accuracy: 0.9110\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0450 - accuracy: 0.9893 - val_loss: 1.2597 - val_accuracy: 0.9137\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0356 - accuracy: 0.9913 - val_loss: 0.9527 - val_accuracy: 0.9152\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0336 - accuracy: 0.9922 - val_loss: 1.3473 - val_accuracy: 0.9101\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0337 - accuracy: 0.9922 - val_loss: 1.1012 - val_accuracy: 0.9143\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0305 - accuracy: 0.9927 - val_loss: 1.0981 - val_accuracy: 0.9117\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0306 - accuracy: 0.9933 - val_loss: 1.2512 - val_accuracy: 0.9123\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0295 - accuracy: 0.9937 - val_loss: 1.4808 - val_accuracy: 0.9163\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0287 - accuracy: 0.9945 - val_loss: 1.3772 - val_accuracy: 0.9146\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 0.028703732416033745\n",
      "Training Accuracy: 0.9945416450500488\n",
      "Validation Loss: 1.3772101402282715\n",
      "Validation Accuracy: 0.9146000146865845\n",
      "Classification Error Rate: 0.08539998531341553\n",
      "----->Evolution: Child net_7 with fitness 1.3772101402282715 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_5 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  256  to  128.0\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cf1297180>, <__main__.Block object at 0x7c1cf0f93b80>, <__main__.Block object at 0x7c1cf0fc3840>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 9s 5ms/step - loss: 0.4644 - accuracy: 0.8414 - val_loss: 0.3303 - val_accuracy: 0.8836\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3071 - accuracy: 0.8919 - val_loss: 0.3397 - val_accuracy: 0.8878\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2699 - accuracy: 0.9077 - val_loss: 0.3109 - val_accuracy: 0.9025\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2590 - accuracy: 0.9151 - val_loss: 0.3936 - val_accuracy: 0.8879\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2454 - accuracy: 0.9203 - val_loss: 0.4480 - val_accuracy: 0.9025\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2376 - accuracy: 0.9252 - val_loss: 0.3770 - val_accuracy: 0.9051\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2340 - accuracy: 0.9289 - val_loss: 0.4608 - val_accuracy: 0.9009\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2321 - accuracy: 0.9315 - val_loss: 0.6333 - val_accuracy: 0.8865\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2241 - accuracy: 0.9367 - val_loss: 0.5289 - val_accuracy: 0.9038\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2125 - accuracy: 0.9400 - val_loss: 0.4813 - val_accuracy: 0.9076\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2262 - accuracy: 0.9409 - val_loss: 0.6414 - val_accuracy: 0.9014\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2273 - accuracy: 0.9440 - val_loss: 0.6407 - val_accuracy: 0.9090\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2227 - accuracy: 0.9452 - val_loss: 0.6112 - val_accuracy: 0.9134\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2294 - accuracy: 0.9483 - val_loss: 0.8580 - val_accuracy: 0.8933\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2209 - accuracy: 0.9488 - val_loss: 0.7625 - val_accuracy: 0.8926\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2273 - accuracy: 0.9498 - val_loss: 0.7484 - val_accuracy: 0.9065\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2265 - accuracy: 0.9520 - val_loss: 1.0879 - val_accuracy: 0.9055\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2327 - accuracy: 0.9536 - val_loss: 0.8494 - val_accuracy: 0.9121\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2310 - accuracy: 0.9528 - val_loss: 1.1380 - val_accuracy: 0.9099\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2378 - accuracy: 0.9549 - val_loss: 1.1728 - val_accuracy: 0.9026\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2098 - accuracy: 0.9574 - val_loss: 1.0722 - val_accuracy: 0.9109\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2247 - accuracy: 0.9572 - val_loss: 1.5623 - val_accuracy: 0.9058\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2400 - accuracy: 0.9580 - val_loss: 1.2028 - val_accuracy: 0.9115\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2275 - accuracy: 0.9604 - val_loss: 1.2762 - val_accuracy: 0.9113\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2265 - accuracy: 0.9602 - val_loss: 1.4489 - val_accuracy: 0.9043\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2273 - accuracy: 0.9601 - val_loss: 1.8254 - val_accuracy: 0.9102\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2402 - accuracy: 0.9613 - val_loss: 1.5203 - val_accuracy: 0.9064\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2443 - accuracy: 0.9603 - val_loss: 1.9547 - val_accuracy: 0.9110\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2341 - accuracy: 0.9620 - val_loss: 2.0115 - val_accuracy: 0.9146\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2320 - accuracy: 0.9630 - val_loss: 1.9506 - val_accuracy: 0.8982\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 0.231977641582489\n",
      "Training Accuracy: 0.9629791378974915\n",
      "Validation Loss: 1.9505869150161743\n",
      "Validation Accuracy: 0.8981999754905701\n",
      "Classification Error Rate: 0.10180002450942993\n",
      "----->Evolution: Child net_8 with fitness 1.9505869150161743 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_5 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cf1677240>, <__main__.Block object at 0x7c1cf178b840>, <__main__.Block object at 0x7c1d074949c0>, <__main__.Block object at 0x7c1cf1546b00>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.5013 - accuracy: 0.8253 - val_loss: 0.3373 - val_accuracy: 0.8751\n",
      "Epoch 2/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3084 - accuracy: 0.8898 - val_loss: 0.3066 - val_accuracy: 0.8978\n",
      "Epoch 3/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2829 - accuracy: 0.9012 - val_loss: 0.2980 - val_accuracy: 0.8971\n",
      "Epoch 4/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2759 - accuracy: 0.9037 - val_loss: 0.3054 - val_accuracy: 0.8973\n",
      "Epoch 5/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2745 - accuracy: 0.9061 - val_loss: 0.3407 - val_accuracy: 0.9070\n",
      "Epoch 6/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2746 - accuracy: 0.9080 - val_loss: 0.4611 - val_accuracy: 0.9033\n",
      "Epoch 7/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2769 - accuracy: 0.9078 - val_loss: 0.3474 - val_accuracy: 0.8863\n",
      "Epoch 8/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2859 - accuracy: 0.9054 - val_loss: 0.3769 - val_accuracy: 0.9007\n",
      "Epoch 9/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2865 - accuracy: 0.9081 - val_loss: 0.3146 - val_accuracy: 0.8960\n",
      "Epoch 10/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2969 - accuracy: 0.9060 - val_loss: 0.3669 - val_accuracy: 0.9016\n",
      "Epoch 11/30\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.3055 - accuracy: 0.9034 - val_loss: 0.4092 - val_accuracy: 0.8903\n",
      "Epoch 12/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3170 - accuracy: 0.9003 - val_loss: 0.3463 - val_accuracy: 0.8923\n",
      "Epoch 13/30\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.3197 - accuracy: 0.9003 - val_loss: 0.3548 - val_accuracy: 0.8909\n",
      "Epoch 14/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3371 - accuracy: 0.8982 - val_loss: 0.4345 - val_accuracy: 0.8762\n",
      "Epoch 15/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3553 - accuracy: 0.8912 - val_loss: 0.6491 - val_accuracy: 0.9016\n",
      "Epoch 16/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3663 - accuracy: 0.8906 - val_loss: 0.4255 - val_accuracy: 0.8870\n",
      "Epoch 17/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3903 - accuracy: 0.8842 - val_loss: 0.4486 - val_accuracy: 0.8810\n",
      "Epoch 18/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4038 - accuracy: 0.8836 - val_loss: 0.3660 - val_accuracy: 0.8820\n",
      "Epoch 19/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4060 - accuracy: 0.8830 - val_loss: 0.4790 - val_accuracy: 0.8783\n",
      "Epoch 20/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4293 - accuracy: 0.8795 - val_loss: 0.7192 - val_accuracy: 0.8626\n",
      "Epoch 21/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4520 - accuracy: 0.8760 - val_loss: 0.4242 - val_accuracy: 0.8791\n",
      "Epoch 22/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4462 - accuracy: 0.8736 - val_loss: 0.5527 - val_accuracy: 0.8421\n",
      "Epoch 23/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5037 - accuracy: 0.8645 - val_loss: 0.4405 - val_accuracy: 0.8594\n",
      "Epoch 24/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5062 - accuracy: 0.8656 - val_loss: 0.4325 - val_accuracy: 0.8538\n",
      "Epoch 25/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5181 - accuracy: 0.8574 - val_loss: 0.5783 - val_accuracy: 0.8686\n",
      "Epoch 26/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.5200 - accuracy: 0.8620 - val_loss: 0.9006 - val_accuracy: 0.8482\n",
      "Epoch 27/30\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6261 - accuracy: 0.8556 - val_loss: 0.5493 - val_accuracy: 0.8727\n",
      "Epoch 28/30\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.6800 - accuracy: 0.8524 - val_loss: 0.4420 - val_accuracy: 0.8753\n",
      "Epoch 29/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.6155 - accuracy: 0.8537 - val_loss: 0.5816 - val_accuracy: 0.8681\n",
      "Epoch 30/30\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.6095 - accuracy: 0.8506 - val_loss: 6.2811 - val_accuracy: 0.8050\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 0.6094723343849182\n",
      "Training Accuracy: 0.8506458401679993\n",
      "Validation Loss: 6.281062602996826\n",
      "Validation Accuracy: 0.8050000071525574\n",
      "Classification Error Rate: 0.19499999284744263\n",
      "----->Evolution: Child net_9 with fitness 6.281062602996826 is discarded\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "Final Population\n",
      "-------------------------------------\n",
      "\n",
      "net_5 :  0.46868467330932617\n",
      "net_3 :  0.5254846215248108\n",
      "net_2 :  0.5385181903839111\n",
      "net_1 :  0.6252947449684143\n",
      "net_4 :  0.6564016938209534\n",
      "parent_0 :  0.6838546395301819\n",
      "\n",
      "-------------------------------------\n",
      "Stats\n",
      "Best individual at generation 1 has fitness 1.519719123840332 and parameters 3572682\n",
      "Best individual at generation 2 has fitness 0.46868467330932617 and parameters 989258\n",
      "-------------------------------------\n",
      "\n",
      "The block is:\n",
      "[<__main__.Block object at 0x7c1cf39e9e40>, <__main__.Block object at 0x7c1cf2c7dc40>, <__main__.Block object at 0x7c1cf2cc0f40>, <__main__.Block object at 0x7c1cf38481c0>]\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Layer added successfully.\n",
      "Model successfully built.\n",
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 9s 5ms/step - loss: 0.4220 - accuracy: 0.8487 - val_loss: 0.4404 - val_accuracy: 0.8495\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2867 - accuracy: 0.8973 - val_loss: 0.2891 - val_accuracy: 0.8923\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2666 - accuracy: 0.9058 - val_loss: 0.3179 - val_accuracy: 0.8882\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2653 - accuracy: 0.9083 - val_loss: 0.2870 - val_accuracy: 0.9013\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2736 - accuracy: 0.9089 - val_loss: 0.3182 - val_accuracy: 0.8956\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2922 - accuracy: 0.9050 - val_loss: 0.3465 - val_accuracy: 0.8902\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3078 - accuracy: 0.8995 - val_loss: 0.3345 - val_accuracy: 0.9039\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3291 - accuracy: 0.8955 - val_loss: 0.3452 - val_accuracy: 0.9031\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3506 - accuracy: 0.8874 - val_loss: 0.3700 - val_accuracy: 0.8777\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3661 - accuracy: 0.8848 - val_loss: 0.4222 - val_accuracy: 0.8650\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3867 - accuracy: 0.8784 - val_loss: 0.3342 - val_accuracy: 0.8888\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3855 - accuracy: 0.8797 - val_loss: 0.4245 - val_accuracy: 0.8874\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3929 - accuracy: 0.8786 - val_loss: 0.5032 - val_accuracy: 0.8818\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4158 - accuracy: 0.8737 - val_loss: 0.4048 - val_accuracy: 0.8792\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4174 - accuracy: 0.8742 - val_loss: 0.4840 - val_accuracy: 0.8849\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4206 - accuracy: 0.8717 - val_loss: 0.5050 - val_accuracy: 0.8609\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4200 - accuracy: 0.8750 - val_loss: 0.4326 - val_accuracy: 0.8795\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4154 - accuracy: 0.8733 - val_loss: 0.4022 - val_accuracy: 0.8669\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4246 - accuracy: 0.8714 - val_loss: 0.5637 - val_accuracy: 0.8108\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4459 - accuracy: 0.8678 - val_loss: 0.4420 - val_accuracy: 0.8784\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "The Final CNN has been evolved successfully in the individual net_5\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "Summary of initial CNN\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 16, 16, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 2, 2, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 2, 2, 512)         1180160   \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 1, 1, 512)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4769930 (18.20 MB)\n",
      "Trainable params: 4769930 (18.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fitness of initial CNN: 1.968990445137024\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "Summary of evolved individual\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_399 (Conv2D)         (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_400 (Conv2D)         (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_186 (MaxPool  (None, 16, 16, 64)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " max_pooling2d_187 (MaxPool  (None, 8, 8, 64)          0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_401 (Conv2D)         (None, 8, 8, 256)         147712    \n",
      "                                                                 \n",
      " conv2d_402 (Conv2D)         (None, 8, 8, 128)         295040    \n",
      "                                                                 \n",
      " max_pooling2d_188 (MaxPool  (None, 4, 4, 128)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " flatten_94 (Flatten)        (None, 2048)              0         \n",
      "                                                                 \n",
      " flatten_95 (Flatten)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_95 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 989258 (3.77 MB)\n",
      "Trainable params: 989258 (3.77 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fitness of the evolved individual: 0.44199898838996887\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from random import sample\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)      # suppress messages from Tensorflow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "def initialize_population(population_size, dataset):\n",
    "    print(\"----->Initializing Population\")\n",
    "    daddy = compute_parent(dataset)                                 # load parent from input\n",
    "    population = [daddy]\n",
    "    for it in range(1, population_size):\n",
    "        population.append(daddy.asexual_reproduction(it, dataset))\n",
    "\n",
    "    # sort population on ascending order based on fitness\n",
    "    return sorted(population, key=lambda cnn: cnn.fitness)\n",
    "\n",
    "\n",
    "def selection(k, population, num_population):\n",
    "    if k == 0:                                              # elitism selection\n",
    "        print(\"----->Elitism selection\")\n",
    "        return population[0], population[1]\n",
    "    elif k == 1:                                            # tournament selection\n",
    "        print(\"----->Tournament selection\")\n",
    "        i = randint(0, num_population - 1)\n",
    "        j = i\n",
    "        while j < num_population - 1:\n",
    "            j += 1\n",
    "            if randint(1, 100) <= 50:\n",
    "                return population[i], population[j]\n",
    "        return population[i], population[0]\n",
    "    else:                                                   # proportionate selection\n",
    "        print(\"----->Proportionate selection\")\n",
    "        cum_sum = 0\n",
    "        for i in range(num_population):\n",
    "            cum_sum += population[i].fitness\n",
    "        perc_range = []\n",
    "        for i in range(num_population):\n",
    "            count = 100 - int(100 * population[i].fitness / cum_sum)\n",
    "            for j in range(count):\n",
    "                perc_range.append(i)\n",
    "        i, j = sample(range(1, len(perc_range)), 2)\n",
    "        while i == j:\n",
    "            i, j = sample(range(1, len(perc_range)), 2)\n",
    "        return population[perc_range[i]], population[perc_range[j]]\n",
    "\n",
    "\n",
    "def crossover(parent1, parent2, it):\n",
    "    print(\"----->Crossover\")\n",
    "    child = Network(it)\n",
    "\n",
    "    first, second = None, None\n",
    "    if randint(0, 1):\n",
    "        first = parent1\n",
    "        second = parent2\n",
    "    else:\n",
    "        first = parent2\n",
    "        second = parent1\n",
    "\n",
    "    child.block_list = deepcopy(first.block_list[:randint(1, len(first.block_list) - 1)]) \\\n",
    "                       + deepcopy(second.block_list[randint(1, len(second.block_list) - 1):])\n",
    "\n",
    "    order_indexes(child)                            # order the indexes of the blocks\n",
    "\n",
    "    return child\n",
    "\n",
    "\n",
    "def genetic_algorithm(num_population, num_generation, num_offspring, dataset, early_stopping_generations=3):\n",
    "    print(\"Genetic Algorithm\")\n",
    "\n",
    "    population = initialize_population(num_population, dataset)\n",
    "\n",
    "    print(\"\\n-------------------------------------\")\n",
    "    print(\"Initial Population:\")\n",
    "    for cnn in population:\n",
    "        print(cnn.name, ': ', cnn.fitness)\n",
    "    print(\"--------------------------------------\\n\")\n",
    "\n",
    "    # for printing statistics about fitness and the number of parameters of the best individual\n",
    "    stats = [(population[0].fitness, population[0].model.count_params())]\n",
    "\n",
    "    # Initialize a variable to keep track of consecutive generations with the same best fitness\n",
    "    consecutive_same_fitness = 0\n",
    "\n",
    "    for gen in range(1, num_generation + 1):\n",
    "        '''\n",
    "            k is the selection parameter:\n",
    "                k = 0 -> elitism selection\n",
    "                k = 1 -> tournament selection\n",
    "                k = 2 -> proportionate selection\n",
    "        '''\n",
    "        k = randint(0, 2)\n",
    "\n",
    "        print(\"\\n------------------------------------\")\n",
    "        print(\"Generation -----------------------------------------------------------------------------------\", gen)\n",
    "        print(\"-------------------------------------\")\n",
    "\n",
    "        for c in range(num_offspring):\n",
    "\n",
    "            print(\"\\nCreating Child\", c)\n",
    "\n",
    "            parent1, parent2 = selection(k, population, num_population)                 # selection\n",
    "            print(\"Selected\", parent1.name, \"and\", parent2.name, \"for reproduction\")\n",
    "\n",
    "            child = crossover(parent1, parent2, c + num_population)                     # crossover\n",
    "            print(\"Child has been created\")\n",
    "\n",
    "            print(\"----->Soft Mutation\")\n",
    "            child.layer_mutation(dataset)                                               # mutation\n",
    "            child.parameters_mutation()\n",
    "            print(\"Child has been mutated\")\n",
    "\n",
    "            model = child.build_model()                                                 # evaluation\n",
    "\n",
    "            while model == -1:\n",
    "                child = crossover(parent1, parent2, c + num_population)\n",
    "                child.block_mutation(dataset)\n",
    "                child.layer_mutation(dataset)\n",
    "                child.parameters_mutation()\n",
    "                model = child.build_model()\n",
    "\n",
    "            child.train_and_evaluate(model, dataset)\n",
    "\n",
    "            if child.fitness < population[-1].fitness:                                  # evolve population\n",
    "                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"replaces parent \", end=\"\")\n",
    "                print(population[-1].name, \"with fitness\", population[-1].fitness)\n",
    "                name = population[-1].name\n",
    "\n",
    "                child.save_network(\"child_model_info.pkl\", \"child_model.h5\")\n",
    "                population[-1].load_network(\"child_model_info.pkl\", \"child_model.h5\")\n",
    "\n",
    "                population[-1].name = name\n",
    "                population = sorted(population, key=lambda net: net.fitness)\n",
    "            else:\n",
    "                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"is discarded\")\n",
    "        \n",
    "        if gen >= 3 and all(population[i].fitness == population[i + 1].fitness for i in range(-3, -1)):\n",
    "            consecutive_same_fitness += 1\n",
    "            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n",
    "        if consecutive_same_fitness >= 3:\n",
    "            print(\"Stopping the algorithm as the best fitness has remained the same for the last 3 generations.\")\n",
    "            break\n",
    "    else:\n",
    "        consecutive_same_fitness = 0\n",
    "        \n",
    "       #Check if the best fitness has remained the same for the last early_stopping_generations generations\n",
    "        if all(population[i].fitness == population[i + 1].fitness for i in range(-early_stopping_generations, -1)):\n",
    "            consecutive_same_fitness += 1\n",
    "            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n",
    "            if consecutive_same_fitness == early_stopping_generations:\n",
    "                print(f\"Stopping the algorithm as the best fitness has remained the same for {early_stopping_generations} generations.\")\n",
    "        else:\n",
    "            consecutive_same_fitness = 0\n",
    "        stats.append((population[0].fitness, population[0].model.count_params()))\n",
    "\n",
    "    print(\"\\n\\n-------------------------------------\")\n",
    "    print(\"Final Population\")\n",
    "    print(\"-------------------------------------\\n\")\n",
    "    for cnn in population:\n",
    "        print(cnn.name, ': ', cnn.fitness)\n",
    "\n",
    "    print(\"\\n-------------------------------------\")\n",
    "    print(\"Stats\")\n",
    "    for i in range(len(stats)):\n",
    "        print(\"Best individual at generation\", i + 1, \"has fitness\", stats[i][0], \"and parameters\", stats[i][1])\n",
    "    print(\"-------------------------------------\\n\")\n",
    "\n",
    "    # plot the fitness and the number of parameters of the best individual at each iteration\n",
    "    plot_statistics(stats)\n",
    "\n",
    "    return population[0]\n",
    "\n",
    "import os\n",
    "import cv2  # OpenCV\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def main():    \n",
    "        #with strategy.scope():\n",
    "        #from tensorflow.python.client import device_lib\n",
    "        #print(device_lib.list_local_devices())\n",
    "        #batch_size = 8\n",
    "        #batch_size = batch_size * strategy.num_replicas_in_sync\n",
    "        batch_size = 32                       # the number of training examples in one forward/backward pass\n",
    "        num_classes = 10                       # number of cifar-10 dataset classes\n",
    "        epochs = 30             # number of forward and backward passes of all the training examples\n",
    "        image_size = (32,32) # Adjust this according to your image size\n",
    "        data_dir = '/kaggle/input/fashion-mnist-dataset-images'\n",
    "        '''\n",
    "            dataset contains the hyper parameters for loading data and the dataset:\n",
    "                dataset = {\n",
    "                    'batch_size': batch_size,\n",
    "                    'num_classes': num_classes,\n",
    "                    'epochs': epochs,\n",
    "                    'x_train': x_train,\n",
    "                    'x_test': x_test,\n",
    "                    'y_train': y_train,\n",
    "                    'y_test': y_test\n",
    "                }\n",
    "        '''\n",
    "        #dataset = load_dataset(batch_size, num_classes, epochs)\n",
    "        dataset=load_dataset(batch_size, num_classes, epochs, image_size, data_dir)\n",
    "        num_population = 6\n",
    "        num_generation = 10\n",
    "        num_offspring = 4\n",
    "\n",
    "        # plot the best model obtained\n",
    "        optCNN = genetic_algorithm(num_population, num_generation, num_offspring, dataset)\n",
    "\n",
    "        # plot the training and validation loss and accuracy\n",
    "        num_epoch = 20\n",
    "        model = optCNN.build_model()\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        history = model.fit(dataset['x_train'],\n",
    "                            dataset['y_train'],\n",
    "                            batch_size=dataset['batch_size'],\n",
    "                            epochs=num_epoch,\n",
    "                            validation_data=(dataset['x_test'], dataset['y_test']),\n",
    "                            shuffle=True)\n",
    "        optCNN.model = model                                        # model\n",
    "        optCNN.fitness = history.history['val_loss'][-1]            # fitness\n",
    "\n",
    "        print(\"\\n\\n-------------------------------------\")\n",
    "        print(\"The Final CNN has been evolved successfully in the individual\", optCNN.name)\n",
    "        print(\"-------------------------------------\\n\")\n",
    "        daddy = load_network('parent_0')\n",
    "        model = tf.keras.models.load_model('parent_0.h5')\n",
    "        print(\"\\n\\n-------------------------------------\")\n",
    "        print(\"Summary of initial CNN\")\n",
    "        print(model.summary())\n",
    "        print(\"Fitness of initial CNN:\", daddy.fitness)\n",
    "\n",
    "        print(\"\\n\\n-------------------------------------\")\n",
    "        print(\"Summary of evolved individual\")\n",
    "        print(optCNN.model.summary())\n",
    "        print(\"Fitness of the evolved individual:\", optCNN.fitness)\n",
    "        print(\"-------------------------------------\\n\")\n",
    "\n",
    "        plot_training(history)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84321c11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-03T04:08:29.134232Z",
     "iopub.status.busy": "2024-04-03T04:08:29.133846Z",
     "iopub.status.idle": "2024-04-03T04:08:29.176237Z",
     "shell.execute_reply": "2024-04-03T04:08:29.174886Z",
     "shell.execute_reply.started": "2024-04-03T04:08:29.134195Z"
    },
    "papermill": {
     "duration": 17.655564,
     "end_time": "2024-04-18T11:12:50.180802",
     "exception": false,
     "start_time": "2024-04-18T11:12:32.525238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## To remove a folder\n",
    "# Clear output folder\n",
    "import os\n",
    "\n",
    "def remove_folder_contents(folder):\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                remove_folder_contents(file_path)\n",
    "                os.rmdir(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "folder_path = '/kaggle/working'\n",
    "remove_folder_contents(folder_path)\n",
    "os.rmdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f2e8ab",
   "metadata": {
    "papermill": {
     "duration": 17.865243,
     "end_time": "2024-04-18T11:13:26.098835",
     "exception": false,
     "start_time": "2024-04-18T11:13:08.233592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8b03c1",
   "metadata": {
    "papermill": {
     "duration": 18.060212,
     "end_time": "2024-04-18T11:14:02.028442",
     "exception": false,
     "start_time": "2024-04-18T11:13:43.968230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4755549,
     "sourceId": 8061761,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4822379,
     "sourceId": 8153205,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30637,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13221.165647,
   "end_time": "2024-04-18T11:14:23.745385",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-18T07:34:02.579738",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
