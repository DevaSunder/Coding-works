{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3a2d695",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T16:03:52.529637Z",
     "iopub.status.busy": "2024-02-08T16:03:52.529271Z",
     "iopub.status.idle": "2024-02-08T16:04:05.102454Z",
     "shell.execute_reply": "2024-02-08T16:04:05.101595Z"
    },
    "papermill": {
     "duration": 12.581495,
     "end_time": "2024-02-08T16:04:05.104949",
     "exception": false,
     "start_time": "2024-02-08T16:03:52.523454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd0ee947",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T16:04:05.115508Z",
     "iopub.status.busy": "2024-02-08T16:04:05.114868Z",
     "iopub.status.idle": "2024-02-08T16:04:05.136576Z",
     "shell.execute_reply": "2024-02-08T16:04:05.135646Z"
    },
    "papermill": {
     "duration": 0.029245,
     "end_time": "2024-02-08T16:04:05.138644",
     "exception": false,
     "start_time": "2024-02-08T16:04:05.109399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### UTILITIES\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "import pickle\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def load_dataset(batch_size, num_classes, epochs):\n",
    "    (x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    # Select a random subset of 4500 images for training\n",
    "    random_indices = np.random.choice(len(x_train_full), size=50000, replace=False)\n",
    "    x_train = x_train_full[random_indices]\n",
    "    y_train = y_train_full[random_indices]\n",
    "\n",
    "    # Normalize and one-hot encode the labels\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "    x_test = x_test.astype('float32') / 255\n",
    "    y_train = to_categorical(y_train, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "    # Randomly select 500 images for validation\n",
    "    random_indices = np.random.choice(len(x_test), size=10000, replace=False)\n",
    "    x_val = x_test[random_indices]\n",
    "    y_val = y_test[random_indices]\n",
    "\n",
    "    dataset = {\n",
    "        'batch_size': batch_size,\n",
    "        'num_classes': num_classes,\n",
    "        'epochs': epochs,\n",
    "        'x_train': x_train,\n",
    "        'y_train': y_train,\n",
    "        'x_val': x_val,\n",
    "        'y_val': y_val,\n",
    "        'x_test': x_test,  \n",
    "        'y_test': y_test\n",
    "    }\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def save_network(network):\n",
    "    #object_file = open(network.name + '.obj', 'wb')\n",
    "    #pickle.dump(network, object_file)\n",
    "    #tf.keras.models.save_model(network, network.name)\n",
    "\n",
    "    model_path = network.name + '_model.h5'\n",
    "    tf.keras.models.save_model(network.model, model_path)\n",
    "\n",
    "    # Save the rest of the network information\n",
    "    network_info = {\n",
    "        'name': network.name,\n",
    "        'block_list': network.block_list,\n",
    "        'fitness': network.fitness\n",
    "    }\n",
    "    network_info_path = network.name + '_info.pkl'\n",
    "    with open(network_info_path, 'wb') as info_file:\n",
    "        pickle.dump(network_info, info_file)\n",
    "\n",
    "\n",
    "def load_network(name):\n",
    "    model_path = name + '_model.h5'\n",
    "    loaded_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # Load the network information\n",
    "    info_path = name + '_info.pkl'\n",
    "    with open(info_path, 'rb') as info_file:\n",
    "        network_info = pickle.load(info_file)\n",
    "\n",
    "    # Create a new Network instance\n",
    "    loaded_network = Network(0)  # Update with appropriate 'it' value\n",
    "\n",
    "    # Set the attributes of the loaded network\n",
    "    loaded_network.name = network_info['name']\n",
    "    loaded_network.block_list = network_info['block_list']\n",
    "    loaded_network.fitness = network_info['fitness']\n",
    "    loaded_network.model = loaded_model\n",
    "\n",
    "    return loaded_network\n",
    "\n",
    "\n",
    "\n",
    "def order_indexes(self):\n",
    "    i = 0\n",
    "    for block in self.block_list:\n",
    "        block.index = i\n",
    "        i += 1\n",
    "\n",
    "\n",
    "def plot_training(history):                                           # plot diagnostic learning curves\n",
    "    plt.figure(figsize=[8, 6])  # accuracy curves\n",
    "    plt.plot(history.history['accuracy'], 'r', linewidth=3.0)\n",
    "    plt.plot(history.history['val_accuracy'], 'b', linewidth=3.0)  # <-- Change 'val_acc' to 'val_accuracy'\n",
    "    plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n",
    "    plt.xlabel('Epochs ', fontsize=16)\n",
    "    plt.ylabel('Accuracy', fontsize=16)\n",
    "    plt.title('Accuracy Curves', fontsize=16)\n",
    "\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_acc_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def plot_statistics(stats):\n",
    "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# fitness curves\n",
    "    plt.plot([s[0] for s in stats], 'r', linewidth=3.0)\n",
    "    plt.plot([stats[0][0]] * len(stats), 'b', linewidth=3.0)\n",
    "    plt.legend(['BestFitness', 'InitialFitness'], fontsize=18)\n",
    "    plt.xlabel('Generations', fontsize=16)\n",
    "    plt.ylabel('FitnessValue', fontsize=16)\n",
    "    plt.title('Fitness Curve', fontsize=16)\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_fitness_plot.png')\n",
    "\n",
    "    plt.figure(figsize=[8, 6])\t\t\t\t\t\t\t\t\t\t\t# parameters curves\n",
    "    plt.plot([s[1] for s in stats], 'r', linewidth=3.0)\n",
    "    plt.plot([stats[0][1]] * len(stats), 'b', linewidth=3.0)\n",
    "    plt.legend(['BestParamsNum', 'InitialParamsNum'], fontsize=18)\n",
    "    plt.xlabel('Generations', fontsize=16)\n",
    "    plt.ylabel('ParamsNum', fontsize=16)\n",
    "    plt.title('Parameters Curve', fontsize=16)\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename + '_params_plot.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a1a05c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T16:04:05.148501Z",
     "iopub.status.busy": "2024-02-08T16:04:05.147676Z",
     "iopub.status.idle": "2024-02-08T16:04:05.157673Z",
     "shell.execute_reply": "2024-02-08T16:04:05.156608Z"
    },
    "papermill": {
     "duration": 0.016917,
     "end_time": "2024-02-08T16:04:05.159680",
     "exception": false,
     "start_time": "2024-02-08T16:04:05.142763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "def compute_parent(dataset):\n",
    "    if os.path.isfile('parent_0.h5'):\n",
    "        daddy = load_network('parent_0')\n",
    "        model = tf.keras.models.load_model('parent_0.h5')\n",
    "        print(\"Loading parent_0\")\n",
    "        print(\"SUMMARY OF\", daddy.name)\n",
    "        print(model.summary())\n",
    "        print(\"FITNESS:\", daddy.fitness)\n",
    "        return daddy\n",
    "\n",
    "    daddy = Network(0)\n",
    "\n",
    "    #INI BLOCK\n",
    "    layerList1 = [\n",
    "        Convolutional(filters=32, filter_size=(3, 3), stride_size=(1, 1), padding='same',\n",
    "                      input_shape=dataset['x_train'].shape[1:]),\n",
    "        Convolutional(filters=32, filter_size=(3, 3), stride_size=(1, 1), padding='valid',\n",
    "                      input_shape=dataset['x_train'].shape[1:])\n",
    "    ]\n",
    "    layerList2 = [\n",
    "        Pooling(pool_size=(2, 2), stride_size=(2, 2), padding='same')\n",
    "    ]\n",
    "    daddy.block_list.append(Block(0, 0, layerList1, layerList2))\n",
    "\n",
    "\n",
    "    #FULLY CONNECTED LAYER\n",
    "    layerList1 = [\n",
    "        FullyConnected(units=128, num_classes=dataset['num_classes'])\n",
    "    ]\n",
    "    layerList2 = []\n",
    "    daddy.block_list.append(Block(2, 1, layerList1, layerList2))\n",
    "    \n",
    "    \n",
    "\n",
    "    model = daddy.build_model()\n",
    "    print(\"Type of model_final:\", type(model))\n",
    "    daddy.train_and_evaluate(model, dataset)\n",
    "    return daddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e20f1cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T16:04:05.169318Z",
     "iopub.status.busy": "2024-02-08T16:04:05.169006Z",
     "iopub.status.idle": "2024-02-08T16:04:05.210987Z",
     "shell.execute_reply": "2024-02-08T16:04:05.210199Z"
    },
    "papermill": {
     "duration": 0.049292,
     "end_time": "2024-02-08T16:04:05.212951",
     "exception": false,
     "start_time": "2024-02-08T16:04:05.163659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Sequential\n",
    "from random import randint, choice\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class Network:\n",
    "    __slots__ = ('name', 'block_list', 'fitness', 'model')\n",
    "\n",
    "    def __init__(self, it):\n",
    "        self.name = 'parent_' + str(it) if it == 0 else 'net_' + str(it)\n",
    "        self.block_list = []\n",
    "        self.fitness = None\n",
    "        self.model = None\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()                                # create model\n",
    "        for block in self.block_list:\n",
    "            for layer in block.get_layers():                # build model\n",
    "                try:\n",
    "                    layer.build_layer(model)\n",
    "                except:\n",
    "                    print(\"\\nINDIVIDUAL ABORTED, CREATING A NEW ONE\\n\")\n",
    "                    return -1\n",
    "        return model\n",
    "\n",
    "    def train_and_evaluate(self, model, dataset):\n",
    "        print(\"Training\", self.name)\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        history = model.fit(dataset['x_train'],\n",
    "                            dataset['y_train'],\n",
    "                            batch_size=dataset['batch_size'],\n",
    "                            epochs=dataset['epochs'],\n",
    "                            validation_data=(dataset['x_val'], dataset['y_val']),\n",
    "                            shuffle=True)\n",
    "\n",
    "        # Extract metrics from the training history\n",
    "        training_loss = history.history['loss'][-1]\n",
    "        training_accuracy = history.history['accuracy'][-1]\n",
    "        validation_loss = history.history['val_loss'][-1]\n",
    "        validation_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "        # Additional metrics (you can customize this based on your needs)\n",
    "        classification_error_rate = 1.0 - validation_accuracy\n",
    "\n",
    "        self.model = model  # Save the model\n",
    "        self.fitness = validation_loss  # Use validation loss as fitness\n",
    "\n",
    "        # Print metrics\n",
    "        print(\"SUMMARY OF\", self.name)\n",
    "        print(\"Training Loss:\", training_loss)\n",
    "        print(\"Training Accuracy:\", training_accuracy)\n",
    "        print(\"Validation Loss:\", validation_loss)\n",
    "        print(\"Validation Accuracy:\", validation_accuracy)\n",
    "        print(\"Classification Error Rate:\", classification_error_rate)\n",
    "\n",
    "        tf.keras.models.save_model(model, self.name + '.h5')         # save model\n",
    "        #model.save(self.name + '.h5')                       # save model\n",
    "        save_network(self)                                  # save topology, model and fitness\n",
    "\n",
    "    def asexual_reproduction(self, it, dataset):\n",
    "\n",
    "        # if the individual already exists, just load it\n",
    "        if os.path.isfile('net_' + str(it) + '.h5'):\n",
    "            print(\"\\n-------------------------------------\")\n",
    "            print(\"Loading individual net_\" + str(it))\n",
    "            print(\"--------------------------------------\\n\")\n",
    "            individual = load_network('net_' + str(it))\n",
    "            model = tf.keras.models.load_model(individual.name + '.h5')\n",
    "            print(\"SUMMARY OF\", individual.name)\n",
    "            print(model.summary())\n",
    "            print(\"FITNESS: \", individual.fitness)\n",
    "            return individual\n",
    "\n",
    "        # otherwise, create the individual by mutating the parent\n",
    "        individual = Network(it)\n",
    "\n",
    "        print(\"\\n-------------------------------------\")\n",
    "        print(\"\\nCreating individual\", individual.name)\n",
    "        print(\"--------------------------------------\\n\")\n",
    "\n",
    "        individual.block_list = deepcopy(self.block_list)           # copy the layer list from parent\n",
    "\n",
    "        print(\"----->Strong Mutation\")\n",
    "        individual.block_mutation(dataset)                          # mutate a block\n",
    "        individual.layer_mutation(dataset)                          # mutate a layer\n",
    "        individual.parameters_mutation()                            # mutate some parameters\n",
    "\n",
    "        model = individual.build_model()\n",
    "\n",
    "        if model == -1:\n",
    "            return self.asexual_reproduction(it, dataset)\n",
    "\n",
    "        individual.train_and_evaluate(model, dataset)\n",
    "\n",
    "        return individual\n",
    "\n",
    "    def block_mutation(self, dataset):\n",
    "        print(\"Block Mutation\")\n",
    "\n",
    "        print([(block.index, block.type) for block in self.block_list])\n",
    "\n",
    "        # block list containing all the blocks with type = 1\n",
    "        bl = [block.index for block in self.block_list if block.type == 1]\n",
    "\n",
    "        if len(bl) == 0:\n",
    "            print(\"Creating a new block with two Convolutional layers and a Pooling layer\")\n",
    "            self.block_list[1].index = 2\n",
    "            layerList1 = [\n",
    "                Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                              filter_size=(3, 3),\n",
    "                              stride_size=(1, 1),\n",
    "                              padding='same',\n",
    "                              input_shape=dataset['x_train'].shape[1:]),\n",
    "                Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                              filter_size=(3, 3),\n",
    "                              stride_size=(1, 1),\n",
    "                              padding='same',\n",
    "                              input_shape=dataset['x_train'].shape[1:])\n",
    "            ]\n",
    "            layerList2 = [\n",
    "                Pooling(pool_size=(2, 2),\n",
    "                        stride_size=(2, 2),\n",
    "                        padding='same')\n",
    "            ]\n",
    "            b = Block(1, 1, layerList1, layerList2)\n",
    "            self.block_list.insert(1, b)\n",
    "            return\n",
    "\n",
    "        block_idx = randint(1, max(bl))         # pick a random block among all the blocks with type = 1\n",
    "        block_type_idx = randint(0, 1)          # 1 -> Conv2D; 0 -> Pooling or Dropout\n",
    "        mutation_type = randint(0, 1)           # 1 -> remove; 0 -> add\n",
    "\n",
    "        # list of layers of the selected block\n",
    "        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
    "        length = len(layerList)\n",
    "\n",
    "        if mutation_type:                                       # remove\n",
    "            if length == 1:\n",
    "                del self.block_list[block_idx]\n",
    "            elif block_type_idx:\n",
    "                pos = randint(0, length - 1)\n",
    "                print(\"Removing a Conv2D layer at\", pos)\n",
    "                del layerList[pos]\n",
    "            else:\n",
    "                pos = randint(0, length - 1)\n",
    "                print(\"Removing a Pooling/Dropout layer at\", pos)\n",
    "                del layerList[pos]\n",
    "        else:                                                   # add\n",
    "            if block_type_idx:\n",
    "                print(\"Inserting a Convolutional layer\")\n",
    "                layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                      filter_size=(3, 3),\n",
    "                                      stride_size=(1, 1),\n",
    "                                      padding='same',\n",
    "                                      input_shape=dataset['x_train'].shape[1:])\n",
    "                layerList.insert(randint(0, length - 1), layer)\n",
    "            else:\n",
    "                if randint(0, 1):                               # 1 -> Pooling; 0 -> Dropout\n",
    "                    print(\"Inserting a Pooling layer\")\n",
    "                    layer = Pooling(pool_size=(2, 2),\n",
    "                                    stride_size=(2, 2),\n",
    "                                    padding='same')\n",
    "                    layerList.insert(randint(0, length - 1), layer)\n",
    "                else:\n",
    "                    print(\"Inserting a Dropout layer\")\n",
    "                    rate = choice([0.15, 0.25, 0.35, 0.50])\n",
    "                    layer = Dropout(rate=rate)\n",
    "                    layerList.insert(randint(0, length - 1), layer)\n",
    "\n",
    "    def layer_mutation(self, dataset):\n",
    "        print(\"Layer Mutation\")\n",
    "\n",
    "        # pick a random block among all the blocks with type = 1\n",
    "        bl = [block.index for block in self.block_list if block.type == 1]\n",
    "\n",
    "        if len(bl) == 0:\n",
    "            return\n",
    "\n",
    "        block_idx = randint(1, max(bl))\n",
    "        block_type_idx = randint(0, 1)      # 1 -> Conv2D; 0 -> Pooling or Dropout\n",
    "\n",
    "        # list of layers of the selected block\n",
    "        layerList = self.block_list[block_idx].layerList1 if block_type_idx else self.block_list[block_idx].layerList2\n",
    "\n",
    "        if len(layerList) == 0:\n",
    "            if block_type_idx:\n",
    "                layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                      filter_size=(3, 3),\n",
    "                                      stride_size=(1, 1),\n",
    "                                      padding='same',\n",
    "                                      input_shape=dataset['x_train'].shape[1:])\n",
    "                self.block_list[block_idx].layerList1.append(layer)\n",
    "                return\n",
    "            else:\n",
    "                layer = Pooling(pool_size=(2, 2),\n",
    "                                stride_size=(2, 2),\n",
    "                                padding='same')\n",
    "                self.block_list[block_idx].layerList2.append(layer)\n",
    "\n",
    "        idx = randint(0, len(layerList) - 1)\n",
    "        layer = layerList[idx]\n",
    "\n",
    "        if layer.name == 'Conv2D':\n",
    "            print(\"Splitting Conv2D layer at index\", idx)\n",
    "            layer.filters = int(layer.filters * 0.5)\n",
    "            layerList.insert(idx, deepcopy(layer))\n",
    "        elif layer.name == 'MaxPooling2D' or layer.name == 'AveragePooling2D':\n",
    "            print(\"Changing Pooling layer at index\", idx, \"with Conv2D layer\")\n",
    "            del layerList[idx]\n",
    "            conv_layer = Convolutional(filters=pow(2, randint(5, 8)),\n",
    "                                       filter_size=(3, 3),\n",
    "                                       stride_size=(2, 2),\n",
    "                                       padding=layer.padding,\n",
    "                                       input_shape=dataset['x_train'].shape[1:])\n",
    "            layerList.insert(idx, conv_layer)\n",
    "\n",
    "    def parameters_mutation(self):\n",
    "        print(\"Parameters Mutation\")\n",
    "        for block in self.block_list:\n",
    "            for layer in block.get_layers():\n",
    "                if randint(0, 1):\n",
    "                    layer.mutate_parameters()\n",
    "\n",
    "    def save_network_info(self, info_filename):\n",
    "        network_info = {\n",
    "            'name': self.name,\n",
    "            'block_list': self.block_list,\n",
    "            'fitness': self.fitness\n",
    "        }\n",
    "\n",
    "        with open(info_filename, 'wb') as info_file:\n",
    "            pickle.dump(network_info, info_file)\n",
    "\n",
    "    def load_network_info(self, info_filename):\n",
    "        with open(info_filename, 'rb') as info_file:\n",
    "            network_info = pickle.load(info_file)\n",
    "\n",
    "        self.name = network_info['name']\n",
    "        self.block_list = network_info['block_list']\n",
    "        self.fitness = network_info['fitness']\n",
    "\n",
    "    def save_model(self, model_filename):\n",
    "        self.model.save(model_filename)\n",
    "\n",
    "    def load_model(self, model_filename):\n",
    "        self.model = tf.keras.models.load_model(model_filename)\n",
    "\n",
    "    def save_network(self, network_info_filename, model_filename):\n",
    "        # Save non-model attributes\n",
    "        self.save_network_info(network_info_filename)\n",
    "\n",
    "        # Save the model separately\n",
    "        self.save_model(model_filename)\n",
    "\n",
    "    def load_network(self, network_info_filename, model_filename):\n",
    "        # Load non-model attributes\n",
    "        self.load_network_info(network_info_filename)\n",
    "\n",
    "        # Load the model separately\n",
    "        self.load_model(model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0de2dece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T16:04:05.222533Z",
     "iopub.status.busy": "2024-02-08T16:04:05.222228Z",
     "iopub.status.idle": "2024-02-08T16:04:05.254127Z",
     "shell.execute_reply": "2024-02-08T16:04:05.253053Z"
    },
    "papermill": {
     "duration": 0.039255,
     "end_time": "2024-02-08T16:04:05.256363",
     "exception": false,
     "start_time": "2024-02-08T16:04:05.217108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras.layers\n",
    "from random import randint\n",
    "\n",
    "\n",
    "class Block:\n",
    "\t__slots__ = ('type', 'index', 'layerList1', 'layerList2')\n",
    "\n",
    "\tdef __init__(self, type, index, layerList1, layerList2):\n",
    "\t\tself.type = type\t\t\t\t\t\t\t\t\t\t# 0 -> initial layer; 1 -> mid layers; 2 -> final layer\n",
    "\t\tself.index = index\t\t\t\t\t\t\t\t\t\t# block index among all the blocks\n",
    "\t\tself.layerList1 = layerList1\t\t\t\t\t\t\t# Convolutional layers\n",
    "\t\tself.layerList2 = layerList2\t\t\t\t\t\t\t# Pooling and Dropout layers\n",
    "\n",
    "\tdef get_layers(self):\n",
    "\t\treturn self.layerList1 + self.layerList2\n",
    "\n",
    "\tdef get_size(self):\n",
    "\t\treturn len(self.get_layers())\n",
    "\n",
    "\n",
    "class Convolutional:\n",
    "\t# __slots__ = ('name', 'filters', 'padding', 'filter_size', 'stride_size', 'input_shape')\n",
    "\n",
    "\tdef __init__(self, filters, padding, filter_size, stride_size, input_shape):\n",
    "\t\tself.name = 'Conv2D'\n",
    "\t\tself.filters = filters\n",
    "\t\tself.padding = padding\n",
    "\t\tself.filter_size = filter_size\n",
    "\t\tself.stride_size = stride_size\n",
    "\t\tself.input_shape = input_shape\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\tmodel.add(keras.layers.Conv2D(filters=self.filters,\n",
    "\t\t\t\t\t\t\t\t\t   kernel_size=self.filter_size,\n",
    "\t\t\t\t\t\t\t\t\t   strides=self.stride_size,\n",
    "\t\t\t\t\t\t\t\t\t   padding=self.padding,\n",
    "\t\t\t\t\t\t\t\t\t   activation='relu',\n",
    "\t\t\t\t\t\t\t\t\t   kernel_initializer='he_uniform',\n",
    "\t\t\t\t\t\t\t\t\t   input_shape=self.input_shape))\n",
    "\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tmutation = randint(0, 4)\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tif mutation == 0 and self.filters >= 32:\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters = int(self.filters / 2)\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 1 and self.filters >= 32:\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters = int(self.filters / 2)\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 2 and self.filters <= 512:\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters *= 2\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 3 and self.filters <= 512:\n",
    "\t\t\tprint(\"-->changed self.filters from \", self.filters, \" \", end=\"\")\n",
    "\t\t\tself.filters *= 2\n",
    "\t\t\tprint(\"to \", self.filters)\n",
    "\t\telif mutation == 4:\n",
    "\t\t\tif self.padding == 'valid':\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'same'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'valid'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\n",
    "\n",
    "'''\n",
    "elif mutation is 4:\n",
    "\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n",
    "\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n",
    "\tprint(\"to \", self.stride_size, \" and \", end=\"\")\n",
    "\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n",
    "\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n",
    "\tprint(\"to \", self.stride_size)\n",
    "'''\n",
    "\n",
    "\n",
    "class Pooling:\n",
    "\t__slots__ = ('name', 'pool_size', 'stride_size', 'padding')\n",
    "\n",
    "\tdef __init__(self, pool_size, stride_size, padding):\n",
    "\t\tself.name = 'MaxPooling2D'\n",
    "\t\tself.pool_size = pool_size\n",
    "\t\tself.stride_size = stride_size\n",
    "\t\tself.padding = padding\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\tif self.name == 'MaxPooling2D':\n",
    "\t\t\tmodel.add(keras.layers.MaxPooling2D(self.pool_size, self.stride_size, self.padding))\n",
    "\t\telif self.name == 'AveragePooling2D':\n",
    "\t\t\tmodel.add(keras.layers.AveragePooling2D(self.pool_size, self.stride_size, self.padding))\n",
    "\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tmutation = randint(0, 1)\n",
    "\t\tif mutation == 0:\n",
    "\t\t\tif self.padding == 'valid':\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'same'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"-->changed self.padding from \", self.padding, \" \", end=\"\")\n",
    "\t\t\t\tself.padding = 'valid'\n",
    "\t\t\t\tprint(\"to \", self.padding)\n",
    "\t\telif mutation == 1:\n",
    "\t\t\tif self.name == 'MaxPooling2D':\n",
    "\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n",
    "\t\t\t\tself.name = 'AveragePooling2D'\n",
    "\t\t\t\tprint(\"to \", self.name)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"-->changed self.name from \", self.name, \" \", end=\"\")\n",
    "\t\t\t\tself.name = 'MaxPooling2D'\n",
    "\t\t\t\tprint(\"to \", self.name)\n",
    "\n",
    "\n",
    "'''\n",
    "if mutation is 0:\n",
    "\tprint(\"changed self.stride_size from \", self.stride_size, \" \", end=\"\")\n",
    "\tself.stride_size = (self.stride_size[0] + 1, self.stride_size[1] + 1)\n",
    "\tprint(\"to \", self.stride_size)\n",
    "'''\n",
    "\n",
    "\n",
    "class FullyConnected:\n",
    "\t__slots__ = ('name', 'units', 'num_classes')\n",
    "\n",
    "\tdef __init__(self, units, num_classes):\n",
    "\t\tself.name = \"FullyConnected\"\n",
    "\t\tself.units = units\n",
    "\t\tself.num_classes = num_classes\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\tmodel.add(keras.layers.Flatten())\n",
    "\t\tmodel.add(keras.layers.Dense(self.units, activation='relu', kernel_initializer='he_uniform'))\n",
    "\t\tmodel.add(keras.layers.Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tmutation = randint(0, 2)\n",
    "\t\tif mutation == 0:\n",
    "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
    "\t\t\tself.units *= 2\n",
    "\t\t\tprint(\"to \", self.units)\n",
    "\t\telif mutation == 1:\n",
    "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
    "\t\t\tself.units *= 2\n",
    "\t\t\tprint(\"to \", self.units)\n",
    "\t\telif mutation == 2:\n",
    "\t\t\tprint(\"-->changed self.units from \", self.units, \" \", end=\"\")\n",
    "\t\t\tself.units /= 2\n",
    "\t\t\tprint(\"to \", self.units)\n",
    "\n",
    "\n",
    "'''\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(self.num_classes, activation='softmax'))\n",
    "'''\n",
    "\n",
    "\n",
    "class Dropout:\n",
    "\t__slots__ = ('name', 'rate')\n",
    "\n",
    "\tdef __init__(self, rate):\n",
    "\t\tself.name = \"Dropout\"\n",
    "\t\tself.rate = rate\n",
    "\n",
    "\tdef build_layer(self, model):\n",
    "\t\tmodel.add(keras.layers.Dropout(self.rate))\n",
    "\n",
    "\tdef mutate_parameters(self):\n",
    "\t\tprint(\"Mutating\", self.name, \"layer:\")\n",
    "\t\tmutation = randint(0, 3)\n",
    "\t\tif mutation == 0 and self.rate <= 0.85:\n",
    "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate + 0.10\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\t\telif mutation == 1 and self.rate <= 0.90:\n",
    "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate + 0.05\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\t\telif mutation == 2 and self.rate >= 0.15:\n",
    "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate - 0.10\n",
    "\t\t\tprint(\"to \", self.rate)\n",
    "\t\telif mutation == 3 and self.rate >= 0.10:\n",
    "\t\t\tprint(\"-->changed self.rate from \", self.rate, \" \", end=\"\")\n",
    "\t\t\tself.rate = self.rate - 0.05\n",
    "\t\t\tprint(\"to \", self.rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f754d23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T16:04:05.266460Z",
     "iopub.status.busy": "2024-02-08T16:04:05.266090Z",
     "iopub.status.idle": "2024-02-08T19:38:45.597161Z",
     "shell.execute_reply": "2024-02-08T19:38:45.596219Z"
    },
    "papermill": {
     "duration": 12880.338876,
     "end_time": "2024-02-08T19:38:45.599466",
     "exception": false,
     "start_time": "2024-02-08T16:04:05.260590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 6s 0us/step\n",
      "Genetic Algorithm\n",
      "----->Initializing Population\n",
      "Type of model_final: <class 'keras.src.engine.sequential.Sequential'>\n",
      "Training parent_0\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 10s 5ms/step - loss: 1.4046 - accuracy: 0.5099 - val_loss: 1.1539 - val_accuracy: 0.5929\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9993 - accuracy: 0.6549 - val_loss: 1.1265 - val_accuracy: 0.6372\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7857 - accuracy: 0.7294 - val_loss: 1.1745 - val_accuracy: 0.6391\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6224 - accuracy: 0.7854 - val_loss: 1.2493 - val_accuracy: 0.6602\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4782 - accuracy: 0.8352 - val_loss: 1.3867 - val_accuracy: 0.6422\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3713 - accuracy: 0.8722 - val_loss: 1.6466 - val_accuracy: 0.6298\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2870 - accuracy: 0.9024 - val_loss: 1.8905 - val_accuracy: 0.6382\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2314 - accuracy: 0.9231 - val_loss: 2.2528 - val_accuracy: 0.6484\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1944 - accuracy: 0.9356 - val_loss: 2.5147 - val_accuracy: 0.6480\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1798 - accuracy: 0.9428 - val_loss: 2.6268 - val_accuracy: 0.6354\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1539 - accuracy: 0.9515 - val_loss: 3.1809 - val_accuracy: 0.6347\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1435 - accuracy: 0.9561 - val_loss: 3.4195 - val_accuracy: 0.6361\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1377 - accuracy: 0.9588 - val_loss: 3.6430 - val_accuracy: 0.6361\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1401 - accuracy: 0.9596 - val_loss: 3.6162 - val_accuracy: 0.6334\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1332 - accuracy: 0.9629 - val_loss: 3.8250 - val_accuracy: 0.6376\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1363 - accuracy: 0.9645 - val_loss: 4.2499 - val_accuracy: 0.6355\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1282 - accuracy: 0.9663 - val_loss: 4.2810 - val_accuracy: 0.6290\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1313 - accuracy: 0.9659 - val_loss: 4.6263 - val_accuracy: 0.6275\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1199 - accuracy: 0.9705 - val_loss: 4.8073 - val_accuracy: 0.6332\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1190 - accuracy: 0.9705 - val_loss: 5.0904 - val_accuracy: 0.6332\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1178 - accuracy: 0.9732 - val_loss: 6.0944 - val_accuracy: 0.6383\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1293 - accuracy: 0.9708 - val_loss: 5.4828 - val_accuracy: 0.6300\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1135 - accuracy: 0.9742 - val_loss: 5.9226 - val_accuracy: 0.6249\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1133 - accuracy: 0.9744 - val_loss: 5.7931 - val_accuracy: 0.6424\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1135 - accuracy: 0.9755 - val_loss: 6.3659 - val_accuracy: 0.6412\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1116 - accuracy: 0.9758 - val_loss: 6.8702 - val_accuracy: 0.6329\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1253 - accuracy: 0.9758 - val_loss: 6.6852 - val_accuracy: 0.6351\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1109 - accuracy: 0.9780 - val_loss: 7.3851 - val_accuracy: 0.6320\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1122 - accuracy: 0.9783 - val_loss: 7.4672 - val_accuracy: 0.6401\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1069 - accuracy: 0.9795 - val_loss: 7.6602 - val_accuracy: 0.6421\n",
      "SUMMARY OF parent_0\n",
      "Training Loss: 0.10690493136644363\n",
      "Training Accuracy: 0.9795200228691101\n",
      "Validation Loss: 7.66024923324585\n",
      "Validation Accuracy: 0.6420999765396118\n",
      "Classification Error Rate: 0.3579000234603882\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_1\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 2)]\n",
      "Creating a new block with two Convolutional layers and a Pooling layer\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 1\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26/481395509.py:61: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model, self.name + '.h5')         # save model\n",
      "/tmp/ipykernel_26/3966292378.py:50: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(network.model, model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training net_1\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 10s 5ms/step - loss: 2.0873 - accuracy: 0.2822 - val_loss: 2.1011 - val_accuracy: 0.2704\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.9035 - accuracy: 0.3368 - val_loss: 2.4197 - val_accuracy: 0.2935\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.9837 - accuracy: 0.3393 - val_loss: 2.4673 - val_accuracy: 0.2593\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.1719 - accuracy: 0.2935 - val_loss: 3.2152 - val_accuracy: 0.1962\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.2726 - accuracy: 0.2450 - val_loss: 2.6501 - val_accuracy: 0.1324\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.2952 - accuracy: 0.1849 - val_loss: 2.9035 - val_accuracy: 0.1110\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.4805 - accuracy: 0.1438 - val_loss: 3.0471 - val_accuracy: 0.1065\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3952 - accuracy: 0.1033 - val_loss: 3.2642 - val_accuracy: 0.1003\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.4164 - accuracy: 0.0991 - val_loss: 2.5207 - val_accuracy: 0.1001\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3494 - accuracy: 0.0961 - val_loss: 2.4942 - val_accuracy: 0.0998\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3465 - accuracy: 0.0967 - val_loss: 2.4167 - val_accuracy: 0.0998\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3278 - accuracy: 0.0982 - val_loss: 2.4219 - val_accuracy: 0.1001\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3388 - accuracy: 0.0999 - val_loss: 2.3957 - val_accuracy: 0.0999\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3219 - accuracy: 0.0984 - val_loss: 2.4088 - val_accuracy: 0.1001\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3267 - accuracy: 0.0986 - val_loss: 2.3870 - val_accuracy: 0.1001\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3203 - accuracy: 0.0984 - val_loss: 2.3721 - val_accuracy: 0.1000\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3154 - accuracy: 0.0976 - val_loss: 2.3471 - val_accuracy: 0.1003\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.4296 - accuracy: 0.0978 - val_loss: 2.3445 - val_accuracy: 0.0998\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3090 - accuracy: 0.0966 - val_loss: 2.3380 - val_accuracy: 0.1002\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3081 - accuracy: 0.0994 - val_loss: 2.3426 - val_accuracy: 0.1002\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3110 - accuracy: 0.0981 - val_loss: 2.3416 - val_accuracy: 0.0998\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3136 - accuracy: 0.0980 - val_loss: 2.3323 - val_accuracy: 0.0996\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3101 - accuracy: 0.0976 - val_loss: 2.3142 - val_accuracy: 0.0998\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3047 - accuracy: 0.0964 - val_loss: 2.3071 - val_accuracy: 0.1000\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3053 - accuracy: 0.0981 - val_loss: 2.3040 - val_accuracy: 0.1000\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3030 - accuracy: 0.0987 - val_loss: 2.3062 - val_accuracy: 0.1001\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3040 - accuracy: 0.0981 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3030 - accuracy: 0.0983 - val_loss: 2.3031 - val_accuracy: 0.1001\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3032 - val_accuracy: 0.1001\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3028 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "SUMMARY OF net_1\n",
      "Training Loss: 2.3028275966644287\n",
      "Training Accuracy: 0.09809999912977219\n",
      "Validation Loss: 2.302645206451416\n",
      "Validation Accuracy: 0.10000000149011612\n",
      "Classification Error Rate: 0.8999999985098839\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_2\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 2)]\n",
      "Creating a new block with two Convolutional layers and a Pooling layer\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 1\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "Training net_2\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 11s 5ms/step - loss: 2.3825 - accuracy: 0.0978 - val_loss: 2.3028 - val_accuracy: 0.1001\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3054 - accuracy: 0.0988 - val_loss: 2.3045 - val_accuracy: 0.1009\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3308 - accuracy: 0.0958 - val_loss: 2.3025 - val_accuracy: 0.1002\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3162 - accuracy: 0.0997 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3092 - accuracy: 0.0989 - val_loss: 2.3023 - val_accuracy: 0.1003\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3169 - accuracy: 0.0994 - val_loss: 2.3024 - val_accuracy: 0.1002\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3319 - accuracy: 0.1002 - val_loss: 2.3033 - val_accuracy: 0.1003\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3347 - accuracy: 0.0986 - val_loss: 2.3019 - val_accuracy: 0.1003\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3096 - accuracy: 0.0978 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3130 - accuracy: 0.0967 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3071 - accuracy: 0.0973 - val_loss: 2.3070 - val_accuracy: 0.1003\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3036 - accuracy: 0.0990 - val_loss: 2.3029 - val_accuracy: 0.1003\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3037 - accuracy: 0.0990 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3029 - accuracy: 0.0960 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3045 - accuracy: 0.0982 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3026 - accuracy: 0.1000 - val_loss: 2.3022 - val_accuracy: 0.1002\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3032 - accuracy: 0.0989 - val_loss: 2.3022 - val_accuracy: 0.1002\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3026 - accuracy: 0.1013 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0973 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0981 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0980 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0983 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0975 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0955 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0968 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0982 - val_loss: 2.3024 - val_accuracy: 0.1001\n",
      "SUMMARY OF net_2\n",
      "Training Loss: 2.302708625793457\n",
      "Training Accuracy: 0.09815999865531921\n",
      "Validation Loss: 2.302428722381592\n",
      "Validation Accuracy: 0.10010000318288803\n",
      "Classification Error Rate: 0.899899996817112\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_3\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 2)]\n",
      "Creating a new block with two Convolutional layers and a Pooling layer\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  256\n",
      "Training net_3\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 10s 5ms/step - loss: 2.9537 - accuracy: 0.1869 - val_loss: 1.8925 - val_accuracy: 0.2837\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9122 - accuracy: 0.2833 - val_loss: 1.8736 - val_accuracy: 0.3053\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.8845 - accuracy: 0.2949 - val_loss: 1.8889 - val_accuracy: 0.2878\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9253 - accuracy: 0.2800 - val_loss: 1.9596 - val_accuracy: 0.2373\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.1704 - accuracy: 0.2090 - val_loss: 11.5756 - val_accuracy: 0.1349\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.2802 - accuracy: 0.1570 - val_loss: 2.6580 - val_accuracy: 0.1209\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.4665 - accuracy: 0.1053 - val_loss: 2.3037 - val_accuracy: 0.1000\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3030 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0994 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.1000 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3027 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3027 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3027 - accuracy: 0.0990 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3027 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0964 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "SUMMARY OF net_3\n",
      "Training Loss: 2.3027427196502686\n",
      "Training Accuracy: 0.09641999751329422\n",
      "Validation Loss: 2.3026223182678223\n",
      "Validation Accuracy: 0.10000000149011612\n",
      "Classification Error Rate: 0.8999999985098839\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_4\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 2)]\n",
      "Creating a new block with two Convolutional layers and a Pooling layer\n",
      "Layer Mutation\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128  to  64.0\n",
      "Training net_4\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 10s 5ms/step - loss: 1.6210 - accuracy: 0.4371 - val_loss: 1.4618 - val_accuracy: 0.4834\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2997 - accuracy: 0.5529 - val_loss: 1.3160 - val_accuracy: 0.5343\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2454 - accuracy: 0.5803 - val_loss: 1.2849 - val_accuracy: 0.5524\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2433 - accuracy: 0.5851 - val_loss: 1.6617 - val_accuracy: 0.4157\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2733 - accuracy: 0.5778 - val_loss: 1.6954 - val_accuracy: 0.4941\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2670 - accuracy: 0.5821 - val_loss: 1.4161 - val_accuracy: 0.5182\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2490 - accuracy: 0.5827 - val_loss: 1.4174 - val_accuracy: 0.5286\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2501 - accuracy: 0.5835 - val_loss: 1.7055 - val_accuracy: 0.4281\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2396 - accuracy: 0.5893 - val_loss: 1.5318 - val_accuracy: 0.4684\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2229 - accuracy: 0.5945 - val_loss: 1.7248 - val_accuracy: 0.3661\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2209 - accuracy: 0.5973 - val_loss: 1.4784 - val_accuracy: 0.5767\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2447 - accuracy: 0.5948 - val_loss: 1.3319 - val_accuracy: 0.5632\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2542 - accuracy: 0.5931 - val_loss: 1.4310 - val_accuracy: 0.5046\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2717 - accuracy: 0.5886 - val_loss: 2.5445 - val_accuracy: 0.4660\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2862 - accuracy: 0.5851 - val_loss: 1.7055 - val_accuracy: 0.4954\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3155 - accuracy: 0.5804 - val_loss: 1.5648 - val_accuracy: 0.4871\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3451 - accuracy: 0.5699 - val_loss: 1.8720 - val_accuracy: 0.4612\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4072 - accuracy: 0.5551 - val_loss: 1.6386 - val_accuracy: 0.4937\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4650 - accuracy: 0.5424 - val_loss: 1.5767 - val_accuracy: 0.5353\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5119 - accuracy: 0.5239 - val_loss: 1.7764 - val_accuracy: 0.4730\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6326 - accuracy: 0.4785 - val_loss: 1.8682 - val_accuracy: 0.4082\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.7078 - accuracy: 0.4468 - val_loss: 1.6786 - val_accuracy: 0.4698\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.6834 - accuracy: 0.4452 - val_loss: 1.8793 - val_accuracy: 0.3383\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7797 - accuracy: 0.4074 - val_loss: 2.4401 - val_accuracy: 0.4195\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7962 - accuracy: 0.4084 - val_loss: 1.9019 - val_accuracy: 0.4105\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.8919 - accuracy: 0.3502 - val_loss: 1.8271 - val_accuracy: 0.3331\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.8147 - accuracy: 0.3546 - val_loss: 2.6636 - val_accuracy: 0.2839\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.8015 - accuracy: 0.3553 - val_loss: 1.7571 - val_accuracy: 0.3266\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8481 - accuracy: 0.3450 - val_loss: 1.7550 - val_accuracy: 0.3380\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7976 - accuracy: 0.3510 - val_loss: 1.7795 - val_accuracy: 0.3437\n",
      "SUMMARY OF net_4\n",
      "Training Loss: 1.7976362705230713\n",
      "Training Accuracy: 0.35100001096725464\n",
      "Validation Loss: 1.7794898748397827\n",
      "Validation Accuracy: 0.34369999170303345\n",
      "Classification Error Rate: 0.6563000082969666\n",
      "\n",
      "-------------------------------------\n",
      "\n",
      "Creating individual net_5\n",
      "--------------------------------------\n",
      "\n",
      "----->Strong Mutation\n",
      "Block Mutation\n",
      "[(0, 0), (1, 2)]\n",
      "Creating a new block with two Convolutional layers and a Pooling layer\n",
      "Layer Mutation\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Training net_5\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 11s 6ms/step - loss: 1.8293 - accuracy: 0.3559 - val_loss: 1.6918 - val_accuracy: 0.3933\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5670 - accuracy: 0.4615 - val_loss: 1.9244 - val_accuracy: 0.3590\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5402 - accuracy: 0.4739 - val_loss: 1.8252 - val_accuracy: 0.3598\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.6402 - accuracy: 0.4536 - val_loss: 2.2478 - val_accuracy: 0.3230\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7589 - accuracy: 0.4422 - val_loss: 2.2725 - val_accuracy: 0.3358\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7361 - accuracy: 0.4218 - val_loss: 3.1538 - val_accuracy: 0.3192\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.9796 - accuracy: 0.4017 - val_loss: 2.4583 - val_accuracy: 0.2593\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 3.0062 - accuracy: 0.3479 - val_loss: 24.2584 - val_accuracy: 0.2001\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 3.0302 - accuracy: 0.2789 - val_loss: 3.8746 - val_accuracy: 0.1803\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.5501 - accuracy: 0.2304 - val_loss: 3.1716 - val_accuracy: 0.1951\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 2.6134 - accuracy: 0.1568 - val_loss: 2.4087 - val_accuracy: 0.1580\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.1708 - accuracy: 0.1662 - val_loss: 2.3187 - val_accuracy: 0.1532\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.2180 - accuracy: 0.1697 - val_loss: 2.2017 - val_accuracy: 0.1531\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.2322 - accuracy: 0.1763 - val_loss: 2.6293 - val_accuracy: 0.1787\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.1368 - accuracy: 0.1802 - val_loss: 2.1497 - val_accuracy: 0.1702\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.2343 - accuracy: 0.1854 - val_loss: 2.2143 - val_accuracy: 0.1718\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.1656 - accuracy: 0.1803 - val_loss: 2.1689 - val_accuracy: 0.1740\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.2511 - accuracy: 0.1797 - val_loss: 2.0694 - val_accuracy: 0.1661\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 2.7530 - accuracy: 0.1799 - val_loss: 2.3414 - val_accuracy: 0.1170\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.4436 - accuracy: 0.1806 - val_loss: 3.5815 - val_accuracy: 0.1570\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.5645 - accuracy: 0.1780 - val_loss: 3.1827 - val_accuracy: 0.1889\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 2.9622 - accuracy: 0.1668 - val_loss: 2.3599 - val_accuracy: 0.1238\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 2.4167 - accuracy: 0.1669 - val_loss: 2.3565 - val_accuracy: 0.1120\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.4215 - accuracy: 0.1579 - val_loss: 5.7093 - val_accuracy: 0.1047\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.5315 - accuracy: 0.1147 - val_loss: 2.3053 - val_accuracy: 0.1000\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3034 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 2.3028 - accuracy: 0.0990 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 2.3028 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.3028 - accuracy: 0.0971 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 2.3028 - accuracy: 0.0973 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "SUMMARY OF net_5\n",
      "Training Loss: 2.3027970790863037\n",
      "Training Accuracy: 0.09731999784708023\n",
      "Validation Loss: 2.3026084899902344\n",
      "Validation Accuracy: 0.10000000149011612\n",
      "Classification Error Rate: 0.8999999985098839\n",
      "\n",
      "-------------------------------------\n",
      "Initial Population:\n",
      "net_4 :  1.7794898748397827\n",
      "net_2 :  2.302428722381592\n",
      "net_5 :  2.3026084899902344\n",
      "net_3 :  2.3026223182678223\n",
      "net_1 :  2.302645206451416\n",
      "parent_0 :  7.66024923324585\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 1\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_4 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Child has been mutated\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 8s 4ms/step - loss: 1.6389 - accuracy: 0.4235 - val_loss: 1.3877 - val_accuracy: 0.5204\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1891 - accuracy: 0.5845 - val_loss: 1.2176 - val_accuracy: 0.5790\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0486 - accuracy: 0.6357 - val_loss: 1.1857 - val_accuracy: 0.6006\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9596 - accuracy: 0.6674 - val_loss: 1.3130 - val_accuracy: 0.5857\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8982 - accuracy: 0.6894 - val_loss: 1.1809 - val_accuracy: 0.6147\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8441 - accuracy: 0.7060 - val_loss: 1.2335 - val_accuracy: 0.6218\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7922 - accuracy: 0.7267 - val_loss: 1.3162 - val_accuracy: 0.6217\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7444 - accuracy: 0.7423 - val_loss: 1.3339 - val_accuracy: 0.6148\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7011 - accuracy: 0.7573 - val_loss: 1.4742 - val_accuracy: 0.6211\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6694 - accuracy: 0.7716 - val_loss: 1.5307 - val_accuracy: 0.6156\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6353 - accuracy: 0.7840 - val_loss: 1.5186 - val_accuracy: 0.6222\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6072 - accuracy: 0.7947 - val_loss: 1.6751 - val_accuracy: 0.6182\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5783 - accuracy: 0.8043 - val_loss: 1.7848 - val_accuracy: 0.6043\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5483 - accuracy: 0.8136 - val_loss: 1.7765 - val_accuracy: 0.6136\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5239 - accuracy: 0.8234 - val_loss: 1.8147 - val_accuracy: 0.6128\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5190 - accuracy: 0.8289 - val_loss: 1.9553 - val_accuracy: 0.6063\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5010 - accuracy: 0.8348 - val_loss: 2.1757 - val_accuracy: 0.6198\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4722 - accuracy: 0.8427 - val_loss: 2.3370 - val_accuracy: 0.5986\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4599 - accuracy: 0.8484 - val_loss: 2.5037 - val_accuracy: 0.6155\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4504 - accuracy: 0.8530 - val_loss: 2.6965 - val_accuracy: 0.6050\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4330 - accuracy: 0.8597 - val_loss: 2.6823 - val_accuracy: 0.6113\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4239 - accuracy: 0.8628 - val_loss: 2.7026 - val_accuracy: 0.6062\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3954 - accuracy: 0.8694 - val_loss: 2.7250 - val_accuracy: 0.5998\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3998 - accuracy: 0.8733 - val_loss: 2.7441 - val_accuracy: 0.6073\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4018 - accuracy: 0.8729 - val_loss: 3.0284 - val_accuracy: 0.5919\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3739 - accuracy: 0.8802 - val_loss: 3.6985 - val_accuracy: 0.5997\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3832 - accuracy: 0.8820 - val_loss: 3.2866 - val_accuracy: 0.6034\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3629 - accuracy: 0.8867 - val_loss: 3.3997 - val_accuracy: 0.6064\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3502 - accuracy: 0.8907 - val_loss: 3.3903 - val_accuracy: 0.5932\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3465 - accuracy: 0.8936 - val_loss: 4.1055 - val_accuracy: 0.5994\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 0.3465002775192261\n",
      "Training Accuracy: 0.8936200141906738\n",
      "Validation Loss: 4.105468273162842\n",
      "Validation Accuracy: 0.599399983882904\n",
      "Classification Error Rate: 0.40060001611709595\n",
      "----->Evolution: Child net_6 with fitness 4.105468273162842 replaces parent parent_0 with fitness 7.66024923324585\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_4 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 1\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  128.0\n",
      "Child has been mutated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training net_7\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 13s 6ms/step - loss: 2.3314 - accuracy: 0.0986 - val_loss: 2.3029 - val_accuracy: 0.0999\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3027 - val_accuracy: 0.1001\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.3101 - accuracy: 0.1009 - val_loss: 2.2711 - val_accuracy: 0.1547\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.8173 - accuracy: 0.3441 - val_loss: 1.7141 - val_accuracy: 0.3741\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6319 - accuracy: 0.4123 - val_loss: 1.7097 - val_accuracy: 0.3727\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5782 - accuracy: 0.4316 - val_loss: 1.6621 - val_accuracy: 0.4035\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5782 - accuracy: 0.4346 - val_loss: 1.9308 - val_accuracy: 0.3509\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5830 - accuracy: 0.4341 - val_loss: 1.6943 - val_accuracy: 0.4001\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5792 - accuracy: 0.4351 - val_loss: 1.7585 - val_accuracy: 0.3690\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5747 - accuracy: 0.4357 - val_loss: 1.7801 - val_accuracy: 0.3574\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5813 - accuracy: 0.4355 - val_loss: 1.9619 - val_accuracy: 0.3460\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6247 - accuracy: 0.4254 - val_loss: 1.6889 - val_accuracy: 0.3943\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6009 - accuracy: 0.4285 - val_loss: 1.8312 - val_accuracy: 0.3705\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6182 - accuracy: 0.4187 - val_loss: 1.9538 - val_accuracy: 0.3266\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6219 - accuracy: 0.4182 - val_loss: 1.7279 - val_accuracy: 0.3726\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6150 - accuracy: 0.4170 - val_loss: 1.5716 - val_accuracy: 0.4240\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5974 - accuracy: 0.4239 - val_loss: 1.7242 - val_accuracy: 0.3766\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5978 - accuracy: 0.4265 - val_loss: 1.6623 - val_accuracy: 0.4105\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5855 - accuracy: 0.4257 - val_loss: 1.7583 - val_accuracy: 0.3761\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6163 - accuracy: 0.4195 - val_loss: 1.6055 - val_accuracy: 0.4235\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6108 - accuracy: 0.4207 - val_loss: 1.6312 - val_accuracy: 0.4127\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6551 - accuracy: 0.4050 - val_loss: 2.4751 - val_accuracy: 0.2587\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6431 - accuracy: 0.4020 - val_loss: 1.7493 - val_accuracy: 0.4069\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6302 - accuracy: 0.4158 - val_loss: 1.5831 - val_accuracy: 0.4121\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6041 - accuracy: 0.4174 - val_loss: 1.6354 - val_accuracy: 0.4012\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6340 - accuracy: 0.4073 - val_loss: 1.6196 - val_accuracy: 0.4109\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6217 - accuracy: 0.4144 - val_loss: 1.9633 - val_accuracy: 0.3755\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6023 - accuracy: 0.4181 - val_loss: 1.9958 - val_accuracy: 0.2724\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6091 - accuracy: 0.4222 - val_loss: 1.6717 - val_accuracy: 0.3883\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6514 - accuracy: 0.3942 - val_loss: 1.8010 - val_accuracy: 0.3460\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 1.6513681411743164\n",
      "Training Accuracy: 0.39419999718666077\n",
      "Validation Loss: 1.8009968996047974\n",
      "Validation Accuracy: 0.34599998593330383\n",
      "Classification Error Rate: 0.6540000140666962\n",
      "----->Evolution: Child net_7 with fitness 1.8009968996047974 replaces parent parent_0 with fitness 4.105468273162842\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_4 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  128.0\n",
      "Child has been mutated\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 13s 6ms/step - loss: 1.8073 - accuracy: 0.3416 - val_loss: 1.7787 - val_accuracy: 0.3670\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5310 - accuracy: 0.4546 - val_loss: 1.7290 - val_accuracy: 0.4073\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4821 - accuracy: 0.4751 - val_loss: 1.5921 - val_accuracy: 0.4241\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4641 - accuracy: 0.4835 - val_loss: 2.0440 - val_accuracy: 0.3683\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4570 - accuracy: 0.4852 - val_loss: 1.7412 - val_accuracy: 0.3837\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4394 - accuracy: 0.4967 - val_loss: 1.9518 - val_accuracy: 0.3423\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4336 - accuracy: 0.4988 - val_loss: 2.6120 - val_accuracy: 0.2639\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4353 - accuracy: 0.4993 - val_loss: 2.0529 - val_accuracy: 0.3534\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4114 - accuracy: 0.5120 - val_loss: 1.9185 - val_accuracy: 0.3613\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4262 - accuracy: 0.5109 - val_loss: 1.8059 - val_accuracy: 0.4099\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4487 - accuracy: 0.5148 - val_loss: 2.4846 - val_accuracy: 0.3072\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4298 - accuracy: 0.5108 - val_loss: 1.8116 - val_accuracy: 0.3779\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5103 - accuracy: 0.5014 - val_loss: 1.8990 - val_accuracy: 0.3755\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4987 - accuracy: 0.4991 - val_loss: 2.0874 - val_accuracy: 0.3412\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4882 - accuracy: 0.4926 - val_loss: 1.4068 - val_accuracy: 0.4905\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4857 - accuracy: 0.5030 - val_loss: 2.0147 - val_accuracy: 0.3645\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5059 - accuracy: 0.5042 - val_loss: 1.8470 - val_accuracy: 0.4651\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.5255 - accuracy: 0.4923 - val_loss: 2.2707 - val_accuracy: 0.3233\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 6.3639 - accuracy: 0.4858 - val_loss: 1.9745 - val_accuracy: 0.3710\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.9005 - accuracy: 0.4823 - val_loss: 2.2447 - val_accuracy: 0.3502\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6465 - accuracy: 0.4766 - val_loss: 1.7428 - val_accuracy: 0.4301\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.7491 - accuracy: 0.4638 - val_loss: 4.0533 - val_accuracy: 0.3641\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.2286 - accuracy: 0.4301 - val_loss: 2.9661 - val_accuracy: 0.2734\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1727 - accuracy: 0.4464 - val_loss: 2.2076 - val_accuracy: 0.3602\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.9164 - accuracy: 0.4344 - val_loss: 4.9525 - val_accuracy: 0.3730\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0476 - accuracy: 0.4393 - val_loss: 2.1016 - val_accuracy: 0.3900\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1412 - accuracy: 0.4273 - val_loss: 4.0048 - val_accuracy: 0.3901\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 4.4408 - accuracy: 0.4139 - val_loss: 4.5837 - val_accuracy: 0.3158\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 3.8504 - accuracy: 0.3839 - val_loss: 2.6726 - val_accuracy: 0.2227\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 5.0424 - accuracy: 0.3710 - val_loss: 2.4992 - val_accuracy: 0.2839\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 5.042375087738037\n",
      "Training Accuracy: 0.370959997177124\n",
      "Validation Loss: 2.4992268085479736\n",
      "Validation Accuracy: 0.2838999927043915\n",
      "Classification Error Rate: 0.7161000072956085\n",
      "----->Evolution: Child net_8 with fitness 2.4992268085479736 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_4 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  64.0\n",
      "Child has been mutated\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.4663 - accuracy: 0.4862 - val_loss: 1.2722 - val_accuracy: 0.5536\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0754 - accuracy: 0.6270 - val_loss: 1.1497 - val_accuracy: 0.6070\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9191 - accuracy: 0.6827 - val_loss: 1.1360 - val_accuracy: 0.6146\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7961 - accuracy: 0.7271 - val_loss: 1.2454 - val_accuracy: 0.6212\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6946 - accuracy: 0.7630 - val_loss: 1.2718 - val_accuracy: 0.6156\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6105 - accuracy: 0.7892 - val_loss: 1.4944 - val_accuracy: 0.6213\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5373 - accuracy: 0.8154 - val_loss: 1.5646 - val_accuracy: 0.6243\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4759 - accuracy: 0.8391 - val_loss: 1.6564 - val_accuracy: 0.6311\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4195 - accuracy: 0.8578 - val_loss: 1.7649 - val_accuracy: 0.6348\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3794 - accuracy: 0.8729 - val_loss: 2.0454 - val_accuracy: 0.6290\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3369 - accuracy: 0.8875 - val_loss: 2.1345 - val_accuracy: 0.6252\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3055 - accuracy: 0.8982 - val_loss: 2.2878 - val_accuracy: 0.6195\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2894 - accuracy: 0.9041 - val_loss: 2.6427 - val_accuracy: 0.6143\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2680 - accuracy: 0.9118 - val_loss: 2.7984 - val_accuracy: 0.6116\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2463 - accuracy: 0.9200 - val_loss: 3.1043 - val_accuracy: 0.6186\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2509 - accuracy: 0.9217 - val_loss: 3.4448 - val_accuracy: 0.6211\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2266 - accuracy: 0.9289 - val_loss: 3.5012 - val_accuracy: 0.6055\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2327 - accuracy: 0.9291 - val_loss: 3.9266 - val_accuracy: 0.6099\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2223 - accuracy: 0.9336 - val_loss: 3.8348 - val_accuracy: 0.6074\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2197 - accuracy: 0.9358 - val_loss: 4.3804 - val_accuracy: 0.6133\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2049 - accuracy: 0.9413 - val_loss: 5.0582 - val_accuracy: 0.6146\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2100 - accuracy: 0.9417 - val_loss: 4.6855 - val_accuracy: 0.5921\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2111 - accuracy: 0.9441 - val_loss: 5.1411 - val_accuracy: 0.6016\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1989 - accuracy: 0.9468 - val_loss: 5.5100 - val_accuracy: 0.6033\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1963 - accuracy: 0.9484 - val_loss: 5.4989 - val_accuracy: 0.6126\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1994 - accuracy: 0.9484 - val_loss: 5.5609 - val_accuracy: 0.6020\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1926 - accuracy: 0.9510 - val_loss: 6.1969 - val_accuracy: 0.6104\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1896 - accuracy: 0.9529 - val_loss: 6.2229 - val_accuracy: 0.6124\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1927 - accuracy: 0.9526 - val_loss: 5.9452 - val_accuracy: 0.5941\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1850 - accuracy: 0.9553 - val_loss: 6.4160 - val_accuracy: 0.6151\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 0.18497581779956818\n",
      "Training Accuracy: 0.9553400278091431\n",
      "Validation Loss: 6.416022300720215\n",
      "Validation Accuracy: 0.6151000261306763\n",
      "Classification Error Rate: 0.38489997386932373\n",
      "----->Evolution: Child net_9 with fitness 6.416022300720215 is discarded\n",
      "\n",
      "Creating Child 4\n",
      "----->Elitism selection\n",
      "Selected net_4 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  128.0\n",
      "Child has been mutated\n",
      "Training net_10\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 12s 6ms/step - loss: 1.7293 - accuracy: 0.3978 - val_loss: 1.7024 - val_accuracy: 0.4282\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5009 - accuracy: 0.4808 - val_loss: 1.5118 - val_accuracy: 0.4764\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4964 - accuracy: 0.4885 - val_loss: 1.7697 - val_accuracy: 0.4451\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4501 - accuracy: 0.5053 - val_loss: 1.8133 - val_accuracy: 0.3809\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3755 - accuracy: 0.5290 - val_loss: 1.7688 - val_accuracy: 0.5011\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4055 - accuracy: 0.5271 - val_loss: 2.2006 - val_accuracy: 0.3440\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4000 - accuracy: 0.5309 - val_loss: 1.8353 - val_accuracy: 0.4094\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4099 - accuracy: 0.5254 - val_loss: 1.8959 - val_accuracy: 0.3950\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4605 - accuracy: 0.5160 - val_loss: 3.1048 - val_accuracy: 0.2850\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5689 - accuracy: 0.5068 - val_loss: 2.4385 - val_accuracy: 0.3320\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5642 - accuracy: 0.4813 - val_loss: 1.8686 - val_accuracy: 0.4381\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6104 - accuracy: 0.4684 - val_loss: 2.0255 - val_accuracy: 0.3809\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6599 - accuracy: 0.4554 - val_loss: 2.5969 - val_accuracy: 0.2547\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7287 - accuracy: 0.4379 - val_loss: 2.4411 - val_accuracy: 0.3640\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7054 - accuracy: 0.4264 - val_loss: 1.9494 - val_accuracy: 0.3577\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7212 - accuracy: 0.4247 - val_loss: 2.2023 - val_accuracy: 0.3227\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.8369 - accuracy: 0.4257 - val_loss: 2.0507 - val_accuracy: 0.3826\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7047 - accuracy: 0.4119 - val_loss: 2.1794 - val_accuracy: 0.2975\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.7165 - accuracy: 0.4174 - val_loss: 2.1698 - val_accuracy: 0.3210\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7238 - accuracy: 0.4136 - val_loss: 1.7314 - val_accuracy: 0.4356\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7331 - accuracy: 0.4149 - val_loss: 2.5937 - val_accuracy: 0.3251\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7384 - accuracy: 0.4011 - val_loss: 1.6556 - val_accuracy: 0.3800\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7466 - accuracy: 0.3974 - val_loss: 1.8190 - val_accuracy: 0.4129\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7183 - accuracy: 0.3995 - val_loss: 1.7326 - val_accuracy: 0.3199\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7740 - accuracy: 0.3675 - val_loss: 2.1946 - val_accuracy: 0.2720\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.8776 - accuracy: 0.3533 - val_loss: 1.9659 - val_accuracy: 0.2769\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.8356 - accuracy: 0.3481 - val_loss: 2.0235 - val_accuracy: 0.2583\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.7927 - accuracy: 0.3471 - val_loss: 1.7873 - val_accuracy: 0.3580\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.8528 - accuracy: 0.3354 - val_loss: 1.6469 - val_accuracy: 0.3622\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.9249 - accuracy: 0.3365 - val_loss: 1.8270 - val_accuracy: 0.2941\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 1.9249389171600342\n",
      "Training Accuracy: 0.3364599943161011\n",
      "Validation Loss: 1.8270263671875\n",
      "Validation Accuracy: 0.29409998655319214\n",
      "Classification Error Rate: 0.7059000134468079\n",
      "----->Evolution: Child net_10 with fitness 1.8270263671875 replaces parent net_1 with fitness 2.302645206451416\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 2\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Proportionate selection\n",
      "Selected net_5 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Child has been mutated\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 8s 4ms/step - loss: 1.5934 - accuracy: 0.4402 - val_loss: 1.4669 - val_accuracy: 0.4880\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2583 - accuracy: 0.5600 - val_loss: 1.3599 - val_accuracy: 0.5309\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1078 - accuracy: 0.6176 - val_loss: 1.3376 - val_accuracy: 0.5540\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9983 - accuracy: 0.6563 - val_loss: 1.3391 - val_accuracy: 0.5683\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8866 - accuracy: 0.6939 - val_loss: 1.4460 - val_accuracy: 0.5726\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7905 - accuracy: 0.7290 - val_loss: 1.5724 - val_accuracy: 0.5314\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6950 - accuracy: 0.7627 - val_loss: 1.7546 - val_accuracy: 0.5514\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6149 - accuracy: 0.7911 - val_loss: 1.9502 - val_accuracy: 0.5575\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5402 - accuracy: 0.8159 - val_loss: 2.0283 - val_accuracy: 0.5534\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4818 - accuracy: 0.8393 - val_loss: 2.3673 - val_accuracy: 0.5439\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4332 - accuracy: 0.8557 - val_loss: 2.7500 - val_accuracy: 0.5320\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3884 - accuracy: 0.8708 - val_loss: 3.0245 - val_accuracy: 0.5515\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3460 - accuracy: 0.8863 - val_loss: 3.1736 - val_accuracy: 0.5488\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3231 - accuracy: 0.8953 - val_loss: 3.2622 - val_accuracy: 0.5372\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2933 - accuracy: 0.9051 - val_loss: 3.4943 - val_accuracy: 0.5326\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2775 - accuracy: 0.9129 - val_loss: 4.2122 - val_accuracy: 0.5448\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2607 - accuracy: 0.9194 - val_loss: 4.5506 - val_accuracy: 0.5461\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2541 - accuracy: 0.9235 - val_loss: 4.8132 - val_accuracy: 0.5494\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2435 - accuracy: 0.9279 - val_loss: 4.8917 - val_accuracy: 0.5461\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2245 - accuracy: 0.9338 - val_loss: 5.3679 - val_accuracy: 0.5517\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2208 - accuracy: 0.9353 - val_loss: 5.6769 - val_accuracy: 0.5315\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2084 - accuracy: 0.9410 - val_loss: 6.0491 - val_accuracy: 0.5449\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2058 - accuracy: 0.9442 - val_loss: 6.4615 - val_accuracy: 0.5404\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2046 - accuracy: 0.9467 - val_loss: 7.0922 - val_accuracy: 0.5434\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2016 - accuracy: 0.9481 - val_loss: 7.2604 - val_accuracy: 0.5446\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1891 - accuracy: 0.9504 - val_loss: 7.9720 - val_accuracy: 0.5362\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1820 - accuracy: 0.9534 - val_loss: 8.1141 - val_accuracy: 0.5478\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1907 - accuracy: 0.9518 - val_loss: 7.8449 - val_accuracy: 0.5390\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1834 - accuracy: 0.9550 - val_loss: 8.1223 - val_accuracy: 0.5404\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1802 - accuracy: 0.9581 - val_loss: 8.7181 - val_accuracy: 0.5394\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 0.1801983267068863\n",
      "Training Accuracy: 0.9581000208854675\n",
      "Validation Loss: 8.718060493469238\n",
      "Validation Accuracy: 0.5393999814987183\n",
      "Classification Error Rate: 0.46060001850128174\n",
      "----->Evolution: Child net_6 with fitness 8.718060493469238 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Proportionate selection\n",
      "Selected parent_0 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 1\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Child has been mutated\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 11s 6ms/step - loss: 2.5804 - accuracy: 0.0992 - val_loss: 2.3056 - val_accuracy: 0.0999\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3081 - accuracy: 0.0979 - val_loss: 3.8963 - val_accuracy: 0.1007\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3149 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1002\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3271 - accuracy: 0.0991 - val_loss: 5.2325 - val_accuracy: 0.1043\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3221 - accuracy: 0.0973 - val_loss: 5.5129 - val_accuracy: 0.0875\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.4133 - accuracy: 0.0979 - val_loss: 6.8990 - val_accuracy: 0.1014\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3449 - accuracy: 0.0974 - val_loss: 2.3029 - val_accuracy: 0.0999\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3029 - accuracy: 0.0972 - val_loss: 2.3180 - val_accuracy: 0.1026\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3029 - accuracy: 0.0992 - val_loss: 3.6588 - val_accuracy: 0.0888\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 2.3041 - accuracy: 0.0991 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3522 - accuracy: 0.0982 - val_loss: 2.3032 - val_accuracy: 0.1002\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3080 - accuracy: 0.0992 - val_loss: 2.3286 - val_accuracy: 0.1008\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3040 - accuracy: 0.0999 - val_loss: 2.3032 - val_accuracy: 0.0998\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.3029 - accuracy: 0.0981 - val_loss: 2.3040 - val_accuracy: 0.0992\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.4442 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.0997\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3438 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3221 - accuracy: 0.0972 - val_loss: 2.3040 - val_accuracy: 0.1002\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3340 - accuracy: 0.0998 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3424 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3415 - accuracy: 0.0990 - val_loss: 2.3272 - val_accuracy: 0.1001\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3410 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3350 - accuracy: 0.0972 - val_loss: 2.3517 - val_accuracy: 0.1003\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 2.3044 - accuracy: 0.0992 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0987 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0974 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0973 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0962 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 2.3027520179748535\n",
      "Training Accuracy: 0.09623999893665314\n",
      "Validation Loss: 2.3026280403137207\n",
      "Validation Accuracy: 0.10000000149011612\n",
      "Classification Error Rate: 0.8999999985098839\n",
      "----->Evolution: Child net_7 with fitness 2.3026280403137207 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Proportionate selection\n",
      "Selected net_4 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  128.0\n",
      "Child has been mutated\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 11s 6ms/step - loss: 1.7519 - accuracy: 0.4061 - val_loss: 2.4698 - val_accuracy: 0.3404\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4724 - accuracy: 0.4935 - val_loss: 1.7587 - val_accuracy: 0.3749\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5284 - accuracy: 0.4854 - val_loss: 2.1355 - val_accuracy: 0.3188\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5479 - accuracy: 0.4666 - val_loss: 1.9335 - val_accuracy: 0.4204\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5857 - accuracy: 0.4552 - val_loss: 2.0787 - val_accuracy: 0.3279\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6742 - accuracy: 0.4419 - val_loss: 1.8757 - val_accuracy: 0.3403\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6462 - accuracy: 0.4419 - val_loss: 2.4107 - val_accuracy: 0.3241\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6648 - accuracy: 0.4262 - val_loss: 2.0707 - val_accuracy: 0.2464\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7888 - accuracy: 0.3968 - val_loss: 2.1131 - val_accuracy: 0.2686\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.1823 - accuracy: 0.2769 - val_loss: 2.1402 - val_accuracy: 0.1720\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.5556 - accuracy: 0.1244 - val_loss: 2.3055 - val_accuracy: 0.1000\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3033 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 2.3028 - accuracy: 0.0972 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0971 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0968 - val_loss: 10.5401 - val_accuracy: 0.1125\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3262 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0981 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 2.3028 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0990 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0991 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0986 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0948 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0990 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0973 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 2.3027729988098145\n",
      "Training Accuracy: 0.09764000028371811\n",
      "Validation Loss: 2.30263352394104\n",
      "Validation Accuracy: 0.10000000149011612\n",
      "Classification Error Rate: 0.8999999985098839\n",
      "----->Evolution: Child net_8 with fitness 2.30263352394104 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Proportionate selection\n",
      "Selected parent_0 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  256.0\n",
      "Child has been mutated\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 13s 7ms/step - loss: 1.8013 - accuracy: 0.3459 - val_loss: 1.5795 - val_accuracy: 0.4349\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4957 - accuracy: 0.4697 - val_loss: 1.7365 - val_accuracy: 0.4005\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4245 - accuracy: 0.4992 - val_loss: 1.6602 - val_accuracy: 0.4427\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3911 - accuracy: 0.5154 - val_loss: 1.8672 - val_accuracy: 0.4144\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3649 - accuracy: 0.5299 - val_loss: 1.3294 - val_accuracy: 0.5493\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3477 - accuracy: 0.5387 - val_loss: 3.1341 - val_accuracy: 0.3881\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3457 - accuracy: 0.5433 - val_loss: 1.6717 - val_accuracy: 0.4096\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3548 - accuracy: 0.5446 - val_loss: 2.2471 - val_accuracy: 0.3953\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5088 - accuracy: 0.5465 - val_loss: 1.5071 - val_accuracy: 0.4910\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3870 - accuracy: 0.5428 - val_loss: 1.6254 - val_accuracy: 0.4584\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3864 - accuracy: 0.5464 - val_loss: 1.4353 - val_accuracy: 0.4788\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4616 - accuracy: 0.5364 - val_loss: 9.9944 - val_accuracy: 0.3632\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5359 - accuracy: 0.5262 - val_loss: 1.6455 - val_accuracy: 0.4549\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5258 - accuracy: 0.5150 - val_loss: 1.5271 - val_accuracy: 0.4817\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.7109 - accuracy: 0.5132 - val_loss: 1.7013 - val_accuracy: 0.4702\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7475 - accuracy: 0.4957 - val_loss: 1.6339 - val_accuracy: 0.4566\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6583 - accuracy: 0.4993 - val_loss: 1.5457 - val_accuracy: 0.4914\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6255 - accuracy: 0.5094 - val_loss: 3.0708 - val_accuracy: 0.3573\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.7917 - accuracy: 0.4949 - val_loss: 1.8192 - val_accuracy: 0.4183\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.9316 - accuracy: 0.4930 - val_loss: 5.3641 - val_accuracy: 0.4683\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6358 - accuracy: 0.4981 - val_loss: 2.2820 - val_accuracy: 0.3629\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6596 - accuracy: 0.4853 - val_loss: 2.0181 - val_accuracy: 0.4922\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0725 - accuracy: 0.4696 - val_loss: 2.2508 - val_accuracy: 0.3662\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0649 - accuracy: 0.4587 - val_loss: 1.5587 - val_accuracy: 0.4690\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.8822 - accuracy: 0.4255 - val_loss: 7.1326 - val_accuracy: 0.1460\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 3.9704 - accuracy: 0.2905 - val_loss: 2.3802 - val_accuracy: 0.1936\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1352 - accuracy: 0.2588 - val_loss: 2.0628 - val_accuracy: 0.2344\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 3.7178 - accuracy: 0.2203 - val_loss: 1.9483 - val_accuracy: 0.2244\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.1826 - accuracy: 0.2103 - val_loss: 1.9175 - val_accuracy: 0.2193\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.6194 - accuracy: 0.2147 - val_loss: 10.1125 - val_accuracy: 0.2349\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 2.619384288787842\n",
      "Training Accuracy: 0.21466000378131866\n",
      "Validation Loss: 10.112462043762207\n",
      "Validation Accuracy: 0.23489999771118164\n",
      "Classification Error Rate: 0.7651000022888184\n",
      "----->Evolution: Child net_9 with fitness 10.112462043762207 is discarded\n",
      "\n",
      "Creating Child 4\n",
      "----->Proportionate selection\n",
      "Selected net_1 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Child has been mutated\n",
      "\n",
      "INDIVIDUAL ABORTED, CREATING A NEW ONE\n",
      "\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 2)]\n",
      "Inserting a Pooling layer\n",
      "Layer Mutation\n",
      "Changing Pooling layer at index 1 with Conv2D layer\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  64.0\n",
      "Training net_10\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 11s 6ms/step - loss: 1.5082 - accuracy: 0.4617 - val_loss: 1.6597 - val_accuracy: 0.4592\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1252 - accuracy: 0.6057 - val_loss: 1.1895 - val_accuracy: 0.5916\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0087 - accuracy: 0.6513 - val_loss: 1.3053 - val_accuracy: 0.5714\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9713 - accuracy: 0.6689 - val_loss: 1.1396 - val_accuracy: 0.6218\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9515 - accuracy: 0.6802 - val_loss: 1.2137 - val_accuracy: 0.5975\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9553 - accuracy: 0.6797 - val_loss: 1.3291 - val_accuracy: 0.6011\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9645 - accuracy: 0.6795 - val_loss: 1.1450 - val_accuracy: 0.6052\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0064 - accuracy: 0.6659 - val_loss: 1.4137 - val_accuracy: 0.5505\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0045 - accuracy: 0.6670 - val_loss: 1.2388 - val_accuracy: 0.6273\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0124 - accuracy: 0.6646 - val_loss: 1.3279 - val_accuracy: 0.5862\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0283 - accuracy: 0.6621 - val_loss: 1.2593 - val_accuracy: 0.5883\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0216 - accuracy: 0.6659 - val_loss: 1.3834 - val_accuracy: 0.5362\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0308 - accuracy: 0.6655 - val_loss: 1.7396 - val_accuracy: 0.4775\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0326 - accuracy: 0.6650 - val_loss: 1.4239 - val_accuracy: 0.5140\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0249 - accuracy: 0.6639 - val_loss: 1.7841 - val_accuracy: 0.4833\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0893 - accuracy: 0.6616 - val_loss: 1.3456 - val_accuracy: 0.5646\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1745 - accuracy: 0.6622 - val_loss: 1.4236 - val_accuracy: 0.5549\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2589 - accuracy: 0.6545 - val_loss: 2.0231 - val_accuracy: 0.4824\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1421 - accuracy: 0.6502 - val_loss: 2.0057 - val_accuracy: 0.5296\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2081 - accuracy: 0.6441 - val_loss: 2.1617 - val_accuracy: 0.4958\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2432 - accuracy: 0.6406 - val_loss: 2.7007 - val_accuracy: 0.4768\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2340 - accuracy: 0.6360 - val_loss: 2.4968 - val_accuracy: 0.4353\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2305 - accuracy: 0.6243 - val_loss: 3.7684 - val_accuracy: 0.4701\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4450 - accuracy: 0.6194 - val_loss: 1.9407 - val_accuracy: 0.4797\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2770 - accuracy: 0.6121 - val_loss: 2.1614 - val_accuracy: 0.5213\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3742 - accuracy: 0.5956 - val_loss: 2.8845 - val_accuracy: 0.5014\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4299 - accuracy: 0.5910 - val_loss: 2.7232 - val_accuracy: 0.3135\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5438 - accuracy: 0.5828 - val_loss: 3.2917 - val_accuracy: 0.3784\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5725 - accuracy: 0.5751 - val_loss: 2.6158 - val_accuracy: 0.4076\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4532 - accuracy: 0.5611 - val_loss: 5.5003 - val_accuracy: 0.3689\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 1.4532254934310913\n",
      "Training Accuracy: 0.5611199736595154\n",
      "Validation Loss: 5.500341415405273\n",
      "Validation Accuracy: 0.36890000104904175\n",
      "Classification Error Rate: 0.6310999989509583\n",
      "----->Evolution: Child net_10 with fitness 5.500341415405273 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 3\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Tournament selection\n",
      "Selected parent_0 and net_2 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  128.0\n",
      "Child has been mutated\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 8s 4ms/step - loss: 1.4849 - accuracy: 0.4740 - val_loss: 1.4434 - val_accuracy: 0.4890\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1156 - accuracy: 0.6113 - val_loss: 1.1268 - val_accuracy: 0.5995\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9558 - accuracy: 0.6663 - val_loss: 1.0278 - val_accuracy: 0.6410\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.8430 - accuracy: 0.7070 - val_loss: 0.9911 - val_accuracy: 0.6572\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.7447 - accuracy: 0.7407 - val_loss: 1.0226 - val_accuracy: 0.6533\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6557 - accuracy: 0.7736 - val_loss: 1.0520 - val_accuracy: 0.6568\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5766 - accuracy: 0.8018 - val_loss: 1.1282 - val_accuracy: 0.6548\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4979 - accuracy: 0.8295 - val_loss: 1.1951 - val_accuracy: 0.6549\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4296 - accuracy: 0.8534 - val_loss: 1.4006 - val_accuracy: 0.6311\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3658 - accuracy: 0.8782 - val_loss: 1.4524 - val_accuracy: 0.6333\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3090 - accuracy: 0.8960 - val_loss: 1.4935 - val_accuracy: 0.6400\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2582 - accuracy: 0.9140 - val_loss: 1.6637 - val_accuracy: 0.6284\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2182 - accuracy: 0.9272 - val_loss: 1.8252 - val_accuracy: 0.6429\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1843 - accuracy: 0.9375 - val_loss: 1.8987 - val_accuracy: 0.6388\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1562 - accuracy: 0.9467 - val_loss: 2.2358 - val_accuracy: 0.6301\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1347 - accuracy: 0.9555 - val_loss: 2.3752 - val_accuracy: 0.6305\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1178 - accuracy: 0.9601 - val_loss: 2.5035 - val_accuracy: 0.6233\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1016 - accuracy: 0.9648 - val_loss: 2.5604 - val_accuracy: 0.6351\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0949 - accuracy: 0.9686 - val_loss: 2.6318 - val_accuracy: 0.6366\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0839 - accuracy: 0.9716 - val_loss: 3.0397 - val_accuracy: 0.6308\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0801 - accuracy: 0.9735 - val_loss: 3.0380 - val_accuracy: 0.6403\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0707 - accuracy: 0.9762 - val_loss: 3.4482 - val_accuracy: 0.6355\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0684 - accuracy: 0.9769 - val_loss: 3.4353 - val_accuracy: 0.6240\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0675 - accuracy: 0.9777 - val_loss: 3.8865 - val_accuracy: 0.6266\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0652 - accuracy: 0.9789 - val_loss: 3.8398 - val_accuracy: 0.6272\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0620 - accuracy: 0.9800 - val_loss: 3.8899 - val_accuracy: 0.6174\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0593 - accuracy: 0.9806 - val_loss: 3.9525 - val_accuracy: 0.6390\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0538 - accuracy: 0.9830 - val_loss: 3.9798 - val_accuracy: 0.6337\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0526 - accuracy: 0.9832 - val_loss: 4.3138 - val_accuracy: 0.6278\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0547 - accuracy: 0.9839 - val_loss: 4.1564 - val_accuracy: 0.6177\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 0.05472249537706375\n",
      "Training Accuracy: 0.9839000105857849\n",
      "Validation Loss: 4.156437397003174\n",
      "Validation Accuracy: 0.6176999807357788\n",
      "Classification Error Rate: 0.3823000192642212\n",
      "----->Evolution: Child net_6 with fitness 4.156437397003174 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Tournament selection\n",
      "Selected net_3 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 8s 4ms/step - loss: 1.5431 - accuracy: 0.4588 - val_loss: 1.3274 - val_accuracy: 0.5346\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1531 - accuracy: 0.5974 - val_loss: 1.1788 - val_accuracy: 0.5923\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9871 - accuracy: 0.6553 - val_loss: 1.1303 - val_accuracy: 0.6182\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8713 - accuracy: 0.6998 - val_loss: 1.1641 - val_accuracy: 0.6159\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7679 - accuracy: 0.7335 - val_loss: 1.2077 - val_accuracy: 0.6276\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6797 - accuracy: 0.7633 - val_loss: 1.3543 - val_accuracy: 0.6159\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6078 - accuracy: 0.7891 - val_loss: 1.4634 - val_accuracy: 0.6156\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5341 - accuracy: 0.8158 - val_loss: 1.6708 - val_accuracy: 0.6212\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4780 - accuracy: 0.8348 - val_loss: 1.6057 - val_accuracy: 0.6208\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4284 - accuracy: 0.8524 - val_loss: 1.8142 - val_accuracy: 0.6027\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3875 - accuracy: 0.8680 - val_loss: 1.9238 - val_accuracy: 0.6236\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3462 - accuracy: 0.8818 - val_loss: 2.2592 - val_accuracy: 0.6129\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3237 - accuracy: 0.8909 - val_loss: 2.3760 - val_accuracy: 0.6194\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2999 - accuracy: 0.8981 - val_loss: 2.4723 - val_accuracy: 0.6222\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2759 - accuracy: 0.9075 - val_loss: 2.8706 - val_accuracy: 0.6068\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2536 - accuracy: 0.9164 - val_loss: 2.8262 - val_accuracy: 0.6187\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2373 - accuracy: 0.9218 - val_loss: 3.0135 - val_accuracy: 0.6204\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2215 - accuracy: 0.9274 - val_loss: 3.1308 - val_accuracy: 0.6121\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2151 - accuracy: 0.9318 - val_loss: 3.5907 - val_accuracy: 0.6166\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2106 - accuracy: 0.9336 - val_loss: 3.4767 - val_accuracy: 0.6047\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1996 - accuracy: 0.9371 - val_loss: 4.0106 - val_accuracy: 0.6105\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1944 - accuracy: 0.9409 - val_loss: 3.9583 - val_accuracy: 0.6124\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1919 - accuracy: 0.9429 - val_loss: 3.6710 - val_accuracy: 0.6091\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1870 - accuracy: 0.9459 - val_loss: 4.8027 - val_accuracy: 0.5882\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1880 - accuracy: 0.9458 - val_loss: 4.8061 - val_accuracy: 0.6051\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1684 - accuracy: 0.9512 - val_loss: 4.7634 - val_accuracy: 0.6127\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1694 - accuracy: 0.9499 - val_loss: 5.1123 - val_accuracy: 0.6129\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1677 - accuracy: 0.9526 - val_loss: 4.7952 - val_accuracy: 0.6009\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1592 - accuracy: 0.9560 - val_loss: 5.2331 - val_accuracy: 0.5980\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1655 - accuracy: 0.9551 - val_loss: 5.5148 - val_accuracy: 0.6118\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 0.16552312672138214\n",
      "Training Accuracy: 0.9551200270652771\n",
      "Validation Loss: 5.514789581298828\n",
      "Validation Accuracy: 0.6118000149726868\n",
      "Classification Error Rate: 0.38819998502731323\n",
      "----->Evolution: Child net_7 with fitness 5.514789581298828 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Tournament selection\n",
      "Selected net_4 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 2\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Child has been mutated\n",
      "\n",
      "INDIVIDUAL ABORTED, CREATING A NEW ONE\n",
      "\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Removing a Conv2D layer at 0\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  128.0\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 13s 6ms/step - loss: 1.8339 - accuracy: 0.3389 - val_loss: 1.6152 - val_accuracy: 0.4228\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5654 - accuracy: 0.4397 - val_loss: 1.6171 - val_accuracy: 0.4253\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5347 - accuracy: 0.4544 - val_loss: 1.5319 - val_accuracy: 0.4577\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5348 - accuracy: 0.4536 - val_loss: 1.5922 - val_accuracy: 0.4313\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5355 - accuracy: 0.4548 - val_loss: 1.8821 - val_accuracy: 0.4013\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5570 - accuracy: 0.4472 - val_loss: 1.6788 - val_accuracy: 0.4265\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5456 - accuracy: 0.4509 - val_loss: 1.5435 - val_accuracy: 0.4335\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5426 - accuracy: 0.4529 - val_loss: 1.9276 - val_accuracy: 0.4273\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6342 - accuracy: 0.4539 - val_loss: 1.9367 - val_accuracy: 0.3971\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5381 - accuracy: 0.4547 - val_loss: 1.9622 - val_accuracy: 0.3630\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5469 - accuracy: 0.4510 - val_loss: 2.4584 - val_accuracy: 0.2511\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5182 - accuracy: 0.4584 - val_loss: 1.6832 - val_accuracy: 0.3882\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5203 - accuracy: 0.4587 - val_loss: 2.9831 - val_accuracy: 0.3915\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5831 - accuracy: 0.4626 - val_loss: 1.5905 - val_accuracy: 0.4295\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5140 - accuracy: 0.4641 - val_loss: 1.5646 - val_accuracy: 0.4511\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5194 - accuracy: 0.4629 - val_loss: 1.6176 - val_accuracy: 0.4628\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5084 - accuracy: 0.4647 - val_loss: 1.5001 - val_accuracy: 0.4552\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5496 - accuracy: 0.4688 - val_loss: 1.8800 - val_accuracy: 0.3686\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5193 - accuracy: 0.4652 - val_loss: 3.1796 - val_accuracy: 0.4308\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7117 - accuracy: 0.4628 - val_loss: 1.4424 - val_accuracy: 0.4740\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5183 - accuracy: 0.4654 - val_loss: 1.5756 - val_accuracy: 0.4552\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5997 - accuracy: 0.4767 - val_loss: 5.4024 - val_accuracy: 0.4821\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.3279 - accuracy: 0.4914 - val_loss: 1.6379 - val_accuracy: 0.4549\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4770 - accuracy: 0.4976 - val_loss: 1.7206 - val_accuracy: 0.4235\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4761 - accuracy: 0.5005 - val_loss: 2.4654 - val_accuracy: 0.3883\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6787 - accuracy: 0.4967 - val_loss: 1.5543 - val_accuracy: 0.4528\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.2816 - accuracy: 0.1547 - val_loss: 2.3049 - val_accuracy: 0.1002\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.3041 - accuracy: 0.1010 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.3039 - accuracy: 0.0994 - val_loss: 2.3032 - val_accuracy: 0.1000\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.3040 - accuracy: 0.0985 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 2.3039698600769043\n",
      "Training Accuracy: 0.09848000109195709\n",
      "Validation Loss: 2.302976608276367\n",
      "Validation Accuracy: 0.10000000149011612\n",
      "Classification Error Rate: 0.8999999985098839\n",
      "----->Evolution: Child net_8 with fitness 2.302976608276367 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Tournament selection\n",
      "Selected net_4 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Child has been mutated\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 10s 5ms/step - loss: 1.4929 - accuracy: 0.4714 - val_loss: 1.5172 - val_accuracy: 0.4574\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1596 - accuracy: 0.6002 - val_loss: 1.4122 - val_accuracy: 0.5167\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1287 - accuracy: 0.6234 - val_loss: 1.3155 - val_accuracy: 0.5477\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1144 - accuracy: 0.6297 - val_loss: 1.7057 - val_accuracy: 0.4695\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0989 - accuracy: 0.6361 - val_loss: 1.5661 - val_accuracy: 0.4649\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0936 - accuracy: 0.6383 - val_loss: 1.6925 - val_accuracy: 0.4602\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0543 - accuracy: 0.6520 - val_loss: 1.7241 - val_accuracy: 0.4239\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0433 - accuracy: 0.6589 - val_loss: 2.0335 - val_accuracy: 0.3678\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0206 - accuracy: 0.6629 - val_loss: 2.0514 - val_accuracy: 0.4110\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0509 - accuracy: 0.6582 - val_loss: 2.0783 - val_accuracy: 0.3363\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0848 - accuracy: 0.6540 - val_loss: 1.7795 - val_accuracy: 0.4809\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0784 - accuracy: 0.6520 - val_loss: 1.6161 - val_accuracy: 0.4425\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.1102 - accuracy: 0.6484 - val_loss: 1.6797 - val_accuracy: 0.3981\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1419 - accuracy: 0.6364 - val_loss: 1.9300 - val_accuracy: 0.4261\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1465 - accuracy: 0.6380 - val_loss: 1.7927 - val_accuracy: 0.4097\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2197 - accuracy: 0.6201 - val_loss: 1.6122 - val_accuracy: 0.4774\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2060 - accuracy: 0.6250 - val_loss: 2.3685 - val_accuracy: 0.3439\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2588 - accuracy: 0.6060 - val_loss: 1.8154 - val_accuracy: 0.3943\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3150 - accuracy: 0.5931 - val_loss: 1.7009 - val_accuracy: 0.4505\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3867 - accuracy: 0.5682 - val_loss: 1.6602 - val_accuracy: 0.4450\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4448 - accuracy: 0.5525 - val_loss: 1.9750 - val_accuracy: 0.3404\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5202 - accuracy: 0.5320 - val_loss: 1.6902 - val_accuracy: 0.3977\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5515 - accuracy: 0.5151 - val_loss: 2.1124 - val_accuracy: 0.4407\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7107 - accuracy: 0.4655 - val_loss: 1.8498 - val_accuracy: 0.3546\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.0226 - accuracy: 0.3239 - val_loss: 2.1572 - val_accuracy: 0.1715\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.1334 - accuracy: 0.2430 - val_loss: 2.1322 - val_accuracy: 0.1689\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.4010 - accuracy: 0.1781 - val_loss: 2.2810 - val_accuracy: 0.1230\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3501 - accuracy: 0.1073 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3225 - accuracy: 0.1034 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3213 - accuracy: 0.1027 - val_loss: 2.3015 - val_accuracy: 0.1005\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 2.3213279247283936\n",
      "Training Accuracy: 0.1027199998497963\n",
      "Validation Loss: 2.301492214202881\n",
      "Validation Accuracy: 0.10050000250339508\n",
      "Classification Error Rate: 0.8994999974966049\n",
      "----->Evolution: Child net_9 with fitness 2.301492214202881 replaces parent net_3 with fitness 2.3026223182678223\n",
      "\n",
      "Creating Child 4\n",
      "----->Tournament selection\n",
      "Selected parent_0 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  64.0\n",
      "Child has been mutated\n",
      "Training net_10\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 8s 4ms/step - loss: 1.5366 - accuracy: 0.4636 - val_loss: 1.2671 - val_accuracy: 0.5491\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1286 - accuracy: 0.6077 - val_loss: 1.1972 - val_accuracy: 0.5927\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9612 - accuracy: 0.6700 - val_loss: 1.3340 - val_accuracy: 0.5481\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8387 - accuracy: 0.7092 - val_loss: 1.1468 - val_accuracy: 0.6273\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7277 - accuracy: 0.7495 - val_loss: 1.4092 - val_accuracy: 0.5823\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6404 - accuracy: 0.7786 - val_loss: 1.4176 - val_accuracy: 0.6145\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5567 - accuracy: 0.8090 - val_loss: 1.4416 - val_accuracy: 0.6115\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4928 - accuracy: 0.8309 - val_loss: 1.6563 - val_accuracy: 0.6152\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4245 - accuracy: 0.8541 - val_loss: 1.7945 - val_accuracy: 0.6104\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3809 - accuracy: 0.8710 - val_loss: 1.9644 - val_accuracy: 0.6195\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3373 - accuracy: 0.8863 - val_loss: 2.0616 - val_accuracy: 0.6076\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3089 - accuracy: 0.8983 - val_loss: 2.5950 - val_accuracy: 0.6094\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2802 - accuracy: 0.9073 - val_loss: 2.5611 - val_accuracy: 0.6136\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2555 - accuracy: 0.9163 - val_loss: 2.9608 - val_accuracy: 0.5989\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2318 - accuracy: 0.9232 - val_loss: 3.0535 - val_accuracy: 0.6018\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2196 - accuracy: 0.9298 - val_loss: 3.2763 - val_accuracy: 0.6083\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2078 - accuracy: 0.9333 - val_loss: 3.4704 - val_accuracy: 0.6041\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1939 - accuracy: 0.9401 - val_loss: 3.4920 - val_accuracy: 0.6082\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1768 - accuracy: 0.9439 - val_loss: 3.9807 - val_accuracy: 0.6065\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1778 - accuracy: 0.9461 - val_loss: 4.0916 - val_accuracy: 0.6054\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1671 - accuracy: 0.9517 - val_loss: 4.4287 - val_accuracy: 0.6071\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1625 - accuracy: 0.9521 - val_loss: 4.2194 - val_accuracy: 0.6066\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1544 - accuracy: 0.9551 - val_loss: 4.7238 - val_accuracy: 0.6071\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1609 - accuracy: 0.9553 - val_loss: 4.6576 - val_accuracy: 0.6093\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1482 - accuracy: 0.9567 - val_loss: 5.2073 - val_accuracy: 0.6053\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1497 - accuracy: 0.9591 - val_loss: 5.4203 - val_accuracy: 0.6109\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1474 - accuracy: 0.9600 - val_loss: 5.3967 - val_accuracy: 0.6004\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1457 - accuracy: 0.9608 - val_loss: 5.5288 - val_accuracy: 0.6041\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1392 - accuracy: 0.9627 - val_loss: 5.6394 - val_accuracy: 0.6035\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1329 - accuracy: 0.9653 - val_loss: 5.9071 - val_accuracy: 0.6058\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.13287898898124695\n",
      "Training Accuracy: 0.9652600288391113\n",
      "Validation Loss: 5.907059192657471\n",
      "Validation Accuracy: 0.6057999730110168\n",
      "Classification Error Rate: 0.39420002698898315\n",
      "----->Evolution: Child net_10 with fitness 5.907059192657471 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 4\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_4 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Child has been mutated\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 11s 6ms/step - loss: 1.9255 - accuracy: 0.3523 - val_loss: 1.7284 - val_accuracy: 0.3892\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8137 - accuracy: 0.4163 - val_loss: 2.6924 - val_accuracy: 0.2882\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7843 - accuracy: 0.4090 - val_loss: 1.6975 - val_accuracy: 0.4079\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7802 - accuracy: 0.3889 - val_loss: 1.9761 - val_accuracy: 0.3053\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7703 - accuracy: 0.3859 - val_loss: 2.3365 - val_accuracy: 0.3326\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.8175 - accuracy: 0.3940 - val_loss: 1.9231 - val_accuracy: 0.3454\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8041 - accuracy: 0.3752 - val_loss: 2.0516 - val_accuracy: 0.2756\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.2508 - accuracy: 0.2096 - val_loss: 2.3658 - val_accuracy: 0.1002\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3489 - accuracy: 0.0996 - val_loss: 2.3126 - val_accuracy: 0.1000\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3115 - accuracy: 0.0967 - val_loss: 2.6699 - val_accuracy: 0.1001\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3223 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0973 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0966 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 2.3028 - accuracy: 0.1002 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0971 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.3028 - accuracy: 0.0998 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0983 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0985 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0968 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0972 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0990 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0997 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 2.302767276763916\n",
      "Training Accuracy: 0.09969999641180038\n",
      "Validation Loss: 2.3026134967803955\n",
      "Validation Accuracy: 0.10000000149011612\n",
      "Classification Error Rate: 0.8999999985098839\n",
      "----->Evolution: Child net_6 with fitness 2.3026134967803955 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_4 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 1\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  128.0\n",
      "Child has been mutated\n",
      "\n",
      "INDIVIDUAL ABORTED, CREATING A NEW ONE\n",
      "\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 2)]\n",
      "Creating a new block with two Convolutional layers and a Pooling layer\n",
      "Layer Mutation\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  128.0\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 13s 7ms/step - loss: 1.4851 - accuracy: 0.4912 - val_loss: 1.8946 - val_accuracy: 0.5095\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0105 - accuracy: 0.6559 - val_loss: 1.6155 - val_accuracy: 0.5446\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8589 - accuracy: 0.7286 - val_loss: 1.4233 - val_accuracy: 0.5788\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7502 - accuracy: 0.7701 - val_loss: 1.9968 - val_accuracy: 0.5935\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6853 - accuracy: 0.7930 - val_loss: 2.5489 - val_accuracy: 0.5115\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6803 - accuracy: 0.8117 - val_loss: 2.8188 - val_accuracy: 0.5052\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6565 - accuracy: 0.8186 - val_loss: 2.4409 - val_accuracy: 0.5495\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6222 - accuracy: 0.8239 - val_loss: 1.9748 - val_accuracy: 0.4901\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6423 - accuracy: 0.8309 - val_loss: 4.3411 - val_accuracy: 0.5652\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6362 - accuracy: 0.8321 - val_loss: 3.5647 - val_accuracy: 0.5547\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5698 - accuracy: 0.8363 - val_loss: 4.1287 - val_accuracy: 0.5167\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6319 - accuracy: 0.8392 - val_loss: 3.9915 - val_accuracy: 0.5597\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6446 - accuracy: 0.8387 - val_loss: 2.3329 - val_accuracy: 0.5979\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6144 - accuracy: 0.8408 - val_loss: 2.7690 - val_accuracy: 0.6238\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6064 - accuracy: 0.8401 - val_loss: 4.1505 - val_accuracy: 0.5762\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6358 - accuracy: 0.8469 - val_loss: 2.9349 - val_accuracy: 0.5230\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6348 - accuracy: 0.8427 - val_loss: 2.7129 - val_accuracy: 0.5451\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6790 - accuracy: 0.8480 - val_loss: 4.6566 - val_accuracy: 0.5731\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6553 - accuracy: 0.8480 - val_loss: 4.4573 - val_accuracy: 0.5906\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7075 - accuracy: 0.8493 - val_loss: 5.3528 - val_accuracy: 0.5499\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7726 - accuracy: 0.8488 - val_loss: 3.6338 - val_accuracy: 0.5894\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6227 - accuracy: 0.8523 - val_loss: 7.1387 - val_accuracy: 0.5466\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7974 - accuracy: 0.8514 - val_loss: 4.1395 - val_accuracy: 0.5518\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5753 - accuracy: 0.8569 - val_loss: 4.7182 - val_accuracy: 0.5776\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6194 - accuracy: 0.8610 - val_loss: 3.0428 - val_accuracy: 0.6071\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6984 - accuracy: 0.8594 - val_loss: 4.7991 - val_accuracy: 0.6279\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6401 - accuracy: 0.8634 - val_loss: 8.2340 - val_accuracy: 0.5230\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7136 - accuracy: 0.8584 - val_loss: 3.3180 - val_accuracy: 0.5483\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6318 - accuracy: 0.8544 - val_loss: 5.4572 - val_accuracy: 0.5876\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7833 - accuracy: 0.8540 - val_loss: 5.3693 - val_accuracy: 0.5288\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 0.7832934260368347\n",
      "Training Accuracy: 0.8539599776268005\n",
      "Validation Loss: 5.369279861450195\n",
      "Validation Accuracy: 0.5288000106811523\n",
      "Classification Error Rate: 0.47119998931884766\n",
      "----->Evolution: Child net_7 with fitness 5.369279861450195 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_4 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  128.0\n",
      "Child has been mutated\n",
      "\n",
      "INDIVIDUAL ABORTED, CREATING A NEW ONE\n",
      "\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Removing a Conv2D layer at 0\n",
      "Layer Mutation\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  64.0\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 13s 7ms/step - loss: 1.6522 - accuracy: 0.3980 - val_loss: 1.4152 - val_accuracy: 0.4886\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2691 - accuracy: 0.5461 - val_loss: 1.5695 - val_accuracy: 0.4775\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1145 - accuracy: 0.6087 - val_loss: 1.1592 - val_accuracy: 0.5926\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0272 - accuracy: 0.6408 - val_loss: 1.1926 - val_accuracy: 0.5967\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9762 - accuracy: 0.6650 - val_loss: 1.2214 - val_accuracy: 0.5896\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9559 - accuracy: 0.6744 - val_loss: 1.1672 - val_accuracy: 0.5955\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.9389 - accuracy: 0.6804 - val_loss: 1.2935 - val_accuracy: 0.5551\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9273 - accuracy: 0.6859 - val_loss: 1.6965 - val_accuracy: 0.5212\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9166 - accuracy: 0.6916 - val_loss: 1.3436 - val_accuracy: 0.5703\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8989 - accuracy: 0.6988 - val_loss: 1.1758 - val_accuracy: 0.6179\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8860 - accuracy: 0.7054 - val_loss: 1.6088 - val_accuracy: 0.5224\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8939 - accuracy: 0.7069 - val_loss: 1.5285 - val_accuracy: 0.5572\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9002 - accuracy: 0.7039 - val_loss: 1.6805 - val_accuracy: 0.4763\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9088 - accuracy: 0.7077 - val_loss: 1.8324 - val_accuracy: 0.5068\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9212 - accuracy: 0.7085 - val_loss: 1.1762 - val_accuracy: 0.6371\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9302 - accuracy: 0.7083 - val_loss: 2.3918 - val_accuracy: 0.4189\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9356 - accuracy: 0.7025 - val_loss: 1.8762 - val_accuracy: 0.4268\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9343 - accuracy: 0.7082 - val_loss: 1.3678 - val_accuracy: 0.6279\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9045 - accuracy: 0.7083 - val_loss: 2.3926 - val_accuracy: 0.3830\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0331 - accuracy: 0.7088 - val_loss: 1.4334 - val_accuracy: 0.5856\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9353 - accuracy: 0.7051 - val_loss: 1.5759 - val_accuracy: 0.4913\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.9319 - accuracy: 0.7085 - val_loss: 1.7048 - val_accuracy: 0.5433\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9386 - accuracy: 0.7109 - val_loss: 1.5165 - val_accuracy: 0.5193\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9216 - accuracy: 0.7126 - val_loss: 1.3669 - val_accuracy: 0.5987\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9904 - accuracy: 0.7009 - val_loss: 3.5176 - val_accuracy: 0.4761\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0067 - accuracy: 0.6973 - val_loss: 3.4855 - val_accuracy: 0.4652\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0476 - accuracy: 0.6913 - val_loss: 1.5471 - val_accuracy: 0.5250\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0860 - accuracy: 0.6880 - val_loss: 1.7099 - val_accuracy: 0.5219\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.2342 - accuracy: 0.6885 - val_loss: 2.5759 - val_accuracy: 0.4245\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1165 - accuracy: 0.6930 - val_loss: 2.4113 - val_accuracy: 0.4336\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 1.1165279150009155\n",
      "Training Accuracy: 0.6930000185966492\n",
      "Validation Loss: 2.4113385677337646\n",
      "Validation Accuracy: 0.4336000084877014\n",
      "Classification Error Rate: 0.5663999915122986\n",
      "----->Evolution: Child net_8 with fitness 2.4113385677337646 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_4 and parent_0 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 2\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Child has been mutated\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 16s 8ms/step - loss: 1.8288 - accuracy: 0.3109 - val_loss: 1.5664 - val_accuracy: 0.4272\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4070 - accuracy: 0.4948 - val_loss: 1.4291 - val_accuracy: 0.5155\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2389 - accuracy: 0.5614 - val_loss: 1.3229 - val_accuracy: 0.5490\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1489 - accuracy: 0.5983 - val_loss: 1.3519 - val_accuracy: 0.5231\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.1098 - accuracy: 0.6191 - val_loss: 1.3150 - val_accuracy: 0.5674\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.1054 - accuracy: 0.6284 - val_loss: 2.3131 - val_accuracy: 0.4670\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1156 - accuracy: 0.6290 - val_loss: 1.6394 - val_accuracy: 0.4982\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1111 - accuracy: 0.6313 - val_loss: 1.7652 - val_accuracy: 0.5328\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1431 - accuracy: 0.6231 - val_loss: 1.2682 - val_accuracy: 0.5762\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1944 - accuracy: 0.6155 - val_loss: 1.2918 - val_accuracy: 0.5709\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.3093 - accuracy: 0.6142 - val_loss: 1.3392 - val_accuracy: 0.5737\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.2532 - accuracy: 0.6047 - val_loss: 1.8553 - val_accuracy: 0.4363\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7337 - accuracy: 0.6010 - val_loss: 1.7059 - val_accuracy: 0.5341\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3848 - accuracy: 0.5948 - val_loss: 1.5538 - val_accuracy: 0.5385\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4657 - accuracy: 0.5866 - val_loss: 1.4290 - val_accuracy: 0.5417\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6732 - accuracy: 0.5901 - val_loss: 1.4966 - val_accuracy: 0.5900\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.8808 - accuracy: 0.5641 - val_loss: 1.5645 - val_accuracy: 0.5133\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 2.8807 - accuracy: 0.5344 - val_loss: 1.4014 - val_accuracy: 0.5530\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.4667 - accuracy: 0.5536 - val_loss: 1.3596 - val_accuracy: 0.5636\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7741 - accuracy: 0.5330 - val_loss: 1.7786 - val_accuracy: 0.4324\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5507 - accuracy: 0.5347 - val_loss: 1.3775 - val_accuracy: 0.5761\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6351 - accuracy: 0.5199 - val_loss: 1.6645 - val_accuracy: 0.5552\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.8417 - accuracy: 0.5214 - val_loss: 1.7270 - val_accuracy: 0.3844\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.4057 - accuracy: 0.5618 - val_loss: 1.2424 - val_accuracy: 0.5748\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.9071 - accuracy: 0.5427 - val_loss: 1.3859 - val_accuracy: 0.5039\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4962 - accuracy: 0.5392 - val_loss: 1.3571 - val_accuracy: 0.5743\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.2001 - accuracy: 0.5412 - val_loss: 1.3548 - val_accuracy: 0.5506\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5820 - accuracy: 0.5295 - val_loss: 3.5192 - val_accuracy: 0.3224\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.6227 - accuracy: 0.3487 - val_loss: 2.4528 - val_accuracy: 0.3267\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 5.3876 - accuracy: 0.4005 - val_loss: 1.5802 - val_accuracy: 0.4080\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 5.387551307678223\n",
      "Training Accuracy: 0.4004800021648407\n",
      "Validation Loss: 1.5801719427108765\n",
      "Validation Accuracy: 0.40799999237060547\n",
      "Classification Error Rate: 0.5920000076293945\n",
      "----->Evolution: Child net_9 with fitness 1.5801719427108765 replaces parent net_5 with fitness 2.3026084899902344\n",
      "\n",
      "Creating Child 4\n",
      "----->Elitism selection\n",
      "Selected net_5 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  256.0\n",
      "Child has been mutated\n",
      "Training net_10\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 11s 6ms/step - loss: 1.8494 - accuracy: 0.3386 - val_loss: 1.7792 - val_accuracy: 0.3799\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.5971 - accuracy: 0.4307 - val_loss: 1.6251 - val_accuracy: 0.4149\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5253 - accuracy: 0.4657 - val_loss: 1.8050 - val_accuracy: 0.4223\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5167 - accuracy: 0.4718 - val_loss: 1.5750 - val_accuracy: 0.4336\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.4915 - accuracy: 0.4801 - val_loss: 1.7050 - val_accuracy: 0.4122\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4668 - accuracy: 0.4939 - val_loss: 1.7031 - val_accuracy: 0.4558\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4360 - accuracy: 0.5051 - val_loss: 1.5080 - val_accuracy: 0.4816\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4176 - accuracy: 0.5134 - val_loss: 1.6450 - val_accuracy: 0.4274\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4149 - accuracy: 0.5196 - val_loss: 1.4888 - val_accuracy: 0.4579\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3949 - accuracy: 0.5289 - val_loss: 1.4185 - val_accuracy: 0.4964\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4241 - accuracy: 0.5247 - val_loss: 2.4306 - val_accuracy: 0.3618\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4393 - accuracy: 0.5247 - val_loss: 2.0284 - val_accuracy: 0.3797\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.4709 - accuracy: 0.5132 - val_loss: 1.7117 - val_accuracy: 0.4057\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.5816 - accuracy: 0.4757 - val_loss: 2.1538 - val_accuracy: 0.3473\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6396 - accuracy: 0.4425 - val_loss: 2.5117 - val_accuracy: 0.3746\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7227 - accuracy: 0.4094 - val_loss: 1.6612 - val_accuracy: 0.3652\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7201 - accuracy: 0.3986 - val_loss: 1.5595 - val_accuracy: 0.4492\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6792 - accuracy: 0.4190 - val_loss: 2.0914 - val_accuracy: 0.2682\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6895 - accuracy: 0.4204 - val_loss: 1.7546 - val_accuracy: 0.4075\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7231 - accuracy: 0.4210 - val_loss: 2.0963 - val_accuracy: 0.2775\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6766 - accuracy: 0.4296 - val_loss: 2.1986 - val_accuracy: 0.2772\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6653 - accuracy: 0.4265 - val_loss: 2.2114 - val_accuracy: 0.2392\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8118 - accuracy: 0.4273 - val_loss: 2.0306 - val_accuracy: 0.3603\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.7687 - accuracy: 0.4223 - val_loss: 1.7188 - val_accuracy: 0.4126\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7063 - accuracy: 0.4237 - val_loss: 1.8313 - val_accuracy: 0.3601\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6971 - accuracy: 0.4273 - val_loss: 2.8285 - val_accuracy: 0.2715\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7102 - accuracy: 0.4269 - val_loss: 2.0038 - val_accuracy: 0.4260\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8063 - accuracy: 0.4183 - val_loss: 2.3232 - val_accuracy: 0.2873\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8410 - accuracy: 0.4223 - val_loss: 2.0761 - val_accuracy: 0.3082\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7105 - accuracy: 0.4209 - val_loss: 2.2235 - val_accuracy: 0.3074\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 1.7104976177215576\n",
      "Training Accuracy: 0.42089998722076416\n",
      "Validation Loss: 2.2235355377197266\n",
      "Validation Accuracy: 0.3073999881744385\n",
      "Classification Error Rate: 0.6926000118255615\n",
      "----->Evolution: Child net_10 with fitness 2.2235355377197266 replaces parent net_2 with fitness 2.302428722381592\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 5\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_5 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 14s 7ms/step - loss: 2.0610 - accuracy: 0.2689 - val_loss: 2.0758 - val_accuracy: 0.3178\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6713 - accuracy: 0.3933 - val_loss: 1.7104 - val_accuracy: 0.3776\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6505 - accuracy: 0.4036 - val_loss: 1.6949 - val_accuracy: 0.3764\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6104 - accuracy: 0.4176 - val_loss: 1.7860 - val_accuracy: 0.3576\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5791 - accuracy: 0.4320 - val_loss: 1.6695 - val_accuracy: 0.4255\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.5714 - accuracy: 0.4338 - val_loss: 1.6466 - val_accuracy: 0.3959\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.5520 - accuracy: 0.4420 - val_loss: 1.6949 - val_accuracy: 0.3904\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5160 - accuracy: 0.4582 - val_loss: 1.7182 - val_accuracy: 0.3989\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4983 - accuracy: 0.4644 - val_loss: 1.9961 - val_accuracy: 0.3829\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4799 - accuracy: 0.4680 - val_loss: 1.7822 - val_accuracy: 0.3488\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4646 - accuracy: 0.4762 - val_loss: 1.8940 - val_accuracy: 0.3742\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4694 - accuracy: 0.4805 - val_loss: 1.5964 - val_accuracy: 0.4446\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4683 - accuracy: 0.4810 - val_loss: 1.7293 - val_accuracy: 0.3878\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4999 - accuracy: 0.4840 - val_loss: 2.2217 - val_accuracy: 0.3372\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4872 - accuracy: 0.4851 - val_loss: 1.6856 - val_accuracy: 0.4089\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.4515 - accuracy: 0.4924 - val_loss: 2.1417 - val_accuracy: 0.3165\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.5093 - accuracy: 0.4920 - val_loss: 1.8975 - val_accuracy: 0.3052\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4642 - accuracy: 0.4968 - val_loss: 1.6843 - val_accuracy: 0.4403\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4352 - accuracy: 0.5006 - val_loss: 1.6765 - val_accuracy: 0.3741\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4459 - accuracy: 0.4985 - val_loss: 1.9149 - val_accuracy: 0.3552\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4420 - accuracy: 0.4997 - val_loss: 1.6134 - val_accuracy: 0.4085\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4153 - accuracy: 0.5072 - val_loss: 1.4949 - val_accuracy: 0.4971\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.4326 - accuracy: 0.5070 - val_loss: 1.5773 - val_accuracy: 0.4398\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4189 - accuracy: 0.5108 - val_loss: 1.7206 - val_accuracy: 0.4083\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4103 - accuracy: 0.5121 - val_loss: 1.5528 - val_accuracy: 0.4196\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4607 - accuracy: 0.5075 - val_loss: 1.8573 - val_accuracy: 0.3784\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.5400 - accuracy: 0.5019 - val_loss: 2.3016 - val_accuracy: 0.2798\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.8242 - accuracy: 0.5097 - val_loss: 1.6950 - val_accuracy: 0.3559\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5246 - accuracy: 0.4995 - val_loss: 2.2434 - val_accuracy: 0.3200\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 4.9569 - accuracy: 0.4845 - val_loss: 1.4951 - val_accuracy: 0.4641\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 4.956881523132324\n",
      "Training Accuracy: 0.484499990940094\n",
      "Validation Loss: 1.4950755834579468\n",
      "Validation Accuracy: 0.4641000032424927\n",
      "Classification Error Rate: 0.5358999967575073\n",
      "----->Evolution: Child net_6 with fitness 1.4950755834579468 replaces parent net_3 with fitness 2.301492214202881\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_3 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Child has been mutated\n",
      "\n",
      "INDIVIDUAL ABORTED, CREATING A NEW ONE\n",
      "\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Inserting a Dropout layer\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Dropout layer:\n",
      "-->changed self.rate from  0.35  to  0.3\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  256.0\n",
      "\n",
      "INDIVIDUAL ABORTED, CREATING A NEW ONE\n",
      "\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 12s 6ms/step - loss: 1.9707 - accuracy: 0.2888 - val_loss: 1.6823 - val_accuracy: 0.3905\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6950 - accuracy: 0.3936 - val_loss: 1.8036 - val_accuracy: 0.3649\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6746 - accuracy: 0.4019 - val_loss: 1.7650 - val_accuracy: 0.3566\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6499 - accuracy: 0.4161 - val_loss: 1.6379 - val_accuracy: 0.4025\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6372 - accuracy: 0.4214 - val_loss: 1.7840 - val_accuracy: 0.3546\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6382 - accuracy: 0.4234 - val_loss: 2.6880 - val_accuracy: 0.2490\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6797 - accuracy: 0.4179 - val_loss: 1.8700 - val_accuracy: 0.3150\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6680 - accuracy: 0.4158 - val_loss: 1.9403 - val_accuracy: 0.3346\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6621 - accuracy: 0.4128 - val_loss: 2.7307 - val_accuracy: 0.2181\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7543 - accuracy: 0.3962 - val_loss: 2.1242 - val_accuracy: 0.2841\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7824 - accuracy: 0.3716 - val_loss: 2.3488 - val_accuracy: 0.2457\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.8015 - accuracy: 0.3682 - val_loss: 2.0102 - val_accuracy: 0.2637\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7633 - accuracy: 0.3680 - val_loss: 2.0818 - val_accuracy: 0.2977\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7818 - accuracy: 0.3634 - val_loss: 1.9260 - val_accuracy: 0.2682\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.8514 - accuracy: 0.3376 - val_loss: 1.8179 - val_accuracy: 0.3071\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.8272 - accuracy: 0.3305 - val_loss: 1.7517 - val_accuracy: 0.3689\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.8326 - accuracy: 0.3309 - val_loss: 1.7960 - val_accuracy: 0.3375\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.7961 - accuracy: 0.3412 - val_loss: 1.8521 - val_accuracy: 0.3254\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.8533 - accuracy: 0.3218 - val_loss: 1.9115 - val_accuracy: 0.2650\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.8323 - accuracy: 0.3237 - val_loss: 1.9290 - val_accuracy: 0.2769\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.2248 - accuracy: 0.3119 - val_loss: 1.7722 - val_accuracy: 0.3411\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.9960 - accuracy: 0.3046 - val_loss: 2.4434 - val_accuracy: 0.2742\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.9170 - accuracy: 0.2860 - val_loss: 1.9200 - val_accuracy: 0.2270\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.0043 - accuracy: 0.2466 - val_loss: 2.0097 - val_accuracy: 0.2046\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.9613 - accuracy: 0.2444 - val_loss: 2.9094 - val_accuracy: 0.1661\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.9838 - accuracy: 0.2387 - val_loss: 2.2934 - val_accuracy: 0.1721\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.9870 - accuracy: 0.2408 - val_loss: 2.0793 - val_accuracy: 0.1905\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.9647 - accuracy: 0.2412 - val_loss: 2.0761 - val_accuracy: 0.2342\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.9558 - accuracy: 0.2388 - val_loss: 2.0197 - val_accuracy: 0.1945\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.9067 - accuracy: 0.2461 - val_loss: 2.0117 - val_accuracy: 0.2052\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 1.9066776037216187\n",
      "Training Accuracy: 0.2461400032043457\n",
      "Validation Loss: 2.0117008686065674\n",
      "Validation Accuracy: 0.20520000159740448\n",
      "Classification Error Rate: 0.7947999984025955\n",
      "----->Evolution: Child net_7 with fitness 2.0117008686065674 replaces parent net_2 with fitness 2.2235355377197266\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_3 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  64.0\n",
      "Child has been mutated\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 11s 6ms/step - loss: 1.5998 - accuracy: 0.4400 - val_loss: 1.3355 - val_accuracy: 0.5362\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2208 - accuracy: 0.5790 - val_loss: 1.4214 - val_accuracy: 0.5556\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.1249 - accuracy: 0.6192 - val_loss: 1.5801 - val_accuracy: 0.5153\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0657 - accuracy: 0.6426 - val_loss: 1.3782 - val_accuracy: 0.5304\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.0287 - accuracy: 0.6582 - val_loss: 1.5611 - val_accuracy: 0.5362\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9905 - accuracy: 0.6731 - val_loss: 1.3710 - val_accuracy: 0.5577\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9579 - accuracy: 0.6874 - val_loss: 1.4625 - val_accuracy: 0.5305\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9437 - accuracy: 0.6931 - val_loss: 1.4268 - val_accuracy: 0.5302\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9070 - accuracy: 0.7077 - val_loss: 2.4668 - val_accuracy: 0.4155\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9332 - accuracy: 0.7095 - val_loss: 1.7246 - val_accuracy: 0.4853\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.9537 - accuracy: 0.7024 - val_loss: 1.6394 - val_accuracy: 0.5375\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9767 - accuracy: 0.7035 - val_loss: 1.7303 - val_accuracy: 0.4828\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0105 - accuracy: 0.6980 - val_loss: 2.6786 - val_accuracy: 0.2821\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.1766 - accuracy: 0.6536 - val_loss: 2.0407 - val_accuracy: 0.4286\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 1.2891 - accuracy: 0.6142 - val_loss: 2.5472 - val_accuracy: 0.3662\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4477 - accuracy: 0.5559 - val_loss: 3.1824 - val_accuracy: 0.3531\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.6087 - accuracy: 0.5155 - val_loss: 3.1487 - val_accuracy: 0.3392\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9631 - accuracy: 0.3741 - val_loss: 2.2328 - val_accuracy: 0.1445\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.5315 - accuracy: 0.1491 - val_loss: 2.3107 - val_accuracy: 0.1031\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3099 - accuracy: 0.1004 - val_loss: 2.3026 - val_accuracy: 0.1001\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.5070 - accuracy: 0.1028 - val_loss: 2.2937 - val_accuracy: 0.1047\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 2.3838 - accuracy: 0.0990 - val_loss: 2.3065 - val_accuracy: 0.1031\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.3027 - accuracy: 0.0974 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.3027 - accuracy: 0.0995 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.3027 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.3028 - accuracy: 0.0962 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 2.3027 - accuracy: 0.0987 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 2.3028 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 2.3027536869049072\n",
      "Training Accuracy: 0.09691999852657318\n",
      "Validation Loss: 2.302600860595703\n",
      "Validation Accuracy: 0.10000000149011612\n",
      "Classification Error Rate: 0.8999999985098839\n",
      "----->Evolution: Child net_8 with fitness 2.302600860595703 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_3 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Child has been mutated\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 14s 7ms/step - loss: 1.6817 - accuracy: 0.3913 - val_loss: 1.5844 - val_accuracy: 0.4502\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3475 - accuracy: 0.5285 - val_loss: 1.2502 - val_accuracy: 0.5729\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2557 - accuracy: 0.5672 - val_loss: 1.3219 - val_accuracy: 0.5629\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.2091 - accuracy: 0.5892 - val_loss: 1.2464 - val_accuracy: 0.5876\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1753 - accuracy: 0.6089 - val_loss: 1.5480 - val_accuracy: 0.5049\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1631 - accuracy: 0.6152 - val_loss: 1.2877 - val_accuracy: 0.5397\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1527 - accuracy: 0.6239 - val_loss: 1.2542 - val_accuracy: 0.5848\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1784 - accuracy: 0.6233 - val_loss: 1.2614 - val_accuracy: 0.5727\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1895 - accuracy: 0.6242 - val_loss: 1.5216 - val_accuracy: 0.4224\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2415 - accuracy: 0.6075 - val_loss: 1.4383 - val_accuracy: 0.5114\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.2691 - accuracy: 0.6002 - val_loss: 1.3471 - val_accuracy: 0.5175\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3374 - accuracy: 0.5788 - val_loss: 1.6040 - val_accuracy: 0.5297\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4224 - accuracy: 0.5563 - val_loss: 1.5047 - val_accuracy: 0.5227\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5324 - accuracy: 0.5234 - val_loss: 1.7007 - val_accuracy: 0.4359\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.7085 - accuracy: 0.4755 - val_loss: 1.7949 - val_accuracy: 0.3787\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6243 - accuracy: 0.4793 - val_loss: 1.9035 - val_accuracy: 0.4073\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.8441 - accuracy: 0.4351 - val_loss: 1.7087 - val_accuracy: 0.4218\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.8358 - accuracy: 0.4241 - val_loss: 2.0234 - val_accuracy: 0.4514\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.9278 - accuracy: 0.4073 - val_loss: 2.5978 - val_accuracy: 0.2817\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.9265 - accuracy: 0.4140 - val_loss: 1.7625 - val_accuracy: 0.4003\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.8473 - accuracy: 0.4030 - val_loss: 2.7938 - val_accuracy: 0.1452\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.9764 - accuracy: 0.3913 - val_loss: 2.4760 - val_accuracy: 0.3168\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.8470 - accuracy: 0.3969 - val_loss: 1.8995 - val_accuracy: 0.3330\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 5.0512 - accuracy: 0.3748 - val_loss: 8.0292 - val_accuracy: 0.3682\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.5149 - accuracy: 0.3497 - val_loss: 2.0842 - val_accuracy: 0.2828\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 3.2972 - accuracy: 0.3598 - val_loss: 3.6988 - val_accuracy: 0.2645\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 5.6573 - accuracy: 0.3652 - val_loss: 3.7150 - val_accuracy: 0.2441\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0969 - accuracy: 0.3480 - val_loss: 5.0979 - val_accuracy: 0.2481\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 10.2103 - accuracy: 0.3460 - val_loss: 2.5465 - val_accuracy: 0.1286\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.7381 - accuracy: 0.3322 - val_loss: 2.6621 - val_accuracy: 0.2112\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 2.7381434440612793\n",
      "Training Accuracy: 0.332179993391037\n",
      "Validation Loss: 2.6621057987213135\n",
      "Validation Accuracy: 0.21119999885559082\n",
      "Classification Error Rate: 0.7888000011444092\n",
      "----->Evolution: Child net_9 with fitness 2.6621057987213135 is discarded\n",
      "\n",
      "Creating Child 4\n",
      "----->Elitism selection\n",
      "Selected net_3 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  256.0\n",
      "Child has been mutated\n",
      "Training net_10\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3614 - accuracy: 0.5308 - val_loss: 1.1660 - val_accuracy: 0.5960\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.9252 - accuracy: 0.6810 - val_loss: 1.0566 - val_accuracy: 0.6443\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6808 - accuracy: 0.7667 - val_loss: 1.0871 - val_accuracy: 0.6595\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4770 - accuracy: 0.8379 - val_loss: 1.3028 - val_accuracy: 0.6401\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3288 - accuracy: 0.8888 - val_loss: 1.4766 - val_accuracy: 0.6547\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2276 - accuracy: 0.9237 - val_loss: 1.7638 - val_accuracy: 0.6523\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1766 - accuracy: 0.9441 - val_loss: 2.0510 - val_accuracy: 0.6338\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1447 - accuracy: 0.9544 - val_loss: 2.2577 - val_accuracy: 0.6579\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1251 - accuracy: 0.9624 - val_loss: 2.5831 - val_accuracy: 0.6493\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1119 - accuracy: 0.9663 - val_loss: 2.8174 - val_accuracy: 0.6498\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.1049 - accuracy: 0.9698 - val_loss: 3.2299 - val_accuracy: 0.6396\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0997 - accuracy: 0.9706 - val_loss: 3.5467 - val_accuracy: 0.6436\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0957 - accuracy: 0.9733 - val_loss: 3.5445 - val_accuracy: 0.6441\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.0845 - accuracy: 0.9772 - val_loss: 3.9718 - val_accuracy: 0.6550\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0869 - accuracy: 0.9768 - val_loss: 3.5525 - val_accuracy: 0.6493\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0979 - accuracy: 0.9759 - val_loss: 4.2124 - val_accuracy: 0.6473\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0859 - accuracy: 0.9788 - val_loss: 4.1275 - val_accuracy: 0.6487\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0852 - accuracy: 0.9797 - val_loss: 4.2382 - val_accuracy: 0.6509\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0832 - accuracy: 0.9808 - val_loss: 5.0542 - val_accuracy: 0.6529\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0816 - accuracy: 0.9805 - val_loss: 5.0326 - val_accuracy: 0.6489\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0737 - accuracy: 0.9828 - val_loss: 5.5590 - val_accuracy: 0.6282\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0811 - accuracy: 0.9817 - val_loss: 5.4044 - val_accuracy: 0.6558\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0797 - accuracy: 0.9838 - val_loss: 5.4550 - val_accuracy: 0.6482\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0876 - accuracy: 0.9821 - val_loss: 5.8610 - val_accuracy: 0.6553\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0757 - accuracy: 0.9839 - val_loss: 5.8923 - val_accuracy: 0.6543\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0761 - accuracy: 0.9847 - val_loss: 6.6015 - val_accuracy: 0.6538\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0778 - accuracy: 0.9846 - val_loss: 6.8332 - val_accuracy: 0.6568\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0868 - accuracy: 0.9836 - val_loss: 7.0346 - val_accuracy: 0.6442\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0676 - accuracy: 0.9870 - val_loss: 6.7855 - val_accuracy: 0.6460\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0886 - accuracy: 0.9844 - val_loss: 6.9896 - val_accuracy: 0.6449\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 0.08855930715799332\n",
      "Training Accuracy: 0.9843800067901611\n",
      "Validation Loss: 6.989583492279053\n",
      "Validation Accuracy: 0.6449000239372253\n",
      "Classification Error Rate: 0.35509997606277466\n",
      "----->Evolution: Child net_10 with fitness 6.989583492279053 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 6\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Elitism selection\n",
      "Selected net_3 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  256.0\n",
      "Child has been mutated\n",
      "\n",
      "INDIVIDUAL ABORTED, CREATING A NEW ONE\n",
      "\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 2)]\n",
      "Creating a new block with two Convolutional layers and a Pooling layer\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 1\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  256.0\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 10s 5ms/step - loss: 1.6435 - accuracy: 0.4297 - val_loss: 1.4004 - val_accuracy: 0.5099\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2338 - accuracy: 0.5783 - val_loss: 1.5418 - val_accuracy: 0.5065\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1464 - accuracy: 0.6202 - val_loss: 1.7834 - val_accuracy: 0.5277\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1274 - accuracy: 0.6345 - val_loss: 1.4811 - val_accuracy: 0.5333\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2403 - accuracy: 0.6107 - val_loss: 2.1405 - val_accuracy: 0.3389\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8798 - accuracy: 0.4461 - val_loss: 2.7687 - val_accuracy: 0.1802\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.2224 - accuracy: 0.3470 - val_loss: 2.5870 - val_accuracy: 0.2321\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7878 - accuracy: 0.3957 - val_loss: 1.7842 - val_accuracy: 0.3468\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.8466 - accuracy: 0.4026 - val_loss: 1.6782 - val_accuracy: 0.4038\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.7296 - accuracy: 0.4004 - val_loss: 2.5597 - val_accuracy: 0.2952\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.8371 - accuracy: 0.3758 - val_loss: 2.6493 - val_accuracy: 0.1984\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.7055 - accuracy: 0.3193 - val_loss: 2.4472 - val_accuracy: 0.2219\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 3.8240 - accuracy: 0.2634 - val_loss: 2.2266 - val_accuracy: 0.1927\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.9914 - accuracy: 0.1449 - val_loss: 2.5512 - val_accuracy: 0.1022\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3219 - accuracy: 0.0984 - val_loss: 2.3299 - val_accuracy: 0.1000\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0968 - val_loss: 2.3299 - val_accuracy: 0.1000\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.0993 - val_loss: 2.3300 - val_accuracy: 0.0999\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0988 - val_loss: 2.3299 - val_accuracy: 0.0999\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3030 - accuracy: 0.0974 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3030 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0960 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3027 - accuracy: 0.1005 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 2.3028 - accuracy: 0.0990 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0986 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0973 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 2.3028 - accuracy: 0.0959 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 2.3027830123901367\n",
      "Training Accuracy: 0.095940001308918\n",
      "Validation Loss: 2.302654266357422\n",
      "Validation Accuracy: 0.10000000149011612\n",
      "Classification Error Rate: 0.8999999985098839\n",
      "----->Evolution: Child net_6 with fitness 2.302654266357422 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Elitism selection\n",
      "Selected net_3 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Child has been mutated\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.6118 - accuracy: 0.4460 - val_loss: 1.2955 - val_accuracy: 0.5434\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1492 - accuracy: 0.5999 - val_loss: 1.3782 - val_accuracy: 0.5498\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 1.0077 - accuracy: 0.6497 - val_loss: 1.1370 - val_accuracy: 0.6167\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.8989 - accuracy: 0.6907 - val_loss: 1.3957 - val_accuracy: 0.5752\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.8153 - accuracy: 0.7203 - val_loss: 1.4215 - val_accuracy: 0.5954\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7383 - accuracy: 0.7499 - val_loss: 1.3177 - val_accuracy: 0.6187\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6768 - accuracy: 0.7726 - val_loss: 1.2783 - val_accuracy: 0.6296\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6179 - accuracy: 0.7944 - val_loss: 1.7483 - val_accuracy: 0.6221\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5745 - accuracy: 0.8114 - val_loss: 1.8404 - val_accuracy: 0.6101\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5159 - accuracy: 0.8298 - val_loss: 1.7837 - val_accuracy: 0.6240\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4916 - accuracy: 0.8437 - val_loss: 2.1632 - val_accuracy: 0.6265\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4653 - accuracy: 0.8530 - val_loss: 2.1356 - val_accuracy: 0.6048\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4389 - accuracy: 0.8643 - val_loss: 2.0411 - val_accuracy: 0.6339\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.4051 - accuracy: 0.8742 - val_loss: 2.4115 - val_accuracy: 0.6254\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3888 - accuracy: 0.8821 - val_loss: 2.6399 - val_accuracy: 0.6173\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3662 - accuracy: 0.8904 - val_loss: 3.0737 - val_accuracy: 0.6138\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3475 - accuracy: 0.8955 - val_loss: 2.9178 - val_accuracy: 0.6040\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3281 - accuracy: 0.9034 - val_loss: 3.4827 - val_accuracy: 0.6235\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3397 - accuracy: 0.9053 - val_loss: 3.5681 - val_accuracy: 0.6289\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3275 - accuracy: 0.9098 - val_loss: 3.7815 - val_accuracy: 0.6186\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3147 - accuracy: 0.9149 - val_loss: 3.9744 - val_accuracy: 0.6169\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3027 - accuracy: 0.9180 - val_loss: 4.1310 - val_accuracy: 0.6276\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2843 - accuracy: 0.9246 - val_loss: 4.2285 - val_accuracy: 0.6217\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2708 - accuracy: 0.9281 - val_loss: 4.4343 - val_accuracy: 0.6113\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2694 - accuracy: 0.9312 - val_loss: 4.7542 - val_accuracy: 0.6210\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2519 - accuracy: 0.9354 - val_loss: 4.7938 - val_accuracy: 0.6293\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2683 - accuracy: 0.9345 - val_loss: 5.7880 - val_accuracy: 0.6248\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2412 - accuracy: 0.9404 - val_loss: 5.1399 - val_accuracy: 0.6272\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2415 - accuracy: 0.9440 - val_loss: 5.4209 - val_accuracy: 0.6288\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.2429 - accuracy: 0.9438 - val_loss: 5.6734 - val_accuracy: 0.6277\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 0.2428816854953766\n",
      "Training Accuracy: 0.9437999725341797\n",
      "Validation Loss: 5.673367977142334\n",
      "Validation Accuracy: 0.6276999711990356\n",
      "Classification Error Rate: 0.37230002880096436\n",
      "----->Evolution: Child net_7 with fitness 5.673367977142334 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Elitism selection\n",
      "Selected net_3 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  256.0\n",
      "Child has been mutated\n",
      "\n",
      "INDIVIDUAL ABORTED, CREATING A NEW ONE\n",
      "\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 2)]\n",
      "Inserting a Convolutional layer\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  256.0\n",
      "\n",
      "INDIVIDUAL ABORTED, CREATING A NEW ONE\n",
      "\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2)]\n",
      "Removing a Conv2D layer at 0\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "\n",
      "INDIVIDUAL ABORTED, CREATING A NEW ONE\n",
      "\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Removing a Conv2D layer at 3\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 2\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  64.0\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 14s 7ms/step - loss: 1.8364 - accuracy: 0.3190 - val_loss: 1.7998 - val_accuracy: 0.3573\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5417 - accuracy: 0.4366 - val_loss: 1.5751 - val_accuracy: 0.4267\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4594 - accuracy: 0.4715 - val_loss: 1.4821 - val_accuracy: 0.4687\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4193 - accuracy: 0.4887 - val_loss: 1.7172 - val_accuracy: 0.4165\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4064 - accuracy: 0.4946 - val_loss: 1.5495 - val_accuracy: 0.4451\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3988 - accuracy: 0.5011 - val_loss: 1.5913 - val_accuracy: 0.4236\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3984 - accuracy: 0.5009 - val_loss: 1.3778 - val_accuracy: 0.5018\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3940 - accuracy: 0.5016 - val_loss: 1.4290 - val_accuracy: 0.4838\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3935 - accuracy: 0.5017 - val_loss: 1.5410 - val_accuracy: 0.4756\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3971 - accuracy: 0.5004 - val_loss: 1.4698 - val_accuracy: 0.4759\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4194 - accuracy: 0.4944 - val_loss: 1.4334 - val_accuracy: 0.4935\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4193 - accuracy: 0.4960 - val_loss: 1.4151 - val_accuracy: 0.4950\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4136 - accuracy: 0.4954 - val_loss: 1.5179 - val_accuracy: 0.4659\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4276 - accuracy: 0.4916 - val_loss: 1.5374 - val_accuracy: 0.4796\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4092 - accuracy: 0.5013 - val_loss: 1.4758 - val_accuracy: 0.4788\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4235 - accuracy: 0.4943 - val_loss: 1.5861 - val_accuracy: 0.4634\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4312 - accuracy: 0.4953 - val_loss: 1.4369 - val_accuracy: 0.4788\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4354 - accuracy: 0.4930 - val_loss: 1.5121 - val_accuracy: 0.4814\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4469 - accuracy: 0.4932 - val_loss: 1.3776 - val_accuracy: 0.5082\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4469 - accuracy: 0.4921 - val_loss: 2.5611 - val_accuracy: 0.4228\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4407 - accuracy: 0.4934 - val_loss: 1.3925 - val_accuracy: 0.4995\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4452 - accuracy: 0.4932 - val_loss: 1.4106 - val_accuracy: 0.5012\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4269 - accuracy: 0.4978 - val_loss: 1.6713 - val_accuracy: 0.4349\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4090 - accuracy: 0.5028 - val_loss: 1.4738 - val_accuracy: 0.4745\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3958 - accuracy: 0.5060 - val_loss: 1.4344 - val_accuracy: 0.4899\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3944 - accuracy: 0.5074 - val_loss: 1.4511 - val_accuracy: 0.4845\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4297 - accuracy: 0.5075 - val_loss: 1.4096 - val_accuracy: 0.5035\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.3738 - accuracy: 0.5154 - val_loss: 1.5184 - val_accuracy: 0.5138\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3964 - accuracy: 0.5169 - val_loss: 1.6077 - val_accuracy: 0.4499\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.3840 - accuracy: 0.5138 - val_loss: 1.7377 - val_accuracy: 0.4141\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 1.3840464353561401\n",
      "Training Accuracy: 0.513759970664978\n",
      "Validation Loss: 1.737733244895935\n",
      "Validation Accuracy: 0.4140999913215637\n",
      "Classification Error Rate: 0.5859000086784363\n",
      "----->Evolution: Child net_8 with fitness 1.737733244895935 replaces parent net_2 with fitness 2.0117008686065674\n",
      "\n",
      "Creating Child 3\n",
      "----->Elitism selection\n",
      "Selected net_3 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 3\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Child has been mutated\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 15s 7ms/step - loss: 1.8374 - accuracy: 0.3151 - val_loss: 1.5854 - val_accuracy: 0.4051\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4554 - accuracy: 0.4758 - val_loss: 1.4894 - val_accuracy: 0.4709\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.3171 - accuracy: 0.5310 - val_loss: 1.5109 - val_accuracy: 0.5019\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2544 - accuracy: 0.5584 - val_loss: 1.2208 - val_accuracy: 0.5801\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2329 - accuracy: 0.5701 - val_loss: 1.2231 - val_accuracy: 0.5613\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2113 - accuracy: 0.5771 - val_loss: 1.2561 - val_accuracy: 0.5473\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1916 - accuracy: 0.5871 - val_loss: 1.8572 - val_accuracy: 0.4989\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1670 - accuracy: 0.5983 - val_loss: 1.5034 - val_accuracy: 0.5219\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1574 - accuracy: 0.6066 - val_loss: 1.1275 - val_accuracy: 0.6103\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1350 - accuracy: 0.6126 - val_loss: 1.2385 - val_accuracy: 0.5711\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1372 - accuracy: 0.6146 - val_loss: 1.0619 - val_accuracy: 0.6274\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1332 - accuracy: 0.6170 - val_loss: 1.5891 - val_accuracy: 0.5048\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1578 - accuracy: 0.6208 - val_loss: 1.3243 - val_accuracy: 0.5627\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1212 - accuracy: 0.6269 - val_loss: 1.1617 - val_accuracy: 0.6247\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1148 - accuracy: 0.6271 - val_loss: 1.2417 - val_accuracy: 0.6018\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.1951 - accuracy: 0.6220 - val_loss: 1.1457 - val_accuracy: 0.5956\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2094 - accuracy: 0.6281 - val_loss: 1.5142 - val_accuracy: 0.4683\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1609 - accuracy: 0.6249 - val_loss: 1.1703 - val_accuracy: 0.6288\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1681 - accuracy: 0.6168 - val_loss: 1.3076 - val_accuracy: 0.6059\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2279 - accuracy: 0.6256 - val_loss: 1.1718 - val_accuracy: 0.6046\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1482 - accuracy: 0.6346 - val_loss: 1.2497 - val_accuracy: 0.5731\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3357 - accuracy: 0.6282 - val_loss: 1.2695 - val_accuracy: 0.5841\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.1433 - accuracy: 0.6331 - val_loss: 1.3613 - val_accuracy: 0.5369\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.2973 - accuracy: 0.6349 - val_loss: 1.4571 - val_accuracy: 0.6224\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1712 - accuracy: 0.6276 - val_loss: 1.3724 - val_accuracy: 0.6171\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2251 - accuracy: 0.6388 - val_loss: 1.0370 - val_accuracy: 0.6503\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7625 - accuracy: 0.6171 - val_loss: 1.4098 - val_accuracy: 0.6167\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.1780 - accuracy: 0.6330 - val_loss: 1.4304 - val_accuracy: 0.4968\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.3614 - accuracy: 0.6382 - val_loss: 1.1787 - val_accuracy: 0.6195\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2066 - accuracy: 0.6297 - val_loss: 1.1409 - val_accuracy: 0.6026\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 1.2066082954406738\n",
      "Training Accuracy: 0.6296600103378296\n",
      "Validation Loss: 1.1408569812774658\n",
      "Validation Accuracy: 0.6025999784469604\n",
      "Classification Error Rate: 0.39740002155303955\n",
      "----->Evolution: Child net_9 with fitness 1.1408569812774658 replaces parent net_1 with fitness 1.8270263671875\n",
      "\n",
      "Creating Child 4\n",
      "----->Elitism selection\n",
      "Selected net_1 and net_3 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  64.0\n",
      "Child has been mutated\n",
      "\n",
      "INDIVIDUAL ABORTED, CREATING A NEW ONE\n",
      "\n",
      "----->Crossover\n",
      "Block Mutation\n",
      "[(0, 0), (1, 1), (2, 1), (3, 2)]\n",
      "Removing a Conv2D layer at 2\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  16  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  256.0\n",
      "Training net_10\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 15s 8ms/step - loss: 1.9934 - accuracy: 0.2676 - val_loss: 1.9288 - val_accuracy: 0.3152\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6929 - accuracy: 0.3791 - val_loss: 1.8615 - val_accuracy: 0.3572\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.6644 - accuracy: 0.3960 - val_loss: 1.7103 - val_accuracy: 0.3952\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6506 - accuracy: 0.3941 - val_loss: 1.7986 - val_accuracy: 0.3673\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6447 - accuracy: 0.4017 - val_loss: 1.5958 - val_accuracy: 0.4104\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.6097 - accuracy: 0.4162 - val_loss: 1.5672 - val_accuracy: 0.4252\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5837 - accuracy: 0.4209 - val_loss: 1.5155 - val_accuracy: 0.4498\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5583 - accuracy: 0.4314 - val_loss: 1.7488 - val_accuracy: 0.4101\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.5350 - accuracy: 0.4347 - val_loss: 1.6883 - val_accuracy: 0.3983\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.5435 - accuracy: 0.4376 - val_loss: 1.8326 - val_accuracy: 0.3677\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.5238 - accuracy: 0.4445 - val_loss: 1.8456 - val_accuracy: 0.3747\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.5065 - accuracy: 0.4490 - val_loss: 1.6997 - val_accuracy: 0.3993\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.4922 - accuracy: 0.4564 - val_loss: 1.9140 - val_accuracy: 0.3619\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.4804 - accuracy: 0.4633 - val_loss: 1.4652 - val_accuracy: 0.4645\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.4792 - accuracy: 0.4647 - val_loss: 1.3841 - val_accuracy: 0.4900\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.4586 - accuracy: 0.4740 - val_loss: 1.4532 - val_accuracy: 0.4634\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.4613 - accuracy: 0.4740 - val_loss: 2.2037 - val_accuracy: 0.3525\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.4818 - accuracy: 0.4733 - val_loss: 1.4851 - val_accuracy: 0.4507\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.4992 - accuracy: 0.4707 - val_loss: 1.5604 - val_accuracy: 0.4642\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 1.5008 - accuracy: 0.4717 - val_loss: 1.6294 - val_accuracy: 0.4065\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.5132 - accuracy: 0.4799 - val_loss: 1.9193 - val_accuracy: 0.4234\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.5061 - accuracy: 0.4770 - val_loss: 1.3915 - val_accuracy: 0.5013\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.9410 - accuracy: 0.4614 - val_loss: 1.7065 - val_accuracy: 0.4073\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7363 - accuracy: 0.4669 - val_loss: 1.5457 - val_accuracy: 0.4525\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7472 - accuracy: 0.4669 - val_loss: 1.6754 - val_accuracy: 0.4181\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.6601 - accuracy: 0.4772 - val_loss: 1.5492 - val_accuracy: 0.4483\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.5328 - accuracy: 0.4774 - val_loss: 1.5118 - val_accuracy: 0.4768\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.5043 - accuracy: 0.4881 - val_loss: 1.4358 - val_accuracy: 0.4785\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.8517 - accuracy: 0.4930 - val_loss: 1.5932 - val_accuracy: 0.4513\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7346 - accuracy: 0.4881 - val_loss: 1.9754 - val_accuracy: 0.4228\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 1.734622836112976\n",
      "Training Accuracy: 0.4881399869918823\n",
      "Validation Loss: 1.9754316806793213\n",
      "Validation Accuracy: 0.4228000044822693\n",
      "Classification Error Rate: 0.5771999955177307\n",
      "----->Evolution: Child net_10 with fitness 1.9754316806793213 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 7\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Proportionate selection\n",
      "Selected net_3 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  64.0\n",
      "Child has been mutated\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 14s 7ms/step - loss: 1.5610 - accuracy: 0.4408 - val_loss: 1.5290 - val_accuracy: 0.4789\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1929 - accuracy: 0.5837 - val_loss: 1.4082 - val_accuracy: 0.5461\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0261 - accuracy: 0.6435 - val_loss: 1.2779 - val_accuracy: 0.5968\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9336 - accuracy: 0.6818 - val_loss: 1.3321 - val_accuracy: 0.6099\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8963 - accuracy: 0.7001 - val_loss: 1.1962 - val_accuracy: 0.6298\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8791 - accuracy: 0.7078 - val_loss: 1.3345 - val_accuracy: 0.6395\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8628 - accuracy: 0.7146 - val_loss: 1.4643 - val_accuracy: 0.6167\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8549 - accuracy: 0.7193 - val_loss: 1.1389 - val_accuracy: 0.6197\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 9s 5ms/step - loss: 0.8232 - accuracy: 0.7305 - val_loss: 1.6606 - val_accuracy: 0.5890\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7898 - accuracy: 0.7394 - val_loss: 1.3183 - val_accuracy: 0.5964\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7537 - accuracy: 0.7512 - val_loss: 1.3806 - val_accuracy: 0.5961\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7286 - accuracy: 0.7606 - val_loss: 1.9006 - val_accuracy: 0.6075\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7169 - accuracy: 0.7662 - val_loss: 1.7812 - val_accuracy: 0.5431\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7061 - accuracy: 0.7736 - val_loss: 1.6936 - val_accuracy: 0.5795\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6700 - accuracy: 0.7836 - val_loss: 1.4767 - val_accuracy: 0.5635\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.6544 - accuracy: 0.7894 - val_loss: 2.0864 - val_accuracy: 0.5925\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.6517 - accuracy: 0.7918 - val_loss: 1.6178 - val_accuracy: 0.5906\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6428 - accuracy: 0.7953 - val_loss: 1.6251 - val_accuracy: 0.5762\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6426 - accuracy: 0.8006 - val_loss: 1.7590 - val_accuracy: 0.5401\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6386 - accuracy: 0.7987 - val_loss: 1.6356 - val_accuracy: 0.5911\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6512 - accuracy: 0.7984 - val_loss: 2.8861 - val_accuracy: 0.5154\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6324 - accuracy: 0.8032 - val_loss: 1.7488 - val_accuracy: 0.5739\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6208 - accuracy: 0.8119 - val_loss: 2.2354 - val_accuracy: 0.5394\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6835 - accuracy: 0.7955 - val_loss: 2.4389 - val_accuracy: 0.4933\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6847 - accuracy: 0.7943 - val_loss: 1.7722 - val_accuracy: 0.5423\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7138 - accuracy: 0.7884 - val_loss: 3.2980 - val_accuracy: 0.5373\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7485 - accuracy: 0.7841 - val_loss: 2.0970 - val_accuracy: 0.5152\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7229 - accuracy: 0.7907 - val_loss: 3.3214 - val_accuracy: 0.5388\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7421 - accuracy: 0.7883 - val_loss: 3.2500 - val_accuracy: 0.4075\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7880 - accuracy: 0.7811 - val_loss: 3.4255 - val_accuracy: 0.4867\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 0.7880113124847412\n",
      "Training Accuracy: 0.7811200022697449\n",
      "Validation Loss: 3.4255290031433105\n",
      "Validation Accuracy: 0.48669999837875366\n",
      "Classification Error Rate: 0.5133000016212463\n",
      "----->Evolution: Child net_6 with fitness 3.4255290031433105 is discarded\n",
      "\n",
      "Creating Child 1\n",
      "----->Proportionate selection\n",
      "Selected net_1 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Changing Pooling layer at index 0 with Conv2D layer\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Child has been mutated\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 15s 8ms/step - loss: 1.5892 - accuracy: 0.4282 - val_loss: 1.3492 - val_accuracy: 0.5217\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1937 - accuracy: 0.5782 - val_loss: 1.1466 - val_accuracy: 0.6102\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0482 - accuracy: 0.6328 - val_loss: 1.1100 - val_accuracy: 0.6045\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9677 - accuracy: 0.6639 - val_loss: 1.1296 - val_accuracy: 0.6195\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.9178 - accuracy: 0.6846 - val_loss: 1.1666 - val_accuracy: 0.6062\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.9163 - accuracy: 0.6883 - val_loss: 1.1470 - val_accuracy: 0.6121\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 0.9207 - accuracy: 0.6908 - val_loss: 1.1504 - val_accuracy: 0.6278\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9490 - accuracy: 0.6803 - val_loss: 1.2599 - val_accuracy: 0.6059\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.9686 - accuracy: 0.6733 - val_loss: 1.2880 - val_accuracy: 0.5864\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0137 - accuracy: 0.6610 - val_loss: 1.2981 - val_accuracy: 0.6301\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.0659 - accuracy: 0.6447 - val_loss: 1.4219 - val_accuracy: 0.5201\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0787 - accuracy: 0.6353 - val_loss: 1.2487 - val_accuracy: 0.5693\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1107 - accuracy: 0.6261 - val_loss: 1.3729 - val_accuracy: 0.5715\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.1304 - accuracy: 0.6208 - val_loss: 1.4965 - val_accuracy: 0.4949\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1281 - accuracy: 0.6203 - val_loss: 1.1649 - val_accuracy: 0.6019\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1221 - accuracy: 0.6247 - val_loss: 1.2433 - val_accuracy: 0.5772\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1320 - accuracy: 0.6220 - val_loss: 1.3974 - val_accuracy: 0.5209\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1471 - accuracy: 0.6190 - val_loss: 2.0711 - val_accuracy: 0.3965\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1385 - accuracy: 0.6182 - val_loss: 1.2604 - val_accuracy: 0.5697\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1256 - accuracy: 0.6244 - val_loss: 1.2481 - val_accuracy: 0.6024\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1438 - accuracy: 0.6197 - val_loss: 1.3369 - val_accuracy: 0.5804\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1472 - accuracy: 0.6200 - val_loss: 1.5287 - val_accuracy: 0.4757\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.1938 - accuracy: 0.6095 - val_loss: 1.4199 - val_accuracy: 0.5041\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1860 - accuracy: 0.6085 - val_loss: 1.4043 - val_accuracy: 0.5327\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1857 - accuracy: 0.6077 - val_loss: 1.6827 - val_accuracy: 0.3857\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.1858 - accuracy: 0.6045 - val_loss: 1.3618 - val_accuracy: 0.5478\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3193 - accuracy: 0.5985 - val_loss: 1.4288 - val_accuracy: 0.5048\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2651 - accuracy: 0.6020 - val_loss: 1.5704 - val_accuracy: 0.4575\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2810 - accuracy: 0.5872 - val_loss: 1.8469 - val_accuracy: 0.4357\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.2613 - accuracy: 0.5868 - val_loss: 1.9686 - val_accuracy: 0.4686\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 1.2613497972488403\n",
      "Training Accuracy: 0.5868200063705444\n",
      "Validation Loss: 1.9685832262039185\n",
      "Validation Accuracy: 0.46860000491142273\n",
      "Classification Error Rate: 0.5313999950885773\n",
      "----->Evolution: Child net_7 with fitness 1.9685832262039185 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Proportionate selection\n",
      "Selected net_3 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 2\n",
      "Parameters Mutation\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  256.0\n",
      "Child has been mutated\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 15s 7ms/step - loss: 2.4132 - accuracy: 0.1009 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.3028 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.0999\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.3083 - accuracy: 0.0982 - val_loss: 2.3020 - val_accuracy: 0.1010\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.2031 - accuracy: 0.1676 - val_loss: 1.7550 - val_accuracy: 0.3652\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6671 - accuracy: 0.4011 - val_loss: 1.8503 - val_accuracy: 0.3808\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.5984 - accuracy: 0.4344 - val_loss: 1.5787 - val_accuracy: 0.4352\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5989 - accuracy: 0.4357 - val_loss: 1.5627 - val_accuracy: 0.4431\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.5835 - accuracy: 0.4383 - val_loss: 1.6277 - val_accuracy: 0.4244\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6034 - accuracy: 0.4324 - val_loss: 1.7055 - val_accuracy: 0.4164\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6724 - accuracy: 0.4247 - val_loss: 1.5718 - val_accuracy: 0.4345\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6118 - accuracy: 0.4276 - val_loss: 1.6451 - val_accuracy: 0.4239\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6438 - accuracy: 0.4201 - val_loss: 1.6394 - val_accuracy: 0.3994\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6496 - accuracy: 0.4132 - val_loss: 1.7497 - val_accuracy: 0.3666\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6384 - accuracy: 0.4139 - val_loss: 1.7160 - val_accuracy: 0.3929\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6481 - accuracy: 0.4079 - val_loss: 1.6269 - val_accuracy: 0.4065\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6487 - accuracy: 0.4075 - val_loss: 3.1172 - val_accuracy: 0.3860\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6615 - accuracy: 0.3992 - val_loss: 3.0745 - val_accuracy: 0.2983\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6833 - accuracy: 0.3970 - val_loss: 1.6777 - val_accuracy: 0.3809\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6892 - accuracy: 0.3893 - val_loss: 1.8682 - val_accuracy: 0.3679\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6843 - accuracy: 0.3884 - val_loss: 1.6658 - val_accuracy: 0.3904\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7060 - accuracy: 0.3873 - val_loss: 1.7645 - val_accuracy: 0.3660\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6835 - accuracy: 0.3877 - val_loss: 1.7437 - val_accuracy: 0.3740\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.6958 - accuracy: 0.3853 - val_loss: 1.7349 - val_accuracy: 0.3746\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7046 - accuracy: 0.3813 - val_loss: 1.7498 - val_accuracy: 0.3661\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6963 - accuracy: 0.3806 - val_loss: 1.7541 - val_accuracy: 0.3711\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6956 - accuracy: 0.3855 - val_loss: 1.6975 - val_accuracy: 0.3774\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6941 - accuracy: 0.3823 - val_loss: 1.6803 - val_accuracy: 0.3803\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.7108 - accuracy: 0.3783 - val_loss: 1.7816 - val_accuracy: 0.3594\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7781 - accuracy: 0.3810 - val_loss: 1.7191 - val_accuracy: 0.3629\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.6983 - accuracy: 0.3801 - val_loss: 1.6986 - val_accuracy: 0.3688\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 1.6982648372650146\n",
      "Training Accuracy: 0.3801000118255615\n",
      "Validation Loss: 1.698641061782837\n",
      "Validation Accuracy: 0.36880001425743103\n",
      "Classification Error Rate: 0.631199985742569\n",
      "----->Evolution: Child net_8 with fitness 1.698641061782837 replaces parent parent_0 with fitness 1.8009968996047974\n",
      "\n",
      "Creating Child 3\n",
      "----->Proportionate selection\n",
      "Selected net_5 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  256.0\n",
      "Child has been mutated\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 16s 8ms/step - loss: 1.6079 - accuracy: 0.4170 - val_loss: 1.4113 - val_accuracy: 0.4974\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.2861 - accuracy: 0.5440 - val_loss: 1.4990 - val_accuracy: 0.5027\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.1659 - accuracy: 0.5937 - val_loss: 1.3625 - val_accuracy: 0.5529\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.1018 - accuracy: 0.6228 - val_loss: 1.2737 - val_accuracy: 0.5635\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.0520 - accuracy: 0.6406 - val_loss: 1.3248 - val_accuracy: 0.5813\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.0269 - accuracy: 0.6530 - val_loss: 1.2052 - val_accuracy: 0.6161\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.0065 - accuracy: 0.6628 - val_loss: 1.2916 - val_accuracy: 0.6363\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.0101 - accuracy: 0.6679 - val_loss: 1.1752 - val_accuracy: 0.6229\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.9933 - accuracy: 0.6749 - val_loss: 1.3285 - val_accuracy: 0.6310\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.0022 - accuracy: 0.6739 - val_loss: 1.4371 - val_accuracy: 0.6045\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.0118 - accuracy: 0.6750 - val_loss: 2.3743 - val_accuracy: 0.5123\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.0413 - accuracy: 0.6763 - val_loss: 1.2866 - val_accuracy: 0.6088\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.0579 - accuracy: 0.6685 - val_loss: 1.3379 - val_accuracy: 0.6260\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.0701 - accuracy: 0.6695 - val_loss: 1.6910 - val_accuracy: 0.5641\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.4511 - accuracy: 0.6719 - val_loss: 1.2971 - val_accuracy: 0.6299\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.0778 - accuracy: 0.6655 - val_loss: 1.4113 - val_accuracy: 0.5747\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 1.0933 - accuracy: 0.6632 - val_loss: 1.7136 - val_accuracy: 0.6074\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.1434 - accuracy: 0.6619 - val_loss: 1.5965 - val_accuracy: 0.6374\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1635 - accuracy: 0.6608 - val_loss: 1.5253 - val_accuracy: 0.5271\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.3607 - accuracy: 0.6666 - val_loss: 1.6029 - val_accuracy: 0.4841\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.1264 - accuracy: 0.6554 - val_loss: 1.4380 - val_accuracy: 0.5448\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.1637 - accuracy: 0.6598 - val_loss: 1.8008 - val_accuracy: 0.4112\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.1940 - accuracy: 0.6513 - val_loss: 1.4590 - val_accuracy: 0.4725\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.3470 - accuracy: 0.6491 - val_loss: 1.8589 - val_accuracy: 0.5248\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.2330 - accuracy: 0.6407 - val_loss: 2.0952 - val_accuracy: 0.4223\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.4079 - accuracy: 0.6110 - val_loss: 2.0653 - val_accuracy: 0.3592\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.4113 - accuracy: 0.5996 - val_loss: 3.0073 - val_accuracy: 0.3494\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.5542 - accuracy: 0.5946 - val_loss: 1.8914 - val_accuracy: 0.4288\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.5569 - accuracy: 0.5824 - val_loss: 1.8593 - val_accuracy: 0.4219\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.5483 - accuracy: 0.5666 - val_loss: 1.9103 - val_accuracy: 0.4195\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 1.5482743978500366\n",
      "Training Accuracy: 0.5666400194168091\n",
      "Validation Loss: 1.9102517366409302\n",
      "Validation Accuracy: 0.4194999933242798\n",
      "Classification Error Rate: 0.5805000066757202\n",
      "----->Evolution: Child net_9 with fitness 1.9102517366409302 is discarded\n",
      "\n",
      "Creating Child 4\n",
      "----->Proportionate selection\n",
      "Selected net_5 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 1\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  128\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  64  to  32\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  128\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  64.0  to  128.0\n",
      "Child has been mutated\n",
      "Training net_10\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 18s 9ms/step - loss: 1.8208 - accuracy: 0.3245 - val_loss: 1.7183 - val_accuracy: 0.3955\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 1.3980 - accuracy: 0.5020 - val_loss: 1.4265 - val_accuracy: 0.4946\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 1.2621 - accuracy: 0.5576 - val_loss: 1.7275 - val_accuracy: 0.4399\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 1.2018 - accuracy: 0.5823 - val_loss: 1.5505 - val_accuracy: 0.5130\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 1.1697 - accuracy: 0.5976 - val_loss: 1.6628 - val_accuracy: 0.4521\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 1.1367 - accuracy: 0.6160 - val_loss: 1.7514 - val_accuracy: 0.4410\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.1348 - accuracy: 0.6185 - val_loss: 1.3174 - val_accuracy: 0.5648\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 1.1519 - accuracy: 0.6211 - val_loss: 1.4522 - val_accuracy: 0.5455\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 1.1629 - accuracy: 0.6242 - val_loss: 1.3899 - val_accuracy: 0.5549\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 1.2067 - accuracy: 0.6249 - val_loss: 1.6093 - val_accuracy: 0.4950\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 13s 9ms/step - loss: 1.2846 - accuracy: 0.6170 - val_loss: 1.5913 - val_accuracy: 0.5150\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.3783 - accuracy: 0.6065 - val_loss: 1.6307 - val_accuracy: 0.4489\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.5661 - accuracy: 0.5910 - val_loss: 2.0953 - val_accuracy: 0.5285\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4713 - accuracy: 0.5914 - val_loss: 1.8562 - val_accuracy: 0.4325\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 1.4832 - accuracy: 0.6094 - val_loss: 2.1832 - val_accuracy: 0.4213\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 1.3269 - accuracy: 0.6134 - val_loss: 2.1066 - val_accuracy: 0.3730\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 1.2959 - accuracy: 0.6195 - val_loss: 2.9531 - val_accuracy: 0.2531\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 8.2213 - accuracy: 0.6006 - val_loss: 1.3630 - val_accuracy: 0.6067\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 2.3001 - accuracy: 0.6037 - val_loss: 1.3977 - val_accuracy: 0.5428\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 14.3202 - accuracy: 0.5866 - val_loss: 1.9553 - val_accuracy: 0.4213\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.1052 - accuracy: 0.5929 - val_loss: 1.5696 - val_accuracy: 0.5085\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 3.8312 - accuracy: 0.5817 - val_loss: 3.2777 - val_accuracy: 0.4695\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.0618 - accuracy: 0.5779 - val_loss: 5.2608 - val_accuracy: 0.4172\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 4.7454 - accuracy: 0.5651 - val_loss: 1.9796 - val_accuracy: 0.4488\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 3.5613 - accuracy: 0.5658 - val_loss: 2.5264 - val_accuracy: 0.3604\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 11.8240 - accuracy: 0.4750 - val_loss: 1.8392 - val_accuracy: 0.3059\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 3.8852 - accuracy: 0.3539 - val_loss: 1.8291 - val_accuracy: 0.2824\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.6021 - accuracy: 0.3894 - val_loss: 5.6742 - val_accuracy: 0.4230\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 15s 10ms/step - loss: 3.0040 - accuracy: 0.2746 - val_loss: 2.5892 - val_accuracy: 0.1000\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 2.4053 - accuracy: 0.1000 - val_loss: 2.3139 - val_accuracy: 0.1000\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 2.405296802520752\n",
      "Training Accuracy: 0.10000000149011612\n",
      "Validation Loss: 2.3138656616210938\n",
      "Validation Accuracy: 0.10000000149011612\n",
      "Classification Error Rate: 0.8999999985098839\n",
      "----->Evolution: Child net_10 with fitness 2.3138656616210938 is discarded\n",
      "\n",
      "------------------------------------\n",
      "Generation ----------------------------------------------------------------------------------- 8\n",
      "-------------------------------------\n",
      "\n",
      "Creating Child 0\n",
      "----->Tournament selection\n",
      "Selected net_2 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Child has been mutated\n",
      "Training net_6\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 13s 7ms/step - loss: 1.8134 - accuracy: 0.3399 - val_loss: 1.5284 - val_accuracy: 0.4329\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.5114 - accuracy: 0.4596 - val_loss: 1.5737 - val_accuracy: 0.4607\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.4610 - accuracy: 0.4856 - val_loss: 1.4416 - val_accuracy: 0.4867\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4523 - accuracy: 0.4903 - val_loss: 1.4789 - val_accuracy: 0.5025\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4501 - accuracy: 0.4924 - val_loss: 1.4670 - val_accuracy: 0.4845\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4488 - accuracy: 0.4972 - val_loss: 1.4856 - val_accuracy: 0.5055\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4248 - accuracy: 0.5045 - val_loss: 1.3852 - val_accuracy: 0.5367\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4285 - accuracy: 0.5066 - val_loss: 1.3519 - val_accuracy: 0.5245\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4418 - accuracy: 0.5048 - val_loss: 1.5665 - val_accuracy: 0.4630\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.4373 - accuracy: 0.4998 - val_loss: 1.5743 - val_accuracy: 0.4300\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.4631 - accuracy: 0.4946 - val_loss: 1.7854 - val_accuracy: 0.4231\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5037 - accuracy: 0.4818 - val_loss: 1.5081 - val_accuracy: 0.4503\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.5389 - accuracy: 0.4718 - val_loss: 1.5557 - val_accuracy: 0.4616\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5390 - accuracy: 0.4649 - val_loss: 1.6498 - val_accuracy: 0.4457\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5891 - accuracy: 0.4562 - val_loss: 1.6247 - val_accuracy: 0.4120\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.5916 - accuracy: 0.4625 - val_loss: 1.6323 - val_accuracy: 0.4421\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5560 - accuracy: 0.4501 - val_loss: 1.6452 - val_accuracy: 0.4208\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6592 - accuracy: 0.4359 - val_loss: 1.6226 - val_accuracy: 0.4239\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6728 - accuracy: 0.4213 - val_loss: 1.6338 - val_accuracy: 0.4029\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.8000 - accuracy: 0.4128 - val_loss: 1.5435 - val_accuracy: 0.4320\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6430 - accuracy: 0.4187 - val_loss: 1.6869 - val_accuracy: 0.3828\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6155 - accuracy: 0.4253 - val_loss: 1.8345 - val_accuracy: 0.3768\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6316 - accuracy: 0.4241 - val_loss: 1.5468 - val_accuracy: 0.4626\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.6984 - accuracy: 0.4338 - val_loss: 1.5574 - val_accuracy: 0.4276\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.6313 - accuracy: 0.4334 - val_loss: 1.5065 - val_accuracy: 0.4626\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6941 - accuracy: 0.4348 - val_loss: 1.7243 - val_accuracy: 0.4015\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6936 - accuracy: 0.4302 - val_loss: 1.7040 - val_accuracy: 0.4020\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6438 - accuracy: 0.4303 - val_loss: 2.3935 - val_accuracy: 0.2884\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6940 - accuracy: 0.4274 - val_loss: 1.6378 - val_accuracy: 0.3993\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.9362 - accuracy: 0.4357 - val_loss: 1.5639 - val_accuracy: 0.4305\n",
      "SUMMARY OF net_6\n",
      "Training Loss: 1.9362367391586304\n",
      "Training Accuracy: 0.435699999332428\n",
      "Validation Loss: 1.5639008283615112\n",
      "Validation Accuracy: 0.43050000071525574\n",
      "Classification Error Rate: 0.5694999992847443\n",
      "----->Evolution: Child net_6 with fitness 1.5639008283615112 replaces parent net_4 with fitness 1.7794898748397827\n",
      "\n",
      "Creating Child 1\n",
      "----->Tournament selection\n",
      "Selected net_3 and net_4 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  256.0\n",
      "Child has been mutated\n",
      "Training net_7\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 15s 7ms/step - loss: 1.8579 - accuracy: 0.3237 - val_loss: 1.7392 - val_accuracy: 0.3933\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5683 - accuracy: 0.4368 - val_loss: 1.6650 - val_accuracy: 0.4049\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5343 - accuracy: 0.4582 - val_loss: 1.5702 - val_accuracy: 0.4418\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5921 - accuracy: 0.4413 - val_loss: 1.6195 - val_accuracy: 0.4215\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6092 - accuracy: 0.4315 - val_loss: 1.6231 - val_accuracy: 0.4292\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6340 - accuracy: 0.4318 - val_loss: 1.6528 - val_accuracy: 0.4113\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6444 - accuracy: 0.4192 - val_loss: 1.6670 - val_accuracy: 0.3992\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6696 - accuracy: 0.4096 - val_loss: 1.7526 - val_accuracy: 0.4115\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6839 - accuracy: 0.4109 - val_loss: 1.9641 - val_accuracy: 0.4179\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7100 - accuracy: 0.4005 - val_loss: 1.8053 - val_accuracy: 0.3824\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6976 - accuracy: 0.4052 - val_loss: 1.7566 - val_accuracy: 0.3937\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7130 - accuracy: 0.4012 - val_loss: 1.6188 - val_accuracy: 0.4118\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6965 - accuracy: 0.4008 - val_loss: 1.7756 - val_accuracy: 0.3561\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6771 - accuracy: 0.4043 - val_loss: 1.6372 - val_accuracy: 0.4191\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7409 - accuracy: 0.4074 - val_loss: 1.9176 - val_accuracy: 0.3566\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7336 - accuracy: 0.3948 - val_loss: 1.8207 - val_accuracy: 0.3470\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.9154 - accuracy: 0.3977 - val_loss: 1.6887 - val_accuracy: 0.3955\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7333 - accuracy: 0.3938 - val_loss: 1.9661 - val_accuracy: 0.3059\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.8263 - accuracy: 0.3794 - val_loss: 3.0291 - val_accuracy: 0.3242\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.7772 - accuracy: 0.3795 - val_loss: 1.6874 - val_accuracy: 0.3999\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 5.2656 - accuracy: 0.3759 - val_loss: 1.7688 - val_accuracy: 0.3753\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.9015 - accuracy: 0.3635 - val_loss: 1.8495 - val_accuracy: 0.3497\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.9128 - accuracy: 0.3399 - val_loss: 1.9842 - val_accuracy: 0.3072\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.5538 - accuracy: 0.3321 - val_loss: 1.7945 - val_accuracy: 0.3345\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.9382 - accuracy: 0.3291 - val_loss: 1.8374 - val_accuracy: 0.3487\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.2834 - accuracy: 0.3145 - val_loss: 1.8083 - val_accuracy: 0.3186\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.1070 - accuracy: 0.2817 - val_loss: 2.1219 - val_accuracy: 0.2789\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.0634 - accuracy: 0.2772 - val_loss: 1.8273 - val_accuracy: 0.3024\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.8109 - accuracy: 0.2606 - val_loss: 1.9605 - val_accuracy: 0.2218\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 2.2251 - accuracy: 0.2721 - val_loss: 1.9587 - val_accuracy: 0.2629\n",
      "SUMMARY OF net_7\n",
      "Training Loss: 2.2251229286193848\n",
      "Training Accuracy: 0.27211999893188477\n",
      "Validation Loss: 1.9586892127990723\n",
      "Validation Accuracy: 0.2628999948501587\n",
      "Classification Error Rate: 0.7371000051498413\n",
      "----->Evolution: Child net_7 with fitness 1.9586892127990723 is discarded\n",
      "\n",
      "Creating Child 2\n",
      "----->Tournament selection\n",
      "Selected net_4 and net_5 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  16\n",
      "Mutating MaxPooling2D layer:\n",
      "-->changed self.name from  MaxPooling2D  to  AveragePooling2D\n",
      "Mutating FullyConnected layer:\n",
      "-->changed self.units from  128.0  to  64.0\n",
      "Child has been mutated\n",
      "Training net_8\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3991 - accuracy: 0.5053 - val_loss: 1.1969 - val_accuracy: 0.5800\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 1.0365 - accuracy: 0.6378 - val_loss: 1.0496 - val_accuracy: 0.6352\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.8975 - accuracy: 0.6876 - val_loss: 1.0101 - val_accuracy: 0.6491\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7968 - accuracy: 0.7252 - val_loss: 0.9435 - val_accuracy: 0.6777\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7154 - accuracy: 0.7522 - val_loss: 0.9691 - val_accuracy: 0.6765\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6424 - accuracy: 0.7768 - val_loss: 1.1061 - val_accuracy: 0.6545\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5795 - accuracy: 0.7992 - val_loss: 1.0683 - val_accuracy: 0.6748\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5176 - accuracy: 0.8215 - val_loss: 1.0783 - val_accuracy: 0.6774\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4618 - accuracy: 0.8418 - val_loss: 1.1676 - val_accuracy: 0.6698\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4125 - accuracy: 0.8594 - val_loss: 1.2889 - val_accuracy: 0.6662\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3616 - accuracy: 0.8772 - val_loss: 1.3810 - val_accuracy: 0.6605\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3245 - accuracy: 0.8902 - val_loss: 1.4898 - val_accuracy: 0.6657\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2876 - accuracy: 0.9029 - val_loss: 1.5772 - val_accuracy: 0.6470\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2520 - accuracy: 0.9152 - val_loss: 1.7172 - val_accuracy: 0.6600\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2259 - accuracy: 0.9242 - val_loss: 1.8689 - val_accuracy: 0.6567\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.2015 - accuracy: 0.9314 - val_loss: 2.0678 - val_accuracy: 0.6505\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1800 - accuracy: 0.9379 - val_loss: 2.3491 - val_accuracy: 0.6403\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1619 - accuracy: 0.9457 - val_loss: 2.3389 - val_accuracy: 0.6455\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1469 - accuracy: 0.9503 - val_loss: 2.4608 - val_accuracy: 0.6370\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1354 - accuracy: 0.9543 - val_loss: 2.6374 - val_accuracy: 0.6443\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1265 - accuracy: 0.9574 - val_loss: 2.6959 - val_accuracy: 0.6420\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1229 - accuracy: 0.9595 - val_loss: 2.9790 - val_accuracy: 0.6471\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1124 - accuracy: 0.9624 - val_loss: 3.2774 - val_accuracy: 0.6382\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.1089 - accuracy: 0.9641 - val_loss: 3.4360 - val_accuracy: 0.6421\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.1049 - accuracy: 0.9656 - val_loss: 3.4638 - val_accuracy: 0.6389\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0994 - accuracy: 0.9683 - val_loss: 3.4743 - val_accuracy: 0.6438\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 0.0940 - accuracy: 0.9695 - val_loss: 3.7140 - val_accuracy: 0.6415\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0960 - accuracy: 0.9692 - val_loss: 3.9398 - val_accuracy: 0.6347\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0927 - accuracy: 0.9710 - val_loss: 3.7490 - val_accuracy: 0.6404\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.0858 - accuracy: 0.9732 - val_loss: 4.5211 - val_accuracy: 0.6442\n",
      "SUMMARY OF net_8\n",
      "Training Loss: 0.08581933379173279\n",
      "Training Accuracy: 0.9731799960136414\n",
      "Validation Loss: 4.521145820617676\n",
      "Validation Accuracy: 0.6442000269889832\n",
      "Classification Error Rate: 0.35579997301101685\n",
      "----->Evolution: Child net_8 with fitness 4.521145820617676 is discarded\n",
      "\n",
      "Creating Child 3\n",
      "----->Tournament selection\n",
      "Selected parent_0 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 2\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.padding from  valid  to  same\n",
      "Mutating AveragePooling2D layer:\n",
      "-->changed self.padding from  same  to  valid\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  256\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  4  to  8\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  256  to  512\n",
      "Child has been mutated\n",
      "Training net_9\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 14s 7ms/step - loss: 2.3914 - accuracy: 0.0991 - val_loss: 2.3070 - val_accuracy: 0.1002\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.3034 - accuracy: 0.0976 - val_loss: 2.3075 - val_accuracy: 0.1000\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.3042 - accuracy: 0.0988 - val_loss: 2.3067 - val_accuracy: 0.0999\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.3034 - accuracy: 0.0986 - val_loss: 2.3034 - val_accuracy: 0.1001\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.3030 - accuracy: 0.0982 - val_loss: 2.3028 - val_accuracy: 0.1001\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.3028 - accuracy: 0.0987 - val_loss: 2.3028 - val_accuracy: 0.0999\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.3028 - accuracy: 0.0953 - val_loss: 2.3028 - val_accuracy: 0.0998\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.3028 - accuracy: 0.0990 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.3028 - accuracy: 0.0975 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 2.3028 - accuracy: 0.0973 - val_loss: 2.3027 - val_accuracy: 0.0999\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.3028 - accuracy: 0.0989 - val_loss: 2.3028 - val_accuracy: 0.1001\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.3028 - accuracy: 0.0986 - val_loss: 2.3028 - val_accuracy: 0.1001\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.3028 - accuracy: 0.0991 - val_loss: 2.3027 - val_accuracy: 0.0997\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.3028 - accuracy: 0.0978 - val_loss: 2.3027 - val_accuracy: 0.0997\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.3028 - accuracy: 0.0971 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.3028 - accuracy: 0.0987 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.3028 - accuracy: 0.0954 - val_loss: 2.3029 - val_accuracy: 0.1001\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.3028 - accuracy: 0.0976 - val_loss: 2.3027 - val_accuracy: 0.0998\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.3027 - accuracy: 0.0985 - val_loss: 2.3029 - val_accuracy: 0.0997\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.3028 - accuracy: 0.0990 - val_loss: 2.3027 - val_accuracy: 0.0999\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.3028 - accuracy: 0.0981 - val_loss: 2.3027 - val_accuracy: 0.0996\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.3028 - accuracy: 0.0977 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.3028 - accuracy: 0.0988 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 2.3028 - accuracy: 0.0979 - val_loss: 2.3026 - val_accuracy: 0.0999\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.3028 - accuracy: 0.0985 - val_loss: 2.3027 - val_accuracy: 0.0997\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.3028 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.1000\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.3028 - accuracy: 0.0986 - val_loss: 2.3027 - val_accuracy: 0.0999\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.3028 - accuracy: 0.0974 - val_loss: 2.3028 - val_accuracy: 0.0998\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.3028 - accuracy: 0.0985 - val_loss: 2.3027 - val_accuracy: 0.0997\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 2.3028 - accuracy: 0.0986 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
      "SUMMARY OF net_9\n",
      "Training Loss: 2.3027842044830322\n",
      "Training Accuracy: 0.098580002784729\n",
      "Validation Loss: 2.3027830123901367\n",
      "Validation Accuracy: 0.10000000149011612\n",
      "Classification Error Rate: 0.8999999985098839\n",
      "----->Evolution: Child net_9 with fitness 2.3027830123901367 is discarded\n",
      "\n",
      "Creating Child 4\n",
      "----->Tournament selection\n",
      "Selected parent_0 and net_1 for reproduction\n",
      "----->Crossover\n",
      "Child has been created\n",
      "----->Soft Mutation\n",
      "Layer Mutation\n",
      "Splitting Conv2D layer at index 0\n",
      "Parameters Mutation\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  32  to  64\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "Mutating Conv2D layer:\n",
      "-->changed self.filters from  128  to  64\n",
      "Child has been mutated\n",
      "Training net_10\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 16s 8ms/step - loss: 1.8216 - accuracy: 0.3479 - val_loss: 1.7750 - val_accuracy: 0.3645\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6204 - accuracy: 0.4285 - val_loss: 1.6507 - val_accuracy: 0.4232\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6371 - accuracy: 0.4243 - val_loss: 1.5966 - val_accuracy: 0.4324\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6509 - accuracy: 0.4167 - val_loss: 3.2512 - val_accuracy: 0.2540\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6801 - accuracy: 0.4030 - val_loss: 1.6540 - val_accuracy: 0.3984\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6764 - accuracy: 0.4008 - val_loss: 1.7736 - val_accuracy: 0.3607\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7005 - accuracy: 0.3960 - val_loss: 1.8940 - val_accuracy: 0.3266\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.6980 - accuracy: 0.3971 - val_loss: 1.7188 - val_accuracy: 0.3890\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6927 - accuracy: 0.3961 - val_loss: 1.6587 - val_accuracy: 0.4044\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7319 - accuracy: 0.3883 - val_loss: 1.6892 - val_accuracy: 0.3811\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7163 - accuracy: 0.3913 - val_loss: 1.7079 - val_accuracy: 0.3812\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7488 - accuracy: 0.3820 - val_loss: 1.6366 - val_accuracy: 0.3966\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7299 - accuracy: 0.3848 - val_loss: 1.7784 - val_accuracy: 0.3580\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.7307 - accuracy: 0.3769 - val_loss: 2.0369 - val_accuracy: 0.3147\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7952 - accuracy: 0.3519 - val_loss: 1.8118 - val_accuracy: 0.3438\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7689 - accuracy: 0.3667 - val_loss: 1.7809 - val_accuracy: 0.3405\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7442 - accuracy: 0.3592 - val_loss: 1.6851 - val_accuracy: 0.3704\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7629 - accuracy: 0.3513 - val_loss: 1.6870 - val_accuracy: 0.3744\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7360 - accuracy: 0.3577 - val_loss: 1.7003 - val_accuracy: 0.3797\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7487 - accuracy: 0.3469 - val_loss: 2.4883 - val_accuracy: 0.3232\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.9474 - accuracy: 0.3495 - val_loss: 1.7421 - val_accuracy: 0.3450\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7555 - accuracy: 0.3517 - val_loss: 1.7703 - val_accuracy: 0.3496\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.8214 - accuracy: 0.3548 - val_loss: 1.7136 - val_accuracy: 0.3690\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7387 - accuracy: 0.3595 - val_loss: 1.7708 - val_accuracy: 0.3471\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7720 - accuracy: 0.3522 - val_loss: 1.8195 - val_accuracy: 0.3439\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 10s 7ms/step - loss: 1.7659 - accuracy: 0.3499 - val_loss: 1.7190 - val_accuracy: 0.3585\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.7405 - accuracy: 0.3563 - val_loss: 1.6867 - val_accuracy: 0.3743\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 2.4914 - accuracy: 0.3555 - val_loss: 2.0386 - val_accuracy: 0.2912\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.8159 - accuracy: 0.3551 - val_loss: 1.7237 - val_accuracy: 0.3525\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.8239 - accuracy: 0.3446 - val_loss: 1.8503 - val_accuracy: 0.3132\n",
      "SUMMARY OF net_10\n",
      "Training Loss: 1.8238557577133179\n",
      "Training Accuracy: 0.34459999203681946\n",
      "Validation Loss: 1.8503148555755615\n",
      "Validation Accuracy: 0.3131999969482422\n",
      "Classification Error Rate: 0.6868000030517578\n",
      "----->Evolution: Child net_10 with fitness 1.8503148555755615 is discarded\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "Final Population\n",
      "-------------------------------------\n",
      "\n",
      "net_1 :  1.1408569812774658\n",
      "net_3 :  1.4950755834579468\n",
      "net_4 :  1.5639008283615112\n",
      "net_5 :  1.5801719427108765\n",
      "parent_0 :  1.698641061782837\n",
      "net_2 :  1.737733244895935\n",
      "\n",
      "-------------------------------------\n",
      "Stats\n",
      "Best individual at generation 1 has fitness 1.7794898748397827 and parameters 979898\n",
      "Best individual at generation 2 has fitness 1.1408569812774658 and parameters 269082\n",
      "-------------------------------------\n",
      "\n",
      "Epoch 1/15\n",
      "1563/1563 [==============================] - 16s 8ms/step - loss: 1.8001 - accuracy: 0.3482 - val_loss: 1.5289 - val_accuracy: 0.4479\n",
      "Epoch 2/15\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.4093 - accuracy: 0.4957 - val_loss: 1.2739 - val_accuracy: 0.5418\n",
      "Epoch 3/15\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2796 - accuracy: 0.5465 - val_loss: 1.2609 - val_accuracy: 0.5517\n",
      "Epoch 4/15\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2206 - accuracy: 0.5727 - val_loss: 1.2132 - val_accuracy: 0.5674\n",
      "Epoch 5/15\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.1853 - accuracy: 0.5860 - val_loss: 1.2242 - val_accuracy: 0.5940\n",
      "Epoch 6/15\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.1539 - accuracy: 0.5995 - val_loss: 1.2195 - val_accuracy: 0.5848\n",
      "Epoch 7/15\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.1367 - accuracy: 0.6094 - val_loss: 1.2265 - val_accuracy: 0.5832\n",
      "Epoch 8/15\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.1128 - accuracy: 0.6196 - val_loss: 1.2009 - val_accuracy: 0.6076\n",
      "Epoch 9/15\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 1.1162 - accuracy: 0.6186 - val_loss: 1.3587 - val_accuracy: 0.5788\n",
      "Epoch 10/15\n",
      "1563/1563 [==============================] - 14s 9ms/step - loss: 1.1277 - accuracy: 0.6201 - val_loss: 1.1723 - val_accuracy: 0.5976\n",
      "Epoch 11/15\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.1444 - accuracy: 0.6208 - val_loss: 1.1692 - val_accuracy: 0.6294\n",
      "Epoch 12/15\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.1420 - accuracy: 0.6235 - val_loss: 1.3007 - val_accuracy: 0.5668\n",
      "Epoch 13/15\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 1.1263 - accuracy: 0.6294 - val_loss: 1.1415 - val_accuracy: 0.6073\n",
      "Epoch 14/15\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1010 - accuracy: 0.6329 - val_loss: 1.3176 - val_accuracy: 0.5879\n",
      "Epoch 15/15\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 1.1316 - accuracy: 0.6252 - val_loss: 1.0413 - val_accuracy: 0.6431\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "The initial CNN has been evolved successfully in the individual net_1\n",
      "-------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "Summary of initial CNN\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 7200)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               921728    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 933162 (3.56 MB)\n",
      "Trainable params: 933162 (3.56 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fitness of initial CNN: 7.66024923324585\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "Summary of evolved individual\n",
      "Model: \"sequential_57\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_431 (Conv2D)         (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_432 (Conv2D)         (None, 30, 30, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPooli  (None, 15, 15, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_433 (Conv2D)         (None, 13, 13, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_434 (Conv2D)         (None, 13, 13, 128)       36992     \n",
      "                                                                 \n",
      " conv2d_435 (Conv2D)         (None, 13, 13, 16)        18448     \n",
      "                                                                 \n",
      " conv2d_436 (Conv2D)         (None, 7, 7, 256)         37120     \n",
      "                                                                 \n",
      " conv2d_437 (Conv2D)         (None, 7, 7, 32)          73760     \n",
      "                                                                 \n",
      " conv2d_438 (Conv2D)         (None, 7, 7, 32)          9248      \n",
      "                                                                 \n",
      " conv2d_439 (Conv2D)         (None, 5, 5, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_440 (Conv2D)         (None, 5, 5, 32)          18464     \n",
      "                                                                 \n",
      " conv2d_441 (Conv2D)         (None, 3, 3, 32)          9248      \n",
      "                                                                 \n",
      " average_pooling2d_18 (Aver  (None, 2, 2, 32)          0         \n",
      " agePooling2D)                                                   \n",
      "                                                                 \n",
      " flatten_46 (Flatten)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_92 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 269082 (1.03 MB)\n",
      "Trainable params: 269082 (1.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Fitness of the evolved individual: 1.0412864685058594\n",
      "-------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from random import sample\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)      # suppress messages from Tensorflow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "def initialize_population(population_size, dataset):\n",
    "    print(\"----->Initializing Population\")\n",
    "    daddy = compute_parent(dataset)                                 # load parent from input\n",
    "    population = [daddy]\n",
    "    for it in range(1, population_size):\n",
    "        population.append(daddy.asexual_reproduction(it, dataset))\n",
    "\n",
    "    # sort population on ascending order based on fitness\n",
    "    return sorted(population, key=lambda cnn: cnn.fitness)\n",
    "\n",
    "\n",
    "def selection(k, population, num_population):\n",
    "    if k == 0:                                              # elitism selection\n",
    "        print(\"----->Elitism selection\")\n",
    "        return population[0], population[1]\n",
    "    elif k == 1:                                            # tournament selection\n",
    "        print(\"----->Tournament selection\")\n",
    "        i = randint(0, num_population - 1)\n",
    "        j = i\n",
    "        while j < num_population - 1:\n",
    "            j += 1\n",
    "            if randint(1, 100) <= 50:\n",
    "                return population[i], population[j]\n",
    "        return population[i], population[0]\n",
    "    else:                                                   # proportionate selection\n",
    "        print(\"----->Proportionate selection\")\n",
    "        cum_sum = 0\n",
    "        for i in range(num_population):\n",
    "            cum_sum += population[i].fitness\n",
    "        perc_range = []\n",
    "        for i in range(num_population):\n",
    "            count = 100 - int(100 * population[i].fitness / cum_sum)\n",
    "            for j in range(count):\n",
    "                perc_range.append(i)\n",
    "        i, j = sample(range(1, len(perc_range)), 2)\n",
    "        while i == j:\n",
    "            i, j = sample(range(1, len(perc_range)), 2)\n",
    "        return population[perc_range[i]], population[perc_range[j]]\n",
    "\n",
    "\n",
    "def crossover(parent1, parent2, it):\n",
    "    print(\"----->Crossover\")\n",
    "    child = Network(it)\n",
    "\n",
    "    first, second = None, None\n",
    "    if randint(0, 1):\n",
    "        first = parent1\n",
    "        second = parent2\n",
    "    else:\n",
    "        first = parent2\n",
    "        second = parent1\n",
    "\n",
    "    child.block_list = deepcopy(first.block_list[:randint(1, len(first.block_list) - 1)]) \\\n",
    "                       + deepcopy(second.block_list[randint(1, len(second.block_list) - 1):])\n",
    "\n",
    "    order_indexes(child)                            # order the indexes of the blocks\n",
    "\n",
    "    return child\n",
    "\n",
    "\n",
    "def genetic_algorithm(num_population, num_generation, num_offspring, dataset, early_stopping_generations=3):\n",
    "    print(\"Genetic Algorithm\")\n",
    "\n",
    "    population = initialize_population(num_population, dataset)\n",
    "\n",
    "    print(\"\\n-------------------------------------\")\n",
    "    print(\"Initial Population:\")\n",
    "    for cnn in population:\n",
    "        print(cnn.name, ': ', cnn.fitness)\n",
    "    print(\"--------------------------------------\\n\")\n",
    "\n",
    "    # for printing statistics about fitness and the number of parameters of the best individual\n",
    "    stats = [(population[0].fitness, population[0].model.count_params())]\n",
    "\n",
    "    # Initialize a variable to keep track of consecutive generations with the same best fitness\n",
    "    consecutive_same_fitness = 0\n",
    "\n",
    "    for gen in range(1, num_generation + 1):\n",
    "        '''\n",
    "            k is the selection parameter:\n",
    "                k = 0 -> elitism selection\n",
    "                k = 1 -> tournament selection\n",
    "                k = 2 -> proportionate selection\n",
    "        '''\n",
    "        k = randint(0, 2)\n",
    "\n",
    "        print(\"\\n------------------------------------\")\n",
    "        print(\"Generation -----------------------------------------------------------------------------------\", gen)\n",
    "        print(\"-------------------------------------\")\n",
    "\n",
    "        for c in range(num_offspring):\n",
    "\n",
    "            print(\"\\nCreating Child\", c)\n",
    "\n",
    "            parent1, parent2 = selection(k, population, num_population)                 # selection\n",
    "            print(\"Selected\", parent1.name, \"and\", parent2.name, \"for reproduction\")\n",
    "\n",
    "            child = crossover(parent1, parent2, c + num_population)                     # crossover\n",
    "            print(\"Child has been created\")\n",
    "\n",
    "            print(\"----->Soft Mutation\")\n",
    "            child.layer_mutation(dataset)                                               # mutation\n",
    "            child.parameters_mutation()\n",
    "            print(\"Child has been mutated\")\n",
    "\n",
    "            model = child.build_model()                                                 # evaluation\n",
    "\n",
    "            while model == -1:\n",
    "                child = crossover(parent1, parent2, c + num_population)\n",
    "                child.block_mutation(dataset)\n",
    "                child.layer_mutation(dataset)\n",
    "                child.parameters_mutation()\n",
    "                model = child.build_model()\n",
    "\n",
    "            child.train_and_evaluate(model, dataset)\n",
    "\n",
    "            if child.fitness < population[-1].fitness:                                  # evolve population\n",
    "                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"replaces parent \", end=\"\")\n",
    "                print(population[-1].name, \"with fitness\", population[-1].fitness)\n",
    "                name = population[-1].name\n",
    "\n",
    "                child.save_network(\"child_model_info.pkl\", \"child_model.h5\")\n",
    "                population[-1].load_network(\"child_model_info.pkl\", \"child_model.h5\")\n",
    "\n",
    "                population[-1].name = name\n",
    "                population = sorted(population, key=lambda net: net.fitness)\n",
    "            else:\n",
    "                print(\"----->Evolution: Child\", child.name, \"with fitness\", child.fitness, \"is discarded\")\n",
    "        \n",
    "        if gen >= 3 and all(population[i].fitness == population[i + 1].fitness for i in range(-3, -1)):\n",
    "            consecutive_same_fitness += 1\n",
    "            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n",
    "        if consecutive_same_fitness >= 3:\n",
    "            print(\"Stopping the algorithm as the best fitness has remained the same for the last 3 generations.\")\n",
    "            break\n",
    "    else:\n",
    "        consecutive_same_fitness = 0\n",
    "        \n",
    "       #Check if the best fitness has remained the same for the last early_stopping_generations generations\n",
    "        if all(population[i].fitness == population[i + 1].fitness for i in range(-early_stopping_generations, -1)):\n",
    "            consecutive_same_fitness += 1\n",
    "            print(f\"Consecutive generations with the same best fitness: {consecutive_same_fitness}\")\n",
    "            if consecutive_same_fitness == early_stopping_generations:\n",
    "                print(f\"Stopping the algorithm as the best fitness has remained the same for {early_stopping_generations} generations.\")\n",
    "        else:\n",
    "            consecutive_same_fitness = 0\n",
    "        stats.append((population[0].fitness, population[0].model.count_params()))\n",
    "\n",
    "    print(\"\\n\\n-------------------------------------\")\n",
    "    print(\"Final Population\")\n",
    "    print(\"-------------------------------------\\n\")\n",
    "    for cnn in population:\n",
    "        print(cnn.name, ': ', cnn.fitness)\n",
    "\n",
    "    print(\"\\n-------------------------------------\")\n",
    "    print(\"Stats\")\n",
    "    for i in range(len(stats)):\n",
    "        print(\"Best individual at generation\", i + 1, \"has fitness\", stats[i][0], \"and parameters\", stats[i][1])\n",
    "    print(\"-------------------------------------\\n\")\n",
    "\n",
    "    # plot the fitness and the number of parameters of the best individual at each iteration\n",
    "    plot_statistics(stats)\n",
    "\n",
    "    return population[0]\n",
    "\n",
    "\n",
    "\n",
    "def main():    \n",
    "        #with strategy.scope():\n",
    "        #from tensorflow.python.client import device_lib\n",
    "        #print(device_lib.list_local_devices())\n",
    "        #batch_size = 8\n",
    "        #batch_size = batch_size * strategy.num_replicas_in_sync\n",
    "        batch_size = 32                       # the number of training examples in one forward/backward pass\n",
    "        num_classes = 10                        # number of cifar-10 dataset classes\n",
    "        epochs = 30                          # number of forward and backward passes of all the training examples\n",
    "\n",
    "        '''\n",
    "            dataset contains the hyper parameters for loading data and the dataset:\n",
    "                dataset = {\n",
    "                    'batch_size': batch_size,\n",
    "                    'num_classes': num_classes,\n",
    "                    'epochs': epochs,\n",
    "                    'x_train': x_train,\n",
    "                    'x_test': x_test,\n",
    "                    'y_train': y_train,\n",
    "                    'y_test': y_test\n",
    "                }\n",
    "        '''\n",
    "        dataset = load_dataset(batch_size, num_classes, epochs)\n",
    "\n",
    "        num_population = 6\n",
    "        num_generation = 8\n",
    "        num_offspring = 5\n",
    "\n",
    "        # plot the best model obtained\n",
    "        optCNN = genetic_algorithm(num_population, num_generation, num_offspring, dataset)\n",
    "\n",
    "        # plot the training and validation loss and accuracy\n",
    "        num_epoch = 15\n",
    "        model = optCNN.build_model()\n",
    "        model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        history = model.fit(dataset['x_train'],\n",
    "                            dataset['y_train'],\n",
    "                            batch_size=dataset['batch_size'],\n",
    "                            epochs=num_epoch,\n",
    "                            validation_data=(dataset['x_test'], dataset['y_test']),\n",
    "                            shuffle=True)\n",
    "        optCNN.model = model                                        # model\n",
    "        optCNN.fitness = history.history['val_loss'][-1]            # fitness\n",
    "\n",
    "        print(\"\\n\\n-------------------------------------\")\n",
    "        print(\"The initial CNN has been evolved successfully in the individual\", optCNN.name)\n",
    "        print(\"-------------------------------------\\n\")\n",
    "        daddy = load_network('parent_0')\n",
    "        model = tf.keras.models.load_model('parent_0.h5')\n",
    "        print(\"\\n\\n-------------------------------------\")\n",
    "        print(\"Summary of initial CNN\")\n",
    "        print(model.summary())\n",
    "        print(\"Fitness of initial CNN:\", daddy.fitness)\n",
    "\n",
    "        print(\"\\n\\n-------------------------------------\")\n",
    "        print(\"Summary of evolved individual\")\n",
    "        print(optCNN.model.summary())\n",
    "        print(\"Fitness of the evolved individual:\", optCNN.fitness)\n",
    "        print(\"-------------------------------------\\n\")\n",
    "\n",
    "        plot_training(history)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ee57396",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-08T19:39:22.298068Z",
     "iopub.status.busy": "2024-02-08T19:39:22.297692Z",
     "iopub.status.idle": "2024-02-08T19:39:22.304430Z",
     "shell.execute_reply": "2024-02-08T19:39:22.303496Z"
    },
    "papermill": {
     "duration": 18.3755,
     "end_time": "2024-02-08T19:39:22.306338",
     "exception": false,
     "start_time": "2024-02-08T19:39:03.930838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"## To remove a folder\\n# Clear output folder\\nimport os\\n\\ndef remove_folder_contents(folder):\\n    for the_file in os.listdir(folder):\\n        file_path = os.path.join(folder, the_file)\\n        try:\\n            if os.path.isfile(file_path):\\n                os.unlink(file_path)\\n            elif os.path.isdir(file_path):\\n                remove_folder_contents(file_path)\\n                os.rmdir(file_path)\\n        except Exception as e:\\n            print(e)\\n\\nfolder_path = '/kaggle/working'\\nremove_folder_contents(folder_path)\\nos.rmdir(folder_path)\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"## To remove a folder\n",
    "# Clear output folder\n",
    "import os\n",
    "\n",
    "def remove_folder_contents(folder):\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                remove_folder_contents(file_path)\n",
    "                os.rmdir(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "folder_path = '/kaggle/working'\n",
    "remove_folder_contents(folder_path)\n",
    "os.rmdir(folder_path)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4135b0dd",
   "metadata": {
    "papermill": {
     "duration": 18.133199,
     "end_time": "2024-02-08T19:39:58.554886",
     "exception": false,
     "start_time": "2024-02-08T19:39:40.421687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30637,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12991.053901,
   "end_time": "2024-02-08T19:40:20.074131",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-08T16:03:49.020230",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
